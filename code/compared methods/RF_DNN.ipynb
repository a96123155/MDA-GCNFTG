{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    D_SSM1 = np.loadtxt(directory + '/D_SSM1.txt')\n",
    "    D_SSM2 = np.loadtxt(directory + '/D_SSM2.txt')\n",
    "    D_GSM = np.loadtxt(directory + '/D_GSM.txt')\n",
    "    M_FSM = np.loadtxt(directory + '/M_FSM.txt')\n",
    "    M_GSM = np.loadtxt(directory + '/M_GSM.txt')\n",
    "    D_SSM = (D_SSM1 + D_SSM2) / 2\n",
    "\n",
    "    ID = np.zeros(shape=(D_SSM.shape[0], D_SSM.shape[1]))\n",
    "    IM = np.zeros(shape=(M_FSM.shape[0], M_FSM.shape[1]))\n",
    "    for i in range(D_SSM.shape[0]):\n",
    "        for j in range(D_SSM.shape[1]):\n",
    "            if D_SSM[i][j] == 0:\n",
    "                ID[i][j] = D_GSM[i][j]\n",
    "            else:\n",
    "                ID[i][j] = D_SSM[i][j]\n",
    "    for i in range(M_FSM.shape[0]):\n",
    "        for j in range(M_FSM.shape[1]):\n",
    "            if M_FSM[i][j] == 0:\n",
    "                IM[i][j] = M_GSM[i][j]\n",
    "            else:\n",
    "                IM[i][j] = M_FSM[i][j]\n",
    "                \n",
    "    ID = pd.DataFrame(ID).reset_index()\n",
    "    IM = pd.DataFrame(IM).reset_index()\n",
    "    ID.rename(columns = {'index':'id'}, inplace = True)\n",
    "    IM.rename(columns = {'index':'id'}, inplace = True)\n",
    "    ID['id'] = ID['id'] + 1\n",
    "    IM['id'] = IM['id'] + 1\n",
    "    \n",
    "    return ID, IM\n",
    "\n",
    "def sample(directory, random_seed):\n",
    "    all_associations = pd.read_csv(directory + '/all_mirna_disease_pairs.csv', names=['miRNA', 'disease', 'label'])\n",
    "    known_associations = all_associations.loc[all_associations['label'] == 1]\n",
    "    unknown_associations = all_associations.loc[all_associations['label'] == 0]\n",
    "    random_negative = unknown_associations.sample(n=known_associations.shape[0], random_state=random_seed, axis=0)\n",
    "\n",
    "    sample_df = known_associations.append(random_negative)\n",
    "    sample_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performances(y_true, y_pred, y_prob):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel().tolist()\n",
    "\n",
    "    pos_acc = tp / sum(y_true)\n",
    "    neg_acc = tn / (len(y_pred) - sum(y_pred)) # [y_true=0 & y_pred=0] / y_pred=0\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    \n",
    "    recall = tp / (tp+fn)\n",
    "    precision = tp / (tp+fp)\n",
    "    f1 = 2*precision*recall / (precision+recall)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    prec, reca, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr = auc(reca, prec)\n",
    "    \n",
    "    print('tn = {}, fp = {}, fn = {}, tp = {}'.format(tn, fp, fn, tp))\n",
    "    print('y_pred: 0 = {} | 1 = {}'.format(Counter(y_pred)[0], Counter(y_pred)[1]))\n",
    "    print('y_true: 0 = {} | 1 = {}'.format(Counter(y_true)[0], Counter(y_true)[1]))\n",
    "    print('acc={:.4f}|precision={:.4f}|recall={:.4f}|f1={:.4f}|auc={:.4f}|aupr={:.4f}|pos_acc={:.4f}|neg_acc={:.4f}'.format(accuracy, precision, recall, f1, roc_auc, aupr, pos_acc, neg_acc))\n",
    "    return (y_true, y_pred, y_prob), (accuracy, precision, recall, f1, roc_auc, aupr, pos_acc, neg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obtain_data(directory, isbalance):\n",
    "\n",
    "    ID, IM = load_data(directory)\n",
    "\n",
    "    if isbalance:\n",
    "        dtp = sample(directory, random_seed = 1234)\n",
    "    else:\n",
    "        dtp = pd.read_csv(directory + '/all_mirna_disease_pairs.csv', names=['miRNA', 'disease', 'label'])\n",
    "\n",
    "    mirna_ids = list(set(dtp['miRNA']))\n",
    "    disease_ids = list(set(dtp['disease']))\n",
    "    random.shuffle(mirna_ids)\n",
    "    random.shuffle(disease_ids)\n",
    "    print('# miRNA = {} | Disease = {}'.format(len(mirna_ids), len(disease_ids)))\n",
    "\n",
    "    mirna_test_num = int(len(mirna_ids) / 5)\n",
    "    disease_test_num = int(len(disease_ids) / 5)\n",
    "    print('# Test: miRNA = {} | Disease = {}'.format(mirna_test_num, disease_test_num))    \n",
    "    \n",
    "    samples = pd.merge(pd.merge(dtp, ID, left_on = 'disease', right_on = 'id'), IM, left_on = 'miRNA', right_on = 'id')\n",
    "    samples.drop(labels = ['id_x', 'id_y'], axis = 1, inplace = True)\n",
    "    \n",
    "    return ID, IM, dtp, mirna_ids, disease_ids, mirna_test_num, disease_test_num, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_task_Tp_train_test_idx(samples):\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 1234)\n",
    "\n",
    "    train_index_all, test_index_all, n = [], [], 0\n",
    "    train_id_all, test_id_all = [], []\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in tqdm(kf.split(samples.iloc[:, 3:])): #train_index与test_index为下标\n",
    "        print('-------Fold ', fold)\n",
    "        train_index_all.append(train_idx) \n",
    "        test_index_all.append(test_idx)\n",
    "\n",
    "        train_id_all.append(np.array(dtp.iloc[train_idx][['miRNA', 'disease']]))\n",
    "        test_id_all.append(np.array(dtp.iloc[test_idx][['miRNA', 'disease']]))\n",
    "\n",
    "        print('# Pairs: Train = {} | Test = {}'.format(len(train_idx), len(test_idx)))\n",
    "        fold += 1\n",
    "    return train_index_all, test_index_all, train_id_all, test_id_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_task_Tm_Td_train_test_idx(item, ids, dtp):\n",
    "    \n",
    "    test_num = int(len(ids) / 5)\n",
    "    \n",
    "    train_index_all, test_index_all = [], []\n",
    "    train_id_all, test_id_all = [], []\n",
    "    \n",
    "    for fold in range(5):\n",
    "        print('-------Fold ', fold)\n",
    "        if fold != 4:\n",
    "            test_ids = ids[fold * test_num : (fold + 1) * test_num]\n",
    "        else:\n",
    "            test_ids = ids[fold * test_num :]\n",
    "\n",
    "        train_ids = list(set(ids) ^ set(test_ids))\n",
    "        print('# {}: Train = {} | Test = {}'.format(item, len(train_ids), len(test_ids)))\n",
    "\n",
    "        test_idx = dtp[dtp[item].isin(test_ids)].index.tolist()\n",
    "        train_idx = dtp[dtp[item].isin(train_ids)].index.tolist()\n",
    "        random.shuffle(test_idx)\n",
    "        random.shuffle(train_idx)\n",
    "        print('# Pairs: Train = {} | Test = {}'.format(len(train_idx), len(test_idx)))\n",
    "        assert len(train_idx) + len(test_idx) == len(dtp)\n",
    "\n",
    "        train_index_all.append(train_idx) \n",
    "        test_index_all.append(test_idx)\n",
    "        \n",
    "        train_id_all.append(train_ids)\n",
    "        test_id_all.append(test_ids)\n",
    "        \n",
    "    return train_index_all, test_index_all, train_id_all, test_id_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_rf(train_index_all, test_index_all, samples):\n",
    "    \n",
    "    fold = 0\n",
    "    for train_idx, test_idx in zip(train_index_all, test_index_all):\n",
    "        print('-----------------------Fold = ', str(fold))\n",
    "\n",
    "        X = samples.iloc[:, 3:]\n",
    "        y = samples['label']\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler().fit(X.iloc[train_idx,:])\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        x_train, y_train = X[train_idx], y[train_idx]\n",
    "        x_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "        clf = RandomForestClassifier(random_state = 19961231)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        y_train_prob = clf.predict_proba(x_train)\n",
    "        y_test_prob = clf.predict_proba(x_test)\n",
    "\n",
    "        y_train_pred = clf.predict(x_train)\n",
    "        y_test_pred = clf.predict(x_test)\n",
    "\n",
    "        print('Train:')\n",
    "        ys_train, metrics_train = performances(y_train, y_train_pred, y_train_prob[:, 1])\n",
    "        print('Test:')\n",
    "        ys_test, metrics_test = performances(y_test, y_test_pred, y_test_prob[:, 1])\n",
    "\n",
    "        fold += 1\n",
    "    \n",
    "    return ys_train, metrics_train, ys_test, metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import *\n",
    "from keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve, confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    # Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "def transfer(y_pred):\n",
    "    return [[0,1][x>0.5] for x in y_pred.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model(x):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='elu', input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(512, activation='elu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(lr = 0.0001)\n",
    "    model.compile(optimizer = optimizer, loss = binary_crossentropy, metrics=[binary_accuracy, f1, recall, precision])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dnn(train_index_all, test_index_all, samples):\n",
    "    \n",
    "    fold = 0\n",
    "    for train_idx, test_idx in zip(train_index_all, test_index_all):\n",
    "        print('----------------------- Fold = ', str(fold))\n",
    "\n",
    "        X = samples.iloc[:, 3:]\n",
    "        y = samples['label']\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler().fit(X.iloc[train_idx,:])\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        x_train, y_train = X[train_idx], y[train_idx]\n",
    "        x_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "        model = Model(x_train)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience = 50)\n",
    "        model.fit(x_train, y_train, epochs = 500, batch_size = 256, validation_data=(x_test, y_test), callbacks=[early_stopping],verbose = 2)\n",
    "\n",
    "        y_train_pred, y_test_pred = model.predict(x_train, verbose = 0), model.predict(x_test, verbose = 0)\n",
    "        y_train_prob, y_test_prob = model.predict_proba(x_train), model.predict_proba(x_test)\n",
    "\n",
    "        if len(Counter(y_train_pred.reshape(-1))) > 2: \n",
    "            y_train_pred = transfer(y_train_pred)\n",
    "        else:\n",
    "            print(Counter(y_train_pred.reshape(-1)))\n",
    "        if len(Counter(y_test_pred.reshape(-1))) > 2: \n",
    "            y_test_pred = transfer(y_test_pred)\n",
    "        else:\n",
    "            print(Counter(y_test_pred.reshape(-1)))\n",
    "\n",
    "        performances_train = performances(y_train, y_train_pred, y_train_prob)\n",
    "        performances_test = performances(y_test, y_test_pred, y_test_prob)\n",
    "\n",
    "        fold += 1\n",
    "    \n",
    "    return y_train_pred, y_test_pred, y_train_prob, y_test_prob, performances_train, performances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# miRNA = 495 | Disease = 383\n",
      "# Test: miRNA = 99 | Disease = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 171.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== isbalance = True | task = Tp\n",
      "-------Fold  0\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  1\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  2\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  3\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  4\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-----------------------Fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "tn = 4330, fp = 0, fn = 0, tp = 4358\n",
      "y_pred: 0 = 4330 | 1 = 4358\n",
      "y_true: 0 = 4330 | 1 = 4358\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 945, fp = 155, fn = 99, tp = 973\n",
      "y_pred: 0 = 1044 | 1 = 1128\n",
      "y_true: 0 = 1100 | 1 = 1072\n",
      "acc=0.8831|precision=0.8626|recall=0.9076|f1=0.8845|auc=0.9492|aupr=0.9443|pos_acc=0.9076|neg_acc=0.9052\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 4336, fp = 0, fn = 0, tp = 4352\n",
      "y_pred: 0 = 4336 | 1 = 4352\n",
      "y_true: 0 = 4336 | 1 = 4352\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 943, fp = 151, fn = 131, tp = 947\n",
      "y_pred: 0 = 1074 | 1 = 1098\n",
      "y_true: 0 = 1094 | 1 = 1078\n",
      "acc=0.8702|precision=0.8625|recall=0.8785|f1=0.8704|auc=0.9396|aupr=0.9354|pos_acc=0.8785|neg_acc=0.8780\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 4332, fp = 1, fn = 0, tp = 4355\n",
      "y_pred: 0 = 4332 | 1 = 4356\n",
      "y_true: 0 = 4333 | 1 = 4355\n",
      "acc=0.9999|precision=0.9998|recall=1.0000|f1=0.9999|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 934, fp = 163, fn = 131, tp = 944\n",
      "y_pred: 0 = 1065 | 1 = 1107\n",
      "y_true: 0 = 1097 | 1 = 1075\n",
      "acc=0.8646|precision=0.8528|recall=0.8781|f1=0.8653|auc=0.9358|aupr=0.9342|pos_acc=0.8781|neg_acc=0.8770\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 4391, fp = 0, fn = 0, tp = 4297\n",
      "y_pred: 0 = 4391 | 1 = 4297\n",
      "y_true: 0 = 4391 | 1 = 4297\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 889, fp = 150, fn = 142, tp = 991\n",
      "y_pred: 0 = 1031 | 1 = 1141\n",
      "y_true: 0 = 1039 | 1 = 1133\n",
      "acc=0.8656|precision=0.8685|recall=0.8747|f1=0.8716|auc=0.9366|aupr=0.9352|pos_acc=0.8747|neg_acc=0.8623\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 4330, fp = 0, fn = 0, tp = 4358\n",
      "y_pred: 0 = 4330 | 1 = 4358\n",
      "y_true: 0 = 4330 | 1 = 4358\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 959, fp = 141, fn = 152, tp = 920\n",
      "y_pred: 0 = 1111 | 1 = 1061\n",
      "y_true: 0 = 1100 | 1 = 1072\n",
      "acc=0.8651|precision=0.8671|recall=0.8582|f1=0.8626|auc=0.9416|aupr=0.9365|pos_acc=0.8582|neg_acc=0.8632\n",
      "========== isbalance = True | task = Tm\n",
      "-------Fold  0\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8798 | Test = 2062\n",
      "-------Fold  1\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8633 | Test = 2227\n",
      "-------Fold  2\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8523 | Test = 2337\n",
      "-------Fold  3\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8789 | Test = 2071\n",
      "-------Fold  4\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8697 | Test = 2163\n",
      "-----------------------Fold =  0\n",
      "Train:\n",
      "tn = 4337, fp = 0, fn = 0, tp = 4461\n",
      "y_pred: 0 = 4337 | 1 = 4461\n",
      "y_true: 0 = 4337 | 1 = 4461\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 938, fp = 155, fn = 137, tp = 832\n",
      "y_pred: 0 = 1075 | 1 = 987\n",
      "y_true: 0 = 1093 | 1 = 969\n",
      "acc=0.8584|precision=0.8430|recall=0.8586|f1=0.8507|auc=0.9332|aupr=0.9209|pos_acc=0.8586|neg_acc=0.8726\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 4292, fp = 0, fn = 1, tp = 4340\n",
      "y_pred: 0 = 4293 | 1 = 4340\n",
      "y_true: 0 = 4292 | 1 = 4341\n",
      "acc=0.9999|precision=1.0000|recall=0.9998|f1=0.9999|auc=1.0000|aupr=1.0000|pos_acc=0.9998|neg_acc=0.9998\n",
      "Test:\n",
      "tn = 993, fp = 145, fn = 139, tp = 950\n",
      "y_pred: 0 = 1132 | 1 = 1095\n",
      "y_true: 0 = 1138 | 1 = 1089\n",
      "acc=0.8725|precision=0.8676|recall=0.8724|f1=0.8700|auc=0.9439|aupr=0.9351|pos_acc=0.8724|neg_acc=0.8772\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 4331, fp = 1, fn = 0, tp = 4191\n",
      "y_pred: 0 = 4331 | 1 = 4192\n",
      "y_true: 0 = 4332 | 1 = 4191\n",
      "acc=0.9999|precision=0.9998|recall=1.0000|f1=0.9999|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 959, fp = 139, fn = 171, tp = 1068\n",
      "y_pred: 0 = 1130 | 1 = 1207\n",
      "y_true: 0 = 1098 | 1 = 1239\n",
      "acc=0.8674|precision=0.8848|recall=0.8620|f1=0.8733|auc=0.9392|aupr=0.9409|pos_acc=0.8620|neg_acc=0.8487\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 4374, fp = 0, fn = 0, tp = 4415\n",
      "y_pred: 0 = 4374 | 1 = 4415\n",
      "y_true: 0 = 4374 | 1 = 4415\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 892, fp = 164, fn = 129, tp = 886\n",
      "y_pred: 0 = 1021 | 1 = 1050\n",
      "y_true: 0 = 1056 | 1 = 1015\n",
      "acc=0.8585|precision=0.8438|recall=0.8729|f1=0.8581|auc=0.9282|aupr=0.9166|pos_acc=0.8729|neg_acc=0.8737\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 4385, fp = 0, fn = 0, tp = 4312\n",
      "y_pred: 0 = 4385 | 1 = 4312\n",
      "y_true: 0 = 4385 | 1 = 4312\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 886, fp = 159, fn = 120, tp = 998\n",
      "y_pred: 0 = 1006 | 1 = 1157\n",
      "y_true: 0 = 1045 | 1 = 1118\n",
      "acc=0.8710|precision=0.8626|recall=0.8927|f1=0.8774|auc=0.9442|aupr=0.9443|pos_acc=0.8927|neg_acc=0.8807\n",
      "========== isbalance = True | task = Td\n",
      "-------Fold  0\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8889 | Test = 1971\n",
      "-------Fold  1\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8579 | Test = 2281\n",
      "-------Fold  2\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8681 | Test = 2179\n",
      "-------Fold  3\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8965 | Test = 1895\n",
      "-------Fold  4\n",
      "# disease: Train = 304 | Test = 79\n",
      "# Pairs: Train = 8326 | Test = 2534\n",
      "-----------------------Fold =  0\n",
      "Train:\n",
      "tn = 4396, fp = 0, fn = 0, tp = 4493\n",
      "y_pred: 0 = 4396 | 1 = 4493\n",
      "y_true: 0 = 4396 | 1 = 4493\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 910, fp = 124, fn = 119, tp = 818\n",
      "y_pred: 0 = 1029 | 1 = 942\n",
      "y_true: 0 = 1034 | 1 = 937\n",
      "acc=0.8767|precision=0.8684|recall=0.8730|f1=0.8707|auc=0.9485|aupr=0.9406|pos_acc=0.8730|neg_acc=0.8844\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 4310, fp = 0, fn = 1, tp = 4268\n",
      "y_pred: 0 = 4311 | 1 = 4268\n",
      "y_true: 0 = 4310 | 1 = 4269\n",
      "acc=0.9999|precision=1.0000|recall=0.9998|f1=0.9999|auc=1.0000|aupr=1.0000|pos_acc=0.9998|neg_acc=0.9998\n",
      "Test:\n",
      "tn = 935, fp = 185, fn = 118, tp = 1043\n",
      "y_pred: 0 = 1053 | 1 = 1228\n",
      "y_true: 0 = 1120 | 1 = 1161\n",
      "acc=0.8672|precision=0.8493|recall=0.8984|f1=0.8732|auc=0.9381|aupr=0.9343|pos_acc=0.8984|neg_acc=0.8879\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 4352, fp = 0, fn = 0, tp = 4329\n",
      "y_pred: 0 = 4352 | 1 = 4329\n",
      "y_true: 0 = 4352 | 1 = 4329\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 922, fp = 156, fn = 133, tp = 968\n",
      "y_pred: 0 = 1055 | 1 = 1124\n",
      "y_true: 0 = 1078 | 1 = 1101\n",
      "acc=0.8674|precision=0.8612|recall=0.8792|f1=0.8701|auc=0.9384|aupr=0.9378|pos_acc=0.8792|neg_acc=0.8739\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 4421, fp = 0, fn = 0, tp = 4544\n",
      "y_pred: 0 = 4421 | 1 = 4544\n",
      "y_true: 0 = 4421 | 1 = 4544\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 888, fp = 121, fn = 120, tp = 766\n",
      "y_pred: 0 = 1008 | 1 = 887\n",
      "y_true: 0 = 1009 | 1 = 886\n",
      "acc=0.8728|precision=0.8636|recall=0.8646|f1=0.8641|auc=0.9373|aupr=0.9257|pos_acc=0.8646|neg_acc=0.8810\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 4241, fp = 0, fn = 0, tp = 4085\n",
      "y_pred: 0 = 4241 | 1 = 4085\n",
      "y_true: 0 = 4241 | 1 = 4085\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 1021, fp = 168, fn = 179, tp = 1166\n",
      "y_pred: 0 = 1200 | 1 = 1334\n",
      "y_true: 0 = 1189 | 1 = 1345\n",
      "acc=0.8631|precision=0.8741|recall=0.8669|f1=0.8705|auc=0.9405|aupr=0.9444|pos_acc=0.8669|neg_acc=0.8508\n",
      "# miRNA = 495 | Disease = 383\n",
      "# Test: miRNA = 99 | Disease = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 36.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== isbalance = False | task = Tp\n",
      "-------Fold  0\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  1\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  2\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  3\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  4\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-----------------------Fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "tn = 147293, fp = 0, fn = 4, tp = 4371\n",
      "y_pred: 0 = 147297 | 1 = 4371\n",
      "y_true: 0 = 147293 | 1 = 4375\n",
      "acc=1.0000|precision=1.0000|recall=0.9991|f1=0.9995|auc=1.0000|aupr=1.0000|pos_acc=0.9991|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36717, fp = 145, fn = 694, tp = 361\n",
      "y_pred: 0 = 37411 | 1 = 506\n",
      "y_true: 0 = 36862 | 1 = 1055\n",
      "acc=0.9779|precision=0.7134|recall=0.3422|f1=0.4625|auc=0.9379|aupr=0.5403|pos_acc=0.3422|neg_acc=0.9814\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 147266, fp = 0, fn = 5, tp = 4397\n",
      "y_pred: 0 = 147271 | 1 = 4397\n",
      "y_true: 0 = 147266 | 1 = 4402\n",
      "acc=1.0000|precision=1.0000|recall=0.9989|f1=0.9994|auc=1.0000|aupr=1.0000|pos_acc=0.9989|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36726, fp = 163, fn = 637, tp = 391\n",
      "y_pred: 0 = 37363 | 1 = 554\n",
      "y_true: 0 = 36889 | 1 = 1028\n",
      "acc=0.9789|precision=0.7058|recall=0.3804|f1=0.4943|auc=0.9366|aupr=0.5652|pos_acc=0.3804|neg_acc=0.9830\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 147357, fp = 0, fn = 1, tp = 4310\n",
      "y_pred: 0 = 147358 | 1 = 4310\n",
      "y_true: 0 = 147357 | 1 = 4311\n",
      "acc=1.0000|precision=1.0000|recall=0.9998|f1=0.9999|auc=1.0000|aupr=1.0000|pos_acc=0.9998|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36648, fp = 150, fn = 720, tp = 399\n",
      "y_pred: 0 = 37368 | 1 = 549\n",
      "y_true: 0 = 36798 | 1 = 1119\n",
      "acc=0.9771|precision=0.7268|recall=0.3566|f1=0.4784|auc=0.9377|aupr=0.5462|pos_acc=0.3566|neg_acc=0.9807\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 147363, fp = 0, fn = 4, tp = 4301\n",
      "y_pred: 0 = 147367 | 1 = 4301\n",
      "y_true: 0 = 147363 | 1 = 4305\n",
      "acc=1.0000|precision=1.0000|recall=0.9991|f1=0.9995|auc=1.0000|aupr=1.0000|pos_acc=0.9991|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36652, fp = 140, fn = 755, tp = 370\n",
      "y_pred: 0 = 37407 | 1 = 510\n",
      "y_true: 0 = 36792 | 1 = 1125\n",
      "acc=0.9764|precision=0.7255|recall=0.3289|f1=0.4526|auc=0.9338|aupr=0.5567|pos_acc=0.3289|neg_acc=0.9798\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 147341, fp = 0, fn = 3, tp = 4324\n",
      "y_pred: 0 = 147344 | 1 = 4324\n",
      "y_true: 0 = 147341 | 1 = 4327\n",
      "acc=1.0000|precision=1.0000|recall=0.9993|f1=0.9997|auc=1.0000|aupr=1.0000|pos_acc=0.9993|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36666, fp = 148, fn = 684, tp = 419\n",
      "y_pred: 0 = 37350 | 1 = 567\n",
      "y_true: 0 = 36814 | 1 = 1103\n",
      "acc=0.9781|precision=0.7390|recall=0.3799|f1=0.5018|auc=0.9379|aupr=0.5769|pos_acc=0.3799|neg_acc=0.9817\n",
      "========== isbalance = False | task = Tm\n",
      "-------Fold  0\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  1\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  2\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  3\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  4\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-----------------------Fold =  0\n",
      "Train:\n",
      "tn = 147319, fp = 0, fn = 0, tp = 4349\n",
      "y_pred: 0 = 147319 | 1 = 4349\n",
      "y_true: 0 = 147319 | 1 = 4349\n",
      "acc=1.0000|precision=1.0000|recall=1.0000|f1=1.0000|auc=1.0000|aupr=1.0000|pos_acc=1.0000|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36714, fp = 122, fn = 722, tp = 359\n",
      "y_pred: 0 = 37436 | 1 = 481\n",
      "y_true: 0 = 36836 | 1 = 1081\n",
      "acc=0.9777|precision=0.7464|recall=0.3321|f1=0.4597|auc=0.9257|aupr=0.5422|pos_acc=0.3321|neg_acc=0.9807\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 147360, fp = 0, fn = 2, tp = 4306\n",
      "y_pred: 0 = 147362 | 1 = 4306\n",
      "y_true: 0 = 147360 | 1 = 4308\n",
      "acc=1.0000|precision=1.0000|recall=0.9995|f1=0.9998|auc=1.0000|aupr=1.0000|pos_acc=0.9995|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36608, fp = 187, fn = 663, tp = 459\n",
      "y_pred: 0 = 37271 | 1 = 646\n",
      "y_true: 0 = 36795 | 1 = 1122\n",
      "acc=0.9776|precision=0.7105|recall=0.4091|f1=0.5192|auc=0.9411|aupr=0.5597|pos_acc=0.4091|neg_acc=0.9822\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 147110, fp = 0, fn = 2, tp = 4556\n",
      "y_pred: 0 = 147112 | 1 = 4556\n",
      "y_true: 0 = 147110 | 1 = 4558\n",
      "acc=1.0000|precision=1.0000|recall=0.9996|f1=0.9998|auc=1.0000|aupr=1.0000|pos_acc=0.9996|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36932, fp = 113, fn = 541, tp = 331\n",
      "y_pred: 0 = 37473 | 1 = 444\n",
      "y_true: 0 = 37045 | 1 = 872\n",
      "acc=0.9828|precision=0.7455|recall=0.3796|f1=0.5030|auc=0.9249|aupr=0.5525|pos_acc=0.3796|neg_acc=0.9856\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 147476, fp = 0, fn = 5, tp = 4187\n",
      "y_pred: 0 = 147481 | 1 = 4187\n",
      "y_true: 0 = 147476 | 1 = 4192\n",
      "acc=1.0000|precision=1.0000|recall=0.9988|f1=0.9994|auc=1.0000|aupr=1.0000|pos_acc=0.9988|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36526, fp = 153, fn = 787, tp = 451\n",
      "y_pred: 0 = 37313 | 1 = 604\n",
      "y_true: 0 = 36679 | 1 = 1238\n",
      "acc=0.9752|precision=0.7467|recall=0.3643|f1=0.4897|auc=0.9265|aupr=0.5579|pos_acc=0.3643|neg_acc=0.9789\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 147355, fp = 0, fn = 2, tp = 4311\n",
      "y_pred: 0 = 147357 | 1 = 4311\n",
      "y_true: 0 = 147355 | 1 = 4313\n",
      "acc=1.0000|precision=1.0000|recall=0.9995|f1=0.9998|auc=1.0000|aupr=1.0000|pos_acc=0.9995|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36669, fp = 131, fn = 710, tp = 407\n",
      "y_pred: 0 = 37379 | 1 = 538\n",
      "y_true: 0 = 36800 | 1 = 1117\n",
      "acc=0.9778|precision=0.7565|recall=0.3644|f1=0.4918|auc=0.9281|aupr=0.5684|pos_acc=0.3644|neg_acc=0.9810\n",
      "========== isbalance = False | task = Td\n",
      "-------Fold  0\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  1\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  2\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  3\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  4\n",
      "# disease: Train = 304 | Test = 79\n",
      "# Pairs: Train = 150480 | Test = 39105\n",
      "-----------------------Fold =  0\n",
      "Train:\n",
      "tn = 147587, fp = 0, fn = 2, tp = 4376\n",
      "y_pred: 0 = 147589 | 1 = 4376\n",
      "y_true: 0 = 147587 | 1 = 4378\n",
      "acc=1.0000|precision=1.0000|recall=0.9995|f1=0.9998|auc=1.0000|aupr=1.0000|pos_acc=0.9995|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36378, fp = 190, fn = 799, tp = 253\n",
      "y_pred: 0 = 37177 | 1 = 443\n",
      "y_true: 0 = 36568 | 1 = 1052\n",
      "acc=0.9737|precision=0.5711|recall=0.2405|f1=0.3385|auc=0.8983|aupr=0.3841|pos_acc=0.2405|neg_acc=0.9785\n",
      "-----------------------Fold =  1\n",
      "Train:\n",
      "tn = 147798, fp = 0, fn = 4, tp = 4163\n",
      "y_pred: 0 = 147802 | 1 = 4163\n",
      "y_true: 0 = 147798 | 1 = 4167\n",
      "acc=1.0000|precision=1.0000|recall=0.9990|f1=0.9995|auc=1.0000|aupr=1.0000|pos_acc=0.9990|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 35998, fp = 359, fn = 869, tp = 394\n",
      "y_pred: 0 = 36867 | 1 = 753\n",
      "y_true: 0 = 36357 | 1 = 1263\n",
      "acc=0.9674|precision=0.5232|recall=0.3120|f1=0.3909|auc=0.8863|aupr=0.4062|pos_acc=0.3120|neg_acc=0.9764\n",
      "-----------------------Fold =  2\n",
      "Train:\n",
      "tn = 147352, fp = 0, fn = 3, tp = 4610\n",
      "y_pred: 0 = 147355 | 1 = 4610\n",
      "y_true: 0 = 147352 | 1 = 4613\n",
      "acc=1.0000|precision=1.0000|recall=0.9993|f1=0.9997|auc=1.0000|aupr=1.0000|pos_acc=0.9993|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36678, fp = 125, fn = 663, tp = 154\n",
      "y_pred: 0 = 37341 | 1 = 279\n",
      "y_true: 0 = 36803 | 1 = 817\n",
      "acc=0.9791|precision=0.5520|recall=0.1885|f1=0.2810|auc=0.8902|aupr=0.3245|pos_acc=0.1885|neg_acc=0.9822\n",
      "-----------------------Fold =  3\n",
      "Train:\n",
      "tn = 147832, fp = 0, fn = 2, tp = 4131\n",
      "y_pred: 0 = 147834 | 1 = 4131\n",
      "y_true: 0 = 147832 | 1 = 4133\n",
      "acc=1.0000|precision=1.0000|recall=0.9995|f1=0.9998|auc=1.0000|aupr=1.0000|pos_acc=0.9995|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 36048, fp = 275, fn = 853, tp = 444\n",
      "y_pred: 0 = 36901 | 1 = 719\n",
      "y_true: 0 = 36323 | 1 = 1297\n",
      "acc=0.9700|precision=0.6175|recall=0.3423|f1=0.4405|auc=0.9111|aupr=0.4694|pos_acc=0.3423|neg_acc=0.9769\n",
      "-----------------------Fold =  4\n",
      "Train:\n",
      "tn = 146051, fp = 0, fn = 3, tp = 4426\n",
      "y_pred: 0 = 146054 | 1 = 4426\n",
      "y_true: 0 = 146051 | 1 = 4429\n",
      "acc=1.0000|precision=1.0000|recall=0.9993|f1=0.9997|auc=1.0000|aupr=1.0000|pos_acc=0.9993|neg_acc=1.0000\n",
      "Test:\n",
      "tn = 37924, fp = 180, fn = 700, tp = 301\n",
      "y_pred: 0 = 38624 | 1 = 481\n",
      "y_true: 0 = 38104 | 1 = 1001\n",
      "acc=0.9775|precision=0.6258|recall=0.3007|f1=0.4062|auc=0.9278|aupr=0.4615|pos_acc=0.3007|neg_acc=0.9819\n"
     ]
    }
   ],
   "source": [
    "directory = 'data'\n",
    "for isbalance in [True, False]:\n",
    "    \n",
    "    ID, IM, dtp, mirna_ids, disease_ids, mirna_test_num, disease_test_num, samples = obtain_data(directory, \n",
    "                                                                                                 isbalance)\n",
    "    for task in ['Tp', 'Tm', 'Td']:\n",
    "        \n",
    "        print('========== isbalance = {} | task = {}'.format(isbalance, task))\n",
    "        \n",
    "        if task == 'Tp':\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tp_train_test_idx(samples)\n",
    "            \n",
    "        elif task == 'Tm':\n",
    "            item = 'miRNA'\n",
    "            ids = mirna_ids\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tm_Td_train_test_idx(item, ids, dtp)\n",
    "\n",
    "        elif task == 'Td':\n",
    "            item = 'disease'\n",
    "            ids = disease_ids\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tm_Td_train_test_idx(item, ids, dtp)\n",
    "\n",
    "        ys_train, metrics_train, ys_test, metrics_test = run_rf(train_index_all, test_index_all, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# miRNA = 495 | Disease = 383\n",
      "# Test: miRNA = 99 | Disease = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 213.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== isbalance = True | task = Tp\n",
      "-------Fold  0\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  1\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  2\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  3\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "-------Fold  4\n",
      "# Pairs: Train = 8688 | Test = 2172\n",
      "----------------------- Fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8688 samples, validate on 2172 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4125 - binary_accuracy: 0.8100 - f1: 0.7776 - recall: 0.7638 - precision: 0.8488 - val_loss: 0.3206 - val_binary_accuracy: 0.8600 - val_f1: 0.8108 - val_recall: 0.7966 - val_precision: 0.8450\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3525 - binary_accuracy: 0.8460 - f1: 0.8458 - recall: 0.8473 - precision: 0.8463 - val_loss: 0.3122 - val_binary_accuracy: 0.8610 - val_f1: 0.8182 - val_recall: 0.8334 - val_precision: 0.8121\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3486 - binary_accuracy: 0.8452 - f1: 0.8443 - recall: 0.8431 - precision: 0.8485 - val_loss: 0.3090 - val_binary_accuracy: 0.8633 - val_f1: 0.8153 - val_recall: 0.8172 - val_precision: 0.8273\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3412 - binary_accuracy: 0.8491 - f1: 0.8490 - recall: 0.8511 - precision: 0.8489 - val_loss: 0.3127 - val_binary_accuracy: 0.8559 - val_f1: 0.8174 - val_recall: 0.8441 - val_precision: 0.8003\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3433 - binary_accuracy: 0.8507 - f1: 0.8508 - recall: 0.8563 - precision: 0.8493 - val_loss: 0.3041 - val_binary_accuracy: 0.8669 - val_f1: 0.8091 - val_recall: 0.7931 - val_precision: 0.8564\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3383 - binary_accuracy: 0.8478 - f1: 0.8491 - recall: 0.8518 - precision: 0.8481 - val_loss: 0.3129 - val_binary_accuracy: 0.8642 - val_f1: 0.8018 - val_recall: 0.8229 - val_precision: 0.8221\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3347 - binary_accuracy: 0.8515 - f1: 0.8522 - recall: 0.8546 - precision: 0.8522 - val_loss: 0.3231 - val_binary_accuracy: 0.8591 - val_f1: 0.8375 - val_recall: 0.9042 - val_precision: 0.7854\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3311 - binary_accuracy: 0.8560 - f1: 0.8568 - recall: 0.8638 - precision: 0.8521 - val_loss: 0.2987 - val_binary_accuracy: 0.8734 - val_f1: 0.8208 - val_recall: 0.8209 - val_precision: 0.8508\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3313 - binary_accuracy: 0.8536 - f1: 0.8535 - recall: 0.8561 - precision: 0.8535 - val_loss: 0.3105 - val_binary_accuracy: 0.8582 - val_f1: 0.7595 - val_recall: 0.7235 - val_precision: 0.8664\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3294 - binary_accuracy: 0.8546 - f1: 0.8550 - recall: 0.8600 - precision: 0.8524 - val_loss: 0.3018 - val_binary_accuracy: 0.8656 - val_f1: 0.7870 - val_recall: 0.7580 - val_precision: 0.8698\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3247 - binary_accuracy: 0.8587 - f1: 0.8595 - recall: 0.8640 - precision: 0.8564 - val_loss: 0.2973 - val_binary_accuracy: 0.8683 - val_f1: 0.8305 - val_recall: 0.8414 - val_precision: 0.8296\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3233 - binary_accuracy: 0.8595 - f1: 0.8594 - recall: 0.8612 - precision: 0.8592 - val_loss: 0.2976 - val_binary_accuracy: 0.8762 - val_f1: 0.8208 - val_recall: 0.8131 - val_precision: 0.8595\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3252 - binary_accuracy: 0.8562 - f1: 0.8567 - recall: 0.8634 - precision: 0.8521 - val_loss: 0.2956 - val_binary_accuracy: 0.8702 - val_f1: 0.8239 - val_recall: 0.8051 - val_precision: 0.8629\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3237 - binary_accuracy: 0.8566 - f1: 0.8575 - recall: 0.8632 - precision: 0.8547 - val_loss: 0.3062 - val_binary_accuracy: 0.8683 - val_f1: 0.8419 - val_recall: 0.8911 - val_precision: 0.8035\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3236 - binary_accuracy: 0.8603 - f1: 0.8603 - recall: 0.8617 - precision: 0.8624 - val_loss: 0.3086 - val_binary_accuracy: 0.8582 - val_f1: 0.7611 - val_recall: 0.7325 - val_precision: 0.8568\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3198 - binary_accuracy: 0.8606 - f1: 0.8610 - recall: 0.8662 - precision: 0.8576 - val_loss: 0.2921 - val_binary_accuracy: 0.8738 - val_f1: 0.8325 - val_recall: 0.8346 - val_precision: 0.8494\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3185 - binary_accuracy: 0.8610 - f1: 0.8612 - recall: 0.8628 - precision: 0.8625 - val_loss: 0.3125 - val_binary_accuracy: 0.8688 - val_f1: 0.8434 - val_recall: 0.9008 - val_precision: 0.7999\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3158 - binary_accuracy: 0.8605 - f1: 0.8615 - recall: 0.8663 - precision: 0.8583 - val_loss: 0.2915 - val_binary_accuracy: 0.8757 - val_f1: 0.8339 - val_recall: 0.8418 - val_precision: 0.8459\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3164 - binary_accuracy: 0.8620 - f1: 0.8628 - recall: 0.8692 - precision: 0.8586 - val_loss: 0.3049 - val_binary_accuracy: 0.8637 - val_f1: 0.8047 - val_recall: 0.7528 - val_precision: 0.8907\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3172 - binary_accuracy: 0.8598 - f1: 0.8594 - recall: 0.8583 - precision: 0.8631 - val_loss: 0.2898 - val_binary_accuracy: 0.8752 - val_f1: 0.8385 - val_recall: 0.8377 - val_precision: 0.8531\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3111 - binary_accuracy: 0.8658 - f1: 0.8656 - recall: 0.8649 - precision: 0.8674 - val_loss: 0.2882 - val_binary_accuracy: 0.8738 - val_f1: 0.8366 - val_recall: 0.8339 - val_precision: 0.8479\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3118 - binary_accuracy: 0.8638 - f1: 0.8639 - recall: 0.8655 - precision: 0.8637 - val_loss: 0.3049 - val_binary_accuracy: 0.8651 - val_f1: 0.8402 - val_recall: 0.8944 - val_precision: 0.7980\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3170 - binary_accuracy: 0.8644 - f1: 0.8653 - recall: 0.8702 - precision: 0.8640 - val_loss: 0.3029 - val_binary_accuracy: 0.8637 - val_f1: 0.8251 - val_recall: 0.7887 - val_precision: 0.8779\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3125 - binary_accuracy: 0.8620 - f1: 0.8606 - recall: 0.8587 - precision: 0.8655 - val_loss: 0.2913 - val_binary_accuracy: 0.8725 - val_f1: 0.8183 - val_recall: 0.7939 - val_precision: 0.8712\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3143 - binary_accuracy: 0.8625 - f1: 0.8630 - recall: 0.8671 - precision: 0.8615 - val_loss: 0.2877 - val_binary_accuracy: 0.8762 - val_f1: 0.8295 - val_recall: 0.8100 - val_precision: 0.8693\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3065 - binary_accuracy: 0.8689 - f1: 0.8700 - recall: 0.8763 - precision: 0.8654 - val_loss: 0.2954 - val_binary_accuracy: 0.8715 - val_f1: 0.8365 - val_recall: 0.8605 - val_precision: 0.8227\n",
      "Epoch 27/500\n",
      "0s - loss: 0.3082 - binary_accuracy: 0.8636 - f1: 0.8640 - recall: 0.8662 - precision: 0.8637 - val_loss: 0.2924 - val_binary_accuracy: 0.8752 - val_f1: 0.8398 - val_recall: 0.8415 - val_precision: 0.8518\n",
      "Epoch 28/500\n",
      "0s - loss: 0.3075 - binary_accuracy: 0.8666 - f1: 0.8666 - recall: 0.8704 - precision: 0.8659 - val_loss: 0.2907 - val_binary_accuracy: 0.8752 - val_f1: 0.8294 - val_recall: 0.8107 - val_precision: 0.8597\n",
      "Epoch 29/500\n",
      "0s - loss: 0.3049 - binary_accuracy: 0.8668 - f1: 0.8667 - recall: 0.8663 - precision: 0.8692 - val_loss: 0.2911 - val_binary_accuracy: 0.8711 - val_f1: 0.8362 - val_recall: 0.8617 - val_precision: 0.8216\n",
      "Epoch 30/500\n",
      "0s - loss: 0.3035 - binary_accuracy: 0.8663 - f1: 0.8663 - recall: 0.8682 - precision: 0.8658 - val_loss: 0.2892 - val_binary_accuracy: 0.8711 - val_f1: 0.8312 - val_recall: 0.8471 - val_precision: 0.8245\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2988 - binary_accuracy: 0.8694 - f1: 0.8689 - recall: 0.8701 - precision: 0.8693 - val_loss: 0.2931 - val_binary_accuracy: 0.8711 - val_f1: 0.8173 - val_recall: 0.7993 - val_precision: 0.8669\n",
      "Epoch 32/500\n",
      "0s - loss: 0.3059 - binary_accuracy: 0.8682 - f1: 0.8683 - recall: 0.8718 - precision: 0.8682 - val_loss: 0.2945 - val_binary_accuracy: 0.8729 - val_f1: 0.8195 - val_recall: 0.8198 - val_precision: 0.8498\n",
      "Epoch 33/500\n",
      "0s - loss: 0.3025 - binary_accuracy: 0.8727 - f1: 0.8726 - recall: 0.8759 - precision: 0.8728 - val_loss: 0.3003 - val_binary_accuracy: 0.8669 - val_f1: 0.8397 - val_recall: 0.8708 - val_precision: 0.8173\n",
      "Epoch 34/500\n",
      "0s - loss: 0.3014 - binary_accuracy: 0.8673 - f1: 0.8674 - recall: 0.8683 - precision: 0.8689 - val_loss: 0.2880 - val_binary_accuracy: 0.8752 - val_f1: 0.8300 - val_recall: 0.8137 - val_precision: 0.8662\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2960 - binary_accuracy: 0.8699 - f1: 0.8701 - recall: 0.8724 - precision: 0.8697 - val_loss: 0.2878 - val_binary_accuracy: 0.8711 - val_f1: 0.8332 - val_recall: 0.8176 - val_precision: 0.8567\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2971 - binary_accuracy: 0.8703 - f1: 0.8706 - recall: 0.8706 - precision: 0.8726 - val_loss: 0.2918 - val_binary_accuracy: 0.8748 - val_f1: 0.8330 - val_recall: 0.8392 - val_precision: 0.8474\n",
      "Epoch 37/500\n",
      "0s - loss: 0.3011 - binary_accuracy: 0.8676 - f1: 0.8671 - recall: 0.8688 - precision: 0.8698 - val_loss: 0.2963 - val_binary_accuracy: 0.8702 - val_f1: 0.7997 - val_recall: 0.7605 - val_precision: 0.8865\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2962 - binary_accuracy: 0.8725 - f1: 0.8732 - recall: 0.8779 - precision: 0.8704 - val_loss: 0.2980 - val_binary_accuracy: 0.8715 - val_f1: 0.8429 - val_recall: 0.8674 - val_precision: 0.8249\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2920 - binary_accuracy: 0.8735 - f1: 0.8737 - recall: 0.8751 - precision: 0.8734 - val_loss: 0.2858 - val_binary_accuracy: 0.8748 - val_f1: 0.8316 - val_recall: 0.8224 - val_precision: 0.8591\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2908 - binary_accuracy: 0.8709 - f1: 0.8712 - recall: 0.8750 - precision: 0.8685 - val_loss: 0.2881 - val_binary_accuracy: 0.8702 - val_f1: 0.8186 - val_recall: 0.7938 - val_precision: 0.8655\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2844 - binary_accuracy: 0.8762 - f1: 0.8761 - recall: 0.8766 - precision: 0.8773 - val_loss: 0.2856 - val_binary_accuracy: 0.8743 - val_f1: 0.8375 - val_recall: 0.8351 - val_precision: 0.8536\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2850 - binary_accuracy: 0.8759 - f1: 0.8767 - recall: 0.8814 - precision: 0.8740 - val_loss: 0.2901 - val_binary_accuracy: 0.8766 - val_f1: 0.8339 - val_recall: 0.8339 - val_precision: 0.8536\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8767 - f1: 0.8772 - recall: 0.8807 - precision: 0.8750 - val_loss: 0.2966 - val_binary_accuracy: 0.8637 - val_f1: 0.8214 - val_recall: 0.8244 - val_precision: 0.8389\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2844 - binary_accuracy: 0.8758 - f1: 0.8760 - recall: 0.8789 - precision: 0.8752 - val_loss: 0.2935 - val_binary_accuracy: 0.8660 - val_f1: 0.8193 - val_recall: 0.7948 - val_precision: 0.8658\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8764 - f1: 0.8762 - recall: 0.8793 - precision: 0.8750 - val_loss: 0.2882 - val_binary_accuracy: 0.8711 - val_f1: 0.8237 - val_recall: 0.8004 - val_precision: 0.8678\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2779 - binary_accuracy: 0.8787 - f1: 0.8794 - recall: 0.8837 - precision: 0.8764 - val_loss: 0.2923 - val_binary_accuracy: 0.8720 - val_f1: 0.8399 - val_recall: 0.8582 - val_precision: 0.8287\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8789 - f1: 0.8793 - recall: 0.8831 - precision: 0.8781 - val_loss: 0.2891 - val_binary_accuracy: 0.8674 - val_f1: 0.8055 - val_recall: 0.7709 - val_precision: 0.8731\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2827 - binary_accuracy: 0.8780 - f1: 0.8778 - recall: 0.8813 - precision: 0.8764 - val_loss: 0.3105 - val_binary_accuracy: 0.8646 - val_f1: 0.8376 - val_recall: 0.8879 - val_precision: 0.8056\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2821 - binary_accuracy: 0.8791 - f1: 0.8794 - recall: 0.8831 - precision: 0.8775 - val_loss: 0.3006 - val_binary_accuracy: 0.8688 - val_f1: 0.8164 - val_recall: 0.8342 - val_precision: 0.8258\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2767 - binary_accuracy: 0.8793 - f1: 0.8798 - recall: 0.8861 - precision: 0.8753 - val_loss: 0.2888 - val_binary_accuracy: 0.8697 - val_f1: 0.8303 - val_recall: 0.8452 - val_precision: 0.8242\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2794 - binary_accuracy: 0.8811 - f1: 0.8809 - recall: 0.8849 - precision: 0.8798 - val_loss: 0.2954 - val_binary_accuracy: 0.8692 - val_f1: 0.8354 - val_recall: 0.8635 - val_precision: 0.8159\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2834 - binary_accuracy: 0.8768 - f1: 0.8771 - recall: 0.8787 - precision: 0.8793 - val_loss: 0.2883 - val_binary_accuracy: 0.8734 - val_f1: 0.8253 - val_recall: 0.8101 - val_precision: 0.8522\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2708 - binary_accuracy: 0.8834 - f1: 0.8838 - recall: 0.8895 - precision: 0.8798 - val_loss: 0.2890 - val_binary_accuracy: 0.8669 - val_f1: 0.8165 - val_recall: 0.8055 - val_precision: 0.8472\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2712 - binary_accuracy: 0.8832 - f1: 0.8837 - recall: 0.8873 - precision: 0.8823 - val_loss: 0.2871 - val_binary_accuracy: 0.8725 - val_f1: 0.8336 - val_recall: 0.8235 - val_precision: 0.8569\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2667 - binary_accuracy: 0.8835 - f1: 0.8837 - recall: 0.8853 - precision: 0.8837 - val_loss: 0.2924 - val_binary_accuracy: 0.8702 - val_f1: 0.8328 - val_recall: 0.8539 - val_precision: 0.8270\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2633 - binary_accuracy: 0.8855 - f1: 0.8859 - recall: 0.8875 - precision: 0.8854 - val_loss: 0.2907 - val_binary_accuracy: 0.8669 - val_f1: 0.8209 - val_recall: 0.8139 - val_precision: 0.8474\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2680 - binary_accuracy: 0.8843 - f1: 0.8842 - recall: 0.8855 - precision: 0.8849 - val_loss: 0.2993 - val_binary_accuracy: 0.8651 - val_f1: 0.8084 - val_recall: 0.8141 - val_precision: 0.8349\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2667 - binary_accuracy: 0.8836 - f1: 0.8847 - recall: 0.8909 - precision: 0.8804 - val_loss: 0.2981 - val_binary_accuracy: 0.8619 - val_f1: 0.7908 - val_recall: 0.7827 - val_precision: 0.8395\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2660 - binary_accuracy: 0.8836 - f1: 0.8835 - recall: 0.8836 - precision: 0.8855 - val_loss: 0.3324 - val_binary_accuracy: 0.8587 - val_f1: 0.8309 - val_recall: 0.9089 - val_precision: 0.7732\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2696 - binary_accuracy: 0.8836 - f1: 0.8834 - recall: 0.8861 - precision: 0.8826 - val_loss: 0.2967 - val_binary_accuracy: 0.8665 - val_f1: 0.8267 - val_recall: 0.8188 - val_precision: 0.8488\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2620 - binary_accuracy: 0.8864 - f1: 0.8871 - recall: 0.8927 - precision: 0.8830 - val_loss: 0.2885 - val_binary_accuracy: 0.8743 - val_f1: 0.8323 - val_recall: 0.8216 - val_precision: 0.8508\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2621 - binary_accuracy: 0.8864 - f1: 0.8871 - recall: 0.8898 - precision: 0.8869 - val_loss: 0.2982 - val_binary_accuracy: 0.8715 - val_f1: 0.8202 - val_recall: 0.7818 - val_precision: 0.8838\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2627 - binary_accuracy: 0.8852 - f1: 0.8853 - recall: 0.8857 - precision: 0.8865 - val_loss: 0.2890 - val_binary_accuracy: 0.8720 - val_f1: 0.8314 - val_recall: 0.8328 - val_precision: 0.8376\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2587 - binary_accuracy: 0.8857 - f1: 0.8860 - recall: 0.8902 - precision: 0.8843 - val_loss: 0.2986 - val_binary_accuracy: 0.8692 - val_f1: 0.8185 - val_recall: 0.7891 - val_precision: 0.8692\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2555 - binary_accuracy: 0.8888 - f1: 0.8886 - recall: 0.8892 - precision: 0.8893 - val_loss: 0.2944 - val_binary_accuracy: 0.8711 - val_f1: 0.8347 - val_recall: 0.8588 - val_precision: 0.8266\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2532 - binary_accuracy: 0.8909 - f1: 0.8911 - recall: 0.8952 - precision: 0.8881 - val_loss: 0.2974 - val_binary_accuracy: 0.8651 - val_f1: 0.8143 - val_recall: 0.8168 - val_precision: 0.8314\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2554 - binary_accuracy: 0.8927 - f1: 0.8929 - recall: 0.8964 - precision: 0.8915 - val_loss: 0.2898 - val_binary_accuracy: 0.8711 - val_f1: 0.8133 - val_recall: 0.7953 - val_precision: 0.8566\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2509 - binary_accuracy: 0.8927 - f1: 0.8934 - recall: 0.8982 - precision: 0.8896 - val_loss: 0.2917 - val_binary_accuracy: 0.8715 - val_f1: 0.8299 - val_recall: 0.8306 - val_precision: 0.8428\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2479 - binary_accuracy: 0.8936 - f1: 0.8933 - recall: 0.8909 - precision: 0.8970 - val_loss: 0.2972 - val_binary_accuracy: 0.8692 - val_f1: 0.8325 - val_recall: 0.8697 - val_precision: 0.8077\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2458 - binary_accuracy: 0.8957 - f1: 0.8965 - recall: 0.9025 - precision: 0.8920 - val_loss: 0.3117 - val_binary_accuracy: 0.8697 - val_f1: 0.8397 - val_recall: 0.8872 - val_precision: 0.8045\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2482 - binary_accuracy: 0.8955 - f1: 0.8961 - recall: 0.9013 - precision: 0.8933 - val_loss: 0.2900 - val_binary_accuracy: 0.8725 - val_f1: 0.8307 - val_recall: 0.8211 - val_precision: 0.8528\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2420 - binary_accuracy: 0.8955 - f1: 0.8955 - recall: 0.8973 - precision: 0.8950 - val_loss: 0.2952 - val_binary_accuracy: 0.8683 - val_f1: 0.8295 - val_recall: 0.8464 - val_precision: 0.8285\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2391 - binary_accuracy: 0.8977 - f1: 0.8980 - recall: 0.9000 - precision: 0.8964 - val_loss: 0.3124 - val_binary_accuracy: 0.8660 - val_f1: 0.8378 - val_recall: 0.8848 - val_precision: 0.8078\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2376 - binary_accuracy: 0.8984 - f1: 0.8984 - recall: 0.9026 - precision: 0.8956 - val_loss: 0.2981 - val_binary_accuracy: 0.8692 - val_f1: 0.8230 - val_recall: 0.8181 - val_precision: 0.8469\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2420 - binary_accuracy: 0.8938 - f1: 0.8938 - recall: 0.8951 - precision: 0.8941 - val_loss: 0.3308 - val_binary_accuracy: 0.8591 - val_f1: 0.8323 - val_recall: 0.9011 - val_precision: 0.7840\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2464 - binary_accuracy: 0.8934 - f1: 0.8935 - recall: 0.8975 - precision: 0.8915 - val_loss: 0.2984 - val_binary_accuracy: 0.8674 - val_f1: 0.8109 - val_recall: 0.7992 - val_precision: 0.8427\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2333 - binary_accuracy: 0.9020 - f1: 0.9017 - recall: 0.9001 - precision: 0.9044 - val_loss: 0.3239 - val_binary_accuracy: 0.8568 - val_f1: 0.8336 - val_recall: 0.8937 - val_precision: 0.7928\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2347 - binary_accuracy: 0.9010 - f1: 0.9015 - recall: 0.9061 - precision: 0.8991 - val_loss: 0.2970 - val_binary_accuracy: 0.8725 - val_f1: 0.8335 - val_recall: 0.8338 - val_precision: 0.8467\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2297 - binary_accuracy: 0.9027 - f1: 0.9028 - recall: 0.9055 - precision: 0.9012 - val_loss: 0.3031 - val_binary_accuracy: 0.8674 - val_f1: 0.8205 - val_recall: 0.8259 - val_precision: 0.8344\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2302 - binary_accuracy: 0.9003 - f1: 0.9005 - recall: 0.9020 - precision: 0.9006 - val_loss: 0.2952 - val_binary_accuracy: 0.8748 - val_f1: 0.8341 - val_recall: 0.8378 - val_precision: 0.8434\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2332 - binary_accuracy: 0.8995 - f1: 0.8994 - recall: 0.9022 - precision: 0.8987 - val_loss: 0.3063 - val_binary_accuracy: 0.8669 - val_f1: 0.8331 - val_recall: 0.8653 - val_precision: 0.8192\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2216 - binary_accuracy: 0.9095 - f1: 0.9098 - recall: 0.9105 - precision: 0.9101 - val_loss: 0.3070 - val_binary_accuracy: 0.8674 - val_f1: 0.8254 - val_recall: 0.8389 - val_precision: 0.8216\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2264 - binary_accuracy: 0.9065 - f1: 0.9072 - recall: 0.9116 - precision: 0.9043 - val_loss: 0.3170 - val_binary_accuracy: 0.8688 - val_f1: 0.8049 - val_recall: 0.7674 - val_precision: 0.8739\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2422 - binary_accuracy: 0.8966 - f1: 0.8960 - recall: 0.8925 - precision: 0.9031 - val_loss: 0.3088 - val_binary_accuracy: 0.8679 - val_f1: 0.8257 - val_recall: 0.8439 - val_precision: 0.8229\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2281 - binary_accuracy: 0.9023 - f1: 0.9023 - recall: 0.9071 - precision: 0.8999 - val_loss: 0.3048 - val_binary_accuracy: 0.8715 - val_f1: 0.8341 - val_recall: 0.8528 - val_precision: 0.8311\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2276 - binary_accuracy: 0.9038 - f1: 0.9027 - recall: 0.9028 - precision: 0.9051 - val_loss: 0.3204 - val_binary_accuracy: 0.8573 - val_f1: 0.8133 - val_recall: 0.8044 - val_precision: 0.8347\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2171 - binary_accuracy: 0.9080 - f1: 0.9083 - recall: 0.9100 - precision: 0.9073 - val_loss: 0.3060 - val_binary_accuracy: 0.8725 - val_f1: 0.8373 - val_recall: 0.8594 - val_precision: 0.8304\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2174 - binary_accuracy: 0.9092 - f1: 0.9094 - recall: 0.9118 - precision: 0.9077 - val_loss: 0.3084 - val_binary_accuracy: 0.8633 - val_f1: 0.8192 - val_recall: 0.8287 - val_precision: 0.8247\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2153 - binary_accuracy: 0.9119 - f1: 0.9123 - recall: 0.9174 - precision: 0.9083 - val_loss: 0.3097 - val_binary_accuracy: 0.8697 - val_f1: 0.8258 - val_recall: 0.8362 - val_precision: 0.8298\n",
      "Epoch 90/500\n",
      "0s - loss: 0.2177 - binary_accuracy: 0.9115 - f1: 0.9117 - recall: 0.9122 - precision: 0.9122 - val_loss: 0.3142 - val_binary_accuracy: 0.8729 - val_f1: 0.8389 - val_recall: 0.8550 - val_precision: 0.8314\n",
      "Epoch 91/500\n",
      "0s - loss: 0.2168 - binary_accuracy: 0.9077 - f1: 0.9075 - recall: 0.9067 - precision: 0.9097 - val_loss: 0.3125 - val_binary_accuracy: 0.8697 - val_f1: 0.8200 - val_recall: 0.8217 - val_precision: 0.8379\n",
      "Epoch 92/500\n",
      "0s - loss: 0.2179 - binary_accuracy: 0.9099 - f1: 0.9100 - recall: 0.9160 - precision: 0.9053 - val_loss: 0.3151 - val_binary_accuracy: 0.8725 - val_f1: 0.8426 - val_recall: 0.8907 - val_precision: 0.8055\n",
      "2048/2172 [===========================>..] - ETA: 0stn = 3821, fp = 509, fn = 232, tp = 4126\n",
      "y_pred: 0 = 4053 | 1 = 4635\n",
      "y_true: 0 = 4330 | 1 = 4358\n",
      "acc=0.9147|precision=0.8902|recall=0.9468|f1=0.9176|auc=0.9770|aupr=0.9781|pos_acc=0.9468|neg_acc=0.9428\n",
      "tn = 908, fp = 192, fn = 85, tp = 987\n",
      "y_pred: 0 = 993 | 1 = 1179\n",
      "y_true: 0 = 1100 | 1 = 1072\n",
      "acc=0.8725|precision=0.8372|recall=0.9207|f1=0.8769|auc=0.9457|aupr=0.9390|pos_acc=0.9207|neg_acc=0.9144\n",
      "----------------------- Fold =  1\n",
      "Train on 8688 samples, validate on 2172 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4039 - binary_accuracy: 0.8142 - f1: 0.7858 - recall: 0.7707 - precision: 0.8559 - val_loss: 0.3718 - val_binary_accuracy: 0.8287 - val_f1: 0.7859 - val_recall: 0.7881 - val_precision: 0.7863\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3547 - binary_accuracy: 0.8438 - f1: 0.8433 - recall: 0.8416 - precision: 0.8486 - val_loss: 0.3586 - val_binary_accuracy: 0.8412 - val_f1: 0.8020 - val_recall: 0.8308 - val_precision: 0.7757\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3396 - binary_accuracy: 0.8528 - f1: 0.8517 - recall: 0.8470 - precision: 0.8589 - val_loss: 0.3439 - val_binary_accuracy: 0.8458 - val_f1: 0.7975 - val_recall: 0.7898 - val_precision: 0.8083\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3354 - binary_accuracy: 0.8532 - f1: 0.8535 - recall: 0.8568 - precision: 0.8519 - val_loss: 0.3409 - val_binary_accuracy: 0.8467 - val_f1: 0.7993 - val_recall: 0.7964 - val_precision: 0.8039\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3304 - binary_accuracy: 0.8578 - f1: 0.8585 - recall: 0.8644 - precision: 0.8553 - val_loss: 0.3434 - val_binary_accuracy: 0.8467 - val_f1: 0.8033 - val_recall: 0.8265 - val_precision: 0.7825\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3287 - binary_accuracy: 0.8591 - f1: 0.8600 - recall: 0.8672 - precision: 0.8558 - val_loss: 0.3359 - val_binary_accuracy: 0.8568 - val_f1: 0.8046 - val_recall: 0.7795 - val_precision: 0.8491\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3268 - binary_accuracy: 0.8545 - f1: 0.8552 - recall: 0.8593 - precision: 0.8533 - val_loss: 0.3353 - val_binary_accuracy: 0.8513 - val_f1: 0.8084 - val_recall: 0.8141 - val_precision: 0.8042\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3252 - binary_accuracy: 0.8585 - f1: 0.8595 - recall: 0.8672 - precision: 0.8550 - val_loss: 0.3369 - val_binary_accuracy: 0.8513 - val_f1: 0.8113 - val_recall: 0.8376 - val_precision: 0.7959\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3227 - binary_accuracy: 0.8612 - f1: 0.8616 - recall: 0.8686 - precision: 0.8581 - val_loss: 0.3372 - val_binary_accuracy: 0.8536 - val_f1: 0.8141 - val_recall: 0.8349 - val_precision: 0.8074\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3199 - binary_accuracy: 0.8613 - f1: 0.8612 - recall: 0.8652 - precision: 0.8595 - val_loss: 0.3331 - val_binary_accuracy: 0.8499 - val_f1: 0.7721 - val_recall: 0.7477 - val_precision: 0.8503\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3208 - binary_accuracy: 0.8598 - f1: 0.8593 - recall: 0.8594 - precision: 0.8616 - val_loss: 0.3592 - val_binary_accuracy: 0.8421 - val_f1: 0.8122 - val_recall: 0.8763 - val_precision: 0.7574\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3204 - binary_accuracy: 0.8598 - f1: 0.8603 - recall: 0.8658 - precision: 0.8578 - val_loss: 0.3346 - val_binary_accuracy: 0.8573 - val_f1: 0.8116 - val_recall: 0.8182 - val_precision: 0.8162\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3128 - binary_accuracy: 0.8677 - f1: 0.8678 - recall: 0.8713 - precision: 0.8657 - val_loss: 0.3509 - val_binary_accuracy: 0.8448 - val_f1: 0.8096 - val_recall: 0.8309 - val_precision: 0.7904\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3119 - binary_accuracy: 0.8688 - f1: 0.8693 - recall: 0.8760 - precision: 0.8641 - val_loss: 0.3332 - val_binary_accuracy: 0.8517 - val_f1: 0.8082 - val_recall: 0.8042 - val_precision: 0.8141\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3119 - binary_accuracy: 0.8667 - f1: 0.8667 - recall: 0.8740 - precision: 0.8618 - val_loss: 0.3290 - val_binary_accuracy: 0.8596 - val_f1: 0.8104 - val_recall: 0.7989 - val_precision: 0.8437\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3110 - binary_accuracy: 0.8642 - f1: 0.8643 - recall: 0.8688 - precision: 0.8623 - val_loss: 0.3320 - val_binary_accuracy: 0.8490 - val_f1: 0.7726 - val_recall: 0.7415 - val_precision: 0.8581\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3118 - binary_accuracy: 0.8621 - f1: 0.8626 - recall: 0.8662 - precision: 0.8615 - val_loss: 0.3296 - val_binary_accuracy: 0.8600 - val_f1: 0.8149 - val_recall: 0.8164 - val_precision: 0.8350\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3102 - binary_accuracy: 0.8645 - f1: 0.8653 - recall: 0.8711 - precision: 0.8624 - val_loss: 0.3304 - val_binary_accuracy: 0.8513 - val_f1: 0.8056 - val_recall: 0.7991 - val_precision: 0.8153\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3073 - binary_accuracy: 0.8679 - f1: 0.8682 - recall: 0.8708 - precision: 0.8678 - val_loss: 0.3340 - val_binary_accuracy: 0.8554 - val_f1: 0.7889 - val_recall: 0.7893 - val_precision: 0.8389\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3109 - binary_accuracy: 0.8643 - f1: 0.8642 - recall: 0.8670 - precision: 0.8639 - val_loss: 0.3334 - val_binary_accuracy: 0.8559 - val_f1: 0.8080 - val_recall: 0.7784 - val_precision: 0.8575\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3085 - binary_accuracy: 0.8638 - f1: 0.8641 - recall: 0.8677 - precision: 0.8634 - val_loss: 0.3309 - val_binary_accuracy: 0.8568 - val_f1: 0.8162 - val_recall: 0.8239 - val_precision: 0.8212\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3042 - binary_accuracy: 0.8666 - f1: 0.8668 - recall: 0.8713 - precision: 0.8641 - val_loss: 0.3270 - val_binary_accuracy: 0.8582 - val_f1: 0.8110 - val_recall: 0.8061 - val_precision: 0.8383\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3020 - binary_accuracy: 0.8675 - f1: 0.8677 - recall: 0.8716 - precision: 0.8654 - val_loss: 0.3414 - val_binary_accuracy: 0.8517 - val_f1: 0.7967 - val_recall: 0.7513 - val_precision: 0.8616\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3013 - binary_accuracy: 0.8696 - f1: 0.8696 - recall: 0.8712 - precision: 0.8702 - val_loss: 0.3272 - val_binary_accuracy: 0.8577 - val_f1: 0.8180 - val_recall: 0.8330 - val_precision: 0.8096\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3011 - binary_accuracy: 0.8703 - f1: 0.8701 - recall: 0.8696 - precision: 0.8730 - val_loss: 0.3307 - val_binary_accuracy: 0.8522 - val_f1: 0.8108 - val_recall: 0.8327 - val_precision: 0.7942\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3006 - binary_accuracy: 0.8718 - f1: 0.8724 - recall: 0.8768 - precision: 0.8716 - val_loss: 0.3328 - val_binary_accuracy: 0.8517 - val_f1: 0.7825 - val_recall: 0.7597 - val_precision: 0.8315\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2951 - binary_accuracy: 0.8725 - f1: 0.8725 - recall: 0.8765 - precision: 0.8702 - val_loss: 0.3337 - val_binary_accuracy: 0.8508 - val_f1: 0.7651 - val_recall: 0.7342 - val_precision: 0.8652\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2950 - binary_accuracy: 0.8718 - f1: 0.8717 - recall: 0.8750 - precision: 0.8704 - val_loss: 0.3279 - val_binary_accuracy: 0.8577 - val_f1: 0.8113 - val_recall: 0.8015 - val_precision: 0.8437\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2950 - binary_accuracy: 0.8729 - f1: 0.8731 - recall: 0.8785 - precision: 0.8696 - val_loss: 0.3437 - val_binary_accuracy: 0.8559 - val_f1: 0.7987 - val_recall: 0.7600 - val_precision: 0.8618\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2980 - binary_accuracy: 0.8711 - f1: 0.8713 - recall: 0.8760 - precision: 0.8693 - val_loss: 0.3528 - val_binary_accuracy: 0.8476 - val_f1: 0.8107 - val_recall: 0.8456 - val_precision: 0.7791\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2973 - binary_accuracy: 0.8703 - f1: 0.8706 - recall: 0.8767 - precision: 0.8674 - val_loss: 0.3329 - val_binary_accuracy: 0.8550 - val_f1: 0.8156 - val_recall: 0.8193 - val_precision: 0.8228\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2894 - binary_accuracy: 0.8751 - f1: 0.8750 - recall: 0.8779 - precision: 0.8737 - val_loss: 0.3299 - val_binary_accuracy: 0.8587 - val_f1: 0.7871 - val_recall: 0.7685 - val_precision: 0.8577\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2879 - binary_accuracy: 0.8747 - f1: 0.8750 - recall: 0.8814 - precision: 0.8698 - val_loss: 0.3285 - val_binary_accuracy: 0.8605 - val_f1: 0.8153 - val_recall: 0.8065 - val_precision: 0.8370\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2894 - binary_accuracy: 0.8760 - f1: 0.8757 - recall: 0.8809 - precision: 0.8734 - val_loss: 0.3433 - val_binary_accuracy: 0.8494 - val_f1: 0.7597 - val_recall: 0.7253 - val_precision: 0.8634\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2900 - binary_accuracy: 0.8713 - f1: 0.8714 - recall: 0.8750 - precision: 0.8695 - val_loss: 0.3328 - val_binary_accuracy: 0.8550 - val_f1: 0.8134 - val_recall: 0.8189 - val_precision: 0.8095\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2829 - binary_accuracy: 0.8770 - f1: 0.8773 - recall: 0.8812 - precision: 0.8750 - val_loss: 0.3382 - val_binary_accuracy: 0.8550 - val_f1: 0.8162 - val_recall: 0.8467 - val_precision: 0.7892\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2905 - binary_accuracy: 0.8727 - f1: 0.8725 - recall: 0.8760 - precision: 0.8729 - val_loss: 0.3384 - val_binary_accuracy: 0.8541 - val_f1: 0.8062 - val_recall: 0.7991 - val_precision: 0.8363\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2902 - binary_accuracy: 0.8729 - f1: 0.8731 - recall: 0.8755 - precision: 0.8721 - val_loss: 0.3272 - val_binary_accuracy: 0.8646 - val_f1: 0.8224 - val_recall: 0.8252 - val_precision: 0.8342\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2882 - binary_accuracy: 0.8764 - f1: 0.8778 - recall: 0.8884 - precision: 0.8698 - val_loss: 0.3310 - val_binary_accuracy: 0.8559 - val_f1: 0.8107 - val_recall: 0.8073 - val_precision: 0.8271\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2790 - binary_accuracy: 0.8786 - f1: 0.8788 - recall: 0.8810 - precision: 0.8776 - val_loss: 0.3309 - val_binary_accuracy: 0.8568 - val_f1: 0.8156 - val_recall: 0.8253 - val_precision: 0.8218\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2771 - binary_accuracy: 0.8806 - f1: 0.8812 - recall: 0.8863 - precision: 0.8780 - val_loss: 0.3293 - val_binary_accuracy: 0.8573 - val_f1: 0.8128 - val_recall: 0.8086 - val_precision: 0.8243\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2774 - binary_accuracy: 0.8783 - f1: 0.8780 - recall: 0.8819 - precision: 0.8764 - val_loss: 0.3353 - val_binary_accuracy: 0.8550 - val_f1: 0.8151 - val_recall: 0.8228 - val_precision: 0.8083\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2756 - binary_accuracy: 0.8798 - f1: 0.8801 - recall: 0.8855 - precision: 0.8774 - val_loss: 0.3300 - val_binary_accuracy: 0.8577 - val_f1: 0.8127 - val_recall: 0.7970 - val_precision: 0.8387\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2716 - binary_accuracy: 0.8836 - f1: 0.8837 - recall: 0.8895 - precision: 0.8796 - val_loss: 0.3362 - val_binary_accuracy: 0.8568 - val_f1: 0.8131 - val_recall: 0.7913 - val_precision: 0.8430\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2734 - binary_accuracy: 0.8803 - f1: 0.8801 - recall: 0.8843 - precision: 0.8777 - val_loss: 0.3406 - val_binary_accuracy: 0.8554 - val_f1: 0.7947 - val_recall: 0.7630 - val_precision: 0.8591\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2747 - binary_accuracy: 0.8794 - f1: 0.8794 - recall: 0.8815 - precision: 0.8795 - val_loss: 0.3370 - val_binary_accuracy: 0.8568 - val_f1: 0.7950 - val_recall: 0.7548 - val_precision: 0.8660\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2674 - binary_accuracy: 0.8840 - f1: 0.8843 - recall: 0.8902 - precision: 0.8797 - val_loss: 0.3336 - val_binary_accuracy: 0.8582 - val_f1: 0.8135 - val_recall: 0.8181 - val_precision: 0.8216\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2648 - binary_accuracy: 0.8865 - f1: 0.8864 - recall: 0.8889 - precision: 0.8852 - val_loss: 0.3350 - val_binary_accuracy: 0.8527 - val_f1: 0.8140 - val_recall: 0.8228 - val_precision: 0.8097\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2634 - binary_accuracy: 0.8848 - f1: 0.8851 - recall: 0.8913 - precision: 0.8798 - val_loss: 0.3595 - val_binary_accuracy: 0.8453 - val_f1: 0.8133 - val_recall: 0.8568 - val_precision: 0.7754\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2714 - binary_accuracy: 0.8835 - f1: 0.8838 - recall: 0.8879 - precision: 0.8833 - val_loss: 0.3355 - val_binary_accuracy: 0.8522 - val_f1: 0.8132 - val_recall: 0.8302 - val_precision: 0.8036\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2623 - binary_accuracy: 0.8854 - f1: 0.8854 - recall: 0.8898 - precision: 0.8825 - val_loss: 0.3322 - val_binary_accuracy: 0.8610 - val_f1: 0.8191 - val_recall: 0.8246 - val_precision: 0.8243\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2587 - binary_accuracy: 0.8886 - f1: 0.8891 - recall: 0.8936 - precision: 0.8856 - val_loss: 0.3332 - val_binary_accuracy: 0.8527 - val_f1: 0.7796 - val_recall: 0.7616 - val_precision: 0.8456\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2610 - binary_accuracy: 0.8869 - f1: 0.8875 - recall: 0.8926 - precision: 0.8835 - val_loss: 0.3339 - val_binary_accuracy: 0.8591 - val_f1: 0.8188 - val_recall: 0.8225 - val_precision: 0.8258\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2571 - binary_accuracy: 0.8872 - f1: 0.8871 - recall: 0.8893 - precision: 0.8860 - val_loss: 0.3331 - val_binary_accuracy: 0.8633 - val_f1: 0.8134 - val_recall: 0.7915 - val_precision: 0.8506\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2576 - binary_accuracy: 0.8907 - f1: 0.8911 - recall: 0.8961 - precision: 0.8878 - val_loss: 0.3325 - val_binary_accuracy: 0.8596 - val_f1: 0.8162 - val_recall: 0.8118 - val_precision: 0.8312\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2597 - binary_accuracy: 0.8898 - f1: 0.8897 - recall: 0.8934 - precision: 0.8886 - val_loss: 0.3349 - val_binary_accuracy: 0.8582 - val_f1: 0.8163 - val_recall: 0.8253 - val_precision: 0.8197\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2578 - binary_accuracy: 0.8874 - f1: 0.8876 - recall: 0.8921 - precision: 0.8854 - val_loss: 0.3418 - val_binary_accuracy: 0.8508 - val_f1: 0.8206 - val_recall: 0.8583 - val_precision: 0.7887\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2567 - binary_accuracy: 0.8909 - f1: 0.8908 - recall: 0.8943 - precision: 0.8893 - val_loss: 0.3325 - val_binary_accuracy: 0.8628 - val_f1: 0.8187 - val_recall: 0.8127 - val_precision: 0.8355\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2483 - binary_accuracy: 0.8954 - f1: 0.8951 - recall: 0.9005 - precision: 0.8909 - val_loss: 0.3515 - val_binary_accuracy: 0.8564 - val_f1: 0.8083 - val_recall: 0.7904 - val_precision: 0.8319\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2643 - binary_accuracy: 0.8864 - f1: 0.8856 - recall: 0.8848 - precision: 0.8917 - val_loss: 0.3458 - val_binary_accuracy: 0.8527 - val_f1: 0.8147 - val_recall: 0.8404 - val_precision: 0.7924\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2496 - binary_accuracy: 0.8930 - f1: 0.8933 - recall: 0.9027 - precision: 0.8862 - val_loss: 0.3382 - val_binary_accuracy: 0.8527 - val_f1: 0.7759 - val_recall: 0.7521 - val_precision: 0.8485\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2444 - binary_accuracy: 0.8959 - f1: 0.8965 - recall: 0.9023 - precision: 0.8916 - val_loss: 0.3361 - val_binary_accuracy: 0.8550 - val_f1: 0.8137 - val_recall: 0.8170 - val_precision: 0.8207\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2472 - binary_accuracy: 0.8943 - f1: 0.8946 - recall: 0.8977 - precision: 0.8936 - val_loss: 0.3347 - val_binary_accuracy: 0.8573 - val_f1: 0.8116 - val_recall: 0.8148 - val_precision: 0.8195\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2421 - binary_accuracy: 0.8988 - f1: 0.8983 - recall: 0.9006 - precision: 0.8978 - val_loss: 0.3478 - val_binary_accuracy: 0.8531 - val_f1: 0.8189 - val_recall: 0.8528 - val_precision: 0.7908\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2433 - binary_accuracy: 0.8965 - f1: 0.8970 - recall: 0.9013 - precision: 0.8943 - val_loss: 0.3381 - val_binary_accuracy: 0.8573 - val_f1: 0.8141 - val_recall: 0.8245 - val_precision: 0.8160\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2401 - binary_accuracy: 0.8993 - f1: 0.8993 - recall: 0.9039 - precision: 0.8971 - val_loss: 0.3512 - val_binary_accuracy: 0.8517 - val_f1: 0.7979 - val_recall: 0.7596 - val_precision: 0.8588\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2368 - binary_accuracy: 0.8993 - f1: 0.8995 - recall: 0.9024 - precision: 0.8975 - val_loss: 0.3392 - val_binary_accuracy: 0.8564 - val_f1: 0.8219 - val_recall: 0.8461 - val_precision: 0.8022\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2423 - binary_accuracy: 0.8969 - f1: 0.8969 - recall: 0.9015 - precision: 0.8947 - val_loss: 0.3595 - val_binary_accuracy: 0.8398 - val_f1: 0.8157 - val_recall: 0.8694 - val_precision: 0.7708\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2402 - binary_accuracy: 0.8974 - f1: 0.8977 - recall: 0.9029 - precision: 0.8938 - val_loss: 0.3497 - val_binary_accuracy: 0.8471 - val_f1: 0.7707 - val_recall: 0.7437 - val_precision: 0.8460\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2344 - binary_accuracy: 0.9010 - f1: 0.9006 - recall: 0.9020 - precision: 0.9003 - val_loss: 0.3422 - val_binary_accuracy: 0.8564 - val_f1: 0.8060 - val_recall: 0.7951 - val_precision: 0.8302\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2318 - binary_accuracy: 0.9033 - f1: 0.9031 - recall: 0.9060 - precision: 0.9024 - val_loss: 0.3542 - val_binary_accuracy: 0.8508 - val_f1: 0.8152 - val_recall: 0.8512 - val_precision: 0.7832\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2312 - binary_accuracy: 0.9027 - f1: 0.9026 - recall: 0.9073 - precision: 0.8999 - val_loss: 0.3396 - val_binary_accuracy: 0.8628 - val_f1: 0.8190 - val_recall: 0.8117 - val_precision: 0.8411\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2264 - binary_accuracy: 0.9046 - f1: 0.9049 - recall: 0.9089 - precision: 0.9020 - val_loss: 0.3596 - val_binary_accuracy: 0.8504 - val_f1: 0.8106 - val_recall: 0.8201 - val_precision: 0.8027\n",
      "2144/2172 [============================>.] - ETA: 0stn = 3837, fp = 499, fn = 353, tp = 3999\n",
      "y_pred: 0 = 4190 | 1 = 4498\n",
      "y_true: 0 = 4336 | 1 = 4352\n",
      "acc=0.9019|precision=0.8891|recall=0.9189|f1=0.9037|auc=0.9681|aupr=0.9683|pos_acc=0.9189|neg_acc=0.9158\n",
      "tn = 917, fp = 177, fn = 148, tp = 930\n",
      "y_pred: 0 = 1065 | 1 = 1107\n",
      "y_true: 0 = 1094 | 1 = 1078\n",
      "acc=0.8504|precision=0.8401|recall=0.8627|f1=0.8513|auc=0.9308|aupr=0.9252|pos_acc=0.8627|neg_acc=0.8610\n",
      "----------------------- Fold =  2\n",
      "Train on 8688 samples, validate on 2172 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4053 - binary_accuracy: 0.8134 - f1: 0.8077 - recall: 0.7927 - precision: 0.8444 - val_loss: 0.3652 - val_binary_accuracy: 0.8435 - val_f1: 0.7915 - val_recall: 0.7623 - val_precision: 0.8263\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3535 - binary_accuracy: 0.8404 - f1: 0.8369 - recall: 0.8250 - precision: 0.8538 - val_loss: 0.3610 - val_binary_accuracy: 0.8494 - val_f1: 0.8043 - val_recall: 0.8263 - val_precision: 0.7857\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3453 - binary_accuracy: 0.8448 - f1: 0.8427 - recall: 0.8351 - precision: 0.8554 - val_loss: 0.3592 - val_binary_accuracy: 0.8430 - val_f1: 0.7986 - val_recall: 0.8085 - val_precision: 0.7910\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3342 - binary_accuracy: 0.8567 - f1: 0.8561 - recall: 0.8558 - precision: 0.8574 - val_loss: 0.3534 - val_binary_accuracy: 0.8421 - val_f1: 0.7957 - val_recall: 0.8033 - val_precision: 0.7902\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3288 - binary_accuracy: 0.8581 - f1: 0.8570 - recall: 0.8540 - precision: 0.8617 - val_loss: 0.3531 - val_binary_accuracy: 0.8453 - val_f1: 0.7783 - val_recall: 0.7370 - val_precision: 0.8382\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3263 - binary_accuracy: 0.8583 - f1: 0.8584 - recall: 0.8596 - precision: 0.8588 - val_loss: 0.3432 - val_binary_accuracy: 0.8494 - val_f1: 0.7757 - val_recall: 0.7476 - val_precision: 0.8625\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3256 - binary_accuracy: 0.8599 - f1: 0.8603 - recall: 0.8615 - precision: 0.8627 - val_loss: 0.3473 - val_binary_accuracy: 0.8508 - val_f1: 0.7772 - val_recall: 0.7429 - val_precision: 0.8318\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3250 - binary_accuracy: 0.8570 - f1: 0.8565 - recall: 0.8577 - precision: 0.8566 - val_loss: 0.3412 - val_binary_accuracy: 0.8490 - val_f1: 0.7898 - val_recall: 0.7713 - val_precision: 0.8226\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3204 - binary_accuracy: 0.8604 - f1: 0.8597 - recall: 0.8616 - precision: 0.8608 - val_loss: 0.3415 - val_binary_accuracy: 0.8536 - val_f1: 0.7815 - val_recall: 0.7495 - val_precision: 0.8464\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3169 - binary_accuracy: 0.8618 - f1: 0.8620 - recall: 0.8633 - precision: 0.8620 - val_loss: 0.3379 - val_binary_accuracy: 0.8462 - val_f1: 0.7759 - val_recall: 0.7586 - val_precision: 0.8200\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3118 - binary_accuracy: 0.8635 - f1: 0.8641 - recall: 0.8685 - precision: 0.8610 - val_loss: 0.3434 - val_binary_accuracy: 0.8513 - val_f1: 0.8064 - val_recall: 0.8355 - val_precision: 0.7845\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3138 - binary_accuracy: 0.8614 - f1: 0.8612 - recall: 0.8617 - precision: 0.8633 - val_loss: 0.3572 - val_binary_accuracy: 0.8499 - val_f1: 0.8112 - val_recall: 0.8674 - val_precision: 0.7674\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3150 - binary_accuracy: 0.8576 - f1: 0.8583 - recall: 0.8624 - precision: 0.8569 - val_loss: 0.3383 - val_binary_accuracy: 0.8513 - val_f1: 0.7924 - val_recall: 0.7876 - val_precision: 0.8111\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3093 - binary_accuracy: 0.8665 - f1: 0.8664 - recall: 0.8677 - precision: 0.8674 - val_loss: 0.3397 - val_binary_accuracy: 0.8517 - val_f1: 0.7909 - val_recall: 0.7746 - val_precision: 0.8235\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3113 - binary_accuracy: 0.8654 - f1: 0.8659 - recall: 0.8698 - precision: 0.8646 - val_loss: 0.3419 - val_binary_accuracy: 0.8476 - val_f1: 0.7853 - val_recall: 0.7620 - val_precision: 0.8235\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3067 - binary_accuracy: 0.8673 - f1: 0.8674 - recall: 0.8696 - precision: 0.8672 - val_loss: 0.3548 - val_binary_accuracy: 0.8485 - val_f1: 0.8047 - val_recall: 0.8628 - val_precision: 0.7593\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3068 - binary_accuracy: 0.8658 - f1: 0.8663 - recall: 0.8711 - precision: 0.8637 - val_loss: 0.3413 - val_binary_accuracy: 0.8513 - val_f1: 0.7709 - val_recall: 0.7630 - val_precision: 0.8031\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3087 - binary_accuracy: 0.8641 - f1: 0.8637 - recall: 0.8652 - precision: 0.8651 - val_loss: 0.3393 - val_binary_accuracy: 0.8536 - val_f1: 0.7846 - val_recall: 0.7615 - val_precision: 0.8414\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3034 - binary_accuracy: 0.8676 - f1: 0.8679 - recall: 0.8715 - precision: 0.8657 - val_loss: 0.3380 - val_binary_accuracy: 0.8545 - val_f1: 0.7970 - val_recall: 0.7997 - val_precision: 0.8079\n",
      "Epoch 20/500\n",
      "0s - loss: 0.2991 - binary_accuracy: 0.8676 - f1: 0.8681 - recall: 0.8721 - precision: 0.8653 - val_loss: 0.3659 - val_binary_accuracy: 0.8435 - val_f1: 0.7830 - val_recall: 0.7560 - val_precision: 0.8189\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3048 - binary_accuracy: 0.8645 - f1: 0.8648 - recall: 0.8687 - precision: 0.8633 - val_loss: 0.3401 - val_binary_accuracy: 0.8545 - val_f1: 0.7946 - val_recall: 0.7831 - val_precision: 0.8321\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3005 - binary_accuracy: 0.8682 - f1: 0.8679 - recall: 0.8653 - precision: 0.8726 - val_loss: 0.3401 - val_binary_accuracy: 0.8554 - val_f1: 0.8050 - val_recall: 0.8119 - val_precision: 0.8101\n",
      "Epoch 23/500\n",
      "0s - loss: 0.2982 - binary_accuracy: 0.8696 - f1: 0.8707 - recall: 0.8775 - precision: 0.8660 - val_loss: 0.3487 - val_binary_accuracy: 0.8564 - val_f1: 0.8073 - val_recall: 0.8432 - val_precision: 0.7879\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3006 - binary_accuracy: 0.8661 - f1: 0.8659 - recall: 0.8675 - precision: 0.8669 - val_loss: 0.3694 - val_binary_accuracy: 0.8393 - val_f1: 0.8087 - val_recall: 0.8879 - val_precision: 0.7448\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3022 - binary_accuracy: 0.8651 - f1: 0.8647 - recall: 0.8683 - precision: 0.8651 - val_loss: 0.3364 - val_binary_accuracy: 0.8545 - val_f1: 0.8022 - val_recall: 0.8167 - val_precision: 0.8013\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2941 - binary_accuracy: 0.8725 - f1: 0.8727 - recall: 0.8738 - precision: 0.8728 - val_loss: 0.3377 - val_binary_accuracy: 0.8531 - val_f1: 0.7882 - val_recall: 0.7851 - val_precision: 0.8218\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2900 - binary_accuracy: 0.8735 - f1: 0.8744 - recall: 0.8805 - precision: 0.8691 - val_loss: 0.3430 - val_binary_accuracy: 0.8485 - val_f1: 0.7873 - val_recall: 0.7613 - val_precision: 0.8387\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2917 - binary_accuracy: 0.8718 - f1: 0.8725 - recall: 0.8764 - precision: 0.8715 - val_loss: 0.3342 - val_binary_accuracy: 0.8536 - val_f1: 0.7945 - val_recall: 0.7887 - val_precision: 0.8248\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2919 - binary_accuracy: 0.8709 - f1: 0.8701 - recall: 0.8689 - precision: 0.8735 - val_loss: 0.3387 - val_binary_accuracy: 0.8545 - val_f1: 0.8066 - val_recall: 0.8307 - val_precision: 0.7897\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2858 - binary_accuracy: 0.8758 - f1: 0.8757 - recall: 0.8753 - precision: 0.8770 - val_loss: 0.3413 - val_binary_accuracy: 0.8513 - val_f1: 0.8023 - val_recall: 0.8279 - val_precision: 0.7835\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2889 - binary_accuracy: 0.8737 - f1: 0.8738 - recall: 0.8771 - precision: 0.8721 - val_loss: 0.3376 - val_binary_accuracy: 0.8527 - val_f1: 0.7930 - val_recall: 0.8030 - val_precision: 0.7959\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2869 - binary_accuracy: 0.8741 - f1: 0.8738 - recall: 0.8743 - precision: 0.8755 - val_loss: 0.3405 - val_binary_accuracy: 0.8559 - val_f1: 0.7995 - val_recall: 0.7913 - val_precision: 0.8400\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2843 - binary_accuracy: 0.8749 - f1: 0.8753 - recall: 0.8779 - precision: 0.8739 - val_loss: 0.3563 - val_binary_accuracy: 0.8504 - val_f1: 0.7872 - val_recall: 0.7660 - val_precision: 0.8230\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2860 - binary_accuracy: 0.8741 - f1: 0.8737 - recall: 0.8752 - precision: 0.8737 - val_loss: 0.3481 - val_binary_accuracy: 0.8536 - val_f1: 0.7781 - val_recall: 0.7886 - val_precision: 0.7882\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2911 - binary_accuracy: 0.8703 - f1: 0.8708 - recall: 0.8770 - precision: 0.8668 - val_loss: 0.3482 - val_binary_accuracy: 0.8559 - val_f1: 0.7913 - val_recall: 0.7586 - val_precision: 0.8538\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2855 - binary_accuracy: 0.8762 - f1: 0.8763 - recall: 0.8778 - precision: 0.8765 - val_loss: 0.3451 - val_binary_accuracy: 0.8536 - val_f1: 0.8048 - val_recall: 0.8251 - val_precision: 0.7940\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2779 - binary_accuracy: 0.8780 - f1: 0.8783 - recall: 0.8821 - precision: 0.8761 - val_loss: 0.3372 - val_binary_accuracy: 0.8587 - val_f1: 0.8023 - val_recall: 0.8028 - val_precision: 0.8232\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2792 - binary_accuracy: 0.8796 - f1: 0.8797 - recall: 0.8808 - precision: 0.8804 - val_loss: 0.3388 - val_binary_accuracy: 0.8541 - val_f1: 0.7966 - val_recall: 0.7927 - val_precision: 0.8215\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2757 - binary_accuracy: 0.8781 - f1: 0.8787 - recall: 0.8834 - precision: 0.8751 - val_loss: 0.3377 - val_binary_accuracy: 0.8541 - val_f1: 0.8005 - val_recall: 0.7928 - val_precision: 0.8192\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2750 - binary_accuracy: 0.8788 - f1: 0.8791 - recall: 0.8831 - precision: 0.8769 - val_loss: 0.3515 - val_binary_accuracy: 0.8517 - val_f1: 0.7910 - val_recall: 0.7665 - val_precision: 0.8376\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2824 - binary_accuracy: 0.8752 - f1: 0.8755 - recall: 0.8790 - precision: 0.8744 - val_loss: 0.3461 - val_binary_accuracy: 0.8531 - val_f1: 0.8045 - val_recall: 0.8312 - val_precision: 0.7885\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2731 - binary_accuracy: 0.8790 - f1: 0.8794 - recall: 0.8817 - precision: 0.8789 - val_loss: 0.3510 - val_binary_accuracy: 0.8517 - val_f1: 0.8117 - val_recall: 0.8575 - val_precision: 0.7736\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2779 - binary_accuracy: 0.8783 - f1: 0.8790 - recall: 0.8863 - precision: 0.8741 - val_loss: 0.3410 - val_binary_accuracy: 0.8527 - val_f1: 0.8016 - val_recall: 0.8007 - val_precision: 0.8086\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2762 - binary_accuracy: 0.8820 - f1: 0.8820 - recall: 0.8837 - precision: 0.8812 - val_loss: 0.3389 - val_binary_accuracy: 0.8600 - val_f1: 0.8005 - val_recall: 0.7842 - val_precision: 0.8484\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2709 - binary_accuracy: 0.8846 - f1: 0.8844 - recall: 0.8882 - precision: 0.8822 - val_loss: 0.3388 - val_binary_accuracy: 0.8550 - val_f1: 0.8003 - val_recall: 0.8039 - val_precision: 0.8100\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2680 - binary_accuracy: 0.8841 - f1: 0.8843 - recall: 0.8890 - precision: 0.8810 - val_loss: 0.3540 - val_binary_accuracy: 0.8513 - val_f1: 0.8004 - val_recall: 0.7942 - val_precision: 0.8118\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2649 - binary_accuracy: 0.8844 - f1: 0.8843 - recall: 0.8859 - precision: 0.8842 - val_loss: 0.3451 - val_binary_accuracy: 0.8476 - val_f1: 0.7951 - val_recall: 0.7944 - val_precision: 0.8034\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2648 - binary_accuracy: 0.8841 - f1: 0.8839 - recall: 0.8866 - precision: 0.8829 - val_loss: 0.3422 - val_binary_accuracy: 0.8541 - val_f1: 0.7939 - val_recall: 0.7668 - val_precision: 0.8440\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2709 - binary_accuracy: 0.8824 - f1: 0.8830 - recall: 0.8898 - precision: 0.8781 - val_loss: 0.3481 - val_binary_accuracy: 0.8545 - val_f1: 0.8117 - val_recall: 0.8442 - val_precision: 0.7894\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2645 - binary_accuracy: 0.8842 - f1: 0.8849 - recall: 0.8904 - precision: 0.8812 - val_loss: 0.3588 - val_binary_accuracy: 0.8513 - val_f1: 0.7644 - val_recall: 0.7312 - val_precision: 0.8219\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2677 - binary_accuracy: 0.8843 - f1: 0.8850 - recall: 0.8911 - precision: 0.8819 - val_loss: 0.3422 - val_binary_accuracy: 0.8527 - val_f1: 0.7979 - val_recall: 0.7847 - val_precision: 0.8235\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2633 - binary_accuracy: 0.8865 - f1: 0.8866 - recall: 0.8892 - precision: 0.8856 - val_loss: 0.3556 - val_binary_accuracy: 0.8554 - val_f1: 0.8121 - val_recall: 0.8439 - val_precision: 0.7911\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2644 - binary_accuracy: 0.8829 - f1: 0.8841 - recall: 0.8915 - precision: 0.8799 - val_loss: 0.3535 - val_binary_accuracy: 0.8499 - val_f1: 0.7908 - val_recall: 0.7605 - val_precision: 0.8365\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2590 - binary_accuracy: 0.8881 - f1: 0.8884 - recall: 0.8921 - precision: 0.8869 - val_loss: 0.3576 - val_binary_accuracy: 0.8499 - val_f1: 0.8138 - val_recall: 0.8541 - val_precision: 0.7793\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2630 - binary_accuracy: 0.8852 - f1: 0.8848 - recall: 0.8860 - precision: 0.8849 - val_loss: 0.3431 - val_binary_accuracy: 0.8577 - val_f1: 0.8016 - val_recall: 0.7923 - val_precision: 0.8280\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2594 - binary_accuracy: 0.8898 - f1: 0.8907 - recall: 0.8973 - precision: 0.8856 - val_loss: 0.3524 - val_binary_accuracy: 0.8573 - val_f1: 0.7989 - val_recall: 0.7953 - val_precision: 0.8249\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2563 - binary_accuracy: 0.8887 - f1: 0.8896 - recall: 0.8961 - precision: 0.8850 - val_loss: 0.3457 - val_binary_accuracy: 0.8536 - val_f1: 0.8104 - val_recall: 0.8290 - val_precision: 0.8000\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2519 - binary_accuracy: 0.8919 - f1: 0.8922 - recall: 0.8955 - precision: 0.8904 - val_loss: 0.3430 - val_binary_accuracy: 0.8568 - val_f1: 0.8055 - val_recall: 0.8204 - val_precision: 0.8061\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2507 - binary_accuracy: 0.8928 - f1: 0.8933 - recall: 0.8991 - precision: 0.8889 - val_loss: 0.3452 - val_binary_accuracy: 0.8573 - val_f1: 0.8001 - val_recall: 0.7871 - val_precision: 0.8302\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2577 - binary_accuracy: 0.8892 - f1: 0.8896 - recall: 0.8929 - precision: 0.8876 - val_loss: 0.3463 - val_binary_accuracy: 0.8587 - val_f1: 0.7926 - val_recall: 0.7920 - val_precision: 0.8178\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2476 - binary_accuracy: 0.8940 - f1: 0.8941 - recall: 0.8970 - precision: 0.8924 - val_loss: 0.3501 - val_binary_accuracy: 0.8591 - val_f1: 0.8094 - val_recall: 0.8338 - val_precision: 0.7948\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2480 - binary_accuracy: 0.8948 - f1: 0.8952 - recall: 0.8992 - precision: 0.8925 - val_loss: 0.3600 - val_binary_accuracy: 0.8412 - val_f1: 0.8019 - val_recall: 0.8226 - val_precision: 0.7849\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2572 - binary_accuracy: 0.8905 - f1: 0.8910 - recall: 0.8940 - precision: 0.8889 - val_loss: 0.3759 - val_binary_accuracy: 0.8559 - val_f1: 0.8094 - val_recall: 0.8282 - val_precision: 0.7948\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2480 - binary_accuracy: 0.8965 - f1: 0.8973 - recall: 0.9020 - precision: 0.8946 - val_loss: 0.3547 - val_binary_accuracy: 0.8527 - val_f1: 0.8119 - val_recall: 0.8549 - val_precision: 0.7764\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2447 - binary_accuracy: 0.8969 - f1: 0.8973 - recall: 0.9010 - precision: 0.8946 - val_loss: 0.3591 - val_binary_accuracy: 0.8573 - val_f1: 0.7972 - val_recall: 0.7861 - val_precision: 0.8269\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2431 - binary_accuracy: 0.8996 - f1: 0.9001 - recall: 0.9028 - precision: 0.8986 - val_loss: 0.3590 - val_binary_accuracy: 0.8517 - val_f1: 0.8118 - val_recall: 0.8479 - val_precision: 0.7837\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2425 - binary_accuracy: 0.8959 - f1: 0.8971 - recall: 0.9040 - precision: 0.8915 - val_loss: 0.3586 - val_binary_accuracy: 0.8582 - val_f1: 0.8089 - val_recall: 0.8204 - val_precision: 0.8057\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2408 - binary_accuracy: 0.8978 - f1: 0.8980 - recall: 0.9027 - precision: 0.8940 - val_loss: 0.3520 - val_binary_accuracy: 0.8508 - val_f1: 0.8027 - val_recall: 0.8031 - val_precision: 0.8117\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2373 - binary_accuracy: 0.8995 - f1: 0.8996 - recall: 0.9032 - precision: 0.8975 - val_loss: 0.3525 - val_binary_accuracy: 0.8577 - val_f1: 0.8101 - val_recall: 0.8181 - val_precision: 0.8090\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2342 - binary_accuracy: 0.9035 - f1: 0.9043 - recall: 0.9096 - precision: 0.9000 - val_loss: 0.3539 - val_binary_accuracy: 0.8513 - val_f1: 0.7982 - val_recall: 0.7958 - val_precision: 0.8099\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2374 - binary_accuracy: 0.9018 - f1: 0.9014 - recall: 0.9019 - precision: 0.9029 - val_loss: 0.3718 - val_binary_accuracy: 0.8448 - val_f1: 0.8078 - val_recall: 0.8446 - val_precision: 0.7768\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2385 - binary_accuracy: 0.8988 - f1: 0.8993 - recall: 0.9059 - precision: 0.8945 - val_loss: 0.3571 - val_binary_accuracy: 0.8508 - val_f1: 0.7811 - val_recall: 0.7502 - val_precision: 0.8288\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2305 - binary_accuracy: 0.9024 - f1: 0.9029 - recall: 0.9070 - precision: 0.8999 - val_loss: 0.3594 - val_binary_accuracy: 0.8577 - val_f1: 0.8017 - val_recall: 0.7930 - val_precision: 0.8296\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2340 - binary_accuracy: 0.9029 - f1: 0.9032 - recall: 0.9062 - precision: 0.9015 - val_loss: 0.3611 - val_binary_accuracy: 0.8610 - val_f1: 0.8048 - val_recall: 0.7966 - val_precision: 0.8264\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2382 - binary_accuracy: 0.9008 - f1: 0.9013 - recall: 0.9085 - precision: 0.8977 - val_loss: 0.3539 - val_binary_accuracy: 0.8587 - val_f1: 0.8017 - val_recall: 0.7778 - val_precision: 0.8438\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2261 - binary_accuracy: 0.9067 - f1: 0.9065 - recall: 0.9108 - precision: 0.9032 - val_loss: 0.3633 - val_binary_accuracy: 0.8587 - val_f1: 0.8098 - val_recall: 0.7986 - val_precision: 0.8275\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2221 - binary_accuracy: 0.9093 - f1: 0.9094 - recall: 0.9109 - precision: 0.9091 - val_loss: 0.3557 - val_binary_accuracy: 0.8536 - val_f1: 0.8036 - val_recall: 0.8252 - val_precision: 0.7915\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2247 - binary_accuracy: 0.9055 - f1: 0.9057 - recall: 0.9079 - precision: 0.9049 - val_loss: 0.3629 - val_binary_accuracy: 0.8536 - val_f1: 0.8036 - val_recall: 0.8195 - val_precision: 0.7959\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2206 - binary_accuracy: 0.9092 - f1: 0.9100 - recall: 0.9167 - precision: 0.9043 - val_loss: 0.3581 - val_binary_accuracy: 0.8564 - val_f1: 0.8122 - val_recall: 0.8251 - val_precision: 0.8047\n",
      "2112/2172 [============================>.] - ETA: 0stn = 3917, fp = 416, fn = 316, tp = 4039\n",
      "y_pred: 0 = 4233 | 1 = 4455\n",
      "y_true: 0 = 4333 | 1 = 4355\n",
      "acc=0.9157|precision=0.9066|recall=0.9274|f1=0.9169|auc=0.9749|aupr=0.9755|pos_acc=0.9274|neg_acc=0.9253\n",
      "tn = 917, fp = 180, fn = 132, tp = 943\n",
      "y_pred: 0 = 1049 | 1 = 1123\n",
      "y_true: 0 = 1097 | 1 = 1075\n",
      "acc=0.8564|precision=0.8397|recall=0.8772|f1=0.8581|auc=0.9279|aupr=0.9226|pos_acc=0.8772|neg_acc=0.8742\n",
      "----------------------- Fold =  3\n",
      "Train on 8688 samples, validate on 2172 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4012 - binary_accuracy: 0.8131 - f1: 0.7790 - recall: 0.7682 - precision: 0.8247 - val_loss: 0.3694 - val_binary_accuracy: 0.8320 - val_f1: 0.7494 - val_recall: 0.6995 - val_precision: 0.8250\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3463 - binary_accuracy: 0.8470 - f1: 0.8436 - recall: 0.8382 - precision: 0.8521 - val_loss: 0.3816 - val_binary_accuracy: 0.8227 - val_f1: 0.7314 - val_recall: 0.6608 - val_precision: 0.8454\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3390 - binary_accuracy: 0.8511 - f1: 0.8480 - recall: 0.8459 - precision: 0.8532 - val_loss: 0.3471 - val_binary_accuracy: 0.8471 - val_f1: 0.8234 - val_recall: 0.8418 - val_precision: 0.8068\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3326 - binary_accuracy: 0.8554 - f1: 0.8533 - recall: 0.8545 - precision: 0.8554 - val_loss: 0.3454 - val_binary_accuracy: 0.8467 - val_f1: 0.8006 - val_recall: 0.7658 - val_precision: 0.8604\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3282 - binary_accuracy: 0.8602 - f1: 0.8580 - recall: 0.8603 - precision: 0.8581 - val_loss: 0.3410 - val_binary_accuracy: 0.8517 - val_f1: 0.8251 - val_recall: 0.8001 - val_precision: 0.8562\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3234 - binary_accuracy: 0.8570 - f1: 0.8549 - recall: 0.8557 - precision: 0.8558 - val_loss: 0.3604 - val_binary_accuracy: 0.8361 - val_f1: 0.7547 - val_recall: 0.7269 - val_precision: 0.8179\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3279 - binary_accuracy: 0.8549 - f1: 0.8524 - recall: 0.8522 - precision: 0.8567 - val_loss: 0.3368 - val_binary_accuracy: 0.8541 - val_f1: 0.8275 - val_recall: 0.8135 - val_precision: 0.8472\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3205 - binary_accuracy: 0.8610 - f1: 0.8591 - recall: 0.8621 - precision: 0.8573 - val_loss: 0.3346 - val_binary_accuracy: 0.8550 - val_f1: 0.8304 - val_recall: 0.8291 - val_precision: 0.8343\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3165 - binary_accuracy: 0.8620 - f1: 0.8606 - recall: 0.8640 - precision: 0.8586 - val_loss: 0.3324 - val_binary_accuracy: 0.8587 - val_f1: 0.8360 - val_recall: 0.8355 - val_precision: 0.8428\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3153 - binary_accuracy: 0.8628 - f1: 0.8610 - recall: 0.8627 - precision: 0.8608 - val_loss: 0.3336 - val_binary_accuracy: 0.8577 - val_f1: 0.8341 - val_recall: 0.8292 - val_precision: 0.8410\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3125 - binary_accuracy: 0.8626 - f1: 0.8611 - recall: 0.8634 - precision: 0.8599 - val_loss: 0.3473 - val_binary_accuracy: 0.8462 - val_f1: 0.7755 - val_recall: 0.7362 - val_precision: 0.8318\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3143 - binary_accuracy: 0.8604 - f1: 0.8584 - recall: 0.8591 - precision: 0.8601 - val_loss: 0.3377 - val_binary_accuracy: 0.8582 - val_f1: 0.8093 - val_recall: 0.7967 - val_precision: 0.8528\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3111 - binary_accuracy: 0.8630 - f1: 0.8618 - recall: 0.8659 - precision: 0.8595 - val_loss: 0.3537 - val_binary_accuracy: 0.8425 - val_f1: 0.7626 - val_recall: 0.7110 - val_precision: 0.8418\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3108 - binary_accuracy: 0.8645 - f1: 0.8627 - recall: 0.8642 - precision: 0.8628 - val_loss: 0.3325 - val_binary_accuracy: 0.8536 - val_f1: 0.8231 - val_recall: 0.8307 - val_precision: 0.8283\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3078 - binary_accuracy: 0.8677 - f1: 0.8661 - recall: 0.8682 - precision: 0.8659 - val_loss: 0.3315 - val_binary_accuracy: 0.8573 - val_f1: 0.8239 - val_recall: 0.8074 - val_precision: 0.8507\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3115 - binary_accuracy: 0.8650 - f1: 0.8632 - recall: 0.8652 - precision: 0.8645 - val_loss: 0.3474 - val_binary_accuracy: 0.8485 - val_f1: 0.7966 - val_recall: 0.8076 - val_precision: 0.8203\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3077 - binary_accuracy: 0.8635 - f1: 0.8614 - recall: 0.8624 - precision: 0.8615 - val_loss: 0.3352 - val_binary_accuracy: 0.8559 - val_f1: 0.8271 - val_recall: 0.8104 - val_precision: 0.8469\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3066 - binary_accuracy: 0.8656 - f1: 0.8637 - recall: 0.8636 - precision: 0.8662 - val_loss: 0.3310 - val_binary_accuracy: 0.8614 - val_f1: 0.8337 - val_recall: 0.8245 - val_precision: 0.8505\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3007 - binary_accuracy: 0.8690 - f1: 0.8674 - recall: 0.8679 - precision: 0.8679 - val_loss: 0.3327 - val_binary_accuracy: 0.8582 - val_f1: 0.8237 - val_recall: 0.8095 - val_precision: 0.8519\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3041 - binary_accuracy: 0.8691 - f1: 0.8678 - recall: 0.8733 - precision: 0.8646 - val_loss: 0.3368 - val_binary_accuracy: 0.8568 - val_f1: 0.8165 - val_recall: 0.7888 - val_precision: 0.8593\n",
      "Epoch 21/500\n",
      "0s - loss: 0.2994 - binary_accuracy: 0.8691 - f1: 0.8668 - recall: 0.8659 - precision: 0.8690 - val_loss: 0.3360 - val_binary_accuracy: 0.8545 - val_f1: 0.8024 - val_recall: 0.7817 - val_precision: 0.8482\n",
      "Epoch 22/500\n",
      "0s - loss: 0.2986 - binary_accuracy: 0.8707 - f1: 0.8694 - recall: 0.8711 - precision: 0.8692 - val_loss: 0.3336 - val_binary_accuracy: 0.8568 - val_f1: 0.8030 - val_recall: 0.7742 - val_precision: 0.8550\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3069 - binary_accuracy: 0.8656 - f1: 0.8634 - recall: 0.8638 - precision: 0.8673 - val_loss: 0.3291 - val_binary_accuracy: 0.8596 - val_f1: 0.8144 - val_recall: 0.7985 - val_precision: 0.8504\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3017 - binary_accuracy: 0.8671 - f1: 0.8645 - recall: 0.8634 - precision: 0.8674 - val_loss: 0.3374 - val_binary_accuracy: 0.8559 - val_f1: 0.8079 - val_recall: 0.7839 - val_precision: 0.8572\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2966 - binary_accuracy: 0.8696 - f1: 0.8676 - recall: 0.8705 - precision: 0.8662 - val_loss: 0.3292 - val_binary_accuracy: 0.8577 - val_f1: 0.8266 - val_recall: 0.8243 - val_precision: 0.8410\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2988 - binary_accuracy: 0.8681 - f1: 0.8659 - recall: 0.8649 - precision: 0.8691 - val_loss: 0.3298 - val_binary_accuracy: 0.8610 - val_f1: 0.8316 - val_recall: 0.8202 - val_precision: 0.8483\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2959 - binary_accuracy: 0.8694 - f1: 0.8685 - recall: 0.8739 - precision: 0.8648 - val_loss: 0.3386 - val_binary_accuracy: 0.8545 - val_f1: 0.8076 - val_recall: 0.7696 - val_precision: 0.8681\n",
      "Epoch 28/500\n",
      "0s - loss: 0.3005 - binary_accuracy: 0.8666 - f1: 0.8642 - recall: 0.8636 - precision: 0.8683 - val_loss: 0.3396 - val_binary_accuracy: 0.8513 - val_f1: 0.8314 - val_recall: 0.8685 - val_precision: 0.8024\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2922 - binary_accuracy: 0.8706 - f1: 0.8688 - recall: 0.8706 - precision: 0.8695 - val_loss: 0.3336 - val_binary_accuracy: 0.8610 - val_f1: 0.8175 - val_recall: 0.7882 - val_precision: 0.8660\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2906 - binary_accuracy: 0.8718 - f1: 0.8708 - recall: 0.8743 - precision: 0.8688 - val_loss: 0.3348 - val_binary_accuracy: 0.8541 - val_f1: 0.7960 - val_recall: 0.7580 - val_precision: 0.8692\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2908 - binary_accuracy: 0.8730 - f1: 0.8710 - recall: 0.8698 - precision: 0.8746 - val_loss: 0.3292 - val_binary_accuracy: 0.8600 - val_f1: 0.8167 - val_recall: 0.7927 - val_precision: 0.8570\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2899 - binary_accuracy: 0.8745 - f1: 0.8724 - recall: 0.8729 - precision: 0.8739 - val_loss: 0.3465 - val_binary_accuracy: 0.8568 - val_f1: 0.8007 - val_recall: 0.7672 - val_precision: 0.8604\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2913 - binary_accuracy: 0.8705 - f1: 0.8692 - recall: 0.8718 - precision: 0.8691 - val_loss: 0.3340 - val_binary_accuracy: 0.8573 - val_f1: 0.8275 - val_recall: 0.8097 - val_precision: 0.8491\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2884 - binary_accuracy: 0.8729 - f1: 0.8710 - recall: 0.8703 - precision: 0.8732 - val_loss: 0.3421 - val_binary_accuracy: 0.8513 - val_f1: 0.7944 - val_recall: 0.7525 - val_precision: 0.8715\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2902 - binary_accuracy: 0.8736 - f1: 0.8718 - recall: 0.8729 - precision: 0.8728 - val_loss: 0.3320 - val_binary_accuracy: 0.8564 - val_f1: 0.8261 - val_recall: 0.8403 - val_precision: 0.8276\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2893 - binary_accuracy: 0.8747 - f1: 0.8731 - recall: 0.8745 - precision: 0.8735 - val_loss: 0.3424 - val_binary_accuracy: 0.8550 - val_f1: 0.8212 - val_recall: 0.7885 - val_precision: 0.8628\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2854 - binary_accuracy: 0.8747 - f1: 0.8735 - recall: 0.8776 - precision: 0.8708 - val_loss: 0.3263 - val_binary_accuracy: 0.8642 - val_f1: 0.8350 - val_recall: 0.8225 - val_precision: 0.8519\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2799 - binary_accuracy: 0.8793 - f1: 0.8772 - recall: 0.8759 - precision: 0.8796 - val_loss: 0.3398 - val_binary_accuracy: 0.8541 - val_f1: 0.7995 - val_recall: 0.7591 - val_precision: 0.8738\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2815 - binary_accuracy: 0.8749 - f1: 0.8733 - recall: 0.8760 - precision: 0.8724 - val_loss: 0.3368 - val_binary_accuracy: 0.8550 - val_f1: 0.8254 - val_recall: 0.8310 - val_precision: 0.8301\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2831 - binary_accuracy: 0.8750 - f1: 0.8733 - recall: 0.8731 - precision: 0.8752 - val_loss: 0.3289 - val_binary_accuracy: 0.8610 - val_f1: 0.8256 - val_recall: 0.8071 - val_precision: 0.8512\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2759 - binary_accuracy: 0.8814 - f1: 0.8793 - recall: 0.8780 - precision: 0.8825 - val_loss: 0.3288 - val_binary_accuracy: 0.8619 - val_f1: 0.8399 - val_recall: 0.8349 - val_precision: 0.8462\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2790 - binary_accuracy: 0.8796 - f1: 0.8785 - recall: 0.8823 - precision: 0.8766 - val_loss: 0.3326 - val_binary_accuracy: 0.8573 - val_f1: 0.8407 - val_recall: 0.8644 - val_precision: 0.8198\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2806 - binary_accuracy: 0.8767 - f1: 0.8746 - recall: 0.8761 - precision: 0.8768 - val_loss: 0.3534 - val_binary_accuracy: 0.8513 - val_f1: 0.7879 - val_recall: 0.7379 - val_precision: 0.8986\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2760 - binary_accuracy: 0.8788 - f1: 0.8771 - recall: 0.8749 - precision: 0.8809 - val_loss: 0.3275 - val_binary_accuracy: 0.8596 - val_f1: 0.8169 - val_recall: 0.7912 - val_precision: 0.8671\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2701 - binary_accuracy: 0.8829 - f1: 0.8811 - recall: 0.8823 - precision: 0.8815 - val_loss: 0.3309 - val_binary_accuracy: 0.8623 - val_f1: 0.8353 - val_recall: 0.8176 - val_precision: 0.8554\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2726 - binary_accuracy: 0.8833 - f1: 0.8812 - recall: 0.8802 - precision: 0.8844 - val_loss: 0.3312 - val_binary_accuracy: 0.8573 - val_f1: 0.8334 - val_recall: 0.8594 - val_precision: 0.8129\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2709 - binary_accuracy: 0.8834 - f1: 0.8813 - recall: 0.8837 - precision: 0.8809 - val_loss: 0.3562 - val_binary_accuracy: 0.8536 - val_f1: 0.7976 - val_recall: 0.7584 - val_precision: 0.8711\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2696 - binary_accuracy: 0.8826 - f1: 0.8806 - recall: 0.8786 - precision: 0.8853 - val_loss: 0.3292 - val_binary_accuracy: 0.8554 - val_f1: 0.8277 - val_recall: 0.8392 - val_precision: 0.8258\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2682 - binary_accuracy: 0.8835 - f1: 0.8823 - recall: 0.8859 - precision: 0.8803 - val_loss: 0.3296 - val_binary_accuracy: 0.8651 - val_f1: 0.8381 - val_recall: 0.8229 - val_precision: 0.8583\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2665 - binary_accuracy: 0.8854 - f1: 0.8837 - recall: 0.8843 - precision: 0.8848 - val_loss: 0.3333 - val_binary_accuracy: 0.8633 - val_f1: 0.8199 - val_recall: 0.7812 - val_precision: 0.8919\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2681 - binary_accuracy: 0.8869 - f1: 0.8853 - recall: 0.8868 - precision: 0.8851 - val_loss: 0.3488 - val_binary_accuracy: 0.8559 - val_f1: 0.7978 - val_recall: 0.7536 - val_precision: 0.8667\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2640 - binary_accuracy: 0.8839 - f1: 0.8828 - recall: 0.8846 - precision: 0.8828 - val_loss: 0.3385 - val_binary_accuracy: 0.8619 - val_f1: 0.8167 - val_recall: 0.7845 - val_precision: 0.8661\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2646 - binary_accuracy: 0.8854 - f1: 0.8838 - recall: 0.8878 - precision: 0.8812 - val_loss: 0.3334 - val_binary_accuracy: 0.8605 - val_f1: 0.8236 - val_recall: 0.8036 - val_precision: 0.8541\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2608 - binary_accuracy: 0.8872 - f1: 0.8851 - recall: 0.8851 - precision: 0.8871 - val_loss: 0.3344 - val_binary_accuracy: 0.8614 - val_f1: 0.8337 - val_recall: 0.8359 - val_precision: 0.8404\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2588 - binary_accuracy: 0.8901 - f1: 0.8886 - recall: 0.8900 - precision: 0.8889 - val_loss: 0.3289 - val_binary_accuracy: 0.8614 - val_f1: 0.8273 - val_recall: 0.8172 - val_precision: 0.8513\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2548 - binary_accuracy: 0.8920 - f1: 0.8907 - recall: 0.8954 - precision: 0.8872 - val_loss: 0.3430 - val_binary_accuracy: 0.8564 - val_f1: 0.8041 - val_recall: 0.7532 - val_precision: 0.8979\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2539 - binary_accuracy: 0.8918 - f1: 0.8906 - recall: 0.8894 - precision: 0.8935 - val_loss: 0.3276 - val_binary_accuracy: 0.8651 - val_f1: 0.8452 - val_recall: 0.8483 - val_precision: 0.8452\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2514 - binary_accuracy: 0.8933 - f1: 0.8919 - recall: 0.8931 - precision: 0.8918 - val_loss: 0.3303 - val_binary_accuracy: 0.8646 - val_f1: 0.8267 - val_recall: 0.7927 - val_precision: 0.8815\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2535 - binary_accuracy: 0.8895 - f1: 0.8880 - recall: 0.8887 - precision: 0.8889 - val_loss: 0.3497 - val_binary_accuracy: 0.8550 - val_f1: 0.8036 - val_recall: 0.7540 - val_precision: 0.8840\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2534 - binary_accuracy: 0.8904 - f1: 0.8892 - recall: 0.8908 - precision: 0.8886 - val_loss: 0.3276 - val_binary_accuracy: 0.8651 - val_f1: 0.8410 - val_recall: 0.8367 - val_precision: 0.8512\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2536 - binary_accuracy: 0.8934 - f1: 0.8921 - recall: 0.8949 - precision: 0.8902 - val_loss: 0.3384 - val_binary_accuracy: 0.8637 - val_f1: 0.8311 - val_recall: 0.8097 - val_precision: 0.8582\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2505 - binary_accuracy: 0.8919 - f1: 0.8904 - recall: 0.8898 - precision: 0.8924 - val_loss: 0.3301 - val_binary_accuracy: 0.8628 - val_f1: 0.8428 - val_recall: 0.8576 - val_precision: 0.8299\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2510 - binary_accuracy: 0.8932 - f1: 0.8919 - recall: 0.8922 - precision: 0.8936 - val_loss: 0.3528 - val_binary_accuracy: 0.8587 - val_f1: 0.8095 - val_recall: 0.7857 - val_precision: 0.8760\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2501 - binary_accuracy: 0.8920 - f1: 0.8904 - recall: 0.8897 - precision: 0.8929 - val_loss: 0.3317 - val_binary_accuracy: 0.8688 - val_f1: 0.8497 - val_recall: 0.8574 - val_precision: 0.8445\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2472 - binary_accuracy: 0.8922 - f1: 0.8902 - recall: 0.8914 - precision: 0.8911 - val_loss: 0.3376 - val_binary_accuracy: 0.8577 - val_f1: 0.8160 - val_recall: 0.7735 - val_precision: 0.8802\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2521 - binary_accuracy: 0.8904 - f1: 0.8891 - recall: 0.8904 - precision: 0.8904 - val_loss: 0.3598 - val_binary_accuracy: 0.8591 - val_f1: 0.8214 - val_recall: 0.7830 - val_precision: 0.8727\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2486 - binary_accuracy: 0.8945 - f1: 0.8925 - recall: 0.8880 - precision: 0.8999 - val_loss: 0.3505 - val_binary_accuracy: 0.8467 - val_f1: 0.8275 - val_recall: 0.8822 - val_precision: 0.7822\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2512 - binary_accuracy: 0.8885 - f1: 0.8869 - recall: 0.8879 - precision: 0.8889 - val_loss: 0.3306 - val_binary_accuracy: 0.8688 - val_f1: 0.8400 - val_recall: 0.8141 - val_precision: 0.8748\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2391 - binary_accuracy: 0.8992 - f1: 0.8979 - recall: 0.8976 - precision: 0.8995 - val_loss: 0.3435 - val_binary_accuracy: 0.8577 - val_f1: 0.8233 - val_recall: 0.7809 - val_precision: 0.8788\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2498 - binary_accuracy: 0.8928 - f1: 0.8908 - recall: 0.8893 - precision: 0.8939 - val_loss: 0.3377 - val_binary_accuracy: 0.8633 - val_f1: 0.8372 - val_recall: 0.8339 - val_precision: 0.8451\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2412 - binary_accuracy: 0.8977 - f1: 0.8957 - recall: 0.8935 - precision: 0.8997 - val_loss: 0.3442 - val_binary_accuracy: 0.8559 - val_f1: 0.8048 - val_recall: 0.7651 - val_precision: 0.8885\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2319 - binary_accuracy: 0.9025 - f1: 0.9009 - recall: 0.8994 - precision: 0.9039 - val_loss: 0.3368 - val_binary_accuracy: 0.8683 - val_f1: 0.8500 - val_recall: 0.8408 - val_precision: 0.8633\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2349 - binary_accuracy: 0.8991 - f1: 0.8976 - recall: 0.8977 - precision: 0.8995 - val_loss: 0.3348 - val_binary_accuracy: 0.8633 - val_f1: 0.8402 - val_recall: 0.8245 - val_precision: 0.8693\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2296 - binary_accuracy: 0.9035 - f1: 0.9018 - recall: 0.8991 - precision: 0.9059 - val_loss: 0.3342 - val_binary_accuracy: 0.8614 - val_f1: 0.8215 - val_recall: 0.7919 - val_precision: 0.8831\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2285 - binary_accuracy: 0.9040 - f1: 0.9022 - recall: 0.9014 - precision: 0.9041 - val_loss: 0.3361 - val_binary_accuracy: 0.8692 - val_f1: 0.8443 - val_recall: 0.8165 - val_precision: 0.8895\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2266 - binary_accuracy: 0.9062 - f1: 0.9045 - recall: 0.9034 - precision: 0.9068 - val_loss: 0.3403 - val_binary_accuracy: 0.8605 - val_f1: 0.8252 - val_recall: 0.8031 - val_precision: 0.8643\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2257 - binary_accuracy: 0.9052 - f1: 0.9028 - recall: 0.8995 - precision: 0.9077 - val_loss: 0.3345 - val_binary_accuracy: 0.8656 - val_f1: 0.8375 - val_recall: 0.8194 - val_precision: 0.8713\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2298 - binary_accuracy: 0.9050 - f1: 0.9033 - recall: 0.9029 - precision: 0.9053 - val_loss: 0.3334 - val_binary_accuracy: 0.8610 - val_f1: 0.8280 - val_recall: 0.8160 - val_precision: 0.8573\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2284 - binary_accuracy: 0.9034 - f1: 0.9017 - recall: 0.8986 - precision: 0.9064 - val_loss: 0.3349 - val_binary_accuracy: 0.8688 - val_f1: 0.8472 - val_recall: 0.8365 - val_precision: 0.8632\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2226 - binary_accuracy: 0.9054 - f1: 0.9040 - recall: 0.9040 - precision: 0.9046 - val_loss: 0.3399 - val_binary_accuracy: 0.8642 - val_f1: 0.8232 - val_recall: 0.7981 - val_precision: 0.8820\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2181 - binary_accuracy: 0.9092 - f1: 0.9074 - recall: 0.9035 - precision: 0.9123 - val_loss: 0.3423 - val_binary_accuracy: 0.8679 - val_f1: 0.8360 - val_recall: 0.8121 - val_precision: 0.8843\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2203 - binary_accuracy: 0.9087 - f1: 0.9069 - recall: 0.9058 - precision: 0.9092 - val_loss: 0.3519 - val_binary_accuracy: 0.8646 - val_f1: 0.8356 - val_recall: 0.8061 - val_precision: 0.8866\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2162 - binary_accuracy: 0.9110 - f1: 0.9094 - recall: 0.9059 - precision: 0.9142 - val_loss: 0.3356 - val_binary_accuracy: 0.8674 - val_f1: 0.8464 - val_recall: 0.8315 - val_precision: 0.8686\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2137 - binary_accuracy: 0.9093 - f1: 0.9077 - recall: 0.9066 - precision: 0.9101 - val_loss: 0.3674 - val_binary_accuracy: 0.8559 - val_f1: 0.8100 - val_recall: 0.7653 - val_precision: 0.8838\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2149 - binary_accuracy: 0.9119 - f1: 0.9107 - recall: 0.9108 - precision: 0.9122 - val_loss: 0.3503 - val_binary_accuracy: 0.8550 - val_f1: 0.8138 - val_recall: 0.7742 - val_precision: 0.8747\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2157 - binary_accuracy: 0.9075 - f1: 0.9058 - recall: 0.9060 - precision: 0.9073 - val_loss: 0.3361 - val_binary_accuracy: 0.8656 - val_f1: 0.8395 - val_recall: 0.8229 - val_precision: 0.8677\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2162 - binary_accuracy: 0.9079 - f1: 0.9065 - recall: 0.9066 - precision: 0.9086 - val_loss: 0.3402 - val_binary_accuracy: 0.8669 - val_f1: 0.8335 - val_recall: 0.8187 - val_precision: 0.8748\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2133 - binary_accuracy: 0.9105 - f1: 0.9088 - recall: 0.9062 - precision: 0.9132 - val_loss: 0.3476 - val_binary_accuracy: 0.8614 - val_f1: 0.8382 - val_recall: 0.8253 - val_precision: 0.8536\n",
      "1856/2172 [========================>.....] - ETA: 0stn = 4025, fp = 366, fn = 381, tp = 3916\n",
      "y_pred: 0 = 4406 | 1 = 4282\n",
      "y_true: 0 = 4391 | 1 = 4297\n",
      "acc=0.9140|precision=0.9145|recall=0.9113|f1=0.9129|auc=0.9740|aupr=0.9747|pos_acc=0.9113|neg_acc=0.9135\n",
      "tn = 895, fp = 144, fn = 157, tp = 976\n",
      "y_pred: 0 = 1052 | 1 = 1120\n",
      "y_true: 0 = 1039 | 1 = 1133\n",
      "acc=0.8614|precision=0.8714|recall=0.8614|f1=0.8664|auc=0.9357|aupr=0.9354|pos_acc=0.8614|neg_acc=0.8508\n",
      "----------------------- Fold =  4\n",
      "Train on 8688 samples, validate on 2172 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4084 - binary_accuracy: 0.8113 - f1: 0.8032 - recall: 0.7911 - precision: 0.8365 - val_loss: 0.3642 - val_binary_accuracy: 0.8356 - val_f1: 0.7888 - val_recall: 0.8141 - val_precision: 0.7671\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3471 - binary_accuracy: 0.8473 - f1: 0.8465 - recall: 0.8434 - precision: 0.8517 - val_loss: 0.3574 - val_binary_accuracy: 0.8430 - val_f1: 0.7987 - val_recall: 0.8165 - val_precision: 0.7844\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3414 - binary_accuracy: 0.8521 - f1: 0.8524 - recall: 0.8531 - precision: 0.8551 - val_loss: 0.3542 - val_binary_accuracy: 0.8430 - val_f1: 0.7581 - val_recall: 0.7075 - val_precision: 0.8433\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3411 - binary_accuracy: 0.8498 - f1: 0.8494 - recall: 0.8498 - precision: 0.8540 - val_loss: 0.3575 - val_binary_accuracy: 0.8412 - val_f1: 0.7171 - val_recall: 0.6620 - val_precision: 0.8688\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3335 - binary_accuracy: 0.8573 - f1: 0.8573 - recall: 0.8606 - precision: 0.8580 - val_loss: 0.3442 - val_binary_accuracy: 0.8499 - val_f1: 0.7658 - val_recall: 0.7187 - val_precision: 0.8619\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3305 - binary_accuracy: 0.8519 - f1: 0.8517 - recall: 0.8524 - precision: 0.8544 - val_loss: 0.3395 - val_binary_accuracy: 0.8517 - val_f1: 0.8090 - val_recall: 0.8201 - val_precision: 0.8018\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3248 - binary_accuracy: 0.8611 - f1: 0.8614 - recall: 0.8650 - precision: 0.8601 - val_loss: 0.3356 - val_binary_accuracy: 0.8527 - val_f1: 0.7915 - val_recall: 0.7684 - val_precision: 0.8312\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3229 - binary_accuracy: 0.8611 - f1: 0.8610 - recall: 0.8629 - precision: 0.8618 - val_loss: 0.3329 - val_binary_accuracy: 0.8554 - val_f1: 0.7933 - val_recall: 0.7754 - val_precision: 0.8297\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3234 - binary_accuracy: 0.8575 - f1: 0.8578 - recall: 0.8609 - precision: 0.8581 - val_loss: 0.3385 - val_binary_accuracy: 0.8485 - val_f1: 0.7877 - val_recall: 0.7630 - val_precision: 0.8254\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3166 - binary_accuracy: 0.8643 - f1: 0.8644 - recall: 0.8668 - precision: 0.8639 - val_loss: 0.3452 - val_binary_accuracy: 0.8430 - val_f1: 0.7255 - val_recall: 0.6636 - val_precision: 0.8724\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3155 - binary_accuracy: 0.8631 - f1: 0.8636 - recall: 0.8672 - precision: 0.8615 - val_loss: 0.3418 - val_binary_accuracy: 0.8527 - val_f1: 0.8188 - val_recall: 0.8422 - val_precision: 0.7979\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3139 - binary_accuracy: 0.8643 - f1: 0.8648 - recall: 0.8702 - precision: 0.8613 - val_loss: 0.3449 - val_binary_accuracy: 0.8471 - val_f1: 0.7816 - val_recall: 0.7248 - val_precision: 0.8611\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3206 - binary_accuracy: 0.8613 - f1: 0.8607 - recall: 0.8630 - precision: 0.8622 - val_loss: 0.3454 - val_binary_accuracy: 0.8517 - val_f1: 0.7549 - val_recall: 0.7098 - val_precision: 0.8644\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3117 - binary_accuracy: 0.8644 - f1: 0.8652 - recall: 0.8718 - precision: 0.8612 - val_loss: 0.3301 - val_binary_accuracy: 0.8513 - val_f1: 0.7860 - val_recall: 0.7500 - val_precision: 0.8409\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3098 - binary_accuracy: 0.8650 - f1: 0.8652 - recall: 0.8669 - precision: 0.8655 - val_loss: 0.3328 - val_binary_accuracy: 0.8490 - val_f1: 0.7806 - val_recall: 0.7719 - val_precision: 0.8268\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3087 - binary_accuracy: 0.8641 - f1: 0.8656 - recall: 0.8732 - precision: 0.8602 - val_loss: 0.3326 - val_binary_accuracy: 0.8559 - val_f1: 0.7889 - val_recall: 0.7688 - val_precision: 0.8330\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3057 - binary_accuracy: 0.8666 - f1: 0.8673 - recall: 0.8721 - precision: 0.8638 - val_loss: 0.3347 - val_binary_accuracy: 0.8517 - val_f1: 0.8052 - val_recall: 0.7947 - val_precision: 0.8193\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3064 - binary_accuracy: 0.8671 - f1: 0.8676 - recall: 0.8717 - precision: 0.8647 - val_loss: 0.3396 - val_binary_accuracy: 0.8517 - val_f1: 0.7508 - val_recall: 0.7142 - val_precision: 0.8564\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3085 - binary_accuracy: 0.8665 - f1: 0.8666 - recall: 0.8687 - precision: 0.8658 - val_loss: 0.3407 - val_binary_accuracy: 0.8550 - val_f1: 0.7830 - val_recall: 0.7445 - val_precision: 0.8528\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3079 - binary_accuracy: 0.8676 - f1: 0.8673 - recall: 0.8665 - precision: 0.8710 - val_loss: 0.3309 - val_binary_accuracy: 0.8522 - val_f1: 0.8091 - val_recall: 0.8091 - val_precision: 0.8202\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3031 - binary_accuracy: 0.8683 - f1: 0.8693 - recall: 0.8752 - precision: 0.8652 - val_loss: 0.3342 - val_binary_accuracy: 0.8481 - val_f1: 0.8110 - val_recall: 0.8184 - val_precision: 0.8055\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3027 - binary_accuracy: 0.8684 - f1: 0.8689 - recall: 0.8716 - precision: 0.8675 - val_loss: 0.3308 - val_binary_accuracy: 0.8490 - val_f1: 0.7651 - val_recall: 0.7495 - val_precision: 0.8299\n",
      "Epoch 23/500\n",
      "0s - loss: 0.2984 - binary_accuracy: 0.8730 - f1: 0.8732 - recall: 0.8751 - precision: 0.8727 - val_loss: 0.3316 - val_binary_accuracy: 0.8545 - val_f1: 0.8050 - val_recall: 0.8054 - val_precision: 0.8101\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3021 - binary_accuracy: 0.8699 - f1: 0.8701 - recall: 0.8737 - precision: 0.8683 - val_loss: 0.3476 - val_binary_accuracy: 0.8421 - val_f1: 0.8089 - val_recall: 0.8427 - val_precision: 0.7809\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2974 - binary_accuracy: 0.8714 - f1: 0.8721 - recall: 0.8761 - precision: 0.8703 - val_loss: 0.3295 - val_binary_accuracy: 0.8517 - val_f1: 0.8074 - val_recall: 0.8104 - val_precision: 0.8087\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2951 - binary_accuracy: 0.8714 - f1: 0.8720 - recall: 0.8771 - precision: 0.8681 - val_loss: 0.3251 - val_binary_accuracy: 0.8536 - val_f1: 0.8027 - val_recall: 0.7913 - val_precision: 0.8284\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2965 - binary_accuracy: 0.8710 - f1: 0.8712 - recall: 0.8747 - precision: 0.8698 - val_loss: 0.3299 - val_binary_accuracy: 0.8494 - val_f1: 0.7917 - val_recall: 0.7612 - val_precision: 0.8408\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2958 - binary_accuracy: 0.8753 - f1: 0.8761 - recall: 0.8818 - precision: 0.8724 - val_loss: 0.3318 - val_binary_accuracy: 0.8541 - val_f1: 0.8237 - val_recall: 0.8270 - val_precision: 0.8220\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2918 - binary_accuracy: 0.8729 - f1: 0.8733 - recall: 0.8778 - precision: 0.8699 - val_loss: 0.3300 - val_binary_accuracy: 0.8508 - val_f1: 0.8083 - val_recall: 0.8079 - val_precision: 0.8115\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2971 - binary_accuracy: 0.8730 - f1: 0.8724 - recall: 0.8716 - precision: 0.8763 - val_loss: 0.3521 - val_binary_accuracy: 0.8439 - val_f1: 0.8180 - val_recall: 0.8768 - val_precision: 0.7680\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2973 - binary_accuracy: 0.8720 - f1: 0.8724 - recall: 0.8783 - precision: 0.8684 - val_loss: 0.3300 - val_binary_accuracy: 0.8531 - val_f1: 0.8110 - val_recall: 0.8150 - val_precision: 0.8124\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2923 - binary_accuracy: 0.8741 - f1: 0.8744 - recall: 0.8793 - precision: 0.8710 - val_loss: 0.3332 - val_binary_accuracy: 0.8522 - val_f1: 0.8068 - val_recall: 0.7991 - val_precision: 0.8177\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2899 - binary_accuracy: 0.8764 - f1: 0.8766 - recall: 0.8801 - precision: 0.8752 - val_loss: 0.3358 - val_binary_accuracy: 0.8485 - val_f1: 0.7807 - val_recall: 0.7321 - val_precision: 0.8577\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2895 - binary_accuracy: 0.8773 - f1: 0.8776 - recall: 0.8815 - precision: 0.8758 - val_loss: 0.3296 - val_binary_accuracy: 0.8554 - val_f1: 0.8084 - val_recall: 0.7994 - val_precision: 0.8256\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2888 - binary_accuracy: 0.8742 - f1: 0.8738 - recall: 0.8740 - precision: 0.8752 - val_loss: 0.3306 - val_binary_accuracy: 0.8545 - val_f1: 0.8231 - val_recall: 0.8350 - val_precision: 0.8161\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2839 - binary_accuracy: 0.8773 - f1: 0.8775 - recall: 0.8816 - precision: 0.8750 - val_loss: 0.3271 - val_binary_accuracy: 0.8476 - val_f1: 0.7831 - val_recall: 0.7721 - val_precision: 0.8216\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2812 - binary_accuracy: 0.8803 - f1: 0.8804 - recall: 0.8809 - precision: 0.8808 - val_loss: 0.3416 - val_binary_accuracy: 0.8508 - val_f1: 0.8149 - val_recall: 0.8235 - val_precision: 0.8176\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2876 - binary_accuracy: 0.8738 - f1: 0.8742 - recall: 0.8790 - precision: 0.8709 - val_loss: 0.3408 - val_binary_accuracy: 0.8554 - val_f1: 0.8013 - val_recall: 0.7785 - val_precision: 0.8351\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2800 - binary_accuracy: 0.8802 - f1: 0.8807 - recall: 0.8842 - precision: 0.8780 - val_loss: 0.3298 - val_binary_accuracy: 0.8541 - val_f1: 0.7917 - val_recall: 0.7612 - val_precision: 0.8474\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2775 - binary_accuracy: 0.8804 - f1: 0.8805 - recall: 0.8823 - precision: 0.8801 - val_loss: 0.3253 - val_binary_accuracy: 0.8536 - val_f1: 0.8055 - val_recall: 0.8015 - val_precision: 0.8244\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2779 - binary_accuracy: 0.8798 - f1: 0.8799 - recall: 0.8856 - precision: 0.8763 - val_loss: 0.3261 - val_binary_accuracy: 0.8554 - val_f1: 0.8061 - val_recall: 0.7875 - val_precision: 0.8372\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2847 - binary_accuracy: 0.8768 - f1: 0.8768 - recall: 0.8755 - precision: 0.8801 - val_loss: 0.3307 - val_binary_accuracy: 0.8467 - val_f1: 0.8172 - val_recall: 0.8435 - val_precision: 0.7943\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2816 - binary_accuracy: 0.8812 - f1: 0.8813 - recall: 0.8833 - precision: 0.8808 - val_loss: 0.3347 - val_binary_accuracy: 0.8527 - val_f1: 0.7607 - val_recall: 0.7204 - val_precision: 0.8570\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2759 - binary_accuracy: 0.8799 - f1: 0.8806 - recall: 0.8865 - precision: 0.8763 - val_loss: 0.3295 - val_binary_accuracy: 0.8517 - val_f1: 0.8187 - val_recall: 0.8463 - val_precision: 0.7943\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2704 - binary_accuracy: 0.8851 - f1: 0.8856 - recall: 0.8905 - precision: 0.8817 - val_loss: 0.3258 - val_binary_accuracy: 0.8494 - val_f1: 0.8055 - val_recall: 0.7951 - val_precision: 0.8200\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2738 - binary_accuracy: 0.8812 - f1: 0.8813 - recall: 0.8853 - precision: 0.8793 - val_loss: 0.3384 - val_binary_accuracy: 0.8481 - val_f1: 0.7963 - val_recall: 0.7814 - val_precision: 0.8313\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2708 - binary_accuracy: 0.8829 - f1: 0.8829 - recall: 0.8847 - precision: 0.8823 - val_loss: 0.3327 - val_binary_accuracy: 0.8550 - val_f1: 0.8039 - val_recall: 0.7854 - val_precision: 0.8321\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2717 - binary_accuracy: 0.8833 - f1: 0.8836 - recall: 0.8865 - precision: 0.8817 - val_loss: 0.3297 - val_binary_accuracy: 0.8490 - val_f1: 0.8047 - val_recall: 0.8043 - val_precision: 0.8124\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2682 - binary_accuracy: 0.8847 - f1: 0.8851 - recall: 0.8898 - precision: 0.8820 - val_loss: 0.3338 - val_binary_accuracy: 0.8545 - val_f1: 0.8026 - val_recall: 0.7834 - val_precision: 0.8332\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2677 - binary_accuracy: 0.8860 - f1: 0.8861 - recall: 0.8882 - precision: 0.8850 - val_loss: 0.3354 - val_binary_accuracy: 0.8499 - val_f1: 0.8044 - val_recall: 0.7956 - val_precision: 0.8163\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2639 - binary_accuracy: 0.8880 - f1: 0.8886 - recall: 0.8923 - precision: 0.8861 - val_loss: 0.3329 - val_binary_accuracy: 0.8541 - val_f1: 0.8188 - val_recall: 0.8353 - val_precision: 0.8049\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2712 - binary_accuracy: 0.8835 - f1: 0.8840 - recall: 0.8893 - precision: 0.8802 - val_loss: 0.3216 - val_binary_accuracy: 0.8513 - val_f1: 0.8096 - val_recall: 0.7960 - val_precision: 0.8326\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2640 - binary_accuracy: 0.8888 - f1: 0.8888 - recall: 0.8926 - precision: 0.8862 - val_loss: 0.3254 - val_binary_accuracy: 0.8499 - val_f1: 0.8106 - val_recall: 0.8146 - val_precision: 0.8116\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2662 - binary_accuracy: 0.8844 - f1: 0.8856 - recall: 0.8917 - precision: 0.8814 - val_loss: 0.3360 - val_binary_accuracy: 0.8564 - val_f1: 0.8095 - val_recall: 0.7880 - val_precision: 0.8436\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2584 - binary_accuracy: 0.8902 - f1: 0.8907 - recall: 0.8930 - precision: 0.8894 - val_loss: 0.3282 - val_binary_accuracy: 0.8513 - val_f1: 0.7867 - val_recall: 0.7492 - val_precision: 0.8526\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2549 - binary_accuracy: 0.8885 - f1: 0.8886 - recall: 0.8903 - precision: 0.8883 - val_loss: 0.3321 - val_binary_accuracy: 0.8485 - val_f1: 0.8047 - val_recall: 0.7811 - val_precision: 0.8351\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2575 - binary_accuracy: 0.8913 - f1: 0.8919 - recall: 0.8954 - precision: 0.8895 - val_loss: 0.3335 - val_binary_accuracy: 0.8485 - val_f1: 0.7979 - val_recall: 0.7908 - val_precision: 0.8230\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2559 - binary_accuracy: 0.8913 - f1: 0.8913 - recall: 0.8942 - precision: 0.8901 - val_loss: 0.3280 - val_binary_accuracy: 0.8504 - val_f1: 0.7987 - val_recall: 0.7658 - val_precision: 0.8458\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2527 - binary_accuracy: 0.8908 - f1: 0.8913 - recall: 0.8953 - precision: 0.8888 - val_loss: 0.3282 - val_binary_accuracy: 0.8513 - val_f1: 0.8065 - val_recall: 0.8026 - val_precision: 0.8179\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2575 - binary_accuracy: 0.8916 - f1: 0.8914 - recall: 0.8913 - precision: 0.8939 - val_loss: 0.3301 - val_binary_accuracy: 0.8527 - val_f1: 0.8124 - val_recall: 0.8193 - val_precision: 0.8103\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2484 - binary_accuracy: 0.8974 - f1: 0.8974 - recall: 0.9007 - precision: 0.8955 - val_loss: 0.3268 - val_binary_accuracy: 0.8513 - val_f1: 0.8158 - val_recall: 0.8214 - val_precision: 0.8132\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2467 - binary_accuracy: 0.8970 - f1: 0.8971 - recall: 0.9027 - precision: 0.8926 - val_loss: 0.3315 - val_binary_accuracy: 0.8536 - val_f1: 0.8060 - val_recall: 0.7902 - val_precision: 0.8323\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2512 - binary_accuracy: 0.8950 - f1: 0.8952 - recall: 0.8948 - precision: 0.8973 - val_loss: 0.3409 - val_binary_accuracy: 0.8471 - val_f1: 0.8190 - val_recall: 0.8606 - val_precision: 0.7827\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2540 - binary_accuracy: 0.8943 - f1: 0.8947 - recall: 0.9002 - precision: 0.8925 - val_loss: 0.3377 - val_binary_accuracy: 0.8568 - val_f1: 0.7880 - val_recall: 0.7459 - val_precision: 0.8575\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2480 - binary_accuracy: 0.8943 - f1: 0.8948 - recall: 0.8978 - precision: 0.8933 - val_loss: 0.3290 - val_binary_accuracy: 0.8485 - val_f1: 0.7787 - val_recall: 0.7407 - val_precision: 0.8476\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2408 - binary_accuracy: 0.8959 - f1: 0.8956 - recall: 0.8961 - precision: 0.8964 - val_loss: 0.3324 - val_binary_accuracy: 0.8554 - val_f1: 0.8136 - val_recall: 0.8087 - val_precision: 0.8229\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2386 - binary_accuracy: 0.8989 - f1: 0.8993 - recall: 0.9035 - precision: 0.8963 - val_loss: 0.3301 - val_binary_accuracy: 0.8559 - val_f1: 0.8107 - val_recall: 0.7858 - val_precision: 0.8424\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2390 - binary_accuracy: 0.9006 - f1: 0.9003 - recall: 0.9008 - precision: 0.9011 - val_loss: 0.3280 - val_binary_accuracy: 0.8531 - val_f1: 0.8083 - val_recall: 0.7868 - val_precision: 0.8405\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2421 - binary_accuracy: 0.8995 - f1: 0.8998 - recall: 0.9036 - precision: 0.8983 - val_loss: 0.3305 - val_binary_accuracy: 0.8536 - val_f1: 0.8088 - val_recall: 0.7803 - val_precision: 0.8481\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2357 - binary_accuracy: 0.9020 - f1: 0.9020 - recall: 0.9048 - precision: 0.9007 - val_loss: 0.3483 - val_binary_accuracy: 0.8541 - val_f1: 0.7877 - val_recall: 0.7415 - val_precision: 0.8631\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2395 - binary_accuracy: 0.8997 - f1: 0.8996 - recall: 0.9022 - precision: 0.8987 - val_loss: 0.3354 - val_binary_accuracy: 0.8545 - val_f1: 0.7986 - val_recall: 0.7703 - val_precision: 0.8483\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2362 - binary_accuracy: 0.8994 - f1: 0.8998 - recall: 0.9020 - precision: 0.8989 - val_loss: 0.3377 - val_binary_accuracy: 0.8522 - val_f1: 0.8019 - val_recall: 0.7684 - val_precision: 0.8490\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2315 - binary_accuracy: 0.9035 - f1: 0.9035 - recall: 0.9079 - precision: 0.9005 - val_loss: 0.3283 - val_binary_accuracy: 0.8577 - val_f1: 0.8182 - val_recall: 0.8105 - val_precision: 0.8298\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2280 - binary_accuracy: 0.9052 - f1: 0.9051 - recall: 0.9076 - precision: 0.9039 - val_loss: 0.3277 - val_binary_accuracy: 0.8522 - val_f1: 0.8157 - val_recall: 0.8123 - val_precision: 0.8219\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2359 - binary_accuracy: 0.9025 - f1: 0.9026 - recall: 0.9020 - precision: 0.9056 - val_loss: 0.3679 - val_binary_accuracy: 0.8379 - val_f1: 0.8045 - val_recall: 0.8700 - val_precision: 0.7536\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2408 - binary_accuracy: 0.8964 - f1: 0.8971 - recall: 0.9047 - precision: 0.8927 - val_loss: 0.3322 - val_binary_accuracy: 0.8573 - val_f1: 0.8165 - val_recall: 0.7933 - val_precision: 0.8477\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2265 - binary_accuracy: 0.9083 - f1: 0.9082 - recall: 0.9074 - precision: 0.9102 - val_loss: 0.3341 - val_binary_accuracy: 0.8435 - val_f1: 0.8020 - val_recall: 0.7975 - val_precision: 0.8090\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2244 - binary_accuracy: 0.9094 - f1: 0.9097 - recall: 0.9138 - precision: 0.9069 - val_loss: 0.3376 - val_binary_accuracy: 0.8494 - val_f1: 0.8137 - val_recall: 0.8211 - val_precision: 0.8088\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2190 - binary_accuracy: 0.9117 - f1: 0.9119 - recall: 0.9156 - precision: 0.9088 - val_loss: 0.3449 - val_binary_accuracy: 0.8435 - val_f1: 0.7832 - val_recall: 0.7620 - val_precision: 0.8251\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2221 - binary_accuracy: 0.9078 - f1: 0.9078 - recall: 0.9069 - precision: 0.9093 - val_loss: 0.3287 - val_binary_accuracy: 0.8568 - val_f1: 0.8114 - val_recall: 0.8009 - val_precision: 0.8280\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2167 - binary_accuracy: 0.9108 - f1: 0.9110 - recall: 0.9128 - precision: 0.9100 - val_loss: 0.3389 - val_binary_accuracy: 0.8494 - val_f1: 0.8109 - val_recall: 0.8172 - val_precision: 0.8098\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2149 - binary_accuracy: 0.9130 - f1: 0.9132 - recall: 0.9161 - precision: 0.9118 - val_loss: 0.3359 - val_binary_accuracy: 0.8527 - val_f1: 0.8004 - val_recall: 0.7749 - val_precision: 0.8412\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2123 - binary_accuracy: 0.9146 - f1: 0.9142 - recall: 0.9186 - precision: 0.9115 - val_loss: 0.3352 - val_binary_accuracy: 0.8554 - val_f1: 0.8102 - val_recall: 0.7898 - val_precision: 0.8421\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2090 - binary_accuracy: 0.9153 - f1: 0.9155 - recall: 0.9196 - precision: 0.9123 - val_loss: 0.3401 - val_binary_accuracy: 0.8481 - val_f1: 0.8005 - val_recall: 0.7871 - val_precision: 0.8217\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2085 - binary_accuracy: 0.9149 - f1: 0.9156 - recall: 0.9204 - precision: 0.9115 - val_loss: 0.3307 - val_binary_accuracy: 0.8536 - val_f1: 0.8085 - val_recall: 0.7920 - val_precision: 0.8312\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2100 - binary_accuracy: 0.9140 - f1: 0.9142 - recall: 0.9167 - precision: 0.9129 - val_loss: 0.3481 - val_binary_accuracy: 0.8490 - val_f1: 0.8141 - val_recall: 0.8553 - val_precision: 0.7795\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2082 - binary_accuracy: 0.9144 - f1: 0.9145 - recall: 0.9184 - precision: 0.9121 - val_loss: 0.3352 - val_binary_accuracy: 0.8536 - val_f1: 0.8116 - val_recall: 0.8033 - val_precision: 0.8228\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2070 - binary_accuracy: 0.9152 - f1: 0.9153 - recall: 0.9166 - precision: 0.9154 - val_loss: 0.3506 - val_binary_accuracy: 0.8490 - val_f1: 0.8128 - val_recall: 0.8183 - val_precision: 0.8134\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2025 - binary_accuracy: 0.9194 - f1: 0.9196 - recall: 0.9275 - precision: 0.9125 - val_loss: 0.3329 - val_binary_accuracy: 0.8531 - val_f1: 0.8118 - val_recall: 0.7940 - val_precision: 0.8364\n",
      "Epoch 90/500\n",
      "0s - loss: 0.2020 - binary_accuracy: 0.9147 - f1: 0.9150 - recall: 0.9176 - precision: 0.9135 - val_loss: 0.3431 - val_binary_accuracy: 0.8573 - val_f1: 0.8126 - val_recall: 0.7863 - val_precision: 0.8477\n",
      "Epoch 91/500\n",
      "0s - loss: 0.1938 - binary_accuracy: 0.9223 - f1: 0.9222 - recall: 0.9248 - precision: 0.9205 - val_loss: 0.3424 - val_binary_accuracy: 0.8536 - val_f1: 0.8124 - val_recall: 0.8030 - val_precision: 0.8254\n",
      "Epoch 92/500\n",
      "0s - loss: 0.2015 - binary_accuracy: 0.9171 - f1: 0.9173 - recall: 0.9201 - precision: 0.9154 - val_loss: 0.3520 - val_binary_accuracy: 0.8633 - val_f1: 0.8282 - val_recall: 0.8360 - val_precision: 0.8234\n",
      "Epoch 93/500\n",
      "0s - loss: 0.1979 - binary_accuracy: 0.9203 - f1: 0.9208 - recall: 0.9252 - precision: 0.9173 - val_loss: 0.3513 - val_binary_accuracy: 0.8559 - val_f1: 0.8157 - val_recall: 0.8166 - val_precision: 0.8189\n",
      "Epoch 94/500\n",
      "0s - loss: 0.1961 - binary_accuracy: 0.9232 - f1: 0.9231 - recall: 0.9252 - precision: 0.9217 - val_loss: 0.3442 - val_binary_accuracy: 0.8494 - val_f1: 0.8180 - val_recall: 0.8380 - val_precision: 0.8011\n",
      "Epoch 95/500\n",
      "0s - loss: 0.1957 - binary_accuracy: 0.9232 - f1: 0.9230 - recall: 0.9272 - precision: 0.9207 - val_loss: 0.3505 - val_binary_accuracy: 0.8554 - val_f1: 0.8161 - val_recall: 0.8296 - val_precision: 0.8070\n",
      "Epoch 96/500\n",
      "0s - loss: 0.1989 - binary_accuracy: 0.9207 - f1: 0.9208 - recall: 0.9220 - precision: 0.9207 - val_loss: 0.3402 - val_binary_accuracy: 0.8513 - val_f1: 0.8017 - val_recall: 0.7825 - val_precision: 0.8317\n",
      "Epoch 97/500\n",
      "0s - loss: 0.1900 - binary_accuracy: 0.9220 - f1: 0.9219 - recall: 0.9209 - precision: 0.9239 - val_loss: 0.3539 - val_binary_accuracy: 0.8596 - val_f1: 0.8165 - val_recall: 0.8231 - val_precision: 0.8125\n",
      "Epoch 98/500\n",
      "0s - loss: 0.1930 - binary_accuracy: 0.9240 - f1: 0.9245 - recall: 0.9303 - precision: 0.9196 - val_loss: 0.3493 - val_binary_accuracy: 0.8536 - val_f1: 0.8050 - val_recall: 0.7729 - val_precision: 0.8477\n",
      "Epoch 99/500\n",
      "0s - loss: 0.1842 - binary_accuracy: 0.9271 - f1: 0.9271 - recall: 0.9280 - precision: 0.9274 - val_loss: 0.3515 - val_binary_accuracy: 0.8596 - val_f1: 0.7995 - val_recall: 0.7522 - val_precision: 0.8684\n",
      "Epoch 100/500\n",
      "0s - loss: 0.1959 - binary_accuracy: 0.9208 - f1: 0.9206 - recall: 0.9175 - precision: 0.9255 - val_loss: 0.3605 - val_binary_accuracy: 0.8499 - val_f1: 0.8187 - val_recall: 0.8385 - val_precision: 0.8030\n",
      "Epoch 101/500\n",
      "0s - loss: 0.1915 - binary_accuracy: 0.9237 - f1: 0.9238 - recall: 0.9258 - precision: 0.9229 - val_loss: 0.3662 - val_binary_accuracy: 0.8517 - val_f1: 0.7978 - val_recall: 0.7607 - val_precision: 0.8504\n",
      "Epoch 102/500\n",
      "0s - loss: 0.1865 - binary_accuracy: 0.9286 - f1: 0.9286 - recall: 0.9311 - precision: 0.9277 - val_loss: 0.3621 - val_binary_accuracy: 0.8389 - val_f1: 0.8028 - val_recall: 0.8397 - val_precision: 0.7733\n",
      "Epoch 103/500\n",
      "0s - loss: 0.1863 - binary_accuracy: 0.9232 - f1: 0.9234 - recall: 0.9246 - precision: 0.9236 - val_loss: 0.3486 - val_binary_accuracy: 0.8522 - val_f1: 0.8040 - val_recall: 0.7811 - val_precision: 0.8374\n",
      "1824/2172 [========================>.....] - ETA: 0stn = 4059, fp = 271, fn = 287, tp = 4071\n",
      "y_pred: 0 = 4346 | 1 = 4342\n",
      "y_true: 0 = 4330 | 1 = 4358\n",
      "acc=0.9358|precision=0.9376|recall=0.9341|f1=0.9359|auc=0.9848|aupr=0.9855|pos_acc=0.9341|neg_acc=0.9340\n",
      "tn = 950, fp = 150, fn = 171, tp = 901\n",
      "y_pred: 0 = 1121 | 1 = 1051\n",
      "y_true: 0 = 1100 | 1 = 1072\n",
      "acc=0.8522|precision=0.8573|recall=0.8405|f1=0.8488|auc=0.9346|aupr=0.9327|pos_acc=0.8405|neg_acc=0.8475\n",
      "========== isbalance = True | task = Tm\n",
      "-------Fold  0\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8686 | Test = 2174\n",
      "-------Fold  1\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8811 | Test = 2049\n",
      "-------Fold  2\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8782 | Test = 2078\n",
      "-------Fold  3\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8684 | Test = 2176\n",
      "-------Fold  4\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 8477 | Test = 2383\n",
      "----------------------- Fold =  0\n",
      "Train on 8686 samples, validate on 2174 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4051 - binary_accuracy: 0.8157 - f1: 0.8034 - recall: 0.7878 - precision: 0.8409 - val_loss: 0.3545 - val_binary_accuracy: 0.8519 - val_f1: 0.8486 - val_recall: 0.8070 - val_precision: 0.8962\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3517 - binary_accuracy: 0.8424 - f1: 0.8392 - recall: 0.8347 - precision: 0.8450 - val_loss: 0.3432 - val_binary_accuracy: 0.8473 - val_f1: 0.8533 - val_recall: 0.8639 - val_precision: 0.8438\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3445 - binary_accuracy: 0.8466 - f1: 0.8436 - recall: 0.8373 - precision: 0.8540 - val_loss: 0.3391 - val_binary_accuracy: 0.8487 - val_f1: 0.8568 - val_recall: 0.8798 - val_precision: 0.8359\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3390 - binary_accuracy: 0.8526 - f1: 0.8505 - recall: 0.8518 - precision: 0.8520 - val_loss: 0.3335 - val_binary_accuracy: 0.8542 - val_f1: 0.8619 - val_recall: 0.8833 - val_precision: 0.8425\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3319 - binary_accuracy: 0.8567 - f1: 0.8551 - recall: 0.8576 - precision: 0.8545 - val_loss: 0.3379 - val_binary_accuracy: 0.8441 - val_f1: 0.8561 - val_recall: 0.9020 - val_precision: 0.8155\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3295 - binary_accuracy: 0.8547 - f1: 0.8537 - recall: 0.8584 - precision: 0.8509 - val_loss: 0.3244 - val_binary_accuracy: 0.8533 - val_f1: 0.8580 - val_recall: 0.8614 - val_precision: 0.8561\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3293 - binary_accuracy: 0.8574 - f1: 0.8551 - recall: 0.8599 - precision: 0.8542 - val_loss: 0.3259 - val_binary_accuracy: 0.8606 - val_f1: 0.8622 - val_recall: 0.8481 - val_precision: 0.8786\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3232 - binary_accuracy: 0.8587 - f1: 0.8572 - recall: 0.8577 - precision: 0.8578 - val_loss: 0.3271 - val_binary_accuracy: 0.8574 - val_f1: 0.8625 - val_recall: 0.8702 - val_precision: 0.8564\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3227 - binary_accuracy: 0.8593 - f1: 0.8587 - recall: 0.8637 - precision: 0.8571 - val_loss: 0.3241 - val_binary_accuracy: 0.8588 - val_f1: 0.8609 - val_recall: 0.8497 - val_precision: 0.8741\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3190 - binary_accuracy: 0.8647 - f1: 0.8640 - recall: 0.8712 - precision: 0.8584 - val_loss: 0.3273 - val_binary_accuracy: 0.8528 - val_f1: 0.8613 - val_recall: 0.8888 - val_precision: 0.8366\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3291 - binary_accuracy: 0.8603 - f1: 0.8589 - recall: 0.8665 - precision: 0.8580 - val_loss: 0.3490 - val_binary_accuracy: 0.8473 - val_f1: 0.8382 - val_recall: 0.7681 - val_precision: 0.9239\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3327 - binary_accuracy: 0.8529 - f1: 0.8507 - recall: 0.8496 - precision: 0.8557 - val_loss: 0.3214 - val_binary_accuracy: 0.8588 - val_f1: 0.8609 - val_recall: 0.8491 - val_precision: 0.8745\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3219 - binary_accuracy: 0.8637 - f1: 0.8629 - recall: 0.8691 - precision: 0.8589 - val_loss: 0.3201 - val_binary_accuracy: 0.8602 - val_f1: 0.8645 - val_recall: 0.8676 - val_precision: 0.8627\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3184 - binary_accuracy: 0.8629 - f1: 0.8619 - recall: 0.8677 - precision: 0.8599 - val_loss: 0.3220 - val_binary_accuracy: 0.8620 - val_f1: 0.8666 - val_recall: 0.8712 - val_precision: 0.8633\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3102 - binary_accuracy: 0.8676 - f1: 0.8669 - recall: 0.8720 - precision: 0.8632 - val_loss: 0.3177 - val_binary_accuracy: 0.8620 - val_f1: 0.8655 - val_recall: 0.8641 - val_precision: 0.8686\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3098 - binary_accuracy: 0.8682 - f1: 0.8670 - recall: 0.8716 - precision: 0.8635 - val_loss: 0.3269 - val_binary_accuracy: 0.8537 - val_f1: 0.8618 - val_recall: 0.8870 - val_precision: 0.8390\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3145 - binary_accuracy: 0.8602 - f1: 0.8596 - recall: 0.8642 - precision: 0.8568 - val_loss: 0.3327 - val_binary_accuracy: 0.8464 - val_f1: 0.8593 - val_recall: 0.9119 - val_precision: 0.8132\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3064 - binary_accuracy: 0.8674 - f1: 0.8659 - recall: 0.8709 - precision: 0.8620 - val_loss: 0.3257 - val_binary_accuracy: 0.8611 - val_f1: 0.8644 - val_recall: 0.8622 - val_precision: 0.8683\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3056 - binary_accuracy: 0.8667 - f1: 0.8655 - recall: 0.8694 - precision: 0.8634 - val_loss: 0.3153 - val_binary_accuracy: 0.8625 - val_f1: 0.8660 - val_recall: 0.8650 - val_precision: 0.8685\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3087 - binary_accuracy: 0.8674 - f1: 0.8661 - recall: 0.8717 - precision: 0.8630 - val_loss: 0.3212 - val_binary_accuracy: 0.8574 - val_f1: 0.8659 - val_recall: 0.8950 - val_precision: 0.8396\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3045 - binary_accuracy: 0.8676 - f1: 0.8670 - recall: 0.8730 - precision: 0.8639 - val_loss: 0.3164 - val_binary_accuracy: 0.8602 - val_f1: 0.8650 - val_recall: 0.8713 - val_precision: 0.8600\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3027 - binary_accuracy: 0.8674 - f1: 0.8661 - recall: 0.8707 - precision: 0.8631 - val_loss: 0.3228 - val_binary_accuracy: 0.8620 - val_f1: 0.8647 - val_recall: 0.8586 - val_precision: 0.8726\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3059 - binary_accuracy: 0.8688 - f1: 0.8680 - recall: 0.8729 - precision: 0.8647 - val_loss: 0.3143 - val_binary_accuracy: 0.8648 - val_f1: 0.8680 - val_recall: 0.8641 - val_precision: 0.8732\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3030 - binary_accuracy: 0.8685 - f1: 0.8675 - recall: 0.8687 - precision: 0.8676 - val_loss: 0.3367 - val_binary_accuracy: 0.8569 - val_f1: 0.8554 - val_recall: 0.8229 - val_precision: 0.8918\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3018 - binary_accuracy: 0.8682 - f1: 0.8679 - recall: 0.8750 - precision: 0.8635 - val_loss: 0.3165 - val_binary_accuracy: 0.8629 - val_f1: 0.8672 - val_recall: 0.8696 - val_precision: 0.8658\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2962 - binary_accuracy: 0.8736 - f1: 0.8733 - recall: 0.8799 - precision: 0.8685 - val_loss: 0.3131 - val_binary_accuracy: 0.8615 - val_f1: 0.8667 - val_recall: 0.8756 - val_precision: 0.8593\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2992 - binary_accuracy: 0.8696 - f1: 0.8683 - recall: 0.8731 - precision: 0.8652 - val_loss: 0.3234 - val_binary_accuracy: 0.8597 - val_f1: 0.8595 - val_recall: 0.8337 - val_precision: 0.8879\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2976 - binary_accuracy: 0.8721 - f1: 0.8712 - recall: 0.8756 - precision: 0.8688 - val_loss: 0.3131 - val_binary_accuracy: 0.8657 - val_f1: 0.8683 - val_recall: 0.8604 - val_precision: 0.8775\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2935 - binary_accuracy: 0.8730 - f1: 0.8719 - recall: 0.8774 - precision: 0.8685 - val_loss: 0.3252 - val_binary_accuracy: 0.8491 - val_f1: 0.8580 - val_recall: 0.8854 - val_precision: 0.8334\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2906 - binary_accuracy: 0.8751 - f1: 0.8750 - recall: 0.8815 - precision: 0.8702 - val_loss: 0.3169 - val_binary_accuracy: 0.8579 - val_f1: 0.8595 - val_recall: 0.8453 - val_precision: 0.8758\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2895 - binary_accuracy: 0.8750 - f1: 0.8740 - recall: 0.8778 - precision: 0.8716 - val_loss: 0.3161 - val_binary_accuracy: 0.8592 - val_f1: 0.8673 - val_recall: 0.8943 - val_precision: 0.8430\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2863 - binary_accuracy: 0.8757 - f1: 0.8753 - recall: 0.8796 - precision: 0.8724 - val_loss: 0.3137 - val_binary_accuracy: 0.8652 - val_f1: 0.8720 - val_recall: 0.8916 - val_precision: 0.8541\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2948 - binary_accuracy: 0.8735 - f1: 0.8729 - recall: 0.8827 - precision: 0.8661 - val_loss: 0.3171 - val_binary_accuracy: 0.8606 - val_f1: 0.8660 - val_recall: 0.8748 - val_precision: 0.8585\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2913 - binary_accuracy: 0.8726 - f1: 0.8713 - recall: 0.8725 - precision: 0.8718 - val_loss: 0.3189 - val_binary_accuracy: 0.8560 - val_f1: 0.8610 - val_recall: 0.8660 - val_precision: 0.8573\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2864 - binary_accuracy: 0.8766 - f1: 0.8756 - recall: 0.8800 - precision: 0.8723 - val_loss: 0.3296 - val_binary_accuracy: 0.8519 - val_f1: 0.8598 - val_recall: 0.8834 - val_precision: 0.8385\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2826 - binary_accuracy: 0.8776 - f1: 0.8771 - recall: 0.8815 - precision: 0.8743 - val_loss: 0.3156 - val_binary_accuracy: 0.8565 - val_f1: 0.8648 - val_recall: 0.8924 - val_precision: 0.8396\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2814 - binary_accuracy: 0.8785 - f1: 0.8776 - recall: 0.8847 - precision: 0.8725 - val_loss: 0.3235 - val_binary_accuracy: 0.8519 - val_f1: 0.8578 - val_recall: 0.8685 - val_precision: 0.8488\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2841 - binary_accuracy: 0.8761 - f1: 0.8749 - recall: 0.8767 - precision: 0.8746 - val_loss: 0.3363 - val_binary_accuracy: 0.8500 - val_f1: 0.8628 - val_recall: 0.9155 - val_precision: 0.8167\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2844 - binary_accuracy: 0.8789 - f1: 0.8778 - recall: 0.8815 - precision: 0.8769 - val_loss: 0.3392 - val_binary_accuracy: 0.8418 - val_f1: 0.8548 - val_recall: 0.9043 - val_precision: 0.8114\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2819 - binary_accuracy: 0.8796 - f1: 0.8793 - recall: 0.8873 - precision: 0.8731 - val_loss: 0.3147 - val_binary_accuracy: 0.8597 - val_f1: 0.8660 - val_recall: 0.8810 - val_precision: 0.8526\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2798 - binary_accuracy: 0.8793 - f1: 0.8786 - recall: 0.8822 - precision: 0.8772 - val_loss: 0.3225 - val_binary_accuracy: 0.8560 - val_f1: 0.8641 - val_recall: 0.8898 - val_precision: 0.8409\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2758 - binary_accuracy: 0.8812 - f1: 0.8803 - recall: 0.8858 - precision: 0.8759 - val_loss: 0.3130 - val_binary_accuracy: 0.8671 - val_f1: 0.8704 - val_recall: 0.8678 - val_precision: 0.8743\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2757 - binary_accuracy: 0.8823 - f1: 0.8810 - recall: 0.8848 - precision: 0.8790 - val_loss: 0.3155 - val_binary_accuracy: 0.8643 - val_f1: 0.8697 - val_recall: 0.8791 - val_precision: 0.8610\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2782 - binary_accuracy: 0.8800 - f1: 0.8800 - recall: 0.8899 - precision: 0.8727 - val_loss: 0.3155 - val_binary_accuracy: 0.8625 - val_f1: 0.8671 - val_recall: 0.8720 - val_precision: 0.8633\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2698 - binary_accuracy: 0.8849 - f1: 0.8841 - recall: 0.8869 - precision: 0.8822 - val_loss: 0.3136 - val_binary_accuracy: 0.8661 - val_f1: 0.8696 - val_recall: 0.8683 - val_precision: 0.8720\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2716 - binary_accuracy: 0.8850 - f1: 0.8836 - recall: 0.8857 - precision: 0.8836 - val_loss: 0.3329 - val_binary_accuracy: 0.8514 - val_f1: 0.8632 - val_recall: 0.9110 - val_precision: 0.8210\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2692 - binary_accuracy: 0.8854 - f1: 0.8842 - recall: 0.8875 - precision: 0.8825 - val_loss: 0.3262 - val_binary_accuracy: 0.8546 - val_f1: 0.8656 - val_recall: 0.9087 - val_precision: 0.8272\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2673 - binary_accuracy: 0.8866 - f1: 0.8861 - recall: 0.8914 - precision: 0.8827 - val_loss: 0.3168 - val_binary_accuracy: 0.8625 - val_f1: 0.8623 - val_recall: 0.8381 - val_precision: 0.8892\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2691 - binary_accuracy: 0.8835 - f1: 0.8828 - recall: 0.8877 - precision: 0.8801 - val_loss: 0.3316 - val_binary_accuracy: 0.8638 - val_f1: 0.8629 - val_recall: 0.8335 - val_precision: 0.8956\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2679 - binary_accuracy: 0.8859 - f1: 0.8852 - recall: 0.8891 - precision: 0.8830 - val_loss: 0.3073 - val_binary_accuracy: 0.8684 - val_f1: 0.8720 - val_recall: 0.8710 - val_precision: 0.8738\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2614 - binary_accuracy: 0.8898 - f1: 0.8891 - recall: 0.8929 - precision: 0.8864 - val_loss: 0.3224 - val_binary_accuracy: 0.8597 - val_f1: 0.8651 - val_recall: 0.8737 - val_precision: 0.8577\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2649 - binary_accuracy: 0.8897 - f1: 0.8884 - recall: 0.8933 - precision: 0.8847 - val_loss: 0.3147 - val_binary_accuracy: 0.8648 - val_f1: 0.8720 - val_recall: 0.8943 - val_precision: 0.8517\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2586 - binary_accuracy: 0.8922 - f1: 0.8917 - recall: 0.8972 - precision: 0.8877 - val_loss: 0.3136 - val_binary_accuracy: 0.8638 - val_f1: 0.8692 - val_recall: 0.8797 - val_precision: 0.8598\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2629 - binary_accuracy: 0.8878 - f1: 0.8863 - recall: 0.8887 - precision: 0.8857 - val_loss: 0.3195 - val_binary_accuracy: 0.8602 - val_f1: 0.8644 - val_recall: 0.8666 - val_precision: 0.8631\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2594 - binary_accuracy: 0.8926 - f1: 0.8926 - recall: 0.9004 - precision: 0.8867 - val_loss: 0.3146 - val_binary_accuracy: 0.8629 - val_f1: 0.8666 - val_recall: 0.8655 - val_precision: 0.8685\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2557 - binary_accuracy: 0.8911 - f1: 0.8904 - recall: 0.8936 - precision: 0.8886 - val_loss: 0.3316 - val_binary_accuracy: 0.8629 - val_f1: 0.8649 - val_recall: 0.8539 - val_precision: 0.8775\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2621 - binary_accuracy: 0.8878 - f1: 0.8874 - recall: 0.8932 - precision: 0.8841 - val_loss: 0.3471 - val_binary_accuracy: 0.8606 - val_f1: 0.8601 - val_recall: 0.8328 - val_precision: 0.8906\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2564 - binary_accuracy: 0.8913 - f1: 0.8904 - recall: 0.8937 - precision: 0.8891 - val_loss: 0.3413 - val_binary_accuracy: 0.8519 - val_f1: 0.8536 - val_recall: 0.8413 - val_precision: 0.8676\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2668 - binary_accuracy: 0.8843 - f1: 0.8842 - recall: 0.8925 - precision: 0.8792 - val_loss: 0.3174 - val_binary_accuracy: 0.8648 - val_f1: 0.8643 - val_recall: 0.8366 - val_precision: 0.8949\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2561 - binary_accuracy: 0.8934 - f1: 0.8922 - recall: 0.8929 - precision: 0.8932 - val_loss: 0.3158 - val_binary_accuracy: 0.8634 - val_f1: 0.8664 - val_recall: 0.8612 - val_precision: 0.8727\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2545 - binary_accuracy: 0.8925 - f1: 0.8920 - recall: 0.8984 - precision: 0.8881 - val_loss: 0.3148 - val_binary_accuracy: 0.8606 - val_f1: 0.8646 - val_recall: 0.8648 - val_precision: 0.8653\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2552 - binary_accuracy: 0.8914 - f1: 0.8907 - recall: 0.8943 - precision: 0.8898 - val_loss: 0.3371 - val_binary_accuracy: 0.8657 - val_f1: 0.8645 - val_recall: 0.8344 - val_precision: 0.8983\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2462 - binary_accuracy: 0.8986 - f1: 0.8976 - recall: 0.9003 - precision: 0.8971 - val_loss: 0.3134 - val_binary_accuracy: 0.8643 - val_f1: 0.8667 - val_recall: 0.8570 - val_precision: 0.8779\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2435 - binary_accuracy: 0.9004 - f1: 0.8993 - recall: 0.9012 - precision: 0.8987 - val_loss: 0.3323 - val_binary_accuracy: 0.8560 - val_f1: 0.8634 - val_recall: 0.8855 - val_precision: 0.8437\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2491 - binary_accuracy: 0.8947 - f1: 0.8936 - recall: 0.8968 - precision: 0.8920 - val_loss: 0.3265 - val_binary_accuracy: 0.8579 - val_f1: 0.8681 - val_recall: 0.9099 - val_precision: 0.8305\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2414 - binary_accuracy: 0.9023 - f1: 0.9015 - recall: 0.9055 - precision: 0.8990 - val_loss: 0.3156 - val_binary_accuracy: 0.8680 - val_f1: 0.8699 - val_recall: 0.8587 - val_precision: 0.8827\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2405 - binary_accuracy: 0.8994 - f1: 0.8983 - recall: 0.9010 - precision: 0.8969 - val_loss: 0.3176 - val_binary_accuracy: 0.8615 - val_f1: 0.8640 - val_recall: 0.8553 - val_precision: 0.8744\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2398 - binary_accuracy: 0.9004 - f1: 0.8993 - recall: 0.9005 - precision: 0.8996 - val_loss: 0.3394 - val_binary_accuracy: 0.8491 - val_f1: 0.8589 - val_recall: 0.8937 - val_precision: 0.8273\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2345 - binary_accuracy: 0.9013 - f1: 0.8996 - recall: 0.9006 - precision: 0.8997 - val_loss: 0.3300 - val_binary_accuracy: 0.8625 - val_f1: 0.8650 - val_recall: 0.8591 - val_precision: 0.8724\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2360 - binary_accuracy: 0.9019 - f1: 0.9006 - recall: 0.9047 - precision: 0.8983 - val_loss: 0.3247 - val_binary_accuracy: 0.8546 - val_f1: 0.8598 - val_recall: 0.8674 - val_precision: 0.8537\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2398 - binary_accuracy: 0.9002 - f1: 0.8991 - recall: 0.9009 - precision: 0.8994 - val_loss: 0.3232 - val_binary_accuracy: 0.8551 - val_f1: 0.8640 - val_recall: 0.8957 - val_precision: 0.8352\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2375 - binary_accuracy: 0.8981 - f1: 0.8973 - recall: 0.9006 - precision: 0.8969 - val_loss: 0.3245 - val_binary_accuracy: 0.8537 - val_f1: 0.8606 - val_recall: 0.8780 - val_precision: 0.8446\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2298 - binary_accuracy: 0.9032 - f1: 0.9025 - recall: 0.9029 - precision: 0.9035 - val_loss: 0.3385 - val_binary_accuracy: 0.8583 - val_f1: 0.8590 - val_recall: 0.8399 - val_precision: 0.8807\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2325 - binary_accuracy: 0.9015 - f1: 0.9004 - recall: 0.9016 - precision: 0.9006 - val_loss: 0.3212 - val_binary_accuracy: 0.8602 - val_f1: 0.8659 - val_recall: 0.8802 - val_precision: 0.8527\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2230 - binary_accuracy: 0.9051 - f1: 0.9044 - recall: 0.9092 - precision: 0.9008 - val_loss: 0.3287 - val_binary_accuracy: 0.8602 - val_f1: 0.8622 - val_recall: 0.8516 - val_precision: 0.8746\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2248 - binary_accuracy: 0.9079 - f1: 0.9069 - recall: 0.9063 - precision: 0.9096 - val_loss: 0.3439 - val_binary_accuracy: 0.8505 - val_f1: 0.8582 - val_recall: 0.8798 - val_precision: 0.8385\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2258 - binary_accuracy: 0.9052 - f1: 0.9038 - recall: 0.9059 - precision: 0.9031 - val_loss: 0.3405 - val_binary_accuracy: 0.8565 - val_f1: 0.8642 - val_recall: 0.8885 - val_precision: 0.8420\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2250 - binary_accuracy: 0.9059 - f1: 0.9052 - recall: 0.9091 - precision: 0.9026 - val_loss: 0.3558 - val_binary_accuracy: 0.8445 - val_f1: 0.8539 - val_recall: 0.8832 - val_precision: 0.8273\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2259 - binary_accuracy: 0.9039 - f1: 0.9033 - recall: 0.9072 - precision: 0.9003 - val_loss: 0.3258 - val_binary_accuracy: 0.8615 - val_f1: 0.8638 - val_recall: 0.8532 - val_precision: 0.8760\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2157 - binary_accuracy: 0.9100 - f1: 0.9089 - recall: 0.9109 - precision: 0.9080 - val_loss: 0.3270 - val_binary_accuracy: 0.8648 - val_f1: 0.8666 - val_recall: 0.8548 - val_precision: 0.8801\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2195 - binary_accuracy: 0.9103 - f1: 0.9093 - recall: 0.9100 - precision: 0.9095 - val_loss: 0.3495 - val_binary_accuracy: 0.8528 - val_f1: 0.8638 - val_recall: 0.9089 - val_precision: 0.8237\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2164 - binary_accuracy: 0.9110 - f1: 0.9100 - recall: 0.9123 - precision: 0.9098 - val_loss: 0.3388 - val_binary_accuracy: 0.8579 - val_f1: 0.8550 - val_recall: 0.8150 - val_precision: 0.9005\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2202 - binary_accuracy: 0.9099 - f1: 0.9089 - recall: 0.9121 - precision: 0.9074 - val_loss: 0.3268 - val_binary_accuracy: 0.8648 - val_f1: 0.8642 - val_recall: 0.8363 - val_precision: 0.8952\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2135 - binary_accuracy: 0.9118 - f1: 0.9104 - recall: 0.9118 - precision: 0.9107 - val_loss: 0.3231 - val_binary_accuracy: 0.8698 - val_f1: 0.8716 - val_recall: 0.8592 - val_precision: 0.8858\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2148 - binary_accuracy: 0.9097 - f1: 0.9088 - recall: 0.9118 - precision: 0.9073 - val_loss: 0.3496 - val_binary_accuracy: 0.8675 - val_f1: 0.8688 - val_recall: 0.8540 - val_precision: 0.8855\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2189 - binary_accuracy: 0.9087 - f1: 0.9078 - recall: 0.9082 - precision: 0.9094 - val_loss: 0.3271 - val_binary_accuracy: 0.8583 - val_f1: 0.8629 - val_recall: 0.8663 - val_precision: 0.8601\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2091 - binary_accuracy: 0.9141 - f1: 0.9135 - recall: 0.9175 - precision: 0.9105 - val_loss: 0.3310 - val_binary_accuracy: 0.8643 - val_f1: 0.8639 - val_recall: 0.8379 - val_precision: 0.8928\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2056 - binary_accuracy: 0.9154 - f1: 0.9142 - recall: 0.9139 - precision: 0.9154 - val_loss: 0.3243 - val_binary_accuracy: 0.8666 - val_f1: 0.8700 - val_recall: 0.8683 - val_precision: 0.8728\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2028 - binary_accuracy: 0.9171 - f1: 0.9162 - recall: 0.9175 - precision: 0.9157 - val_loss: 0.3360 - val_binary_accuracy: 0.8514 - val_f1: 0.8561 - val_recall: 0.8586 - val_precision: 0.8546\n",
      "Epoch 90/500\n",
      "0s - loss: 0.2011 - binary_accuracy: 0.9157 - f1: 0.9149 - recall: 0.9145 - precision: 0.9160 - val_loss: 0.3324 - val_binary_accuracy: 0.8611 - val_f1: 0.8667 - val_recall: 0.8789 - val_precision: 0.8561\n",
      "Epoch 91/500\n",
      "0s - loss: 0.2043 - binary_accuracy: 0.9146 - f1: 0.9131 - recall: 0.9115 - precision: 0.9165 - val_loss: 0.3792 - val_binary_accuracy: 0.8395 - val_f1: 0.8544 - val_recall: 0.9146 - val_precision: 0.8019\n",
      "Epoch 92/500\n",
      "0s - loss: 0.2138 - binary_accuracy: 0.9099 - f1: 0.9094 - recall: 0.9140 - precision: 0.9084 - val_loss: 0.3461 - val_binary_accuracy: 0.8629 - val_f1: 0.8675 - val_recall: 0.8727 - val_precision: 0.8633\n",
      "Epoch 93/500\n",
      "0s - loss: 0.1973 - binary_accuracy: 0.9201 - f1: 0.9194 - recall: 0.9209 - precision: 0.9190 - val_loss: 0.3550 - val_binary_accuracy: 0.8629 - val_f1: 0.8638 - val_recall: 0.8467 - val_precision: 0.8830\n",
      "Epoch 94/500\n",
      "0s - loss: 0.2046 - binary_accuracy: 0.9169 - f1: 0.9158 - recall: 0.9152 - precision: 0.9179 - val_loss: 0.3478 - val_binary_accuracy: 0.8652 - val_f1: 0.8705 - val_recall: 0.8815 - val_precision: 0.8608\n",
      "Epoch 95/500\n",
      "0s - loss: 0.1994 - binary_accuracy: 0.9201 - f1: 0.9193 - recall: 0.9217 - precision: 0.9181 - val_loss: 0.3528 - val_binary_accuracy: 0.8569 - val_f1: 0.8585 - val_recall: 0.8448 - val_precision: 0.8737\n",
      "Epoch 96/500\n",
      "0s - loss: 0.1904 - binary_accuracy: 0.9265 - f1: 0.9257 - recall: 0.9252 - precision: 0.9272 - val_loss: 0.3780 - val_binary_accuracy: 0.8459 - val_f1: 0.8545 - val_recall: 0.8800 - val_precision: 0.8316\n",
      "Epoch 97/500\n",
      "0s - loss: 0.1955 - binary_accuracy: 0.9196 - f1: 0.9190 - recall: 0.9173 - precision: 0.9223 - val_loss: 0.3469 - val_binary_accuracy: 0.8638 - val_f1: 0.8642 - val_recall: 0.8433 - val_precision: 0.8872\n",
      "Epoch 98/500\n",
      "0s - loss: 0.1858 - binary_accuracy: 0.9262 - f1: 0.9254 - recall: 0.9245 - precision: 0.9272 - val_loss: 0.3384 - val_binary_accuracy: 0.8629 - val_f1: 0.8694 - val_recall: 0.8875 - val_precision: 0.8526\n",
      "Epoch 99/500\n",
      "0s - loss: 0.1849 - binary_accuracy: 0.9247 - f1: 0.9241 - recall: 0.9273 - precision: 0.9223 - val_loss: 0.3563 - val_binary_accuracy: 0.8574 - val_f1: 0.8584 - val_recall: 0.8395 - val_precision: 0.8790\n",
      "Epoch 100/500\n",
      "0s - loss: 0.1857 - binary_accuracy: 0.9249 - f1: 0.9236 - recall: 0.9210 - precision: 0.9275 - val_loss: 0.3388 - val_binary_accuracy: 0.8648 - val_f1: 0.8705 - val_recall: 0.8850 - val_precision: 0.8572\n",
      "Epoch 101/500\n",
      "0s - loss: 0.1859 - binary_accuracy: 0.9265 - f1: 0.9254 - recall: 0.9243 - precision: 0.9274 - val_loss: 0.3585 - val_binary_accuracy: 0.8505 - val_f1: 0.8608 - val_recall: 0.8983 - val_precision: 0.8269\n",
      "1792/2174 [=======================>......] - ETA: 0stn = 3907, fp = 471, fn = 163, tp = 4145\n",
      "y_pred: 0 = 4070 | 1 = 4616\n",
      "y_true: 0 = 4378 | 1 = 4308\n",
      "acc=0.9270|precision=0.8980|recall=0.9622|f1=0.9290|auc=0.9843|aupr=0.9850|pos_acc=0.9622|neg_acc=0.9600\n",
      "tn = 841, fp = 211, fn = 114, tp = 1008\n",
      "y_pred: 0 = 955 | 1 = 1219\n",
      "y_true: 0 = 1052 | 1 = 1122\n",
      "acc=0.8505|precision=0.8269|recall=0.8984|f1=0.8612|auc=0.9359|aupr=0.9397|pos_acc=0.8984|neg_acc=0.8806\n",
      "----------------------- Fold =  1\n",
      "Train on 8811 samples, validate on 2049 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4200 - binary_accuracy: 0.8086 - f1: 0.8024 - recall: 0.7826 - precision: 0.8455 - val_loss: 0.3654 - val_binary_accuracy: 0.8516 - val_f1: 0.8460 - val_recall: 0.8427 - val_precision: 0.8503\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3534 - binary_accuracy: 0.8454 - f1: 0.8438 - recall: 0.8349 - precision: 0.8555 - val_loss: 0.3552 - val_binary_accuracy: 0.8472 - val_f1: 0.8323 - val_recall: 0.7852 - val_precision: 0.8868\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3476 - binary_accuracy: 0.8453 - f1: 0.8438 - recall: 0.8360 - precision: 0.8540 - val_loss: 0.3578 - val_binary_accuracy: 0.8365 - val_f1: 0.8281 - val_recall: 0.8111 - val_precision: 0.8470\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3400 - binary_accuracy: 0.8511 - f1: 0.8511 - recall: 0.8484 - precision: 0.8565 - val_loss: 0.3364 - val_binary_accuracy: 0.8624 - val_f1: 0.8547 - val_recall: 0.8378 - val_precision: 0.8728\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3335 - binary_accuracy: 0.8535 - f1: 0.8534 - recall: 0.8534 - precision: 0.8548 - val_loss: 0.3356 - val_binary_accuracy: 0.8575 - val_f1: 0.8513 - val_recall: 0.8437 - val_precision: 0.8597\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3307 - binary_accuracy: 0.8598 - f1: 0.8596 - recall: 0.8562 - precision: 0.8646 - val_loss: 0.3433 - val_binary_accuracy: 0.8526 - val_f1: 0.8369 - val_recall: 0.7826 - val_precision: 0.9004\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3330 - binary_accuracy: 0.8544 - f1: 0.8545 - recall: 0.8541 - precision: 0.8588 - val_loss: 0.3321 - val_binary_accuracy: 0.8560 - val_f1: 0.8531 - val_recall: 0.8667 - val_precision: 0.8409\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3266 - binary_accuracy: 0.8534 - f1: 0.8528 - recall: 0.8479 - precision: 0.8610 - val_loss: 0.3257 - val_binary_accuracy: 0.8619 - val_f1: 0.8576 - val_recall: 0.8618 - val_precision: 0.8544\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3258 - binary_accuracy: 0.8561 - f1: 0.8568 - recall: 0.8590 - precision: 0.8577 - val_loss: 0.3326 - val_binary_accuracy: 0.8604 - val_f1: 0.8490 - val_recall: 0.8117 - val_precision: 0.8912\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3189 - binary_accuracy: 0.8620 - f1: 0.8623 - recall: 0.8626 - precision: 0.8629 - val_loss: 0.3249 - val_binary_accuracy: 0.8677 - val_f1: 0.8649 - val_recall: 0.8760 - val_precision: 0.8552\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3218 - binary_accuracy: 0.8611 - f1: 0.8617 - recall: 0.8634 - precision: 0.8640 - val_loss: 0.3275 - val_binary_accuracy: 0.8594 - val_f1: 0.8504 - val_recall: 0.8270 - val_precision: 0.8762\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3206 - binary_accuracy: 0.8586 - f1: 0.8584 - recall: 0.8590 - precision: 0.8608 - val_loss: 0.3287 - val_binary_accuracy: 0.8570 - val_f1: 0.8462 - val_recall: 0.8148 - val_precision: 0.8817\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3163 - binary_accuracy: 0.8620 - f1: 0.8621 - recall: 0.8619 - precision: 0.8650 - val_loss: 0.3279 - val_binary_accuracy: 0.8614 - val_f1: 0.8593 - val_recall: 0.8751 - val_precision: 0.8451\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3138 - binary_accuracy: 0.8635 - f1: 0.8639 - recall: 0.8639 - precision: 0.8661 - val_loss: 0.3288 - val_binary_accuracy: 0.8590 - val_f1: 0.8465 - val_recall: 0.8058 - val_precision: 0.8929\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3131 - binary_accuracy: 0.8635 - f1: 0.8639 - recall: 0.8643 - precision: 0.8648 - val_loss: 0.3254 - val_binary_accuracy: 0.8555 - val_f1: 0.8437 - val_recall: 0.8068 - val_precision: 0.8855\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3133 - binary_accuracy: 0.8630 - f1: 0.8633 - recall: 0.8643 - precision: 0.8655 - val_loss: 0.3477 - val_binary_accuracy: 0.8453 - val_f1: 0.8252 - val_recall: 0.7573 - val_precision: 0.9088\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3124 - binary_accuracy: 0.8623 - f1: 0.8618 - recall: 0.8587 - precision: 0.8681 - val_loss: 0.3189 - val_binary_accuracy: 0.8609 - val_f1: 0.8557 - val_recall: 0.8539 - val_precision: 0.8591\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3099 - binary_accuracy: 0.8637 - f1: 0.8641 - recall: 0.8660 - precision: 0.8645 - val_loss: 0.3261 - val_binary_accuracy: 0.8536 - val_f1: 0.8487 - val_recall: 0.8488 - val_precision: 0.8495\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3083 - binary_accuracy: 0.8628 - f1: 0.8636 - recall: 0.8671 - precision: 0.8624 - val_loss: 0.3343 - val_binary_accuracy: 0.8555 - val_f1: 0.8412 - val_recall: 0.7932 - val_precision: 0.8965\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3074 - binary_accuracy: 0.8676 - f1: 0.8677 - recall: 0.8664 - precision: 0.8720 - val_loss: 0.3262 - val_binary_accuracy: 0.8575 - val_f1: 0.8449 - val_recall: 0.8060 - val_precision: 0.8890\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3071 - binary_accuracy: 0.8663 - f1: 0.8664 - recall: 0.8635 - precision: 0.8711 - val_loss: 0.3280 - val_binary_accuracy: 0.8526 - val_f1: 0.8395 - val_recall: 0.7993 - val_precision: 0.8854\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3042 - binary_accuracy: 0.8654 - f1: 0.8653 - recall: 0.8634 - precision: 0.8695 - val_loss: 0.3178 - val_binary_accuracy: 0.8653 - val_f1: 0.8626 - val_recall: 0.8734 - val_precision: 0.8532\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3042 - binary_accuracy: 0.8665 - f1: 0.8676 - recall: 0.8726 - precision: 0.8643 - val_loss: 0.3322 - val_binary_accuracy: 0.8507 - val_f1: 0.8369 - val_recall: 0.7908 - val_precision: 0.8897\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3055 - binary_accuracy: 0.8641 - f1: 0.8637 - recall: 0.8609 - precision: 0.8686 - val_loss: 0.3214 - val_binary_accuracy: 0.8638 - val_f1: 0.8521 - val_recall: 0.8142 - val_precision: 0.8955\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2992 - binary_accuracy: 0.8697 - f1: 0.8698 - recall: 0.8690 - precision: 0.8730 - val_loss: 0.3255 - val_binary_accuracy: 0.8531 - val_f1: 0.8485 - val_recall: 0.8509 - val_precision: 0.8472\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3008 - binary_accuracy: 0.8682 - f1: 0.8687 - recall: 0.8723 - precision: 0.8672 - val_loss: 0.3328 - val_binary_accuracy: 0.8511 - val_f1: 0.8357 - val_recall: 0.7851 - val_precision: 0.8960\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2983 - binary_accuracy: 0.8706 - f1: 0.8706 - recall: 0.8690 - precision: 0.8740 - val_loss: 0.3224 - val_binary_accuracy: 0.8511 - val_f1: 0.8428 - val_recall: 0.8248 - val_precision: 0.8625\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2972 - binary_accuracy: 0.8676 - f1: 0.8681 - recall: 0.8681 - precision: 0.8699 - val_loss: 0.3127 - val_binary_accuracy: 0.8619 - val_f1: 0.8560 - val_recall: 0.8483 - val_precision: 0.8652\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2947 - binary_accuracy: 0.8691 - f1: 0.8695 - recall: 0.8704 - precision: 0.8706 - val_loss: 0.3156 - val_binary_accuracy: 0.8609 - val_f1: 0.8560 - val_recall: 0.8561 - val_precision: 0.8575\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2946 - binary_accuracy: 0.8698 - f1: 0.8695 - recall: 0.8659 - precision: 0.8742 - val_loss: 0.3243 - val_binary_accuracy: 0.8546 - val_f1: 0.8505 - val_recall: 0.8559 - val_precision: 0.8460\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2904 - binary_accuracy: 0.8715 - f1: 0.8717 - recall: 0.8725 - precision: 0.8727 - val_loss: 0.3199 - val_binary_accuracy: 0.8575 - val_f1: 0.8478 - val_recall: 0.8225 - val_precision: 0.8764\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2943 - binary_accuracy: 0.8732 - f1: 0.8733 - recall: 0.8734 - precision: 0.8764 - val_loss: 0.3348 - val_binary_accuracy: 0.8502 - val_f1: 0.8520 - val_recall: 0.8911 - val_precision: 0.8176\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2944 - binary_accuracy: 0.8696 - f1: 0.8703 - recall: 0.8726 - precision: 0.8710 - val_loss: 0.3134 - val_binary_accuracy: 0.8668 - val_f1: 0.8643 - val_recall: 0.8782 - val_precision: 0.8520\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2852 - binary_accuracy: 0.8792 - f1: 0.8796 - recall: 0.8828 - precision: 0.8785 - val_loss: 0.3149 - val_binary_accuracy: 0.8619 - val_f1: 0.8525 - val_recall: 0.8266 - val_precision: 0.8809\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2836 - binary_accuracy: 0.8762 - f1: 0.8766 - recall: 0.8780 - precision: 0.8766 - val_loss: 0.3175 - val_binary_accuracy: 0.8575 - val_f1: 0.8500 - val_recall: 0.8367 - val_precision: 0.8646\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2809 - binary_accuracy: 0.8745 - f1: 0.8748 - recall: 0.8776 - precision: 0.8733 - val_loss: 0.3260 - val_binary_accuracy: 0.8516 - val_f1: 0.8459 - val_recall: 0.8421 - val_precision: 0.8503\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2837 - binary_accuracy: 0.8781 - f1: 0.8786 - recall: 0.8809 - precision: 0.8779 - val_loss: 0.3222 - val_binary_accuracy: 0.8619 - val_f1: 0.8518 - val_recall: 0.8235 - val_precision: 0.8836\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2815 - binary_accuracy: 0.8769 - f1: 0.8768 - recall: 0.8760 - precision: 0.8798 - val_loss: 0.3235 - val_binary_accuracy: 0.8614 - val_f1: 0.8610 - val_recall: 0.8872 - val_precision: 0.8374\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2814 - binary_accuracy: 0.8772 - f1: 0.8777 - recall: 0.8816 - precision: 0.8752 - val_loss: 0.3149 - val_binary_accuracy: 0.8629 - val_f1: 0.8528 - val_recall: 0.8234 - val_precision: 0.8854\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2790 - binary_accuracy: 0.8817 - f1: 0.8817 - recall: 0.8794 - precision: 0.8861 - val_loss: 0.3168 - val_binary_accuracy: 0.8580 - val_f1: 0.8484 - val_recall: 0.8245 - val_precision: 0.8745\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2763 - binary_accuracy: 0.8823 - f1: 0.8827 - recall: 0.8837 - precision: 0.8830 - val_loss: 0.3215 - val_binary_accuracy: 0.8551 - val_f1: 0.8472 - val_recall: 0.8311 - val_precision: 0.8645\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2757 - binary_accuracy: 0.8799 - f1: 0.8801 - recall: 0.8807 - precision: 0.8813 - val_loss: 0.3248 - val_binary_accuracy: 0.8516 - val_f1: 0.8458 - val_recall: 0.8453 - val_precision: 0.8471\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2774 - binary_accuracy: 0.8800 - f1: 0.8803 - recall: 0.8802 - precision: 0.8822 - val_loss: 0.3173 - val_binary_accuracy: 0.8599 - val_f1: 0.8541 - val_recall: 0.8488 - val_precision: 0.8602\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2708 - binary_accuracy: 0.8825 - f1: 0.8832 - recall: 0.8871 - precision: 0.8811 - val_loss: 0.3310 - val_binary_accuracy: 0.8546 - val_f1: 0.8403 - val_recall: 0.7941 - val_precision: 0.8938\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2692 - binary_accuracy: 0.8819 - f1: 0.8823 - recall: 0.8848 - precision: 0.8813 - val_loss: 0.3265 - val_binary_accuracy: 0.8604 - val_f1: 0.8511 - val_recall: 0.8250 - val_precision: 0.8798\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2714 - binary_accuracy: 0.8822 - f1: 0.8829 - recall: 0.8831 - precision: 0.8856 - val_loss: 0.3174 - val_binary_accuracy: 0.8643 - val_f1: 0.8563 - val_recall: 0.8360 - val_precision: 0.8789\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2667 - binary_accuracy: 0.8853 - f1: 0.8857 - recall: 0.8865 - precision: 0.8864 - val_loss: 0.3442 - val_binary_accuracy: 0.8492 - val_f1: 0.8512 - val_recall: 0.8936 - val_precision: 0.8132\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2691 - binary_accuracy: 0.8838 - f1: 0.8847 - recall: 0.8873 - precision: 0.8833 - val_loss: 0.3130 - val_binary_accuracy: 0.8633 - val_f1: 0.8583 - val_recall: 0.8571 - val_precision: 0.8606\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2636 - binary_accuracy: 0.8859 - f1: 0.8863 - recall: 0.8881 - precision: 0.8861 - val_loss: 0.3141 - val_binary_accuracy: 0.8594 - val_f1: 0.8551 - val_recall: 0.8564 - val_precision: 0.8544\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2660 - binary_accuracy: 0.8853 - f1: 0.8850 - recall: 0.8842 - precision: 0.8885 - val_loss: 0.3221 - val_binary_accuracy: 0.8609 - val_f1: 0.8586 - val_recall: 0.8732 - val_precision: 0.8458\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2639 - binary_accuracy: 0.8861 - f1: 0.8866 - recall: 0.8892 - precision: 0.8859 - val_loss: 0.3160 - val_binary_accuracy: 0.8604 - val_f1: 0.8564 - val_recall: 0.8611 - val_precision: 0.8525\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2622 - binary_accuracy: 0.8838 - f1: 0.8844 - recall: 0.8876 - precision: 0.8825 - val_loss: 0.3147 - val_binary_accuracy: 0.8619 - val_f1: 0.8520 - val_recall: 0.8261 - val_precision: 0.8811\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2575 - binary_accuracy: 0.8898 - f1: 0.8903 - recall: 0.8919 - precision: 0.8904 - val_loss: 0.3256 - val_binary_accuracy: 0.8570 - val_f1: 0.8457 - val_recall: 0.8116 - val_precision: 0.8839\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2575 - binary_accuracy: 0.8892 - f1: 0.8894 - recall: 0.8908 - precision: 0.8897 - val_loss: 0.3388 - val_binary_accuracy: 0.8516 - val_f1: 0.8523 - val_recall: 0.8860 - val_precision: 0.8218\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2551 - binary_accuracy: 0.8900 - f1: 0.8902 - recall: 0.8923 - precision: 0.8892 - val_loss: 0.3238 - val_binary_accuracy: 0.8531 - val_f1: 0.8435 - val_recall: 0.8198 - val_precision: 0.8693\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2587 - binary_accuracy: 0.8867 - f1: 0.8870 - recall: 0.8882 - precision: 0.8883 - val_loss: 0.3169 - val_binary_accuracy: 0.8594 - val_f1: 0.8510 - val_recall: 0.8333 - val_precision: 0.8704\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2650 - binary_accuracy: 0.8868 - f1: 0.8871 - recall: 0.8884 - precision: 0.8887 - val_loss: 0.3278 - val_binary_accuracy: 0.8516 - val_f1: 0.8477 - val_recall: 0.8541 - val_precision: 0.8419\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2525 - binary_accuracy: 0.8918 - f1: 0.8920 - recall: 0.8916 - precision: 0.8932 - val_loss: 0.3266 - val_binary_accuracy: 0.8624 - val_f1: 0.8523 - val_recall: 0.8211 - val_precision: 0.8873\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2512 - binary_accuracy: 0.8901 - f1: 0.8902 - recall: 0.8923 - precision: 0.8898 - val_loss: 0.3197 - val_binary_accuracy: 0.8555 - val_f1: 0.8521 - val_recall: 0.8621 - val_precision: 0.8431\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2440 - binary_accuracy: 0.8967 - f1: 0.8967 - recall: 0.8973 - precision: 0.8968 - val_loss: 0.3160 - val_binary_accuracy: 0.8624 - val_f1: 0.8584 - val_recall: 0.8620 - val_precision: 0.8554\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2429 - binary_accuracy: 0.8997 - f1: 0.8999 - recall: 0.8998 - precision: 0.9008 - val_loss: 0.3148 - val_binary_accuracy: 0.8643 - val_f1: 0.8561 - val_recall: 0.8357 - val_precision: 0.8781\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2425 - binary_accuracy: 0.8971 - f1: 0.8972 - recall: 0.8981 - precision: 0.8974 - val_loss: 0.3209 - val_binary_accuracy: 0.8629 - val_f1: 0.8520 - val_recall: 0.8218 - val_precision: 0.8853\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2421 - binary_accuracy: 0.8955 - f1: 0.8958 - recall: 0.8968 - precision: 0.8955 - val_loss: 0.3245 - val_binary_accuracy: 0.8551 - val_f1: 0.8486 - val_recall: 0.8418 - val_precision: 0.8564\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2422 - binary_accuracy: 0.8954 - f1: 0.8961 - recall: 0.8984 - precision: 0.8956 - val_loss: 0.3375 - val_binary_accuracy: 0.8536 - val_f1: 0.8382 - val_recall: 0.7833 - val_precision: 0.9031\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2421 - binary_accuracy: 0.8990 - f1: 0.8991 - recall: 0.8988 - precision: 0.9008 - val_loss: 0.3259 - val_binary_accuracy: 0.8614 - val_f1: 0.8574 - val_recall: 0.8630 - val_precision: 0.8529\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2403 - binary_accuracy: 0.8966 - f1: 0.8973 - recall: 0.9016 - precision: 0.8947 - val_loss: 0.3231 - val_binary_accuracy: 0.8604 - val_f1: 0.8530 - val_recall: 0.8370 - val_precision: 0.8702\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2443 - binary_accuracy: 0.8971 - f1: 0.8968 - recall: 0.8967 - precision: 0.8985 - val_loss: 0.3196 - val_binary_accuracy: 0.8580 - val_f1: 0.8489 - val_recall: 0.8268 - val_precision: 0.8734\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2394 - binary_accuracy: 0.8974 - f1: 0.8977 - recall: 0.8969 - precision: 0.9005 - val_loss: 0.3383 - val_binary_accuracy: 0.8604 - val_f1: 0.8521 - val_recall: 0.8318 - val_precision: 0.8746\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2400 - binary_accuracy: 0.8975 - f1: 0.8973 - recall: 0.8968 - precision: 0.8994 - val_loss: 0.3352 - val_binary_accuracy: 0.8511 - val_f1: 0.8387 - val_recall: 0.8035 - val_precision: 0.8787\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2344 - binary_accuracy: 0.8999 - f1: 0.8999 - recall: 0.8984 - precision: 0.9032 - val_loss: 0.3307 - val_binary_accuracy: 0.8570 - val_f1: 0.8471 - val_recall: 0.8207 - val_precision: 0.8765\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2271 - binary_accuracy: 0.9040 - f1: 0.9038 - recall: 0.9024 - precision: 0.9068 - val_loss: 0.3351 - val_binary_accuracy: 0.8565 - val_f1: 0.8517 - val_recall: 0.8532 - val_precision: 0.8510\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2298 - binary_accuracy: 0.9028 - f1: 0.9030 - recall: 0.9037 - precision: 0.9031 - val_loss: 0.3233 - val_binary_accuracy: 0.8590 - val_f1: 0.8505 - val_recall: 0.8327 - val_precision: 0.8705\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2241 - binary_accuracy: 0.9082 - f1: 0.9084 - recall: 0.9079 - precision: 0.9097 - val_loss: 0.3261 - val_binary_accuracy: 0.8638 - val_f1: 0.8580 - val_recall: 0.8551 - val_precision: 0.8613\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2262 - binary_accuracy: 0.9052 - f1: 0.9051 - recall: 0.9050 - precision: 0.9072 - val_loss: 0.3401 - val_binary_accuracy: 0.8536 - val_f1: 0.8427 - val_recall: 0.8136 - val_precision: 0.8747\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2244 - binary_accuracy: 0.9068 - f1: 0.9074 - recall: 0.9092 - precision: 0.9072 - val_loss: 0.3370 - val_binary_accuracy: 0.8633 - val_f1: 0.8573 - val_recall: 0.8507 - val_precision: 0.8647\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2238 - binary_accuracy: 0.9066 - f1: 0.9067 - recall: 0.9059 - precision: 0.9087 - val_loss: 0.3292 - val_binary_accuracy: 0.8663 - val_f1: 0.8567 - val_recall: 0.8293 - val_precision: 0.8868\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2224 - binary_accuracy: 0.9090 - f1: 0.9096 - recall: 0.9119 - precision: 0.9082 - val_loss: 0.3532 - val_binary_accuracy: 0.8487 - val_f1: 0.8345 - val_recall: 0.7881 - val_precision: 0.8877\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2276 - binary_accuracy: 0.9049 - f1: 0.9053 - recall: 0.9052 - precision: 0.9078 - val_loss: 0.3367 - val_binary_accuracy: 0.8633 - val_f1: 0.8559 - val_recall: 0.8391 - val_precision: 0.8738\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2171 - binary_accuracy: 0.9091 - f1: 0.9090 - recall: 0.9079 - precision: 0.9124 - val_loss: 0.3253 - val_binary_accuracy: 0.8624 - val_f1: 0.8571 - val_recall: 0.8566 - val_precision: 0.8581\n",
      "2049/2049 [==============================] - 0s     \n",
      "tn = 3927, fp = 453, fn = 314, tp = 4117\n",
      "y_pred: 0 = 4241 | 1 = 4570\n",
      "y_true: 0 = 4380 | 1 = 4431\n",
      "acc=0.9129|precision=0.9009|recall=0.9291|f1=0.9148|auc=0.9740|aupr=0.9752|pos_acc=0.9291|neg_acc=0.9260\n",
      "tn = 910, fp = 140, fn = 142, tp = 857\n",
      "y_pred: 0 = 1052 | 1 = 997\n",
      "y_true: 0 = 1050 | 1 = 999\n",
      "acc=0.8624|precision=0.8596|recall=0.8579|f1=0.8587|auc=0.9385|aupr=0.9314|pos_acc=0.8579|neg_acc=0.8650\n",
      "----------------------- Fold =  2\n",
      "Train on 8782 samples, validate on 2078 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4039 - binary_accuracy: 0.8138 - f1: 0.7964 - recall: 0.7771 - precision: 0.8531 - val_loss: 0.3622 - val_binary_accuracy: 0.8369 - val_f1: 0.8065 - val_recall: 0.7666 - val_precision: 0.8527\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3557 - binary_accuracy: 0.8406 - f1: 0.8428 - recall: 0.8380 - precision: 0.8514 - val_loss: 0.3568 - val_binary_accuracy: 0.8436 - val_f1: 0.8267 - val_recall: 0.8451 - val_precision: 0.8105\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3438 - binary_accuracy: 0.8473 - f1: 0.8505 - recall: 0.8500 - precision: 0.8546 - val_loss: 0.3535 - val_binary_accuracy: 0.8470 - val_f1: 0.8333 - val_recall: 0.8678 - val_precision: 0.8028\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3394 - binary_accuracy: 0.8499 - f1: 0.8531 - recall: 0.8550 - precision: 0.8546 - val_loss: 0.3495 - val_binary_accuracy: 0.8489 - val_f1: 0.8205 - val_recall: 0.7807 - val_precision: 0.8664\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3295 - binary_accuracy: 0.8565 - f1: 0.8593 - recall: 0.8599 - precision: 0.8601 - val_loss: 0.3401 - val_binary_accuracy: 0.8542 - val_f1: 0.8322 - val_recall: 0.8205 - val_precision: 0.8461\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3265 - binary_accuracy: 0.8574 - f1: 0.8600 - recall: 0.8599 - precision: 0.8614 - val_loss: 0.3647 - val_binary_accuracy: 0.8441 - val_f1: 0.8342 - val_recall: 0.8874 - val_precision: 0.7882\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3236 - binary_accuracy: 0.8583 - f1: 0.8613 - recall: 0.8622 - precision: 0.8627 - val_loss: 0.3507 - val_binary_accuracy: 0.8499 - val_f1: 0.8371 - val_recall: 0.8756 - val_precision: 0.8038\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3246 - binary_accuracy: 0.8572 - f1: 0.8620 - recall: 0.8715 - precision: 0.8547 - val_loss: 0.3329 - val_binary_accuracy: 0.8571 - val_f1: 0.8355 - val_recall: 0.8210 - val_precision: 0.8518\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3206 - binary_accuracy: 0.8603 - f1: 0.8641 - recall: 0.8706 - precision: 0.8608 - val_loss: 0.3354 - val_binary_accuracy: 0.8566 - val_f1: 0.8318 - val_recall: 0.8035 - val_precision: 0.8641\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3147 - binary_accuracy: 0.8629 - f1: 0.8662 - recall: 0.8690 - precision: 0.8652 - val_loss: 0.3443 - val_binary_accuracy: 0.8518 - val_f1: 0.8226 - val_recall: 0.7788 - val_precision: 0.8749\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3222 - binary_accuracy: 0.8571 - f1: 0.8588 - recall: 0.8575 - precision: 0.8642 - val_loss: 0.3471 - val_binary_accuracy: 0.8450 - val_f1: 0.8333 - val_recall: 0.8740 - val_precision: 0.7971\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3147 - binary_accuracy: 0.8614 - f1: 0.8655 - recall: 0.8730 - precision: 0.8602 - val_loss: 0.3415 - val_binary_accuracy: 0.8523 - val_f1: 0.8386 - val_recall: 0.8674 - val_precision: 0.8130\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3140 - binary_accuracy: 0.8602 - f1: 0.8631 - recall: 0.8655 - precision: 0.8626 - val_loss: 0.3355 - val_binary_accuracy: 0.8571 - val_f1: 0.8387 - val_recall: 0.8406 - val_precision: 0.8386\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3135 - binary_accuracy: 0.8610 - f1: 0.8638 - recall: 0.8668 - precision: 0.8639 - val_loss: 0.3691 - val_binary_accuracy: 0.8369 - val_f1: 0.8336 - val_recall: 0.9205 - val_precision: 0.7626\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3139 - binary_accuracy: 0.8619 - f1: 0.8649 - recall: 0.8697 - precision: 0.8640 - val_loss: 0.3500 - val_binary_accuracy: 0.8532 - val_f1: 0.8394 - val_recall: 0.8695 - val_precision: 0.8132\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3073 - binary_accuracy: 0.8636 - f1: 0.8667 - recall: 0.8683 - precision: 0.8669 - val_loss: 0.3352 - val_binary_accuracy: 0.8600 - val_f1: 0.8462 - val_recall: 0.8719 - val_precision: 0.8236\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3077 - binary_accuracy: 0.8634 - f1: 0.8671 - recall: 0.8730 - precision: 0.8640 - val_loss: 0.3301 - val_binary_accuracy: 0.8547 - val_f1: 0.8302 - val_recall: 0.8059 - val_precision: 0.8578\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3063 - binary_accuracy: 0.8670 - f1: 0.8702 - recall: 0.8740 - precision: 0.8686 - val_loss: 0.3360 - val_binary_accuracy: 0.8590 - val_f1: 0.8420 - val_recall: 0.8511 - val_precision: 0.8347\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3072 - binary_accuracy: 0.8655 - f1: 0.8693 - recall: 0.8776 - precision: 0.8630 - val_loss: 0.3409 - val_binary_accuracy: 0.8590 - val_f1: 0.8463 - val_recall: 0.8794 - val_precision: 0.8169\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3022 - binary_accuracy: 0.8665 - f1: 0.8695 - recall: 0.8699 - precision: 0.8705 - val_loss: 0.3435 - val_binary_accuracy: 0.8523 - val_f1: 0.8421 - val_recall: 0.8869 - val_precision: 0.8024\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3050 - binary_accuracy: 0.8652 - f1: 0.8685 - recall: 0.8712 - precision: 0.8681 - val_loss: 0.3416 - val_binary_accuracy: 0.8518 - val_f1: 0.8378 - val_recall: 0.8665 - val_precision: 0.8126\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3054 - binary_accuracy: 0.8648 - f1: 0.8685 - recall: 0.8765 - precision: 0.8631 - val_loss: 0.3356 - val_binary_accuracy: 0.8571 - val_f1: 0.8415 - val_recall: 0.8567 - val_precision: 0.8283\n",
      "Epoch 23/500\n",
      "0s - loss: 0.2984 - binary_accuracy: 0.8716 - f1: 0.8751 - recall: 0.8813 - precision: 0.8700 - val_loss: 0.3280 - val_binary_accuracy: 0.8590 - val_f1: 0.8387 - val_recall: 0.8290 - val_precision: 0.8501\n",
      "Epoch 24/500\n",
      "0s - loss: 0.2967 - binary_accuracy: 0.8685 - f1: 0.8718 - recall: 0.8755 - precision: 0.8693 - val_loss: 0.3340 - val_binary_accuracy: 0.8561 - val_f1: 0.8321 - val_recall: 0.8081 - val_precision: 0.8596\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2945 - binary_accuracy: 0.8696 - f1: 0.8732 - recall: 0.8790 - precision: 0.8685 - val_loss: 0.3659 - val_binary_accuracy: 0.8465 - val_f1: 0.8408 - val_recall: 0.9148 - val_precision: 0.7783\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3066 - binary_accuracy: 0.8654 - f1: 0.8683 - recall: 0.8738 - precision: 0.8678 - val_loss: 0.3311 - val_binary_accuracy: 0.8619 - val_f1: 0.8455 - val_recall: 0.8547 - val_precision: 0.8385\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2961 - binary_accuracy: 0.8712 - f1: 0.8741 - recall: 0.8787 - precision: 0.8704 - val_loss: 0.3339 - val_binary_accuracy: 0.8508 - val_f1: 0.8246 - val_recall: 0.7926 - val_precision: 0.8615\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2949 - binary_accuracy: 0.8703 - f1: 0.8733 - recall: 0.8769 - precision: 0.8719 - val_loss: 0.3770 - val_binary_accuracy: 0.8436 - val_f1: 0.8390 - val_recall: 0.9180 - val_precision: 0.7736\n",
      "Epoch 29/500\n",
      "0s - loss: 0.3035 - binary_accuracy: 0.8685 - f1: 0.8723 - recall: 0.8783 - precision: 0.8709 - val_loss: 0.3419 - val_binary_accuracy: 0.8518 - val_f1: 0.8374 - val_recall: 0.8612 - val_precision: 0.8156\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2966 - binary_accuracy: 0.8697 - f1: 0.8733 - recall: 0.8796 - precision: 0.8689 - val_loss: 0.3399 - val_binary_accuracy: 0.8518 - val_f1: 0.8234 - val_recall: 0.7840 - val_precision: 0.8694\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2929 - binary_accuracy: 0.8717 - f1: 0.8741 - recall: 0.8741 - precision: 0.8765 - val_loss: 0.3326 - val_binary_accuracy: 0.8590 - val_f1: 0.8449 - val_recall: 0.8676 - val_precision: 0.8246\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2863 - binary_accuracy: 0.8734 - f1: 0.8770 - recall: 0.8804 - precision: 0.8749 - val_loss: 0.3317 - val_binary_accuracy: 0.8638 - val_f1: 0.8484 - val_recall: 0.8593 - val_precision: 0.8391\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8779 - f1: 0.8814 - recall: 0.8859 - precision: 0.8781 - val_loss: 0.3325 - val_binary_accuracy: 0.8624 - val_f1: 0.8472 - val_recall: 0.8632 - val_precision: 0.8332\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2803 - binary_accuracy: 0.8770 - f1: 0.8804 - recall: 0.8856 - precision: 0.8765 - val_loss: 0.3297 - val_binary_accuracy: 0.8672 - val_f1: 0.8500 - val_recall: 0.8541 - val_precision: 0.8476\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2797 - binary_accuracy: 0.8787 - f1: 0.8815 - recall: 0.8833 - precision: 0.8803 - val_loss: 0.3348 - val_binary_accuracy: 0.8628 - val_f1: 0.8487 - val_recall: 0.8701 - val_precision: 0.8300\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2884 - binary_accuracy: 0.8777 - f1: 0.8814 - recall: 0.8892 - precision: 0.8761 - val_loss: 0.3371 - val_binary_accuracy: 0.8503 - val_f1: 0.8212 - val_recall: 0.7782 - val_precision: 0.8715\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2862 - binary_accuracy: 0.8727 - f1: 0.8752 - recall: 0.8769 - precision: 0.8758 - val_loss: 0.3337 - val_binary_accuracy: 0.8571 - val_f1: 0.8336 - val_recall: 0.8101 - val_precision: 0.8603\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2819 - binary_accuracy: 0.8749 - f1: 0.8778 - recall: 0.8807 - precision: 0.8765 - val_loss: 0.3293 - val_binary_accuracy: 0.8672 - val_f1: 0.8503 - val_recall: 0.8555 - val_precision: 0.8467\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2834 - binary_accuracy: 0.8736 - f1: 0.8766 - recall: 0.8790 - precision: 0.8770 - val_loss: 0.3329 - val_binary_accuracy: 0.8628 - val_f1: 0.8471 - val_recall: 0.8601 - val_precision: 0.8358\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2719 - binary_accuracy: 0.8819 - f1: 0.8845 - recall: 0.8865 - precision: 0.8836 - val_loss: 0.3389 - val_binary_accuracy: 0.8571 - val_f1: 0.8455 - val_recall: 0.8825 - val_precision: 0.8121\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2798 - binary_accuracy: 0.8761 - f1: 0.8797 - recall: 0.8869 - precision: 0.8738 - val_loss: 0.3320 - val_binary_accuracy: 0.8556 - val_f1: 0.8304 - val_recall: 0.8004 - val_precision: 0.8649\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2704 - binary_accuracy: 0.8845 - f1: 0.8870 - recall: 0.8887 - precision: 0.8865 - val_loss: 0.3322 - val_binary_accuracy: 0.8600 - val_f1: 0.8383 - val_recall: 0.8234 - val_precision: 0.8569\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2687 - binary_accuracy: 0.8854 - f1: 0.8876 - recall: 0.8877 - precision: 0.8887 - val_loss: 0.3333 - val_binary_accuracy: 0.8561 - val_f1: 0.8360 - val_recall: 0.8297 - val_precision: 0.8434\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2737 - binary_accuracy: 0.8820 - f1: 0.8852 - recall: 0.8901 - precision: 0.8832 - val_loss: 0.3498 - val_binary_accuracy: 0.8527 - val_f1: 0.8438 - val_recall: 0.8986 - val_precision: 0.7959\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2680 - binary_accuracy: 0.8828 - f1: 0.8857 - recall: 0.8878 - precision: 0.8855 - val_loss: 0.3395 - val_binary_accuracy: 0.8614 - val_f1: 0.8430 - val_recall: 0.8418 - val_precision: 0.8457\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2737 - binary_accuracy: 0.8811 - f1: 0.8837 - recall: 0.8873 - precision: 0.8826 - val_loss: 0.3321 - val_binary_accuracy: 0.8653 - val_f1: 0.8484 - val_recall: 0.8554 - val_precision: 0.8435\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2682 - binary_accuracy: 0.8829 - f1: 0.8861 - recall: 0.8903 - precision: 0.8833 - val_loss: 0.3329 - val_binary_accuracy: 0.8576 - val_f1: 0.8392 - val_recall: 0.8439 - val_precision: 0.8359\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2606 - binary_accuracy: 0.8860 - f1: 0.8889 - recall: 0.8929 - precision: 0.8857 - val_loss: 0.3358 - val_binary_accuracy: 0.8576 - val_f1: 0.8412 - val_recall: 0.8561 - val_precision: 0.8299\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2603 - binary_accuracy: 0.8899 - f1: 0.8923 - recall: 0.8969 - precision: 0.8888 - val_loss: 0.3343 - val_binary_accuracy: 0.8576 - val_f1: 0.8399 - val_recall: 0.8454 - val_precision: 0.8350\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2563 - binary_accuracy: 0.8898 - f1: 0.8924 - recall: 0.8956 - precision: 0.8901 - val_loss: 0.3467 - val_binary_accuracy: 0.8590 - val_f1: 0.8458 - val_recall: 0.8718 - val_precision: 0.8220\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2568 - binary_accuracy: 0.8927 - f1: 0.8960 - recall: 0.9032 - precision: 0.8899 - val_loss: 0.3534 - val_binary_accuracy: 0.8590 - val_f1: 0.8352 - val_recall: 0.8116 - val_precision: 0.8619\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2595 - binary_accuracy: 0.8894 - f1: 0.8922 - recall: 0.8965 - precision: 0.8895 - val_loss: 0.3342 - val_binary_accuracy: 0.8580 - val_f1: 0.8361 - val_recall: 0.8221 - val_precision: 0.8534\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2535 - binary_accuracy: 0.8907 - f1: 0.8936 - recall: 0.8976 - precision: 0.8911 - val_loss: 0.3490 - val_binary_accuracy: 0.8561 - val_f1: 0.8343 - val_recall: 0.8198 - val_precision: 0.8507\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2541 - binary_accuracy: 0.8882 - f1: 0.8912 - recall: 0.8972 - precision: 0.8872 - val_loss: 0.3354 - val_binary_accuracy: 0.8580 - val_f1: 0.8389 - val_recall: 0.8403 - val_precision: 0.8395\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2530 - binary_accuracy: 0.8914 - f1: 0.8941 - recall: 0.8965 - precision: 0.8928 - val_loss: 0.3352 - val_binary_accuracy: 0.8523 - val_f1: 0.8324 - val_recall: 0.8336 - val_precision: 0.8329\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2508 - binary_accuracy: 0.8927 - f1: 0.8959 - recall: 0.9004 - precision: 0.8928 - val_loss: 0.3402 - val_binary_accuracy: 0.8600 - val_f1: 0.8402 - val_recall: 0.8318 - val_precision: 0.8503\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2468 - binary_accuracy: 0.8956 - f1: 0.8981 - recall: 0.8994 - precision: 0.8978 - val_loss: 0.3443 - val_binary_accuracy: 0.8609 - val_f1: 0.8443 - val_recall: 0.8536 - val_precision: 0.8360\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2476 - binary_accuracy: 0.8921 - f1: 0.8944 - recall: 0.8969 - precision: 0.8930 - val_loss: 0.3390 - val_binary_accuracy: 0.8494 - val_f1: 0.8321 - val_recall: 0.8453 - val_precision: 0.8205\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2465 - binary_accuracy: 0.8946 - f1: 0.8970 - recall: 0.9012 - precision: 0.8935 - val_loss: 0.3507 - val_binary_accuracy: 0.8499 - val_f1: 0.8329 - val_recall: 0.8464 - val_precision: 0.8204\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2451 - binary_accuracy: 0.8936 - f1: 0.8968 - recall: 0.9016 - precision: 0.8932 - val_loss: 0.3471 - val_binary_accuracy: 0.8532 - val_f1: 0.8372 - val_recall: 0.8542 - val_precision: 0.8219\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2475 - binary_accuracy: 0.8927 - f1: 0.8949 - recall: 0.8945 - precision: 0.8970 - val_loss: 0.3440 - val_binary_accuracy: 0.8614 - val_f1: 0.8469 - val_recall: 0.8680 - val_precision: 0.8275\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2422 - binary_accuracy: 0.8962 - f1: 0.8991 - recall: 0.9051 - precision: 0.8949 - val_loss: 0.3369 - val_binary_accuracy: 0.8580 - val_f1: 0.8392 - val_recall: 0.8431 - val_precision: 0.8372\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2446 - binary_accuracy: 0.8963 - f1: 0.8977 - recall: 0.8936 - precision: 0.9040 - val_loss: 0.3522 - val_binary_accuracy: 0.8542 - val_f1: 0.8419 - val_recall: 0.8777 - val_precision: 0.8093\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2334 - binary_accuracy: 0.9031 - f1: 0.9054 - recall: 0.9083 - precision: 0.9035 - val_loss: 0.3407 - val_binary_accuracy: 0.8513 - val_f1: 0.8345 - val_recall: 0.8517 - val_precision: 0.8196\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2348 - binary_accuracy: 0.9022 - f1: 0.9043 - recall: 0.9085 - precision: 0.9009 - val_loss: 0.3520 - val_binary_accuracy: 0.8547 - val_f1: 0.8409 - val_recall: 0.8712 - val_precision: 0.8133\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2353 - binary_accuracy: 0.8985 - f1: 0.9009 - recall: 0.9044 - precision: 0.8988 - val_loss: 0.3549 - val_binary_accuracy: 0.8460 - val_f1: 0.8307 - val_recall: 0.8563 - val_precision: 0.8074\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2325 - binary_accuracy: 0.9014 - f1: 0.9037 - recall: 0.9070 - precision: 0.9024 - val_loss: 0.3472 - val_binary_accuracy: 0.8580 - val_f1: 0.8438 - val_recall: 0.8661 - val_precision: 0.8234\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2279 - binary_accuracy: 0.9041 - f1: 0.9055 - recall: 0.9081 - precision: 0.9042 - val_loss: 0.3434 - val_binary_accuracy: 0.8561 - val_f1: 0.8346 - val_recall: 0.8250 - val_precision: 0.8463\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2333 - binary_accuracy: 0.8995 - f1: 0.9017 - recall: 0.9053 - precision: 0.8994 - val_loss: 0.3503 - val_binary_accuracy: 0.8527 - val_f1: 0.8348 - val_recall: 0.8468 - val_precision: 0.8244\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2348 - binary_accuracy: 0.9004 - f1: 0.9025 - recall: 0.9059 - precision: 0.9003 - val_loss: 0.3606 - val_binary_accuracy: 0.8479 - val_f1: 0.8338 - val_recall: 0.8663 - val_precision: 0.8049\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2316 - binary_accuracy: 0.8981 - f1: 0.9006 - recall: 0.9045 - precision: 0.8993 - val_loss: 0.3492 - val_binary_accuracy: 0.8595 - val_f1: 0.8344 - val_recall: 0.8051 - val_precision: 0.8692\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2317 - binary_accuracy: 0.9037 - f1: 0.9061 - recall: 0.9114 - precision: 0.9027 - val_loss: 0.3551 - val_binary_accuracy: 0.8503 - val_f1: 0.8264 - val_recall: 0.8098 - val_precision: 0.8465\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2198 - binary_accuracy: 0.9079 - f1: 0.9096 - recall: 0.9071 - precision: 0.9131 - val_loss: 0.3501 - val_binary_accuracy: 0.8470 - val_f1: 0.8336 - val_recall: 0.8689 - val_precision: 0.8017\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2174 - binary_accuracy: 0.9096 - f1: 0.9115 - recall: 0.9121 - precision: 0.9120 - val_loss: 0.3465 - val_binary_accuracy: 0.8518 - val_f1: 0.8342 - val_recall: 0.8481 - val_precision: 0.8223\n",
      "1984/2078 [===========================>..] - ETA: 0stn = 3889, fp = 392, fn = 364, tp = 4137\n",
      "y_pred: 0 = 4253 | 1 = 4529\n",
      "y_true: 0 = 4281 | 1 = 4501\n",
      "acc=0.9139|precision=0.9134|recall=0.9191|f1=0.9163|auc=0.9748|aupr=0.9769|pos_acc=0.9191|neg_acc=0.9144\n",
      "tn = 980, fp = 169, fn = 139, tp = 790\n",
      "y_pred: 0 = 1119 | 1 = 959\n",
      "y_true: 0 = 1149 | 1 = 929\n",
      "acc=0.8518|precision=0.8238|recall=0.8504|f1=0.8369|auc=0.9305|aupr=0.9128|pos_acc=0.8504|neg_acc=0.8758\n",
      "----------------------- Fold =  3\n",
      "Train on 8684 samples, validate on 2176 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4150 - binary_accuracy: 0.8092 - f1: 0.8026 - recall: 0.7904 - precision: 0.8355 - val_loss: 0.3575 - val_binary_accuracy: 0.8396 - val_f1: 0.8484 - val_recall: 0.8590 - val_precision: 0.8388\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3544 - binary_accuracy: 0.8464 - f1: 0.8427 - recall: 0.8379 - precision: 0.8510 - val_loss: 0.3437 - val_binary_accuracy: 0.8548 - val_f1: 0.8610 - val_recall: 0.8614 - val_precision: 0.8611\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3478 - binary_accuracy: 0.8493 - f1: 0.8465 - recall: 0.8443 - precision: 0.8525 - val_loss: 0.3398 - val_binary_accuracy: 0.8502 - val_f1: 0.8600 - val_recall: 0.8807 - val_precision: 0.8410\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3385 - binary_accuracy: 0.8494 - f1: 0.8461 - recall: 0.8412 - precision: 0.8535 - val_loss: 0.3333 - val_binary_accuracy: 0.8520 - val_f1: 0.8547 - val_recall: 0.8348 - val_precision: 0.8763\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3375 - binary_accuracy: 0.8529 - f1: 0.8492 - recall: 0.8465 - precision: 0.8567 - val_loss: 0.3353 - val_binary_accuracy: 0.8460 - val_f1: 0.8597 - val_recall: 0.9019 - val_precision: 0.8219\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3319 - binary_accuracy: 0.8544 - f1: 0.8524 - recall: 0.8550 - precision: 0.8527 - val_loss: 0.3282 - val_binary_accuracy: 0.8511 - val_f1: 0.8559 - val_recall: 0.8473 - val_precision: 0.8653\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3276 - binary_accuracy: 0.8551 - f1: 0.8523 - recall: 0.8490 - precision: 0.8580 - val_loss: 0.3251 - val_binary_accuracy: 0.8594 - val_f1: 0.8678 - val_recall: 0.8842 - val_precision: 0.8526\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3245 - binary_accuracy: 0.8578 - f1: 0.8559 - recall: 0.8589 - precision: 0.8550 - val_loss: 0.3335 - val_binary_accuracy: 0.8529 - val_f1: 0.8537 - val_recall: 0.8226 - val_precision: 0.8879\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3278 - binary_accuracy: 0.8544 - f1: 0.8521 - recall: 0.8505 - precision: 0.8564 - val_loss: 0.3295 - val_binary_accuracy: 0.8566 - val_f1: 0.8608 - val_recall: 0.8497 - val_precision: 0.8728\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3192 - binary_accuracy: 0.8586 - f1: 0.8565 - recall: 0.8579 - precision: 0.8570 - val_loss: 0.3231 - val_binary_accuracy: 0.8626 - val_f1: 0.8719 - val_recall: 0.8956 - val_precision: 0.8500\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3233 - binary_accuracy: 0.8586 - f1: 0.8566 - recall: 0.8580 - precision: 0.8587 - val_loss: 0.3307 - val_binary_accuracy: 0.8502 - val_f1: 0.8551 - val_recall: 0.8455 - val_precision: 0.8654\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3184 - binary_accuracy: 0.8597 - f1: 0.8580 - recall: 0.8593 - precision: 0.8586 - val_loss: 0.3217 - val_binary_accuracy: 0.8603 - val_f1: 0.8628 - val_recall: 0.8422 - val_precision: 0.8851\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3156 - binary_accuracy: 0.8615 - f1: 0.8591 - recall: 0.8572 - precision: 0.8632 - val_loss: 0.3329 - val_binary_accuracy: 0.8511 - val_f1: 0.8583 - val_recall: 0.8614 - val_precision: 0.8557\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3152 - binary_accuracy: 0.8592 - f1: 0.8578 - recall: 0.8620 - precision: 0.8558 - val_loss: 0.3213 - val_binary_accuracy: 0.8653 - val_f1: 0.8701 - val_recall: 0.8654 - val_precision: 0.8755\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3131 - binary_accuracy: 0.8629 - f1: 0.8605 - recall: 0.8604 - precision: 0.8633 - val_loss: 0.3242 - val_binary_accuracy: 0.8543 - val_f1: 0.8592 - val_recall: 0.8492 - val_precision: 0.8697\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3132 - binary_accuracy: 0.8592 - f1: 0.8575 - recall: 0.8594 - precision: 0.8579 - val_loss: 0.3228 - val_binary_accuracy: 0.8649 - val_f1: 0.8756 - val_recall: 0.9097 - val_precision: 0.8445\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3089 - binary_accuracy: 0.8625 - f1: 0.8597 - recall: 0.8575 - precision: 0.8646 - val_loss: 0.3215 - val_binary_accuracy: 0.8644 - val_f1: 0.8746 - val_recall: 0.9044 - val_precision: 0.8470\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3086 - binary_accuracy: 0.8646 - f1: 0.8628 - recall: 0.8645 - precision: 0.8631 - val_loss: 0.3230 - val_binary_accuracy: 0.8585 - val_f1: 0.8620 - val_recall: 0.8479 - val_precision: 0.8773\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3154 - binary_accuracy: 0.8618 - f1: 0.8597 - recall: 0.8613 - precision: 0.8620 - val_loss: 0.3199 - val_binary_accuracy: 0.8585 - val_f1: 0.8624 - val_recall: 0.8493 - val_precision: 0.8766\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3090 - binary_accuracy: 0.8640 - f1: 0.8622 - recall: 0.8610 - precision: 0.8656 - val_loss: 0.3244 - val_binary_accuracy: 0.8539 - val_f1: 0.8543 - val_recall: 0.8195 - val_precision: 0.8927\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3053 - binary_accuracy: 0.8687 - f1: 0.8669 - recall: 0.8694 - precision: 0.8662 - val_loss: 0.3157 - val_binary_accuracy: 0.8631 - val_f1: 0.8705 - val_recall: 0.8822 - val_precision: 0.8596\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3059 - binary_accuracy: 0.8647 - f1: 0.8620 - recall: 0.8601 - precision: 0.8665 - val_loss: 0.3290 - val_binary_accuracy: 0.8552 - val_f1: 0.8669 - val_recall: 0.9017 - val_precision: 0.8353\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3005 - binary_accuracy: 0.8664 - f1: 0.8646 - recall: 0.8673 - precision: 0.8635 - val_loss: 0.3155 - val_binary_accuracy: 0.8617 - val_f1: 0.8668 - val_recall: 0.8630 - val_precision: 0.8713\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3007 - binary_accuracy: 0.8688 - f1: 0.8666 - recall: 0.8681 - precision: 0.8679 - val_loss: 0.3220 - val_binary_accuracy: 0.8635 - val_f1: 0.8719 - val_recall: 0.8902 - val_precision: 0.8549\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3013 - binary_accuracy: 0.8696 - f1: 0.8679 - recall: 0.8688 - precision: 0.8689 - val_loss: 0.3239 - val_binary_accuracy: 0.8520 - val_f1: 0.8536 - val_recall: 0.8259 - val_precision: 0.8842\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2967 - binary_accuracy: 0.8699 - f1: 0.8675 - recall: 0.8680 - precision: 0.8688 - val_loss: 0.3202 - val_binary_accuracy: 0.8626 - val_f1: 0.8650 - val_recall: 0.8445 - val_precision: 0.8872\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2987 - binary_accuracy: 0.8708 - f1: 0.8684 - recall: 0.8682 - precision: 0.8710 - val_loss: 0.3155 - val_binary_accuracy: 0.8658 - val_f1: 0.8738 - val_recall: 0.8910 - val_precision: 0.8580\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2970 - binary_accuracy: 0.8696 - f1: 0.8678 - recall: 0.8689 - precision: 0.8694 - val_loss: 0.3181 - val_binary_accuracy: 0.8617 - val_f1: 0.8711 - val_recall: 0.8954 - val_precision: 0.8489\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2960 - binary_accuracy: 0.8706 - f1: 0.8685 - recall: 0.8678 - precision: 0.8717 - val_loss: 0.3133 - val_binary_accuracy: 0.8649 - val_f1: 0.8698 - val_recall: 0.8648 - val_precision: 0.8754\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2955 - binary_accuracy: 0.8730 - f1: 0.8719 - recall: 0.8752 - precision: 0.8713 - val_loss: 0.3155 - val_binary_accuracy: 0.8658 - val_f1: 0.8733 - val_recall: 0.8858 - val_precision: 0.8615\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2939 - binary_accuracy: 0.8700 - f1: 0.8683 - recall: 0.8687 - precision: 0.8701 - val_loss: 0.3140 - val_binary_accuracy: 0.8617 - val_f1: 0.8670 - val_recall: 0.8641 - val_precision: 0.8709\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2892 - binary_accuracy: 0.8721 - f1: 0.8703 - recall: 0.8702 - precision: 0.8715 - val_loss: 0.3163 - val_binary_accuracy: 0.8621 - val_f1: 0.8673 - val_recall: 0.8639 - val_precision: 0.8713\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2886 - binary_accuracy: 0.8745 - f1: 0.8725 - recall: 0.8745 - precision: 0.8723 - val_loss: 0.3166 - val_binary_accuracy: 0.8612 - val_f1: 0.8664 - val_recall: 0.8609 - val_precision: 0.8724\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2909 - binary_accuracy: 0.8726 - f1: 0.8710 - recall: 0.8728 - precision: 0.8721 - val_loss: 0.3172 - val_binary_accuracy: 0.8626 - val_f1: 0.8671 - val_recall: 0.8596 - val_precision: 0.8757\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2892 - binary_accuracy: 0.8715 - f1: 0.8702 - recall: 0.8736 - precision: 0.8689 - val_loss: 0.3225 - val_binary_accuracy: 0.8562 - val_f1: 0.8599 - val_recall: 0.8459 - val_precision: 0.8751\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2823 - binary_accuracy: 0.8767 - f1: 0.8743 - recall: 0.8733 - precision: 0.8763 - val_loss: 0.3150 - val_binary_accuracy: 0.8653 - val_f1: 0.8693 - val_recall: 0.8585 - val_precision: 0.8811\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2802 - binary_accuracy: 0.8778 - f1: 0.8758 - recall: 0.8755 - precision: 0.8774 - val_loss: 0.3205 - val_binary_accuracy: 0.8617 - val_f1: 0.8716 - val_recall: 0.8990 - val_precision: 0.8463\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2829 - binary_accuracy: 0.8747 - f1: 0.8727 - recall: 0.8755 - precision: 0.8718 - val_loss: 0.3320 - val_binary_accuracy: 0.8566 - val_f1: 0.8580 - val_recall: 0.8312 - val_precision: 0.8874\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2815 - binary_accuracy: 0.8777 - f1: 0.8761 - recall: 0.8779 - precision: 0.8760 - val_loss: 0.3209 - val_binary_accuracy: 0.8506 - val_f1: 0.8537 - val_recall: 0.8338 - val_precision: 0.8752\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2790 - binary_accuracy: 0.8772 - f1: 0.8756 - recall: 0.8755 - precision: 0.8772 - val_loss: 0.3182 - val_binary_accuracy: 0.8653 - val_f1: 0.8714 - val_recall: 0.8735 - val_precision: 0.8696\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2816 - binary_accuracy: 0.8755 - f1: 0.8734 - recall: 0.8755 - precision: 0.8739 - val_loss: 0.3302 - val_binary_accuracy: 0.8529 - val_f1: 0.8560 - val_recall: 0.8369 - val_precision: 0.8764\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2784 - binary_accuracy: 0.8806 - f1: 0.8785 - recall: 0.8772 - precision: 0.8809 - val_loss: 0.3228 - val_binary_accuracy: 0.8548 - val_f1: 0.8571 - val_recall: 0.8335 - val_precision: 0.8827\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2758 - binary_accuracy: 0.8791 - f1: 0.8773 - recall: 0.8791 - precision: 0.8762 - val_loss: 0.3210 - val_binary_accuracy: 0.8640 - val_f1: 0.8665 - val_recall: 0.8464 - val_precision: 0.8883\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2718 - binary_accuracy: 0.8790 - f1: 0.8772 - recall: 0.8775 - precision: 0.8782 - val_loss: 0.3206 - val_binary_accuracy: 0.8644 - val_f1: 0.8683 - val_recall: 0.8569 - val_precision: 0.8810\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2777 - binary_accuracy: 0.8807 - f1: 0.8791 - recall: 0.8818 - precision: 0.8781 - val_loss: 0.3243 - val_binary_accuracy: 0.8631 - val_f1: 0.8707 - val_recall: 0.8839 - val_precision: 0.8587\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2747 - binary_accuracy: 0.8804 - f1: 0.8792 - recall: 0.8818 - precision: 0.8786 - val_loss: 0.3192 - val_binary_accuracy: 0.8640 - val_f1: 0.8710 - val_recall: 0.8797 - val_precision: 0.8630\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2725 - binary_accuracy: 0.8832 - f1: 0.8812 - recall: 0.8810 - precision: 0.8828 - val_loss: 0.3258 - val_binary_accuracy: 0.8534 - val_f1: 0.8549 - val_recall: 0.8263 - val_precision: 0.8860\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2694 - binary_accuracy: 0.8837 - f1: 0.8815 - recall: 0.8791 - precision: 0.8850 - val_loss: 0.3147 - val_binary_accuracy: 0.8653 - val_f1: 0.8717 - val_recall: 0.8763 - val_precision: 0.8677\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2656 - binary_accuracy: 0.8859 - f1: 0.8843 - recall: 0.8864 - precision: 0.8837 - val_loss: 0.3209 - val_binary_accuracy: 0.8690 - val_f1: 0.8723 - val_recall: 0.8570 - val_precision: 0.8888\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2715 - binary_accuracy: 0.8812 - f1: 0.8781 - recall: 0.8732 - precision: 0.8860 - val_loss: 0.3204 - val_binary_accuracy: 0.8672 - val_f1: 0.8771 - val_recall: 0.9076 - val_precision: 0.8488\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2672 - binary_accuracy: 0.8824 - f1: 0.8807 - recall: 0.8845 - precision: 0.8791 - val_loss: 0.3223 - val_binary_accuracy: 0.8626 - val_f1: 0.8655 - val_recall: 0.8478 - val_precision: 0.8846\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2664 - binary_accuracy: 0.8833 - f1: 0.8812 - recall: 0.8794 - precision: 0.8851 - val_loss: 0.3166 - val_binary_accuracy: 0.8635 - val_f1: 0.8708 - val_recall: 0.8807 - val_precision: 0.8617\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2641 - binary_accuracy: 0.8858 - f1: 0.8840 - recall: 0.8841 - precision: 0.8855 - val_loss: 0.3120 - val_binary_accuracy: 0.8686 - val_f1: 0.8751 - val_recall: 0.8823 - val_precision: 0.8685\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2579 - binary_accuracy: 0.8866 - f1: 0.8847 - recall: 0.8825 - precision: 0.8878 - val_loss: 0.3142 - val_binary_accuracy: 0.8736 - val_f1: 0.8782 - val_recall: 0.8726 - val_precision: 0.8843\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2566 - binary_accuracy: 0.8881 - f1: 0.8859 - recall: 0.8824 - precision: 0.8903 - val_loss: 0.3212 - val_binary_accuracy: 0.8658 - val_f1: 0.8708 - val_recall: 0.8671 - val_precision: 0.8750\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2594 - binary_accuracy: 0.8891 - f1: 0.8874 - recall: 0.8862 - precision: 0.8899 - val_loss: 0.3224 - val_binary_accuracy: 0.8571 - val_f1: 0.8672 - val_recall: 0.8928 - val_precision: 0.8434\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2626 - binary_accuracy: 0.8844 - f1: 0.8824 - recall: 0.8842 - precision: 0.8827 - val_loss: 0.3147 - val_binary_accuracy: 0.8686 - val_f1: 0.8761 - val_recall: 0.8901 - val_precision: 0.8626\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2592 - binary_accuracy: 0.8860 - f1: 0.8840 - recall: 0.8846 - precision: 0.8851 - val_loss: 0.3208 - val_binary_accuracy: 0.8681 - val_f1: 0.8738 - val_recall: 0.8744 - val_precision: 0.8738\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2555 - binary_accuracy: 0.8876 - f1: 0.8856 - recall: 0.8830 - precision: 0.8896 - val_loss: 0.3342 - val_binary_accuracy: 0.8626 - val_f1: 0.8675 - val_recall: 0.8621 - val_precision: 0.8737\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2557 - binary_accuracy: 0.8869 - f1: 0.8859 - recall: 0.8889 - precision: 0.8853 - val_loss: 0.3269 - val_binary_accuracy: 0.8589 - val_f1: 0.8609 - val_recall: 0.8365 - val_precision: 0.8873\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2460 - binary_accuracy: 0.8922 - f1: 0.8900 - recall: 0.8892 - precision: 0.8919 - val_loss: 0.3175 - val_binary_accuracy: 0.8681 - val_f1: 0.8744 - val_recall: 0.8795 - val_precision: 0.8699\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2462 - binary_accuracy: 0.8930 - f1: 0.8913 - recall: 0.8898 - precision: 0.8943 - val_loss: 0.3228 - val_binary_accuracy: 0.8562 - val_f1: 0.8618 - val_recall: 0.8592 - val_precision: 0.8648\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2455 - binary_accuracy: 0.8949 - f1: 0.8933 - recall: 0.8954 - precision: 0.8924 - val_loss: 0.3296 - val_binary_accuracy: 0.8621 - val_f1: 0.8683 - val_recall: 0.8717 - val_precision: 0.8655\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2450 - binary_accuracy: 0.8931 - f1: 0.8919 - recall: 0.8937 - precision: 0.8921 - val_loss: 0.3399 - val_binary_accuracy: 0.8603 - val_f1: 0.8652 - val_recall: 0.8595 - val_precision: 0.8717\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2424 - binary_accuracy: 0.8931 - f1: 0.8913 - recall: 0.8882 - precision: 0.8958 - val_loss: 0.3232 - val_binary_accuracy: 0.8566 - val_f1: 0.8584 - val_recall: 0.8330 - val_precision: 0.8861\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2412 - binary_accuracy: 0.8975 - f1: 0.8956 - recall: 0.8953 - precision: 0.8978 - val_loss: 0.3253 - val_binary_accuracy: 0.8640 - val_f1: 0.8681 - val_recall: 0.8576 - val_precision: 0.8793\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2438 - binary_accuracy: 0.8951 - f1: 0.8937 - recall: 0.8964 - precision: 0.8925 - val_loss: 0.3363 - val_binary_accuracy: 0.8548 - val_f1: 0.8544 - val_recall: 0.8172 - val_precision: 0.8961\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2379 - binary_accuracy: 0.8974 - f1: 0.8959 - recall: 0.8994 - precision: 0.8939 - val_loss: 0.3263 - val_binary_accuracy: 0.8681 - val_f1: 0.8741 - val_recall: 0.8770 - val_precision: 0.8720\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2344 - binary_accuracy: 0.9015 - f1: 0.9000 - recall: 0.8998 - precision: 0.9015 - val_loss: 0.3422 - val_binary_accuracy: 0.8603 - val_f1: 0.8624 - val_recall: 0.8392 - val_precision: 0.8877\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2453 - binary_accuracy: 0.8908 - f1: 0.8895 - recall: 0.8922 - precision: 0.8892 - val_loss: 0.3243 - val_binary_accuracy: 0.8658 - val_f1: 0.8687 - val_recall: 0.8513 - val_precision: 0.8878\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2337 - binary_accuracy: 0.9006 - f1: 0.8992 - recall: 0.9010 - precision: 0.8992 - val_loss: 0.3301 - val_binary_accuracy: 0.8658 - val_f1: 0.8677 - val_recall: 0.8435 - val_precision: 0.8941\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2309 - binary_accuracy: 0.8998 - f1: 0.8977 - recall: 0.8931 - precision: 0.9037 - val_loss: 0.3303 - val_binary_accuracy: 0.8653 - val_f1: 0.8736 - val_recall: 0.8919 - val_precision: 0.8566\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2308 - binary_accuracy: 0.9026 - f1: 0.9012 - recall: 0.9006 - precision: 0.9035 - val_loss: 0.3298 - val_binary_accuracy: 0.8686 - val_f1: 0.8753 - val_recall: 0.8833 - val_precision: 0.8681\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2350 - binary_accuracy: 0.9005 - f1: 0.8989 - recall: 0.8971 - precision: 0.9039 - val_loss: 0.3384 - val_binary_accuracy: 0.8640 - val_f1: 0.8741 - val_recall: 0.9050 - val_precision: 0.8456\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2276 - binary_accuracy: 0.9033 - f1: 0.9019 - recall: 0.9009 - precision: 0.9045 - val_loss: 0.3228 - val_binary_accuracy: 0.8672 - val_f1: 0.8710 - val_recall: 0.8586 - val_precision: 0.8844\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2254 - binary_accuracy: 0.9027 - f1: 0.9006 - recall: 0.8965 - precision: 0.9071 - val_loss: 0.3311 - val_binary_accuracy: 0.8699 - val_f1: 0.8748 - val_recall: 0.8714 - val_precision: 0.8788\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2225 - binary_accuracy: 0.9059 - f1: 0.9049 - recall: 0.9092 - precision: 0.9028 - val_loss: 0.3335 - val_binary_accuracy: 0.8612 - val_f1: 0.8628 - val_recall: 0.8378 - val_precision: 0.8900\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2272 - binary_accuracy: 0.9029 - f1: 0.9012 - recall: 0.8992 - precision: 0.9053 - val_loss: 0.3357 - val_binary_accuracy: 0.8539 - val_f1: 0.8633 - val_recall: 0.8822 - val_precision: 0.8458\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2252 - binary_accuracy: 0.9029 - f1: 0.9014 - recall: 0.9024 - precision: 0.9024 - val_loss: 0.3287 - val_binary_accuracy: 0.8676 - val_f1: 0.8729 - val_recall: 0.8715 - val_precision: 0.8752\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2221 - binary_accuracy: 0.9035 - f1: 0.9018 - recall: 0.8983 - precision: 0.9073 - val_loss: 0.3262 - val_binary_accuracy: 0.8644 - val_f1: 0.8705 - val_recall: 0.8748 - val_precision: 0.8672\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2242 - binary_accuracy: 0.9034 - f1: 0.9019 - recall: 0.9039 - precision: 0.9025 - val_loss: 0.3435 - val_binary_accuracy: 0.8548 - val_f1: 0.8553 - val_recall: 0.8225 - val_precision: 0.8915\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2139 - binary_accuracy: 0.9109 - f1: 0.9089 - recall: 0.9060 - precision: 0.9136 - val_loss: 0.3284 - val_binary_accuracy: 0.8631 - val_f1: 0.8679 - val_recall: 0.8617 - val_precision: 0.8746\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2167 - binary_accuracy: 0.9081 - f1: 0.9067 - recall: 0.9051 - precision: 0.9097 - val_loss: 0.3292 - val_binary_accuracy: 0.8681 - val_f1: 0.8724 - val_recall: 0.8637 - val_precision: 0.8818\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2108 - binary_accuracy: 0.9121 - f1: 0.9101 - recall: 0.9083 - precision: 0.9128 - val_loss: 0.3373 - val_binary_accuracy: 0.8681 - val_f1: 0.8704 - val_recall: 0.8505 - val_precision: 0.8924\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2084 - binary_accuracy: 0.9141 - f1: 0.9128 - recall: 0.9110 - precision: 0.9157 - val_loss: 0.3535 - val_binary_accuracy: 0.8571 - val_f1: 0.8613 - val_recall: 0.8499 - val_precision: 0.8738\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2144 - binary_accuracy: 0.9106 - f1: 0.9088 - recall: 0.9064 - precision: 0.9125 - val_loss: 0.3504 - val_binary_accuracy: 0.8451 - val_f1: 0.8429 - val_recall: 0.7976 - val_precision: 0.8945\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2063 - binary_accuracy: 0.9142 - f1: 0.9126 - recall: 0.9101 - precision: 0.9160 - val_loss: 0.3373 - val_binary_accuracy: 0.8617 - val_f1: 0.8669 - val_recall: 0.8643 - val_precision: 0.8704\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2113 - binary_accuracy: 0.9096 - f1: 0.9077 - recall: 0.9043 - precision: 0.9130 - val_loss: 0.3525 - val_binary_accuracy: 0.8571 - val_f1: 0.8654 - val_recall: 0.8805 - val_precision: 0.8517\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2089 - binary_accuracy: 0.9127 - f1: 0.9111 - recall: 0.9096 - precision: 0.9149 - val_loss: 0.3412 - val_binary_accuracy: 0.8612 - val_f1: 0.8687 - val_recall: 0.8788 - val_precision: 0.8594\n",
      "Epoch 90/500\n",
      "0s - loss: 0.2026 - binary_accuracy: 0.9149 - f1: 0.9132 - recall: 0.9126 - precision: 0.9151 - val_loss: 0.3412 - val_binary_accuracy: 0.8621 - val_f1: 0.8666 - val_recall: 0.8577 - val_precision: 0.8767\n",
      "Epoch 91/500\n",
      "0s - loss: 0.2015 - binary_accuracy: 0.9169 - f1: 0.9151 - recall: 0.9112 - precision: 0.9203 - val_loss: 0.3380 - val_binary_accuracy: 0.8635 - val_f1: 0.8732 - val_recall: 0.8981 - val_precision: 0.8501\n",
      "Epoch 92/500\n",
      "0s - loss: 0.2017 - binary_accuracy: 0.9167 - f1: 0.9152 - recall: 0.9139 - precision: 0.9178 - val_loss: 0.3564 - val_binary_accuracy: 0.8617 - val_f1: 0.8659 - val_recall: 0.8557 - val_precision: 0.8769\n",
      "Epoch 93/500\n",
      "0s - loss: 0.1946 - binary_accuracy: 0.9175 - f1: 0.9158 - recall: 0.9117 - precision: 0.9208 - val_loss: 0.3483 - val_binary_accuracy: 0.8617 - val_f1: 0.8684 - val_recall: 0.8753 - val_precision: 0.8628\n",
      "Epoch 94/500\n",
      "0s - loss: 0.2018 - binary_accuracy: 0.9144 - f1: 0.9134 - recall: 0.9158 - precision: 0.9136 - val_loss: 0.3948 - val_binary_accuracy: 0.8474 - val_f1: 0.8451 - val_recall: 0.7972 - val_precision: 0.8997\n",
      "Epoch 95/500\n",
      "0s - loss: 0.2014 - binary_accuracy: 0.9165 - f1: 0.9150 - recall: 0.9097 - precision: 0.9229 - val_loss: 0.3596 - val_binary_accuracy: 0.8465 - val_f1: 0.8492 - val_recall: 0.8265 - val_precision: 0.8739\n",
      "Epoch 96/500\n",
      "0s - loss: 0.1955 - binary_accuracy: 0.9216 - f1: 0.9193 - recall: 0.9151 - precision: 0.9249 - val_loss: 0.3392 - val_binary_accuracy: 0.8603 - val_f1: 0.8663 - val_recall: 0.8664 - val_precision: 0.8667\n",
      "Epoch 97/500\n",
      "0s - loss: 0.1916 - binary_accuracy: 0.9212 - f1: 0.9201 - recall: 0.9174 - precision: 0.9240 - val_loss: 0.3482 - val_binary_accuracy: 0.8598 - val_f1: 0.8622 - val_recall: 0.8409 - val_precision: 0.8852\n",
      "Epoch 98/500\n",
      "0s - loss: 0.1880 - binary_accuracy: 0.9239 - f1: 0.9228 - recall: 0.9196 - precision: 0.9271 - val_loss: 0.3544 - val_binary_accuracy: 0.8631 - val_f1: 0.8713 - val_recall: 0.8876 - val_precision: 0.8565\n",
      "Epoch 99/500\n",
      "0s - loss: 0.1879 - binary_accuracy: 0.9245 - f1: 0.9233 - recall: 0.9220 - precision: 0.9258 - val_loss: 0.3600 - val_binary_accuracy: 0.8612 - val_f1: 0.8661 - val_recall: 0.8597 - val_precision: 0.8734\n",
      "Epoch 100/500\n",
      "0s - loss: 0.1820 - binary_accuracy: 0.9287 - f1: 0.9274 - recall: 0.9234 - precision: 0.9326 - val_loss: 0.3476 - val_binary_accuracy: 0.8667 - val_f1: 0.8710 - val_recall: 0.8604 - val_precision: 0.8828\n",
      "Epoch 101/500\n",
      "0s - loss: 0.1823 - binary_accuracy: 0.9263 - f1: 0.9248 - recall: 0.9219 - precision: 0.9294 - val_loss: 0.3544 - val_binary_accuracy: 0.8658 - val_f1: 0.8704 - val_recall: 0.8628 - val_precision: 0.8788\n",
      "Epoch 102/500\n",
      "0s - loss: 0.1844 - binary_accuracy: 0.9232 - f1: 0.9220 - recall: 0.9207 - precision: 0.9246 - val_loss: 0.3539 - val_binary_accuracy: 0.8608 - val_f1: 0.8632 - val_recall: 0.8413 - val_precision: 0.8873\n",
      "Epoch 103/500\n",
      "0s - loss: 0.1798 - binary_accuracy: 0.9277 - f1: 0.9254 - recall: 0.9184 - precision: 0.9338 - val_loss: 0.3470 - val_binary_accuracy: 0.8649 - val_f1: 0.8712 - val_recall: 0.8744 - val_precision: 0.8689\n",
      "Epoch 104/500\n",
      "0s - loss: 0.1812 - binary_accuracy: 0.9268 - f1: 0.9255 - recall: 0.9232 - precision: 0.9290 - val_loss: 0.3613 - val_binary_accuracy: 0.8571 - val_f1: 0.8592 - val_recall: 0.8337 - val_precision: 0.8871\n",
      "1824/2176 [========================>.....] - ETA: 0stn = 4207, fp = 185, fn = 372, tp = 3920\n",
      "y_pred: 0 = 4579 | 1 = 4105\n",
      "y_true: 0 = 4392 | 1 = 4292\n",
      "acc=0.9359|precision=0.9549|recall=0.9133|f1=0.9337|auc=0.9854|aupr=0.9860|pos_acc=0.9133|neg_acc=0.9188\n",
      "tn = 917, fp = 121, fn = 190, tp = 948\n",
      "y_pred: 0 = 1107 | 1 = 1069\n",
      "y_true: 0 = 1038 | 1 = 1138\n",
      "acc=0.8571|precision=0.8868|recall=0.8330|f1=0.8591|auc=0.9350|aupr=0.9357|pos_acc=0.8330|neg_acc=0.8284\n",
      "----------------------- Fold =  4\n",
      "Train on 8477 samples, validate on 2383 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4117 - binary_accuracy: 0.8131 - f1: 0.7796 - recall: 0.7735 - precision: 0.8310 - val_loss: 0.3749 - val_binary_accuracy: 0.8175 - val_f1: 0.8086 - val_recall: 0.7416 - val_precision: 0.8899\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3554 - binary_accuracy: 0.8443 - f1: 0.8392 - recall: 0.8283 - precision: 0.8575 - val_loss: 0.3598 - val_binary_accuracy: 0.8296 - val_f1: 0.8273 - val_recall: 0.7844 - val_precision: 0.8759\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3386 - binary_accuracy: 0.8511 - f1: 0.8473 - recall: 0.8423 - precision: 0.8557 - val_loss: 0.3578 - val_binary_accuracy: 0.8342 - val_f1: 0.8340 - val_recall: 0.8004 - val_precision: 0.8711\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3360 - binary_accuracy: 0.8534 - f1: 0.8502 - recall: 0.8465 - precision: 0.8552 - val_loss: 0.3612 - val_binary_accuracy: 0.8271 - val_f1: 0.8298 - val_recall: 0.8101 - val_precision: 0.8509\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3317 - binary_accuracy: 0.8555 - f1: 0.8528 - recall: 0.8511 - precision: 0.8574 - val_loss: 0.3453 - val_binary_accuracy: 0.8431 - val_f1: 0.8536 - val_recall: 0.8793 - val_precision: 0.8297\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3277 - binary_accuracy: 0.8575 - f1: 0.8549 - recall: 0.8557 - precision: 0.8563 - val_loss: 0.3491 - val_binary_accuracy: 0.8426 - val_f1: 0.8583 - val_recall: 0.9182 - val_precision: 0.8060\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3438 - binary_accuracy: 0.8543 - f1: 0.8502 - recall: 0.8476 - precision: 0.8616 - val_loss: 0.3405 - val_binary_accuracy: 0.8456 - val_f1: 0.8553 - val_recall: 0.8781 - val_precision: 0.8340\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3259 - binary_accuracy: 0.8601 - f1: 0.8588 - recall: 0.8637 - precision: 0.8557 - val_loss: 0.3457 - val_binary_accuracy: 0.8376 - val_f1: 0.8367 - val_recall: 0.7989 - val_precision: 0.8787\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3293 - binary_accuracy: 0.8558 - f1: 0.8524 - recall: 0.8502 - precision: 0.8600 - val_loss: 0.3399 - val_binary_accuracy: 0.8376 - val_f1: 0.8440 - val_recall: 0.8432 - val_precision: 0.8451\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3197 - binary_accuracy: 0.8629 - f1: 0.8614 - recall: 0.8626 - precision: 0.8612 - val_loss: 0.3471 - val_binary_accuracy: 0.8393 - val_f1: 0.8416 - val_recall: 0.8206 - val_precision: 0.8640\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3200 - binary_accuracy: 0.8609 - f1: 0.8582 - recall: 0.8576 - precision: 0.8611 - val_loss: 0.3427 - val_binary_accuracy: 0.8393 - val_f1: 0.8445 - val_recall: 0.8385 - val_precision: 0.8510\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3233 - binary_accuracy: 0.8602 - f1: 0.8568 - recall: 0.8519 - precision: 0.8658 - val_loss: 0.3400 - val_binary_accuracy: 0.8439 - val_f1: 0.8561 - val_recall: 0.8916 - val_precision: 0.8236\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3169 - binary_accuracy: 0.8653 - f1: 0.8638 - recall: 0.8703 - precision: 0.8598 - val_loss: 0.3471 - val_binary_accuracy: 0.8355 - val_f1: 0.8333 - val_recall: 0.7894 - val_precision: 0.8828\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3165 - binary_accuracy: 0.8623 - f1: 0.8590 - recall: 0.8541 - precision: 0.8669 - val_loss: 0.3357 - val_binary_accuracy: 0.8452 - val_f1: 0.8536 - val_recall: 0.8672 - val_precision: 0.8407\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3155 - binary_accuracy: 0.8635 - f1: 0.8615 - recall: 0.8631 - precision: 0.8624 - val_loss: 0.3324 - val_binary_accuracy: 0.8489 - val_f1: 0.8565 - val_recall: 0.8651 - val_precision: 0.8485\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3097 - binary_accuracy: 0.8671 - f1: 0.8650 - recall: 0.8645 - precision: 0.8668 - val_loss: 0.3367 - val_binary_accuracy: 0.8443 - val_f1: 0.8489 - val_recall: 0.8394 - val_precision: 0.8591\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3137 - binary_accuracy: 0.8646 - f1: 0.8620 - recall: 0.8630 - precision: 0.8640 - val_loss: 0.3332 - val_binary_accuracy: 0.8477 - val_f1: 0.8586 - val_recall: 0.8890 - val_precision: 0.8306\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3088 - binary_accuracy: 0.8648 - f1: 0.8628 - recall: 0.8639 - precision: 0.8633 - val_loss: 0.3405 - val_binary_accuracy: 0.8439 - val_f1: 0.8465 - val_recall: 0.8257 - val_precision: 0.8688\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3062 - binary_accuracy: 0.8688 - f1: 0.8661 - recall: 0.8649 - precision: 0.8689 - val_loss: 0.3374 - val_binary_accuracy: 0.8452 - val_f1: 0.8475 - val_recall: 0.8263 - val_precision: 0.8702\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3103 - binary_accuracy: 0.8633 - f1: 0.8605 - recall: 0.8577 - precision: 0.8657 - val_loss: 0.3315 - val_binary_accuracy: 0.8473 - val_f1: 0.8564 - val_recall: 0.8752 - val_precision: 0.8388\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3041 - binary_accuracy: 0.8695 - f1: 0.8674 - recall: 0.8698 - precision: 0.8660 - val_loss: 0.3416 - val_binary_accuracy: 0.8418 - val_f1: 0.8504 - val_recall: 0.8635 - val_precision: 0.8380\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3057 - binary_accuracy: 0.8673 - f1: 0.8654 - recall: 0.8664 - precision: 0.8661 - val_loss: 0.3321 - val_binary_accuracy: 0.8481 - val_f1: 0.8576 - val_recall: 0.8779 - val_precision: 0.8386\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3060 - binary_accuracy: 0.8642 - f1: 0.8620 - recall: 0.8632 - precision: 0.8636 - val_loss: 0.3476 - val_binary_accuracy: 0.8410 - val_f1: 0.8528 - val_recall: 0.8836 - val_precision: 0.8243\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3048 - binary_accuracy: 0.8661 - f1: 0.8631 - recall: 0.8611 - precision: 0.8678 - val_loss: 0.3450 - val_binary_accuracy: 0.8414 - val_f1: 0.8529 - val_recall: 0.8820 - val_precision: 0.8259\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3007 - binary_accuracy: 0.8672 - f1: 0.8646 - recall: 0.8648 - precision: 0.8662 - val_loss: 0.3268 - val_binary_accuracy: 0.8535 - val_f1: 0.8632 - val_recall: 0.8861 - val_precision: 0.8418\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3029 - binary_accuracy: 0.8671 - f1: 0.8647 - recall: 0.8657 - precision: 0.8671 - val_loss: 0.3351 - val_binary_accuracy: 0.8489 - val_f1: 0.8606 - val_recall: 0.8941 - val_precision: 0.8297\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2987 - binary_accuracy: 0.8695 - f1: 0.8674 - recall: 0.8687 - precision: 0.8681 - val_loss: 0.3603 - val_binary_accuracy: 0.8426 - val_f1: 0.8534 - val_recall: 0.8788 - val_precision: 0.8298\n",
      "Epoch 28/500\n",
      "0s - loss: 0.3007 - binary_accuracy: 0.8707 - f1: 0.8683 - recall: 0.8672 - precision: 0.8718 - val_loss: 0.3339 - val_binary_accuracy: 0.8464 - val_f1: 0.8548 - val_recall: 0.8666 - val_precision: 0.8436\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2992 - binary_accuracy: 0.8700 - f1: 0.8680 - recall: 0.8688 - precision: 0.8691 - val_loss: 0.3284 - val_binary_accuracy: 0.8502 - val_f1: 0.8572 - val_recall: 0.8633 - val_precision: 0.8515\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2963 - binary_accuracy: 0.8704 - f1: 0.8689 - recall: 0.8722 - precision: 0.8665 - val_loss: 0.3350 - val_binary_accuracy: 0.8473 - val_f1: 0.8540 - val_recall: 0.8563 - val_precision: 0.8522\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2913 - binary_accuracy: 0.8739 - f1: 0.8717 - recall: 0.8722 - precision: 0.8724 - val_loss: 0.3441 - val_binary_accuracy: 0.8439 - val_f1: 0.8470 - val_recall: 0.8290 - val_precision: 0.8661\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2959 - binary_accuracy: 0.8727 - f1: 0.8713 - recall: 0.8745 - precision: 0.8697 - val_loss: 0.3302 - val_binary_accuracy: 0.8510 - val_f1: 0.8569 - val_recall: 0.8548 - val_precision: 0.8593\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2877 - binary_accuracy: 0.8737 - f1: 0.8710 - recall: 0.8701 - precision: 0.8730 - val_loss: 0.3383 - val_binary_accuracy: 0.8460 - val_f1: 0.8519 - val_recall: 0.8499 - val_precision: 0.8542\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2909 - binary_accuracy: 0.8746 - f1: 0.8729 - recall: 0.8752 - precision: 0.8719 - val_loss: 0.3532 - val_binary_accuracy: 0.8389 - val_f1: 0.8370 - val_recall: 0.7950 - val_precision: 0.8845\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2923 - binary_accuracy: 0.8761 - f1: 0.8732 - recall: 0.8710 - precision: 0.8776 - val_loss: 0.3275 - val_binary_accuracy: 0.8477 - val_f1: 0.8572 - val_recall: 0.8771 - val_precision: 0.8383\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2969 - binary_accuracy: 0.8728 - f1: 0.8709 - recall: 0.8746 - precision: 0.8703 - val_loss: 0.3413 - val_binary_accuracy: 0.8447 - val_f1: 0.8543 - val_recall: 0.8738 - val_precision: 0.8360\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2911 - binary_accuracy: 0.8745 - f1: 0.8718 - recall: 0.8723 - precision: 0.8741 - val_loss: 0.3322 - val_binary_accuracy: 0.8519 - val_f1: 0.8590 - val_recall: 0.8666 - val_precision: 0.8518\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2884 - binary_accuracy: 0.8740 - f1: 0.8720 - recall: 0.8716 - precision: 0.8742 - val_loss: 0.3691 - val_binary_accuracy: 0.8389 - val_f1: 0.8375 - val_recall: 0.7982 - val_precision: 0.8816\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2962 - binary_accuracy: 0.8715 - f1: 0.8696 - recall: 0.8713 - precision: 0.8697 - val_loss: 0.3436 - val_binary_accuracy: 0.8447 - val_f1: 0.8454 - val_recall: 0.8153 - val_precision: 0.8783\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2868 - binary_accuracy: 0.8732 - f1: 0.8704 - recall: 0.8679 - precision: 0.8757 - val_loss: 0.3312 - val_binary_accuracy: 0.8489 - val_f1: 0.8531 - val_recall: 0.8417 - val_precision: 0.8650\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8759 - f1: 0.8725 - recall: 0.8669 - precision: 0.8805 - val_loss: 0.3369 - val_binary_accuracy: 0.8418 - val_f1: 0.8549 - val_recall: 0.8947 - val_precision: 0.8187\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2797 - binary_accuracy: 0.8798 - f1: 0.8779 - recall: 0.8805 - precision: 0.8771 - val_loss: 0.3281 - val_binary_accuracy: 0.8447 - val_f1: 0.8504 - val_recall: 0.8464 - val_precision: 0.8545\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2769 - binary_accuracy: 0.8791 - f1: 0.8777 - recall: 0.8822 - precision: 0.8745 - val_loss: 0.3294 - val_binary_accuracy: 0.8477 - val_f1: 0.8515 - val_recall: 0.8370 - val_precision: 0.8669\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2741 - binary_accuracy: 0.8804 - f1: 0.8777 - recall: 0.8762 - precision: 0.8808 - val_loss: 0.3429 - val_binary_accuracy: 0.8452 - val_f1: 0.8484 - val_recall: 0.8313 - val_precision: 0.8666\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2731 - binary_accuracy: 0.8829 - f1: 0.8811 - recall: 0.8807 - precision: 0.8835 - val_loss: 0.3411 - val_binary_accuracy: 0.8418 - val_f1: 0.8488 - val_recall: 0.8528 - val_precision: 0.8452\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2731 - binary_accuracy: 0.8833 - f1: 0.8817 - recall: 0.8850 - precision: 0.8794 - val_loss: 0.3370 - val_binary_accuracy: 0.8464 - val_f1: 0.8481 - val_recall: 0.8236 - val_precision: 0.8742\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2738 - binary_accuracy: 0.8800 - f1: 0.8786 - recall: 0.8815 - precision: 0.8769 - val_loss: 0.3388 - val_binary_accuracy: 0.8439 - val_f1: 0.8540 - val_recall: 0.8771 - val_precision: 0.8325\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2700 - binary_accuracy: 0.8811 - f1: 0.8791 - recall: 0.8814 - precision: 0.8781 - val_loss: 0.3287 - val_binary_accuracy: 0.8514 - val_f1: 0.8608 - val_recall: 0.8804 - val_precision: 0.8424\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2673 - binary_accuracy: 0.8847 - f1: 0.8836 - recall: 0.8877 - precision: 0.8805 - val_loss: 0.3392 - val_binary_accuracy: 0.8460 - val_f1: 0.8503 - val_recall: 0.8399 - val_precision: 0.8614\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2694 - binary_accuracy: 0.8818 - f1: 0.8798 - recall: 0.8811 - precision: 0.8804 - val_loss: 0.3338 - val_binary_accuracy: 0.8514 - val_f1: 0.8557 - val_recall: 0.8443 - val_precision: 0.8676\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2756 - binary_accuracy: 0.8826 - f1: 0.8805 - recall: 0.8807 - precision: 0.8820 - val_loss: 0.3411 - val_binary_accuracy: 0.8527 - val_f1: 0.8565 - val_recall: 0.8433 - val_precision: 0.8703\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2742 - binary_accuracy: 0.8793 - f1: 0.8770 - recall: 0.8740 - precision: 0.8830 - val_loss: 0.3341 - val_binary_accuracy: 0.8502 - val_f1: 0.8571 - val_recall: 0.8632 - val_precision: 0.8514\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2654 - binary_accuracy: 0.8851 - f1: 0.8837 - recall: 0.8854 - precision: 0.8833 - val_loss: 0.3351 - val_binary_accuracy: 0.8498 - val_f1: 0.8564 - val_recall: 0.8602 - val_precision: 0.8529\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2630 - binary_accuracy: 0.8872 - f1: 0.8862 - recall: 0.8898 - precision: 0.8843 - val_loss: 0.3420 - val_binary_accuracy: 0.8468 - val_f1: 0.8534 - val_recall: 0.8559 - val_precision: 0.8514\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2591 - binary_accuracy: 0.8879 - f1: 0.8858 - recall: 0.8811 - precision: 0.8917 - val_loss: 0.3373 - val_binary_accuracy: 0.8452 - val_f1: 0.8591 - val_recall: 0.9054 - val_precision: 0.8175\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2590 - binary_accuracy: 0.8876 - f1: 0.8859 - recall: 0.8888 - precision: 0.8845 - val_loss: 0.3385 - val_binary_accuracy: 0.8485 - val_f1: 0.8520 - val_recall: 0.8359 - val_precision: 0.8688\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2634 - binary_accuracy: 0.8862 - f1: 0.8849 - recall: 0.8916 - precision: 0.8795 - val_loss: 0.3357 - val_binary_accuracy: 0.8502 - val_f1: 0.8550 - val_recall: 0.8468 - val_precision: 0.8638\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2619 - binary_accuracy: 0.8893 - f1: 0.8877 - recall: 0.8879 - precision: 0.8893 - val_loss: 0.3371 - val_binary_accuracy: 0.8447 - val_f1: 0.8557 - val_recall: 0.8820 - val_precision: 0.8311\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2537 - binary_accuracy: 0.8922 - f1: 0.8906 - recall: 0.8907 - precision: 0.8920 - val_loss: 0.3466 - val_binary_accuracy: 0.8493 - val_f1: 0.8537 - val_recall: 0.8425 - val_precision: 0.8654\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2588 - binary_accuracy: 0.8905 - f1: 0.8891 - recall: 0.8900 - precision: 0.8898 - val_loss: 0.3401 - val_binary_accuracy: 0.8447 - val_f1: 0.8552 - val_recall: 0.8809 - val_precision: 0.8313\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2527 - binary_accuracy: 0.8890 - f1: 0.8874 - recall: 0.8912 - precision: 0.8852 - val_loss: 0.3342 - val_binary_accuracy: 0.8460 - val_f1: 0.8579 - val_recall: 0.8923 - val_precision: 0.8264\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2487 - binary_accuracy: 0.8936 - f1: 0.8920 - recall: 0.8951 - precision: 0.8903 - val_loss: 0.3289 - val_binary_accuracy: 0.8531 - val_f1: 0.8651 - val_recall: 0.8999 - val_precision: 0.8334\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2498 - binary_accuracy: 0.8924 - f1: 0.8913 - recall: 0.8950 - precision: 0.8885 - val_loss: 0.3404 - val_binary_accuracy: 0.8426 - val_f1: 0.8527 - val_recall: 0.8737 - val_precision: 0.8331\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2501 - binary_accuracy: 0.8923 - f1: 0.8907 - recall: 0.8906 - precision: 0.8919 - val_loss: 0.3435 - val_binary_accuracy: 0.8485 - val_f1: 0.8587 - val_recall: 0.8835 - val_precision: 0.8354\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2430 - binary_accuracy: 0.8970 - f1: 0.8953 - recall: 0.8963 - precision: 0.8950 - val_loss: 0.3487 - val_binary_accuracy: 0.8426 - val_f1: 0.8467 - val_recall: 0.8349 - val_precision: 0.8592\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2397 - binary_accuracy: 0.8982 - f1: 0.8969 - recall: 0.8973 - precision: 0.8975 - val_loss: 0.3416 - val_binary_accuracy: 0.8544 - val_f1: 0.8656 - val_recall: 0.8977 - val_precision: 0.8361\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2423 - binary_accuracy: 0.8974 - f1: 0.8960 - recall: 0.8995 - precision: 0.8939 - val_loss: 0.3415 - val_binary_accuracy: 0.8510 - val_f1: 0.8595 - val_recall: 0.8739 - val_precision: 0.8460\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2495 - binary_accuracy: 0.8962 - f1: 0.8944 - recall: 0.8955 - precision: 0.8951 - val_loss: 0.3494 - val_binary_accuracy: 0.8468 - val_f1: 0.8583 - val_recall: 0.8913 - val_precision: 0.8280\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2427 - binary_accuracy: 0.8956 - f1: 0.8941 - recall: 0.8968 - precision: 0.8935 - val_loss: 0.3431 - val_binary_accuracy: 0.8519 - val_f1: 0.8565 - val_recall: 0.8480 - val_precision: 0.8653\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2440 - binary_accuracy: 0.8958 - f1: 0.8937 - recall: 0.8934 - precision: 0.8966 - val_loss: 0.3449 - val_binary_accuracy: 0.8452 - val_f1: 0.8547 - val_recall: 0.8745 - val_precision: 0.8361\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2372 - binary_accuracy: 0.8996 - f1: 0.8983 - recall: 0.9018 - precision: 0.8965 - val_loss: 0.3399 - val_binary_accuracy: 0.8519 - val_f1: 0.8638 - val_recall: 0.8998 - val_precision: 0.8309\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2411 - binary_accuracy: 0.8989 - f1: 0.8974 - recall: 0.8986 - precision: 0.8973 - val_loss: 0.3499 - val_binary_accuracy: 0.8502 - val_f1: 0.8563 - val_recall: 0.8573 - val_precision: 0.8555\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2356 - binary_accuracy: 0.9010 - f1: 0.8994 - recall: 0.8996 - precision: 0.9005 - val_loss: 0.3430 - val_binary_accuracy: 0.8477 - val_f1: 0.8563 - val_recall: 0.8698 - val_precision: 0.8435\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2319 - binary_accuracy: 0.9013 - f1: 0.9001 - recall: 0.9031 - precision: 0.8987 - val_loss: 0.3451 - val_binary_accuracy: 0.8435 - val_f1: 0.8461 - val_recall: 0.8269 - val_precision: 0.8671\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2361 - binary_accuracy: 0.8994 - f1: 0.8978 - recall: 0.8986 - precision: 0.8981 - val_loss: 0.3394 - val_binary_accuracy: 0.8473 - val_f1: 0.8533 - val_recall: 0.8517 - val_precision: 0.8552\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2286 - binary_accuracy: 0.9028 - f1: 0.9014 - recall: 0.9043 - precision: 0.8997 - val_loss: 0.3576 - val_binary_accuracy: 0.8380 - val_f1: 0.8480 - val_recall: 0.8688 - val_precision: 0.8287\n",
      "2048/2383 [========================>.....] - ETA: 0stn = 3796, fp = 493, fn = 329, tp = 3859\n",
      "y_pred: 0 = 4125 | 1 = 4352\n",
      "y_true: 0 = 4289 | 1 = 4188\n",
      "acc=0.9030|precision=0.8867|recall=0.9214|f1=0.9037|auc=0.9694|aupr=0.9691|pos_acc=0.9214|neg_acc=0.9202\n",
      "tn = 918, fp = 223, fn = 163, tp = 1079\n",
      "y_pred: 0 = 1081 | 1 = 1302\n",
      "y_true: 0 = 1141 | 1 = 1242\n",
      "acc=0.8380|precision=0.8287|recall=0.8688|f1=0.8483|auc=0.9244|aupr=0.9287|pos_acc=0.8688|neg_acc=0.8492\n",
      "========== isbalance = True | task = Td\n",
      "-------Fold  0\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8344 | Test = 2516\n",
      "-------Fold  1\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8611 | Test = 2249\n",
      "-------Fold  2\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8648 | Test = 2212\n",
      "-------Fold  3\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 8793 | Test = 2067\n",
      "-------Fold  4\n",
      "# disease: Train = 304 | Test = 79\n",
      "# Pairs: Train = 9044 | Test = 1816\n",
      "----------------------- Fold =  0\n",
      "Train on 8344 samples, validate on 2516 samples\n",
      "Epoch 1/500\n",
      "0s - loss: 0.4131 - binary_accuracy: 0.8104 - f1: 0.7803 - recall: 0.7644 - precision: 0.8429 - val_loss: 0.3514 - val_binary_accuracy: 0.8430 - val_f1: 0.8471 - val_recall: 0.8352 - val_precision: 0.8602\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3521 - binary_accuracy: 0.8483 - f1: 0.8445 - recall: 0.8364 - precision: 0.8554 - val_loss: 0.3437 - val_binary_accuracy: 0.8486 - val_f1: 0.8586 - val_recall: 0.8810 - val_precision: 0.8382\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3408 - binary_accuracy: 0.8532 - f1: 0.8504 - recall: 0.8478 - precision: 0.8542 - val_loss: 0.3337 - val_binary_accuracy: 0.8506 - val_f1: 0.8543 - val_recall: 0.8420 - val_precision: 0.8680\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3354 - binary_accuracy: 0.8552 - f1: 0.8525 - recall: 0.8516 - precision: 0.8557 - val_loss: 0.3341 - val_binary_accuracy: 0.8506 - val_f1: 0.8609 - val_recall: 0.8883 - val_precision: 0.8360\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3293 - binary_accuracy: 0.8587 - f1: 0.8561 - recall: 0.8552 - precision: 0.8589 - val_loss: 0.3293 - val_binary_accuracy: 0.8529 - val_f1: 0.8630 - val_recall: 0.8898 - val_precision: 0.8387\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3289 - binary_accuracy: 0.8576 - f1: 0.8557 - recall: 0.8587 - precision: 0.8560 - val_loss: 0.3335 - val_binary_accuracy: 0.8490 - val_f1: 0.8525 - val_recall: 0.8383 - val_precision: 0.8687\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3249 - binary_accuracy: 0.8589 - f1: 0.8568 - recall: 0.8579 - precision: 0.8566 - val_loss: 0.3227 - val_binary_accuracy: 0.8597 - val_f1: 0.8647 - val_recall: 0.8618 - val_precision: 0.8690\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3218 - binary_accuracy: 0.8616 - f1: 0.8598 - recall: 0.8634 - precision: 0.8582 - val_loss: 0.3242 - val_binary_accuracy: 0.8549 - val_f1: 0.8595 - val_recall: 0.8519 - val_precision: 0.8682\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3205 - binary_accuracy: 0.8606 - f1: 0.8589 - recall: 0.8640 - precision: 0.8558 - val_loss: 0.3292 - val_binary_accuracy: 0.8478 - val_f1: 0.8514 - val_recall: 0.8362 - val_precision: 0.8684\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3221 - binary_accuracy: 0.8593 - f1: 0.8567 - recall: 0.8559 - precision: 0.8594 - val_loss: 0.3237 - val_binary_accuracy: 0.8545 - val_f1: 0.8608 - val_recall: 0.8633 - val_precision: 0.8593\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3174 - binary_accuracy: 0.8637 - f1: 0.8616 - recall: 0.8639 - precision: 0.8618 - val_loss: 0.3201 - val_binary_accuracy: 0.8573 - val_f1: 0.8630 - val_recall: 0.8624 - val_precision: 0.8645\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3212 - binary_accuracy: 0.8579 - f1: 0.8565 - recall: 0.8636 - precision: 0.8538 - val_loss: 0.3273 - val_binary_accuracy: 0.8541 - val_f1: 0.8575 - val_recall: 0.8427 - val_precision: 0.8736\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3143 - binary_accuracy: 0.8639 - f1: 0.8619 - recall: 0.8631 - precision: 0.8622 - val_loss: 0.3209 - val_binary_accuracy: 0.8569 - val_f1: 0.8636 - val_recall: 0.8693 - val_precision: 0.8590\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3111 - binary_accuracy: 0.8633 - f1: 0.8605 - recall: 0.8619 - precision: 0.8610 - val_loss: 0.3268 - val_binary_accuracy: 0.8557 - val_f1: 0.8647 - val_recall: 0.8845 - val_precision: 0.8466\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3161 - binary_accuracy: 0.8621 - f1: 0.8607 - recall: 0.8657 - precision: 0.8587 - val_loss: 0.3274 - val_binary_accuracy: 0.8573 - val_f1: 0.8688 - val_recall: 0.9059 - val_precision: 0.8356\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3193 - binary_accuracy: 0.8629 - f1: 0.8601 - recall: 0.8594 - precision: 0.8652 - val_loss: 0.3225 - val_binary_accuracy: 0.8585 - val_f1: 0.8643 - val_recall: 0.8655 - val_precision: 0.8640\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3089 - binary_accuracy: 0.8661 - f1: 0.8633 - recall: 0.8630 - precision: 0.8652 - val_loss: 0.3239 - val_binary_accuracy: 0.8533 - val_f1: 0.8611 - val_recall: 0.8723 - val_precision: 0.8512\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3079 - binary_accuracy: 0.8658 - f1: 0.8631 - recall: 0.8602 - precision: 0.8685 - val_loss: 0.3457 - val_binary_accuracy: 0.8482 - val_f1: 0.8623 - val_recall: 0.9126 - val_precision: 0.8180\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3113 - binary_accuracy: 0.8633 - f1: 0.8617 - recall: 0.8667 - precision: 0.8603 - val_loss: 0.3267 - val_binary_accuracy: 0.8553 - val_f1: 0.8659 - val_recall: 0.8958 - val_precision: 0.8387\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3020 - binary_accuracy: 0.8671 - f1: 0.8652 - recall: 0.8654 - precision: 0.8663 - val_loss: 0.3220 - val_binary_accuracy: 0.8561 - val_f1: 0.8622 - val_recall: 0.8633 - val_precision: 0.8621\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3015 - binary_accuracy: 0.8676 - f1: 0.8657 - recall: 0.8693 - precision: 0.8639 - val_loss: 0.3257 - val_binary_accuracy: 0.8597 - val_f1: 0.8650 - val_recall: 0.8623 - val_precision: 0.8683\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3035 - binary_accuracy: 0.8676 - f1: 0.8651 - recall: 0.8640 - precision: 0.8688 - val_loss: 0.3229 - val_binary_accuracy: 0.8589 - val_f1: 0.8669 - val_recall: 0.8808 - val_precision: 0.8545\n",
      "Epoch 23/500\n",
      "0s - loss: 0.2959 - binary_accuracy: 0.8714 - f1: 0.8695 - recall: 0.8702 - precision: 0.8698 - val_loss: 0.3241 - val_binary_accuracy: 0.8585 - val_f1: 0.8670 - val_recall: 0.8845 - val_precision: 0.8510\n",
      "Epoch 24/500\n",
      "0s - loss: 0.2988 - binary_accuracy: 0.8697 - f1: 0.8683 - recall: 0.8710 - precision: 0.8672 - val_loss: 0.3248 - val_binary_accuracy: 0.8557 - val_f1: 0.8620 - val_recall: 0.8641 - val_precision: 0.8611\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2989 - binary_accuracy: 0.8704 - f1: 0.8685 - recall: 0.8721 - precision: 0.8676 - val_loss: 0.3260 - val_binary_accuracy: 0.8589 - val_f1: 0.8631 - val_recall: 0.8533 - val_precision: 0.8739\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2980 - binary_accuracy: 0.8690 - f1: 0.8664 - recall: 0.8659 - precision: 0.8683 - val_loss: 0.3226 - val_binary_accuracy: 0.8581 - val_f1: 0.8657 - val_recall: 0.8770 - val_precision: 0.8555\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2996 - binary_accuracy: 0.8684 - f1: 0.8667 - recall: 0.8693 - precision: 0.8664 - val_loss: 0.3465 - val_binary_accuracy: 0.8474 - val_f1: 0.8546 - val_recall: 0.8607 - val_precision: 0.8493\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2962 - binary_accuracy: 0.8702 - f1: 0.8678 - recall: 0.8682 - precision: 0.8690 - val_loss: 0.3261 - val_binary_accuracy: 0.8561 - val_f1: 0.8619 - val_recall: 0.8609 - val_precision: 0.8637\n",
      "Epoch 29/500\n",
      "0s - loss: 0.3010 - binary_accuracy: 0.8690 - f1: 0.8672 - recall: 0.8715 - precision: 0.8651 - val_loss: 0.3310 - val_binary_accuracy: 0.8561 - val_f1: 0.8684 - val_recall: 0.9096 - val_precision: 0.8313\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2918 - binary_accuracy: 0.8701 - f1: 0.8678 - recall: 0.8661 - precision: 0.8715 - val_loss: 0.3267 - val_binary_accuracy: 0.8541 - val_f1: 0.8600 - val_recall: 0.8587 - val_precision: 0.8620\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2886 - binary_accuracy: 0.8732 - f1: 0.8709 - recall: 0.8697 - precision: 0.8738 - val_loss: 0.3268 - val_binary_accuracy: 0.8557 - val_f1: 0.8651 - val_recall: 0.8868 - val_precision: 0.8450\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2869 - binary_accuracy: 0.8727 - f1: 0.8712 - recall: 0.8734 - precision: 0.8704 - val_loss: 0.3246 - val_binary_accuracy: 0.8573 - val_f1: 0.8635 - val_recall: 0.8647 - val_precision: 0.8630\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2865 - binary_accuracy: 0.8732 - f1: 0.8706 - recall: 0.8694 - precision: 0.8736 - val_loss: 0.3288 - val_binary_accuracy: 0.8541 - val_f1: 0.8597 - val_recall: 0.8571 - val_precision: 0.8633\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2854 - binary_accuracy: 0.8725 - f1: 0.8707 - recall: 0.8739 - precision: 0.8694 - val_loss: 0.3251 - val_binary_accuracy: 0.8557 - val_f1: 0.8593 - val_recall: 0.8456 - val_precision: 0.8741\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2846 - binary_accuracy: 0.8769 - f1: 0.8745 - recall: 0.8771 - precision: 0.8740 - val_loss: 0.3205 - val_binary_accuracy: 0.8561 - val_f1: 0.8614 - val_recall: 0.8578 - val_precision: 0.8659\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2803 - binary_accuracy: 0.8774 - f1: 0.8747 - recall: 0.8746 - precision: 0.8764 - val_loss: 0.3224 - val_binary_accuracy: 0.8581 - val_f1: 0.8651 - val_recall: 0.8731 - val_precision: 0.8578\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2840 - binary_accuracy: 0.8772 - f1: 0.8753 - recall: 0.8786 - precision: 0.8737 - val_loss: 0.3314 - val_binary_accuracy: 0.8553 - val_f1: 0.8660 - val_recall: 0.8967 - val_precision: 0.8382\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2886 - binary_accuracy: 0.8774 - f1: 0.8756 - recall: 0.8799 - precision: 0.8745 - val_loss: 0.3213 - val_binary_accuracy: 0.8585 - val_f1: 0.8632 - val_recall: 0.8558 - val_precision: 0.8717\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2794 - binary_accuracy: 0.8781 - f1: 0.8758 - recall: 0.8769 - precision: 0.8768 - val_loss: 0.3254 - val_binary_accuracy: 0.8561 - val_f1: 0.8604 - val_recall: 0.8508 - val_precision: 0.8708\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2792 - binary_accuracy: 0.8764 - f1: 0.8738 - recall: 0.8737 - precision: 0.8760 - val_loss: 0.3243 - val_binary_accuracy: 0.8601 - val_f1: 0.8683 - val_recall: 0.8839 - val_precision: 0.8539\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2834 - binary_accuracy: 0.8784 - f1: 0.8762 - recall: 0.8744 - precision: 0.8801 - val_loss: 0.3290 - val_binary_accuracy: 0.8569 - val_f1: 0.8643 - val_recall: 0.8752 - val_precision: 0.8544\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2733 - binary_accuracy: 0.8796 - f1: 0.8772 - recall: 0.8796 - precision: 0.8767 - val_loss: 0.3235 - val_binary_accuracy: 0.8613 - val_f1: 0.8684 - val_recall: 0.8778 - val_precision: 0.8598\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2784 - binary_accuracy: 0.8800 - f1: 0.8783 - recall: 0.8816 - precision: 0.8774 - val_loss: 0.3195 - val_binary_accuracy: 0.8617 - val_f1: 0.8674 - val_recall: 0.8670 - val_precision: 0.8684\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2765 - binary_accuracy: 0.8810 - f1: 0.8791 - recall: 0.8828 - precision: 0.8770 - val_loss: 0.3328 - val_binary_accuracy: 0.8517 - val_f1: 0.8603 - val_recall: 0.8760 - val_precision: 0.8460\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2740 - binary_accuracy: 0.8828 - f1: 0.8806 - recall: 0.8825 - precision: 0.8806 - val_loss: 0.3263 - val_binary_accuracy: 0.8593 - val_f1: 0.8667 - val_recall: 0.8770 - val_precision: 0.8575\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2704 - binary_accuracy: 0.8815 - f1: 0.8794 - recall: 0.8824 - precision: 0.8776 - val_loss: 0.3443 - val_binary_accuracy: 0.8581 - val_f1: 0.8694 - val_recall: 0.9050 - val_precision: 0.8371\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2676 - binary_accuracy: 0.8818 - f1: 0.8801 - recall: 0.8821 - precision: 0.8796 - val_loss: 0.3256 - val_binary_accuracy: 0.8577 - val_f1: 0.8631 - val_recall: 0.8608 - val_precision: 0.8661\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2634 - binary_accuracy: 0.8858 - f1: 0.8832 - recall: 0.8818 - precision: 0.8863 - val_loss: 0.3290 - val_binary_accuracy: 0.8589 - val_f1: 0.8651 - val_recall: 0.8685 - val_precision: 0.8626\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2644 - binary_accuracy: 0.8853 - f1: 0.8834 - recall: 0.8848 - precision: 0.8832 - val_loss: 0.3346 - val_binary_accuracy: 0.8565 - val_f1: 0.8660 - val_recall: 0.8899 - val_precision: 0.8442\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2630 - binary_accuracy: 0.8890 - f1: 0.8872 - recall: 0.8905 - precision: 0.8855 - val_loss: 0.3406 - val_binary_accuracy: 0.8525 - val_f1: 0.8633 - val_recall: 0.8935 - val_precision: 0.8359\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2611 - binary_accuracy: 0.8853 - f1: 0.8833 - recall: 0.8864 - precision: 0.8824 - val_loss: 0.3216 - val_binary_accuracy: 0.8601 - val_f1: 0.8660 - val_recall: 0.8669 - val_precision: 0.8657\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2568 - binary_accuracy: 0.8923 - f1: 0.8902 - recall: 0.8913 - precision: 0.8905 - val_loss: 0.3280 - val_binary_accuracy: 0.8573 - val_f1: 0.8609 - val_recall: 0.8465 - val_precision: 0.8766\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2553 - binary_accuracy: 0.8890 - f1: 0.8875 - recall: 0.8909 - precision: 0.8856 - val_loss: 0.3324 - val_binary_accuracy: 0.8581 - val_f1: 0.8627 - val_recall: 0.8548 - val_precision: 0.8715\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2610 - binary_accuracy: 0.8887 - f1: 0.8871 - recall: 0.8889 - precision: 0.8870 - val_loss: 0.3288 - val_binary_accuracy: 0.8545 - val_f1: 0.8592 - val_recall: 0.8524 - val_precision: 0.8670\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2570 - binary_accuracy: 0.8895 - f1: 0.8876 - recall: 0.8886 - precision: 0.8888 - val_loss: 0.3293 - val_binary_accuracy: 0.8625 - val_f1: 0.8710 - val_recall: 0.8899 - val_precision: 0.8535\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2497 - binary_accuracy: 0.8957 - f1: 0.8938 - recall: 0.8969 - precision: 0.8921 - val_loss: 0.3244 - val_binary_accuracy: 0.8597 - val_f1: 0.8633 - val_recall: 0.8509 - val_precision: 0.8768\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2496 - binary_accuracy: 0.8921 - f1: 0.8906 - recall: 0.8904 - precision: 0.8925 - val_loss: 0.3223 - val_binary_accuracy: 0.8589 - val_f1: 0.8630 - val_recall: 0.8531 - val_precision: 0.8737\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2471 - binary_accuracy: 0.8957 - f1: 0.8944 - recall: 0.8994 - precision: 0.8910 - val_loss: 0.3228 - val_binary_accuracy: 0.8593 - val_f1: 0.8655 - val_recall: 0.8685 - val_precision: 0.8632\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2536 - binary_accuracy: 0.8920 - f1: 0.8901 - recall: 0.8900 - precision: 0.8927 - val_loss: 0.3404 - val_binary_accuracy: 0.8549 - val_f1: 0.8552 - val_recall: 0.8234 - val_precision: 0.8900\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2466 - binary_accuracy: 0.8939 - f1: 0.8923 - recall: 0.8929 - precision: 0.8935 - val_loss: 0.3424 - val_binary_accuracy: 0.8617 - val_f1: 0.8714 - val_recall: 0.8984 - val_precision: 0.8468\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2471 - binary_accuracy: 0.8955 - f1: 0.8941 - recall: 0.9015 - precision: 0.8882 - val_loss: 0.3442 - val_binary_accuracy: 0.8609 - val_f1: 0.8637 - val_recall: 0.8449 - val_precision: 0.8838\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2435 - binary_accuracy: 0.8960 - f1: 0.8943 - recall: 0.8917 - precision: 0.8978 - val_loss: 0.3306 - val_binary_accuracy: 0.8581 - val_f1: 0.8666 - val_recall: 0.8836 - val_precision: 0.8507\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2462 - binary_accuracy: 0.8968 - f1: 0.8956 - recall: 0.8972 - precision: 0.8960 - val_loss: 0.3210 - val_binary_accuracy: 0.8625 - val_f1: 0.8666 - val_recall: 0.8570 - val_precision: 0.8770\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2384 - binary_accuracy: 0.9002 - f1: 0.8985 - recall: 0.8988 - precision: 0.8992 - val_loss: 0.3426 - val_binary_accuracy: 0.8593 - val_f1: 0.8691 - val_recall: 0.8953 - val_precision: 0.8452\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2358 - binary_accuracy: 0.9026 - f1: 0.9009 - recall: 0.9025 - precision: 0.9005 - val_loss: 0.3376 - val_binary_accuracy: 0.8613 - val_f1: 0.8693 - val_recall: 0.8844 - val_precision: 0.8555\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2351 - binary_accuracy: 0.9028 - f1: 0.9013 - recall: 0.9020 - precision: 0.9020 - val_loss: 0.3538 - val_binary_accuracy: 0.8589 - val_f1: 0.8662 - val_recall: 0.8755 - val_precision: 0.8580\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2430 - binary_accuracy: 0.8947 - f1: 0.8937 - recall: 0.8983 - precision: 0.8914 - val_loss: 0.3400 - val_binary_accuracy: 0.8553 - val_f1: 0.8623 - val_recall: 0.8692 - val_precision: 0.8563\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2383 - binary_accuracy: 0.8981 - f1: 0.8962 - recall: 0.8928 - precision: 0.9027 - val_loss: 0.3371 - val_binary_accuracy: 0.8521 - val_f1: 0.8599 - val_recall: 0.8706 - val_precision: 0.8500\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2293 - binary_accuracy: 0.9053 - f1: 0.9043 - recall: 0.9076 - precision: 0.9023 - val_loss: 0.3541 - val_binary_accuracy: 0.8525 - val_f1: 0.8569 - val_recall: 0.8478 - val_precision: 0.8670\n",
      "Epoch 70/500\n",
      "0s - loss: 0.2283 - binary_accuracy: 0.9053 - f1: 0.9039 - recall: 0.9047 - precision: 0.9041 - val_loss: 0.3741 - val_binary_accuracy: 0.8577 - val_f1: 0.8688 - val_recall: 0.9020 - val_precision: 0.8383\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2344 - binary_accuracy: 0.8997 - f1: 0.8982 - recall: 0.8997 - precision: 0.8983 - val_loss: 0.3365 - val_binary_accuracy: 0.8593 - val_f1: 0.8663 - val_recall: 0.8739 - val_precision: 0.8593\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2301 - binary_accuracy: 0.9038 - f1: 0.9020 - recall: 0.9026 - precision: 0.9036 - val_loss: 0.3347 - val_binary_accuracy: 0.8569 - val_f1: 0.8600 - val_recall: 0.8439 - val_precision: 0.8773\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2285 - binary_accuracy: 0.9030 - f1: 0.9022 - recall: 0.9079 - precision: 0.8992 - val_loss: 0.3411 - val_binary_accuracy: 0.8641 - val_f1: 0.8713 - val_recall: 0.8821 - val_precision: 0.8614\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2209 - binary_accuracy: 0.9063 - f1: 0.9045 - recall: 0.9032 - precision: 0.9069 - val_loss: 0.3457 - val_binary_accuracy: 0.8629 - val_f1: 0.8674 - val_recall: 0.8608 - val_precision: 0.8748\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2202 - binary_accuracy: 0.9093 - f1: 0.9079 - recall: 0.9087 - precision: 0.9084 - val_loss: 0.3468 - val_binary_accuracy: 0.8653 - val_f1: 0.8723 - val_recall: 0.8822 - val_precision: 0.8633\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2148 - binary_accuracy: 0.9090 - f1: 0.9075 - recall: 0.9067 - precision: 0.9095 - val_loss: 0.3470 - val_binary_accuracy: 0.8629 - val_f1: 0.8689 - val_recall: 0.8713 - val_precision: 0.8667\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2154 - binary_accuracy: 0.9094 - f1: 0.9080 - recall: 0.9105 - precision: 0.9069 - val_loss: 0.3472 - val_binary_accuracy: 0.8585 - val_f1: 0.8638 - val_recall: 0.8620 - val_precision: 0.8659\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2171 - binary_accuracy: 0.9111 - f1: 0.9094 - recall: 0.9067 - precision: 0.9135 - val_loss: 0.3588 - val_binary_accuracy: 0.8585 - val_f1: 0.8644 - val_recall: 0.8653 - val_precision: 0.8642\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2155 - binary_accuracy: 0.9088 - f1: 0.9072 - recall: 0.9058 - precision: 0.9101 - val_loss: 0.3440 - val_binary_accuracy: 0.8521 - val_f1: 0.8629 - val_recall: 0.8919 - val_precision: 0.8362\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2069 - binary_accuracy: 0.9138 - f1: 0.9127 - recall: 0.9139 - precision: 0.9123 - val_loss: 0.3492 - val_binary_accuracy: 0.8617 - val_f1: 0.8713 - val_recall: 0.8968 - val_precision: 0.8479\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2074 - binary_accuracy: 0.9178 - f1: 0.9169 - recall: 0.9202 - precision: 0.9149 - val_loss: 0.3482 - val_binary_accuracy: 0.8645 - val_f1: 0.8688 - val_recall: 0.8608 - val_precision: 0.8774\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2053 - binary_accuracy: 0.9159 - f1: 0.9145 - recall: 0.9145 - precision: 0.9158 - val_loss: 0.3622 - val_binary_accuracy: 0.8581 - val_f1: 0.8671 - val_recall: 0.8874 - val_precision: 0.8483\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2127 - binary_accuracy: 0.9125 - f1: 0.9110 - recall: 0.9104 - precision: 0.9137 - val_loss: 0.3557 - val_binary_accuracy: 0.8613 - val_f1: 0.8698 - val_recall: 0.8895 - val_precision: 0.8512\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2027 - binary_accuracy: 0.9175 - f1: 0.9160 - recall: 0.9146 - precision: 0.9184 - val_loss: 0.3552 - val_binary_accuracy: 0.8577 - val_f1: 0.8583 - val_recall: 0.8279 - val_precision: 0.8915\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2005 - binary_accuracy: 0.9189 - f1: 0.9169 - recall: 0.9137 - precision: 0.9210 - val_loss: 0.3599 - val_binary_accuracy: 0.8613 - val_f1: 0.8676 - val_recall: 0.8715 - val_precision: 0.8644\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2052 - binary_accuracy: 0.9173 - f1: 0.9162 - recall: 0.9178 - precision: 0.9164 - val_loss: 0.3561 - val_binary_accuracy: 0.8549 - val_f1: 0.8621 - val_recall: 0.8692 - val_precision: 0.8554\n",
      "Epoch 87/500\n",
      "0s - loss: 0.1955 - binary_accuracy: 0.9189 - f1: 0.9173 - recall: 0.9170 - precision: 0.9185 - val_loss: 0.3576 - val_binary_accuracy: 0.8506 - val_f1: 0.8577 - val_recall: 0.8639 - val_precision: 0.8520\n",
      "Epoch 88/500\n",
      "0s - loss: 0.1958 - binary_accuracy: 0.9210 - f1: 0.9198 - recall: 0.9196 - precision: 0.9214 - val_loss: 0.3649 - val_binary_accuracy: 0.8442 - val_f1: 0.8495 - val_recall: 0.8458 - val_precision: 0.8535\n",
      "Epoch 89/500\n",
      "0s - loss: 0.1927 - binary_accuracy: 0.9211 - f1: 0.9199 - recall: 0.9216 - precision: 0.9189 - val_loss: 0.3582 - val_binary_accuracy: 0.8593 - val_f1: 0.8673 - val_recall: 0.8819 - val_precision: 0.8536\n",
      "Epoch 90/500\n",
      "0s - loss: 0.1886 - binary_accuracy: 0.9247 - f1: 0.9234 - recall: 0.9227 - precision: 0.9249 - val_loss: 0.3604 - val_binary_accuracy: 0.8589 - val_f1: 0.8643 - val_recall: 0.8629 - val_precision: 0.8660\n",
      "Epoch 91/500\n",
      "0s - loss: 0.1898 - binary_accuracy: 0.9208 - f1: 0.9196 - recall: 0.9220 - precision: 0.9186 - val_loss: 0.3574 - val_binary_accuracy: 0.8601 - val_f1: 0.8649 - val_recall: 0.8577 - val_precision: 0.8726\n",
      "Epoch 92/500\n",
      "0s - loss: 0.1840 - binary_accuracy: 0.9281 - f1: 0.9266 - recall: 0.9249 - precision: 0.9291 - val_loss: 0.3616 - val_binary_accuracy: 0.8553 - val_f1: 0.8629 - val_recall: 0.8734 - val_precision: 0.8529\n",
      "Epoch 93/500\n",
      "0s - loss: 0.1852 - binary_accuracy: 0.9241 - f1: 0.9227 - recall: 0.9235 - precision: 0.9225 - val_loss: 0.3574 - val_binary_accuracy: 0.8621 - val_f1: 0.8653 - val_recall: 0.8507 - val_precision: 0.8808\n",
      "Epoch 94/500\n",
      "0s - loss: 0.1888 - binary_accuracy: 0.9204 - f1: 0.9191 - recall: 0.9198 - precision: 0.9198 - val_loss: 0.3826 - val_binary_accuracy: 0.8462 - val_f1: 0.8471 - val_recall: 0.8179 - val_precision: 0.8791\n",
      "2176/2516 [========================>.....] - ETA: 0stn = 4018, fp = 209, fn = 398, tp = 3719\n",
      "y_pred: 0 = 4416 | 1 = 3928\n",
      "y_true: 0 = 4227 | 1 = 4117\n",
      "acc=0.9273|precision=0.9468|recall=0.9033|f1=0.9245|auc=0.9816|aupr=0.9818|pos_acc=0.9033|neg_acc=0.9099\n",
      "tn = 1055, fp = 148, fn = 239, tp = 1074\n",
      "y_pred: 0 = 1294 | 1 = 1222\n",
      "y_true: 0 = 1203 | 1 = 1313\n",
      "acc=0.8462|precision=0.8789|recall=0.8180|f1=0.8473|auc=0.9293|aupr=0.9294|pos_acc=0.8180|neg_acc=0.8153\n",
      "----------------------- Fold =  1\n",
      "Train on 8611 samples, validate on 2249 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 0.4141 - binary_accuracy: 0.8118 - f1: 0.8003 - recall: 0.7812 - precision: 0.8424 - val_loss: 0.3599 - val_binary_accuracy: 0.8364 - val_f1: 0.8398 - val_recall: 0.8513 - val_precision: 0.8289\n",
      "Epoch 2/500\n",
      "1s - loss: 0.3539 - binary_accuracy: 0.8431 - f1: 0.8422 - recall: 0.8430 - precision: 0.8427 - val_loss: 0.3379 - val_binary_accuracy: 0.8502 - val_f1: 0.8507 - val_recall: 0.8476 - val_precision: 0.8542\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3498 - binary_accuracy: 0.8450 - f1: 0.8439 - recall: 0.8438 - precision: 0.8490 - val_loss: 0.3361 - val_binary_accuracy: 0.8470 - val_f1: 0.8415 - val_recall: 0.8061 - val_precision: 0.8807\n",
      "Epoch 4/500\n",
      "1s - loss: 0.3387 - binary_accuracy: 0.8529 - f1: 0.8511 - recall: 0.8457 - precision: 0.8588 - val_loss: 0.3271 - val_binary_accuracy: 0.8564 - val_f1: 0.8578 - val_recall: 0.8608 - val_precision: 0.8554\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3387 - binary_accuracy: 0.8501 - f1: 0.8492 - recall: 0.8531 - precision: 0.8491 - val_loss: 0.3314 - val_binary_accuracy: 0.8502 - val_f1: 0.8580 - val_recall: 0.8993 - val_precision: 0.8211\n",
      "Epoch 6/500\n",
      "1s - loss: 0.3295 - binary_accuracy: 0.8577 - f1: 0.8567 - recall: 0.8553 - precision: 0.8595 - val_loss: 0.3235 - val_binary_accuracy: 0.8590 - val_f1: 0.8645 - val_recall: 0.8933 - val_precision: 0.8383\n",
      "Epoch 7/500\n",
      "1s - loss: 0.3265 - binary_accuracy: 0.8588 - f1: 0.8577 - recall: 0.8580 - precision: 0.8587 - val_loss: 0.3212 - val_binary_accuracy: 0.8577 - val_f1: 0.8607 - val_recall: 0.8739 - val_precision: 0.8486\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3285 - binary_accuracy: 0.8555 - f1: 0.8553 - recall: 0.8581 - precision: 0.8554 - val_loss: 0.3256 - val_binary_accuracy: 0.8550 - val_f1: 0.8615 - val_recall: 0.8967 - val_precision: 0.8296\n",
      "Epoch 9/500\n",
      "1s - loss: 0.3288 - binary_accuracy: 0.8566 - f1: 0.8560 - recall: 0.8629 - precision: 0.8527 - val_loss: 0.3208 - val_binary_accuracy: 0.8635 - val_f1: 0.8610 - val_recall: 0.8397 - val_precision: 0.8842\n",
      "Epoch 10/500\n",
      "1s - loss: 0.3232 - binary_accuracy: 0.8624 - f1: 0.8615 - recall: 0.8623 - precision: 0.8633 - val_loss: 0.3163 - val_binary_accuracy: 0.8608 - val_f1: 0.8588 - val_recall: 0.8404 - val_precision: 0.8789\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3187 - binary_accuracy: 0.8613 - f1: 0.8607 - recall: 0.8622 - precision: 0.8606 - val_loss: 0.3183 - val_binary_accuracy: 0.8626 - val_f1: 0.8683 - val_recall: 0.9001 - val_precision: 0.8396\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3196 - binary_accuracy: 0.8598 - f1: 0.8585 - recall: 0.8578 - precision: 0.8611 - val_loss: 0.3205 - val_binary_accuracy: 0.8577 - val_f1: 0.8651 - val_recall: 0.9063 - val_precision: 0.8281\n",
      "Epoch 13/500\n",
      "1s - loss: 0.3179 - binary_accuracy: 0.8637 - f1: 0.8638 - recall: 0.8719 - precision: 0.8581 - val_loss: 0.3141 - val_binary_accuracy: 0.8617 - val_f1: 0.8638 - val_recall: 0.8688 - val_precision: 0.8598\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3154 - binary_accuracy: 0.8637 - f1: 0.8641 - recall: 0.8700 - precision: 0.8596 - val_loss: 0.3125 - val_binary_accuracy: 0.8653 - val_f1: 0.8677 - val_recall: 0.8782 - val_precision: 0.8585\n",
      "Epoch 15/500\n",
      "1s - loss: 0.3160 - binary_accuracy: 0.8623 - f1: 0.8621 - recall: 0.8659 - precision: 0.8601 - val_loss: 0.3126 - val_binary_accuracy: 0.8666 - val_f1: 0.8692 - val_recall: 0.8800 - val_precision: 0.8595\n",
      "Epoch 16/500\n",
      "1s - loss: 0.3129 - binary_accuracy: 0.8631 - f1: 0.8624 - recall: 0.8631 - precision: 0.8638 - val_loss: 0.3118 - val_binary_accuracy: 0.8599 - val_f1: 0.8630 - val_recall: 0.8740 - val_precision: 0.8531\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3199 - binary_accuracy: 0.8617 - f1: 0.8613 - recall: 0.8657 - precision: 0.8602 - val_loss: 0.3250 - val_binary_accuracy: 0.8590 - val_f1: 0.8542 - val_recall: 0.8194 - val_precision: 0.8928\n",
      "Epoch 18/500\n",
      "1s - loss: 0.3217 - binary_accuracy: 0.8588 - f1: 0.8574 - recall: 0.8561 - precision: 0.8633 - val_loss: 0.3301 - val_binary_accuracy: 0.8519 - val_f1: 0.8559 - val_recall: 0.8747 - val_precision: 0.8385\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3158 - binary_accuracy: 0.8589 - f1: 0.8588 - recall: 0.8630 - precision: 0.8563 - val_loss: 0.3164 - val_binary_accuracy: 0.8577 - val_f1: 0.8625 - val_recall: 0.8854 - val_precision: 0.8416\n",
      "Epoch 20/500\n",
      "1s - loss: 0.3140 - binary_accuracy: 0.8605 - f1: 0.8599 - recall: 0.8617 - precision: 0.8603 - val_loss: 0.3100 - val_binary_accuracy: 0.8657 - val_f1: 0.8681 - val_recall: 0.8775 - val_precision: 0.8599\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3087 - binary_accuracy: 0.8645 - f1: 0.8637 - recall: 0.8645 - precision: 0.8644 - val_loss: 0.3153 - val_binary_accuracy: 0.8693 - val_f1: 0.8693 - val_recall: 0.8625 - val_precision: 0.8771\n",
      "Epoch 22/500\n",
      "1s - loss: 0.3113 - binary_accuracy: 0.8653 - f1: 0.8651 - recall: 0.8688 - precision: 0.8648 - val_loss: 0.3160 - val_binary_accuracy: 0.8635 - val_f1: 0.8700 - val_recall: 0.9075 - val_precision: 0.8363\n",
      "Epoch 23/500\n",
      "1s - loss: 0.3034 - binary_accuracy: 0.8685 - f1: 0.8682 - recall: 0.8720 - precision: 0.8656 - val_loss: 0.3118 - val_binary_accuracy: 0.8671 - val_f1: 0.8692 - val_recall: 0.8799 - val_precision: 0.8597\n",
      "Epoch 24/500\n",
      "1s - loss: 0.3058 - binary_accuracy: 0.8660 - f1: 0.8652 - recall: 0.8675 - precision: 0.8657 - val_loss: 0.3115 - val_binary_accuracy: 0.8666 - val_f1: 0.8698 - val_recall: 0.8853 - val_precision: 0.8557\n",
      "Epoch 25/500\n",
      "1s - loss: 0.3046 - binary_accuracy: 0.8671 - f1: 0.8663 - recall: 0.8679 - precision: 0.8671 - val_loss: 0.3105 - val_binary_accuracy: 0.8662 - val_f1: 0.8699 - val_recall: 0.8896 - val_precision: 0.8520\n",
      "Epoch 26/500\n",
      "1s - loss: 0.3046 - binary_accuracy: 0.8671 - f1: 0.8663 - recall: 0.8644 - precision: 0.8707 - val_loss: 0.3260 - val_binary_accuracy: 0.8542 - val_f1: 0.8605 - val_recall: 0.8939 - val_precision: 0.8303\n",
      "Epoch 27/500\n",
      "1s - loss: 0.3058 - binary_accuracy: 0.8638 - f1: 0.8629 - recall: 0.8659 - precision: 0.8623 - val_loss: 0.3153 - val_binary_accuracy: 0.8671 - val_f1: 0.8728 - val_recall: 0.9055 - val_precision: 0.8430\n",
      "Epoch 28/500\n",
      "0s - loss: 0.3023 - binary_accuracy: 0.8692 - f1: 0.8693 - recall: 0.8723 - precision: 0.8681 - val_loss: 0.3158 - val_binary_accuracy: 0.8626 - val_f1: 0.8691 - val_recall: 0.9064 - val_precision: 0.8355\n",
      "Epoch 29/500\n",
      "1s - loss: 0.2981 - binary_accuracy: 0.8691 - f1: 0.8687 - recall: 0.8720 - precision: 0.8671 - val_loss: 0.3120 - val_binary_accuracy: 0.8613 - val_f1: 0.8640 - val_recall: 0.8748 - val_precision: 0.8546\n",
      "Epoch 30/500\n",
      "1s - loss: 0.2988 - binary_accuracy: 0.8671 - f1: 0.8676 - recall: 0.8738 - precision: 0.8630 - val_loss: 0.3132 - val_binary_accuracy: 0.8662 - val_f1: 0.8643 - val_recall: 0.8473 - val_precision: 0.8827\n",
      "Epoch 31/500\n",
      "1s - loss: 0.2997 - binary_accuracy: 0.8706 - f1: 0.8696 - recall: 0.8693 - precision: 0.8730 - val_loss: 0.3121 - val_binary_accuracy: 0.8675 - val_f1: 0.8700 - val_recall: 0.8818 - val_precision: 0.8593\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2945 - binary_accuracy: 0.8721 - f1: 0.8719 - recall: 0.8739 - precision: 0.8709 - val_loss: 0.3111 - val_binary_accuracy: 0.8702 - val_f1: 0.8735 - val_recall: 0.8905 - val_precision: 0.8578\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2930 - binary_accuracy: 0.8736 - f1: 0.8734 - recall: 0.8763 - precision: 0.8717 - val_loss: 0.3139 - val_binary_accuracy: 0.8648 - val_f1: 0.8696 - val_recall: 0.8950 - val_precision: 0.8465\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2909 - binary_accuracy: 0.8745 - f1: 0.8742 - recall: 0.8766 - precision: 0.8733 - val_loss: 0.3147 - val_binary_accuracy: 0.8675 - val_f1: 0.8668 - val_recall: 0.8570 - val_precision: 0.8777\n",
      "Epoch 35/500\n",
      "1s - loss: 0.3021 - binary_accuracy: 0.8676 - f1: 0.8662 - recall: 0.8699 - precision: 0.8655 - val_loss: 0.3204 - val_binary_accuracy: 0.8631 - val_f1: 0.8705 - val_recall: 0.9145 - val_precision: 0.8316\n",
      "Epoch 36/500\n",
      "1s - loss: 0.2913 - binary_accuracy: 0.8740 - f1: 0.8737 - recall: 0.8771 - precision: 0.8715 - val_loss: 0.3196 - val_binary_accuracy: 0.8653 - val_f1: 0.8630 - val_recall: 0.8438 - val_precision: 0.8840\n",
      "Epoch 37/500\n",
      "1s - loss: 0.2923 - binary_accuracy: 0.8760 - f1: 0.8750 - recall: 0.8781 - precision: 0.8742 - val_loss: 0.3129 - val_binary_accuracy: 0.8671 - val_f1: 0.8704 - val_recall: 0.8878 - val_precision: 0.8547\n",
      "Epoch 38/500\n",
      "1s - loss: 0.2858 - binary_accuracy: 0.8755 - f1: 0.8750 - recall: 0.8771 - precision: 0.8744 - val_loss: 0.3174 - val_binary_accuracy: 0.8635 - val_f1: 0.8692 - val_recall: 0.9013 - val_precision: 0.8402\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2828 - binary_accuracy: 0.8791 - f1: 0.8787 - recall: 0.8829 - precision: 0.8758 - val_loss: 0.3104 - val_binary_accuracy: 0.8697 - val_f1: 0.8696 - val_recall: 0.8639 - val_precision: 0.8761\n",
      "Epoch 40/500\n",
      "1s - loss: 0.2861 - binary_accuracy: 0.8748 - f1: 0.8739 - recall: 0.8740 - precision: 0.8757 - val_loss: 0.3101 - val_binary_accuracy: 0.8653 - val_f1: 0.8655 - val_recall: 0.8615 - val_precision: 0.8705\n",
      "Epoch 41/500\n",
      "1s - loss: 0.2841 - binary_accuracy: 0.8760 - f1: 0.8754 - recall: 0.8773 - precision: 0.8750 - val_loss: 0.3090 - val_binary_accuracy: 0.8671 - val_f1: 0.8696 - val_recall: 0.8808 - val_precision: 0.8597\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2886 - binary_accuracy: 0.8752 - f1: 0.8745 - recall: 0.8761 - precision: 0.8765 - val_loss: 0.3289 - val_binary_accuracy: 0.8604 - val_f1: 0.8547 - val_recall: 0.8180 - val_precision: 0.8960\n",
      "Epoch 43/500\n",
      "1s - loss: 0.2839 - binary_accuracy: 0.8749 - f1: 0.8744 - recall: 0.8772 - precision: 0.8747 - val_loss: 0.3195 - val_binary_accuracy: 0.8648 - val_f1: 0.8662 - val_recall: 0.8700 - val_precision: 0.8633\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2838 - binary_accuracy: 0.8761 - f1: 0.8763 - recall: 0.8816 - precision: 0.8740 - val_loss: 0.3122 - val_binary_accuracy: 0.8662 - val_f1: 0.8684 - val_recall: 0.8776 - val_precision: 0.8607\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2799 - binary_accuracy: 0.8782 - f1: 0.8772 - recall: 0.8735 - precision: 0.8829 - val_loss: 0.3215 - val_binary_accuracy: 0.8622 - val_f1: 0.8686 - val_recall: 0.9063 - val_precision: 0.8350\n",
      "Epoch 46/500\n",
      "1s - loss: 0.2826 - binary_accuracy: 0.8763 - f1: 0.8755 - recall: 0.8794 - precision: 0.8741 - val_loss: 0.3100 - val_binary_accuracy: 0.8662 - val_f1: 0.8670 - val_recall: 0.8685 - val_precision: 0.8663\n",
      "Epoch 47/500\n",
      "1s - loss: 0.2800 - binary_accuracy: 0.8775 - f1: 0.8764 - recall: 0.8769 - precision: 0.8773 - val_loss: 0.3198 - val_binary_accuracy: 0.8599 - val_f1: 0.8654 - val_recall: 0.8941 - val_precision: 0.8390\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2766 - binary_accuracy: 0.8815 - f1: 0.8810 - recall: 0.8826 - precision: 0.8813 - val_loss: 0.3095 - val_binary_accuracy: 0.8653 - val_f1: 0.8667 - val_recall: 0.8712 - val_precision: 0.8629\n",
      "Epoch 49/500\n",
      "1s - loss: 0.2720 - binary_accuracy: 0.8815 - f1: 0.8813 - recall: 0.8854 - precision: 0.8788 - val_loss: 0.3150 - val_binary_accuracy: 0.8662 - val_f1: 0.8671 - val_recall: 0.8661 - val_precision: 0.8689\n",
      "Epoch 50/500\n",
      "1s - loss: 0.2719 - binary_accuracy: 0.8849 - f1: 0.8837 - recall: 0.8824 - precision: 0.8871 - val_loss: 0.3138 - val_binary_accuracy: 0.8631 - val_f1: 0.8677 - val_recall: 0.8924 - val_precision: 0.8452\n",
      "Epoch 51/500\n",
      "1s - loss: 0.2699 - binary_accuracy: 0.8845 - f1: 0.8841 - recall: 0.8867 - precision: 0.8828 - val_loss: 0.3198 - val_binary_accuracy: 0.8577 - val_f1: 0.8626 - val_recall: 0.8886 - val_precision: 0.8385\n",
      "Epoch 52/500\n",
      "1s - loss: 0.2662 - binary_accuracy: 0.8869 - f1: 0.8865 - recall: 0.8895 - precision: 0.8844 - val_loss: 0.3143 - val_binary_accuracy: 0.8693 - val_f1: 0.8713 - val_recall: 0.8800 - val_precision: 0.8637\n",
      "Epoch 53/500\n",
      "1s - loss: 0.2682 - binary_accuracy: 0.8853 - f1: 0.8847 - recall: 0.8857 - precision: 0.8858 - val_loss: 0.3170 - val_binary_accuracy: 0.8631 - val_f1: 0.8659 - val_recall: 0.8792 - val_precision: 0.8539\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2774 - binary_accuracy: 0.8797 - f1: 0.8789 - recall: 0.8791 - precision: 0.8809 - val_loss: 0.3255 - val_binary_accuracy: 0.8617 - val_f1: 0.8569 - val_recall: 0.8249 - val_precision: 0.8922\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2671 - binary_accuracy: 0.8807 - f1: 0.8801 - recall: 0.8836 - precision: 0.8785 - val_loss: 0.3103 - val_binary_accuracy: 0.8684 - val_f1: 0.8698 - val_recall: 0.8754 - val_precision: 0.8653\n",
      "Epoch 56/500\n",
      "1s - loss: 0.2619 - binary_accuracy: 0.8874 - f1: 0.8868 - recall: 0.8868 - precision: 0.8881 - val_loss: 0.3213 - val_binary_accuracy: 0.8684 - val_f1: 0.8641 - val_recall: 0.8337 - val_precision: 0.8980\n",
      "Epoch 57/500\n",
      "1s - loss: 0.2628 - binary_accuracy: 0.8869 - f1: 0.8865 - recall: 0.8886 - precision: 0.8860 - val_loss: 0.3178 - val_binary_accuracy: 0.8631 - val_f1: 0.8685 - val_recall: 0.8978 - val_precision: 0.8422\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2593 - binary_accuracy: 0.8871 - f1: 0.8865 - recall: 0.8870 - precision: 0.8876 - val_loss: 0.3290 - val_binary_accuracy: 0.8622 - val_f1: 0.8664 - val_recall: 0.8881 - val_precision: 0.8466\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2627 - binary_accuracy: 0.8882 - f1: 0.8870 - recall: 0.8871 - precision: 0.8889 - val_loss: 0.3293 - val_binary_accuracy: 0.8653 - val_f1: 0.8690 - val_recall: 0.8888 - val_precision: 0.8508\n",
      "Epoch 60/500\n",
      "1s - loss: 0.2622 - binary_accuracy: 0.8850 - f1: 0.8850 - recall: 0.8891 - precision: 0.8831 - val_loss: 0.3337 - val_binary_accuracy: 0.8564 - val_f1: 0.8656 - val_recall: 0.9187 - val_precision: 0.8189\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2534 - binary_accuracy: 0.8903 - f1: 0.8902 - recall: 0.8945 - precision: 0.8876 - val_loss: 0.3209 - val_binary_accuracy: 0.8657 - val_f1: 0.8670 - val_recall: 0.8712 - val_precision: 0.8635\n",
      "Epoch 62/500\n",
      "1s - loss: 0.2614 - binary_accuracy: 0.8881 - f1: 0.8875 - recall: 0.8888 - precision: 0.8888 - val_loss: 0.3254 - val_binary_accuracy: 0.8653 - val_f1: 0.8605 - val_recall: 0.8311 - val_precision: 0.8936\n",
      "Epoch 63/500\n",
      "1s - loss: 0.2532 - binary_accuracy: 0.8906 - f1: 0.8900 - recall: 0.8898 - precision: 0.8920 - val_loss: 0.3222 - val_binary_accuracy: 0.8613 - val_f1: 0.8679 - val_recall: 0.9055 - val_precision: 0.8341\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2502 - binary_accuracy: 0.8917 - f1: 0.8909 - recall: 0.8909 - precision: 0.8920 - val_loss: 0.3195 - val_binary_accuracy: 0.8662 - val_f1: 0.8676 - val_recall: 0.8728 - val_precision: 0.8631\n",
      "Epoch 65/500\n",
      "0s - loss: 0.2535 - binary_accuracy: 0.8925 - f1: 0.8920 - recall: 0.8920 - precision: 0.8937 - val_loss: 0.3331 - val_binary_accuracy: 0.8626 - val_f1: 0.8704 - val_recall: 0.9154 - val_precision: 0.8303\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2501 - binary_accuracy: 0.8918 - f1: 0.8916 - recall: 0.8953 - precision: 0.8895 - val_loss: 0.3202 - val_binary_accuracy: 0.8604 - val_f1: 0.8610 - val_recall: 0.8628 - val_precision: 0.8601\n",
      "Epoch 67/500\n",
      "1s - loss: 0.2484 - binary_accuracy: 0.8929 - f1: 0.8918 - recall: 0.8922 - precision: 0.8930 - val_loss: 0.3227 - val_binary_accuracy: 0.8631 - val_f1: 0.8616 - val_recall: 0.8498 - val_precision: 0.8745\n",
      "Epoch 68/500\n",
      "1s - loss: 0.2482 - binary_accuracy: 0.8929 - f1: 0.8917 - recall: 0.8892 - precision: 0.8953 - val_loss: 0.3281 - val_binary_accuracy: 0.8639 - val_f1: 0.8685 - val_recall: 0.8941 - val_precision: 0.8452\n",
      "Epoch 69/500\n",
      "1s - loss: 0.2521 - binary_accuracy: 0.8943 - f1: 0.8933 - recall: 0.8957 - precision: 0.8938 - val_loss: 0.3196 - val_binary_accuracy: 0.8653 - val_f1: 0.8647 - val_recall: 0.8577 - val_precision: 0.8726\n",
      "Epoch 70/500\n",
      "1s - loss: 0.2427 - binary_accuracy: 0.8969 - f1: 0.8961 - recall: 0.8965 - precision: 0.8974 - val_loss: 0.3217 - val_binary_accuracy: 0.8604 - val_f1: 0.8611 - val_recall: 0.8622 - val_precision: 0.8614\n",
      "Epoch 71/500\n",
      "1s - loss: 0.2452 - binary_accuracy: 0.8958 - f1: 0.8955 - recall: 0.8958 - precision: 0.8969 - val_loss: 0.3203 - val_binary_accuracy: 0.8679 - val_f1: 0.8671 - val_recall: 0.8588 - val_precision: 0.8767\n",
      "Epoch 72/500\n",
      "1s - loss: 0.2386 - binary_accuracy: 0.8992 - f1: 0.8989 - recall: 0.9018 - precision: 0.8968 - val_loss: 0.3258 - val_binary_accuracy: 0.8693 - val_f1: 0.8727 - val_recall: 0.8905 - val_precision: 0.8563\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2352 - binary_accuracy: 0.8998 - f1: 0.8993 - recall: 0.8981 - precision: 0.9011 - val_loss: 0.3230 - val_binary_accuracy: 0.8648 - val_f1: 0.8670 - val_recall: 0.8772 - val_precision: 0.8578\n",
      "Epoch 74/500\n",
      "1s - loss: 0.2324 - binary_accuracy: 0.9012 - f1: 0.9011 - recall: 0.9023 - precision: 0.9010 - val_loss: 0.3225 - val_binary_accuracy: 0.8662 - val_f1: 0.8656 - val_recall: 0.8588 - val_precision: 0.8735\n",
      "Epoch 75/500\n",
      "1s - loss: 0.2365 - binary_accuracy: 0.8991 - f1: 0.8988 - recall: 0.9000 - precision: 0.8993 - val_loss: 0.3319 - val_binary_accuracy: 0.8715 - val_f1: 0.8710 - val_recall: 0.8646 - val_precision: 0.8785\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2328 - binary_accuracy: 0.9001 - f1: 0.8996 - recall: 0.9006 - precision: 0.8997 - val_loss: 0.3270 - val_binary_accuracy: 0.8684 - val_f1: 0.8697 - val_recall: 0.8754 - val_precision: 0.8648\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2337 - binary_accuracy: 0.8994 - f1: 0.8987 - recall: 0.8973 - precision: 0.9022 - val_loss: 0.3260 - val_binary_accuracy: 0.8675 - val_f1: 0.8703 - val_recall: 0.8852 - val_precision: 0.8565\n",
      "Epoch 78/500\n",
      "0s - loss: 0.2322 - binary_accuracy: 0.8990 - f1: 0.8987 - recall: 0.8989 - precision: 0.8999 - val_loss: 0.3259 - val_binary_accuracy: 0.8693 - val_f1: 0.8707 - val_recall: 0.8772 - val_precision: 0.8653\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2296 - binary_accuracy: 0.9013 - f1: 0.9001 - recall: 0.8977 - precision: 0.9042 - val_loss: 0.3256 - val_binary_accuracy: 0.8675 - val_f1: 0.8681 - val_recall: 0.8690 - val_precision: 0.8681\n",
      "Epoch 80/500\n",
      "1s - loss: 0.2238 - binary_accuracy: 0.9062 - f1: 0.9056 - recall: 0.9045 - precision: 0.9078 - val_loss: 0.3407 - val_binary_accuracy: 0.8639 - val_f1: 0.8614 - val_recall: 0.8428 - val_precision: 0.8820\n",
      "Epoch 81/500\n",
      "0s - loss: 0.2279 - binary_accuracy: 0.9043 - f1: 0.9039 - recall: 0.9038 - precision: 0.9064 - val_loss: 0.3403 - val_binary_accuracy: 0.8631 - val_f1: 0.8698 - val_recall: 0.9082 - val_precision: 0.8356\n",
      "Epoch 82/500\n",
      "1s - loss: 0.2214 - binary_accuracy: 0.9052 - f1: 0.9051 - recall: 0.9083 - precision: 0.9039 - val_loss: 0.3451 - val_binary_accuracy: 0.8719 - val_f1: 0.8705 - val_recall: 0.8553 - val_precision: 0.8872\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2282 - binary_accuracy: 0.9015 - f1: 0.9004 - recall: 0.8975 - precision: 0.9054 - val_loss: 0.3433 - val_binary_accuracy: 0.8568 - val_f1: 0.8633 - val_recall: 0.8996 - val_precision: 0.8308\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2221 - binary_accuracy: 0.9067 - f1: 0.9062 - recall: 0.9062 - precision: 0.9077 - val_loss: 0.3267 - val_binary_accuracy: 0.8706 - val_f1: 0.8725 - val_recall: 0.8809 - val_precision: 0.8657\n",
      "Epoch 85/500\n",
      "1s - loss: 0.2169 - binary_accuracy: 0.9076 - f1: 0.9070 - recall: 0.9076 - precision: 0.9074 - val_loss: 0.3383 - val_binary_accuracy: 0.8715 - val_f1: 0.8731 - val_recall: 0.8799 - val_precision: 0.8671\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2221 - binary_accuracy: 0.9081 - f1: 0.9076 - recall: 0.9066 - precision: 0.9099 - val_loss: 0.3409 - val_binary_accuracy: 0.8635 - val_f1: 0.8670 - val_recall: 0.8864 - val_precision: 0.8498\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2172 - binary_accuracy: 0.9121 - f1: 0.9117 - recall: 0.9125 - precision: 0.9126 - val_loss: 0.3324 - val_binary_accuracy: 0.8688 - val_f1: 0.8705 - val_recall: 0.8774 - val_precision: 0.8647\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2195 - binary_accuracy: 0.9077 - f1: 0.9070 - recall: 0.9066 - precision: 0.9091 - val_loss: 0.3404 - val_binary_accuracy: 0.8502 - val_f1: 0.8512 - val_recall: 0.8544 - val_precision: 0.8491\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2130 - binary_accuracy: 0.9107 - f1: 0.9104 - recall: 0.9125 - precision: 0.9090 - val_loss: 0.3353 - val_binary_accuracy: 0.8622 - val_f1: 0.8606 - val_recall: 0.8481 - val_precision: 0.8745\n",
      "Epoch 90/500\n",
      "1s - loss: 0.2106 - binary_accuracy: 0.9112 - f1: 0.9102 - recall: 0.9081 - precision: 0.9136 - val_loss: 0.3406 - val_binary_accuracy: 0.8546 - val_f1: 0.8598 - val_recall: 0.8896 - val_precision: 0.8331\n",
      "Epoch 91/500\n",
      "1s - loss: 0.2188 - binary_accuracy: 0.9093 - f1: 0.9088 - recall: 0.9097 - precision: 0.9112 - val_loss: 0.3459 - val_binary_accuracy: 0.8622 - val_f1: 0.8588 - val_recall: 0.8343 - val_precision: 0.8856\n",
      "Epoch 92/500\n",
      "1s - loss: 0.2078 - binary_accuracy: 0.9157 - f1: 0.9150 - recall: 0.9131 - precision: 0.9180 - val_loss: 0.3438 - val_binary_accuracy: 0.8555 - val_f1: 0.8551 - val_recall: 0.8498 - val_precision: 0.8617\n",
      "2144/2249 [===========================>..] - ETA: 0stn = 4038, fp = 278, fn = 444, tp = 3851\n",
      "y_pred: 0 = 4482 | 1 = 4129\n",
      "y_true: 0 = 4316 | 1 = 4295\n",
      "acc=0.9162|precision=0.9327|recall=0.8966|f1=0.9143|auc=0.9757|aupr=0.9770|pos_acc=0.8966|neg_acc=0.9009\n",
      "tn = 959, fp = 155, fn = 170, tp = 965\n",
      "y_pred: 0 = 1129 | 1 = 1120\n",
      "y_true: 0 = 1114 | 1 = 1135\n",
      "acc=0.8555|precision=0.8616|recall=0.8502|f1=0.8559|auc=0.9367|aupr=0.9280|pos_acc=0.8502|neg_acc=0.8494\n",
      "----------------------- Fold =  2\n",
      "Train on 8648 samples, validate on 2212 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.4022 - binary_accuracy: 0.8246 - f1: 0.8145 - recall: 0.7944 - precision: 0.8486 - val_loss: 0.3671 - val_binary_accuracy: 0.8404 - val_f1: 0.8416 - val_recall: 0.8404 - val_precision: 0.8439\n",
      "Epoch 2/500\n",
      "1s - loss: 0.3462 - binary_accuracy: 0.8491 - f1: 0.8473 - recall: 0.8440 - precision: 0.8541 - val_loss: 0.3664 - val_binary_accuracy: 0.8395 - val_f1: 0.8415 - val_recall: 0.8449 - val_precision: 0.8393\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3383 - binary_accuracy: 0.8515 - f1: 0.8501 - recall: 0.8467 - precision: 0.8574 - val_loss: 0.3604 - val_binary_accuracy: 0.8454 - val_f1: 0.8420 - val_recall: 0.8170 - val_precision: 0.8694\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3272 - binary_accuracy: 0.8600 - f1: 0.8590 - recall: 0.8576 - precision: 0.8621 - val_loss: 0.3516 - val_binary_accuracy: 0.8508 - val_f1: 0.8538 - val_recall: 0.8633 - val_precision: 0.8454\n",
      "Epoch 5/500\n",
      "1s - loss: 0.3248 - binary_accuracy: 0.8573 - f1: 0.8569 - recall: 0.8611 - precision: 0.8551 - val_loss: 0.3575 - val_binary_accuracy: 0.8522 - val_f1: 0.8533 - val_recall: 0.8534 - val_precision: 0.8541\n",
      "Epoch 6/500\n",
      "1s - loss: 0.3245 - binary_accuracy: 0.8553 - f1: 0.8537 - recall: 0.8527 - precision: 0.8572 - val_loss: 0.3747 - val_binary_accuracy: 0.8368 - val_f1: 0.8267 - val_recall: 0.7700 - val_precision: 0.8931\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3217 - binary_accuracy: 0.8596 - f1: 0.8580 - recall: 0.8565 - precision: 0.8621 - val_loss: 0.3489 - val_binary_accuracy: 0.8513 - val_f1: 0.8554 - val_recall: 0.8730 - val_precision: 0.8394\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3163 - binary_accuracy: 0.8633 - f1: 0.8634 - recall: 0.8718 - precision: 0.8579 - val_loss: 0.3507 - val_binary_accuracy: 0.8481 - val_f1: 0.8504 - val_recall: 0.8578 - val_precision: 0.8443\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3177 - binary_accuracy: 0.8564 - f1: 0.8543 - recall: 0.8504 - precision: 0.8611 - val_loss: 0.3471 - val_binary_accuracy: 0.8540 - val_f1: 0.8591 - val_recall: 0.8844 - val_precision: 0.8359\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3173 - binary_accuracy: 0.8625 - f1: 0.8624 - recall: 0.8693 - precision: 0.8583 - val_loss: 0.3499 - val_binary_accuracy: 0.8508 - val_f1: 0.8490 - val_recall: 0.8321 - val_precision: 0.8676\n",
      "Epoch 11/500\n",
      "1s - loss: 0.3117 - binary_accuracy: 0.8634 - f1: 0.8620 - recall: 0.8605 - precision: 0.8656 - val_loss: 0.3490 - val_binary_accuracy: 0.8508 - val_f1: 0.8541 - val_recall: 0.8668 - val_precision: 0.8428\n",
      "Epoch 12/500\n",
      "1s - loss: 0.3096 - binary_accuracy: 0.8636 - f1: 0.8631 - recall: 0.8665 - precision: 0.8621 - val_loss: 0.3643 - val_binary_accuracy: 0.8476 - val_f1: 0.8418 - val_recall: 0.8043 - val_precision: 0.8838\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3101 - binary_accuracy: 0.8651 - f1: 0.8645 - recall: 0.8678 - precision: 0.8630 - val_loss: 0.3452 - val_binary_accuracy: 0.8517 - val_f1: 0.8540 - val_recall: 0.8605 - val_precision: 0.8483\n",
      "Epoch 14/500\n",
      "1s - loss: 0.3090 - binary_accuracy: 0.8626 - f1: 0.8612 - recall: 0.8629 - precision: 0.8606 - val_loss: 0.3528 - val_binary_accuracy: 0.8449 - val_f1: 0.8503 - val_recall: 0.8738 - val_precision: 0.8290\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3065 - binary_accuracy: 0.8656 - f1: 0.8650 - recall: 0.8684 - precision: 0.8634 - val_loss: 0.3469 - val_binary_accuracy: 0.8562 - val_f1: 0.8557 - val_recall: 0.8462 - val_precision: 0.8661\n",
      "Epoch 16/500\n",
      "1s - loss: 0.3086 - binary_accuracy: 0.8645 - f1: 0.8638 - recall: 0.8653 - precision: 0.8646 - val_loss: 0.3490 - val_binary_accuracy: 0.8522 - val_f1: 0.8585 - val_recall: 0.8894 - val_precision: 0.8308\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3058 - binary_accuracy: 0.8688 - f1: 0.8678 - recall: 0.8688 - precision: 0.8690 - val_loss: 0.3492 - val_binary_accuracy: 0.8526 - val_f1: 0.8560 - val_recall: 0.8702 - val_precision: 0.8433\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3029 - binary_accuracy: 0.8671 - f1: 0.8669 - recall: 0.8707 - precision: 0.8641 - val_loss: 0.3480 - val_binary_accuracy: 0.8558 - val_f1: 0.8562 - val_recall: 0.8524 - val_precision: 0.8609\n",
      "Epoch 19/500\n",
      "1s - loss: 0.3021 - binary_accuracy: 0.8697 - f1: 0.8688 - recall: 0.8695 - precision: 0.8701 - val_loss: 0.3541 - val_binary_accuracy: 0.8467 - val_f1: 0.8519 - val_recall: 0.8755 - val_precision: 0.8307\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3025 - binary_accuracy: 0.8667 - f1: 0.8664 - recall: 0.8723 - precision: 0.8631 - val_loss: 0.3520 - val_binary_accuracy: 0.8522 - val_f1: 0.8494 - val_recall: 0.8267 - val_precision: 0.8741\n",
      "Epoch 21/500\n",
      "1s - loss: 0.3001 - binary_accuracy: 0.8681 - f1: 0.8669 - recall: 0.8701 - precision: 0.8661 - val_loss: 0.3460 - val_binary_accuracy: 0.8553 - val_f1: 0.8550 - val_recall: 0.8472 - val_precision: 0.8639\n",
      "Epoch 22/500\n",
      "0s - loss: 0.2995 - binary_accuracy: 0.8683 - f1: 0.8666 - recall: 0.8662 - precision: 0.8700 - val_loss: 0.3433 - val_binary_accuracy: 0.8590 - val_f1: 0.8614 - val_recall: 0.8705 - val_precision: 0.8537\n",
      "Epoch 23/500\n",
      "1s - loss: 0.2965 - binary_accuracy: 0.8723 - f1: 0.8721 - recall: 0.8750 - precision: 0.8703 - val_loss: 0.3502 - val_binary_accuracy: 0.8531 - val_f1: 0.8598 - val_recall: 0.8944 - val_precision: 0.8291\n",
      "Epoch 24/500\n",
      "1s - loss: 0.3056 - binary_accuracy: 0.8639 - f1: 0.8633 - recall: 0.8682 - precision: 0.8637 - val_loss: 0.3447 - val_binary_accuracy: 0.8580 - val_f1: 0.8586 - val_recall: 0.8560 - val_precision: 0.8623\n",
      "Epoch 25/500\n",
      "0s - loss: 0.2984 - binary_accuracy: 0.8686 - f1: 0.8677 - recall: 0.8706 - precision: 0.8675 - val_loss: 0.3481 - val_binary_accuracy: 0.8558 - val_f1: 0.8554 - val_recall: 0.8468 - val_precision: 0.8652\n",
      "Epoch 26/500\n",
      "0s - loss: 0.2940 - binary_accuracy: 0.8714 - f1: 0.8703 - recall: 0.8720 - precision: 0.8709 - val_loss: 0.3487 - val_binary_accuracy: 0.8531 - val_f1: 0.8597 - val_recall: 0.8929 - val_precision: 0.8305\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2938 - binary_accuracy: 0.8715 - f1: 0.8711 - recall: 0.8756 - precision: 0.8687 - val_loss: 0.3467 - val_binary_accuracy: 0.8513 - val_f1: 0.8498 - val_recall: 0.8347 - val_precision: 0.8664\n",
      "Epoch 28/500\n",
      "1s - loss: 0.2941 - binary_accuracy: 0.8725 - f1: 0.8716 - recall: 0.8757 - precision: 0.8693 - val_loss: 0.3470 - val_binary_accuracy: 0.8540 - val_f1: 0.8535 - val_recall: 0.8438 - val_precision: 0.8644\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2886 - binary_accuracy: 0.8751 - f1: 0.8744 - recall: 0.8764 - precision: 0.8741 - val_loss: 0.3483 - val_binary_accuracy: 0.8553 - val_f1: 0.8588 - val_recall: 0.8731 - val_precision: 0.8463\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2937 - binary_accuracy: 0.8689 - f1: 0.8687 - recall: 0.8720 - precision: 0.8671 - val_loss: 0.3467 - val_binary_accuracy: 0.8504 - val_f1: 0.8563 - val_recall: 0.8854 - val_precision: 0.8302\n",
      "Epoch 31/500\n",
      "1s - loss: 0.2943 - binary_accuracy: 0.8708 - f1: 0.8700 - recall: 0.8736 - precision: 0.8692 - val_loss: 0.3471 - val_binary_accuracy: 0.8535 - val_f1: 0.8581 - val_recall: 0.8784 - val_precision: 0.8395\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2887 - binary_accuracy: 0.8731 - f1: 0.8726 - recall: 0.8769 - precision: 0.8700 - val_loss: 0.3507 - val_binary_accuracy: 0.8576 - val_f1: 0.8564 - val_recall: 0.8419 - val_precision: 0.8722\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2910 - binary_accuracy: 0.8737 - f1: 0.8736 - recall: 0.8777 - precision: 0.8725 - val_loss: 0.3517 - val_binary_accuracy: 0.8531 - val_f1: 0.8494 - val_recall: 0.8222 - val_precision: 0.8792\n",
      "Epoch 34/500\n",
      "1s - loss: 0.2865 - binary_accuracy: 0.8718 - f1: 0.8706 - recall: 0.8719 - precision: 0.8709 - val_loss: 0.3476 - val_binary_accuracy: 0.8517 - val_f1: 0.8576 - val_recall: 0.8866 - val_precision: 0.8317\n",
      "Epoch 35/500\n",
      "1s - loss: 0.2861 - binary_accuracy: 0.8731 - f1: 0.8727 - recall: 0.8791 - precision: 0.8693 - val_loss: 0.3497 - val_binary_accuracy: 0.8540 - val_f1: 0.8565 - val_recall: 0.8643 - val_precision: 0.8498\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2918 - binary_accuracy: 0.8707 - f1: 0.8689 - recall: 0.8689 - precision: 0.8725 - val_loss: 0.3515 - val_binary_accuracy: 0.8513 - val_f1: 0.8590 - val_recall: 0.9005 - val_precision: 0.8222\n",
      "Epoch 37/500\n",
      "1s - loss: 0.2812 - binary_accuracy: 0.8772 - f1: 0.8775 - recall: 0.8834 - precision: 0.8730 - val_loss: 0.3448 - val_binary_accuracy: 0.8594 - val_f1: 0.8592 - val_recall: 0.8515 - val_precision: 0.8680\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2844 - binary_accuracy: 0.8729 - f1: 0.8720 - recall: 0.8718 - precision: 0.8757 - val_loss: 0.3451 - val_binary_accuracy: 0.8544 - val_f1: 0.8595 - val_recall: 0.8837 - val_precision: 0.8373\n",
      "Epoch 39/500\n",
      "1s - loss: 0.2825 - binary_accuracy: 0.8763 - f1: 0.8761 - recall: 0.8825 - precision: 0.8717 - val_loss: 0.3621 - val_binary_accuracy: 0.8567 - val_f1: 0.8533 - val_recall: 0.8276 - val_precision: 0.8815\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2823 - binary_accuracy: 0.8750 - f1: 0.8749 - recall: 0.8800 - precision: 0.8709 - val_loss: 0.3550 - val_binary_accuracy: 0.8558 - val_f1: 0.8544 - val_recall: 0.8383 - val_precision: 0.8721\n",
      "Epoch 41/500\n",
      "1s - loss: 0.2774 - binary_accuracy: 0.8790 - f1: 0.8785 - recall: 0.8817 - precision: 0.8771 - val_loss: 0.3477 - val_binary_accuracy: 0.8580 - val_f1: 0.8586 - val_recall: 0.8551 - val_precision: 0.8630\n",
      "Epoch 42/500\n",
      "1s - loss: 0.2755 - binary_accuracy: 0.8770 - f1: 0.8766 - recall: 0.8815 - precision: 0.8737 - val_loss: 0.3475 - val_binary_accuracy: 0.8549 - val_f1: 0.8557 - val_recall: 0.8542 - val_precision: 0.8582\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2776 - binary_accuracy: 0.8766 - f1: 0.8765 - recall: 0.8807 - precision: 0.8749 - val_loss: 0.3551 - val_binary_accuracy: 0.8522 - val_f1: 0.8525 - val_recall: 0.8510 - val_precision: 0.8546\n",
      "Epoch 44/500\n",
      "1s - loss: 0.2800 - binary_accuracy: 0.8766 - f1: 0.8762 - recall: 0.8806 - precision: 0.8741 - val_loss: 0.3524 - val_binary_accuracy: 0.8567 - val_f1: 0.8602 - val_recall: 0.8748 - val_precision: 0.8470\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2780 - binary_accuracy: 0.8780 - f1: 0.8773 - recall: 0.8792 - precision: 0.8777 - val_loss: 0.3453 - val_binary_accuracy: 0.8535 - val_f1: 0.8591 - val_recall: 0.8871 - val_precision: 0.8335\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2777 - binary_accuracy: 0.8767 - f1: 0.8766 - recall: 0.8835 - precision: 0.8713 - val_loss: 0.3566 - val_binary_accuracy: 0.8526 - val_f1: 0.8505 - val_recall: 0.8311 - val_precision: 0.8721\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2777 - binary_accuracy: 0.8785 - f1: 0.8782 - recall: 0.8845 - precision: 0.8739 - val_loss: 0.3565 - val_binary_accuracy: 0.8526 - val_f1: 0.8491 - val_recall: 0.8228 - val_precision: 0.8776\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2735 - binary_accuracy: 0.8808 - f1: 0.8801 - recall: 0.8828 - precision: 0.8794 - val_loss: 0.3432 - val_binary_accuracy: 0.8612 - val_f1: 0.8652 - val_recall: 0.8839 - val_precision: 0.8483\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2697 - binary_accuracy: 0.8816 - f1: 0.8812 - recall: 0.8882 - precision: 0.8759 - val_loss: 0.3475 - val_binary_accuracy: 0.8540 - val_f1: 0.8543 - val_recall: 0.8483 - val_precision: 0.8612\n",
      "Epoch 50/500\n",
      "1s - loss: 0.2658 - binary_accuracy: 0.8847 - f1: 0.8843 - recall: 0.8861 - precision: 0.8834 - val_loss: 0.3435 - val_binary_accuracy: 0.8558 - val_f1: 0.8590 - val_recall: 0.8712 - val_precision: 0.8480\n",
      "Epoch 51/500\n",
      "1s - loss: 0.2720 - binary_accuracy: 0.8797 - f1: 0.8790 - recall: 0.8842 - precision: 0.8773 - val_loss: 0.3572 - val_binary_accuracy: 0.8608 - val_f1: 0.8577 - val_recall: 0.8327 - val_precision: 0.8848\n",
      "Epoch 52/500\n",
      "1s - loss: 0.2771 - binary_accuracy: 0.8767 - f1: 0.8764 - recall: 0.8823 - precision: 0.8732 - val_loss: 0.3430 - val_binary_accuracy: 0.8576 - val_f1: 0.8574 - val_recall: 0.8496 - val_precision: 0.8658\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2671 - binary_accuracy: 0.8837 - f1: 0.8828 - recall: 0.8858 - precision: 0.8816 - val_loss: 0.3713 - val_binary_accuracy: 0.8458 - val_f1: 0.8484 - val_recall: 0.8545 - val_precision: 0.8433\n",
      "Epoch 54/500\n",
      "1s - loss: 0.2639 - binary_accuracy: 0.8832 - f1: 0.8826 - recall: 0.8840 - precision: 0.8826 - val_loss: 0.3426 - val_binary_accuracy: 0.8580 - val_f1: 0.8602 - val_recall: 0.8675 - val_precision: 0.8540\n",
      "Epoch 55/500\n",
      "0s - loss: 0.2608 - binary_accuracy: 0.8862 - f1: 0.8865 - recall: 0.8955 - precision: 0.8789 - val_loss: 0.3465 - val_binary_accuracy: 0.8635 - val_f1: 0.8639 - val_recall: 0.8604 - val_precision: 0.8686\n",
      "Epoch 56/500\n",
      "1s - loss: 0.2590 - binary_accuracy: 0.8888 - f1: 0.8884 - recall: 0.8945 - precision: 0.8837 - val_loss: 0.3453 - val_binary_accuracy: 0.8608 - val_f1: 0.8591 - val_recall: 0.8433 - val_precision: 0.8765\n",
      "Epoch 57/500\n",
      "0s - loss: 0.2580 - binary_accuracy: 0.8863 - f1: 0.8858 - recall: 0.8894 - precision: 0.8835 - val_loss: 0.3511 - val_binary_accuracy: 0.8603 - val_f1: 0.8581 - val_recall: 0.8375 - val_precision: 0.8807\n",
      "Epoch 58/500\n",
      "1s - loss: 0.2619 - binary_accuracy: 0.8867 - f1: 0.8860 - recall: 0.8868 - precision: 0.8868 - val_loss: 0.3445 - val_binary_accuracy: 0.8594 - val_f1: 0.8617 - val_recall: 0.8709 - val_precision: 0.8535\n",
      "Epoch 59/500\n",
      "0s - loss: 0.2606 - binary_accuracy: 0.8834 - f1: 0.8828 - recall: 0.8861 - precision: 0.8808 - val_loss: 0.3447 - val_binary_accuracy: 0.8590 - val_f1: 0.8649 - val_recall: 0.8963 - val_precision: 0.8369\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2564 - binary_accuracy: 0.8878 - f1: 0.8876 - recall: 0.8911 - precision: 0.8858 - val_loss: 0.3443 - val_binary_accuracy: 0.8621 - val_f1: 0.8636 - val_recall: 0.8653 - val_precision: 0.8627\n",
      "Epoch 61/500\n",
      "1s - loss: 0.2551 - binary_accuracy: 0.8876 - f1: 0.8875 - recall: 0.8946 - precision: 0.8818 - val_loss: 0.3438 - val_binary_accuracy: 0.8585 - val_f1: 0.8584 - val_recall: 0.8522 - val_precision: 0.8651\n",
      "Epoch 62/500\n",
      "1s - loss: 0.2518 - binary_accuracy: 0.8906 - f1: 0.8902 - recall: 0.8934 - precision: 0.8885 - val_loss: 0.3421 - val_binary_accuracy: 0.8608 - val_f1: 0.8635 - val_recall: 0.8725 - val_precision: 0.8556\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2513 - binary_accuracy: 0.8904 - f1: 0.8898 - recall: 0.8945 - precision: 0.8871 - val_loss: 0.3490 - val_binary_accuracy: 0.8535 - val_f1: 0.8610 - val_recall: 0.8999 - val_precision: 0.8263\n",
      "Epoch 64/500\n",
      "1s - loss: 0.2522 - binary_accuracy: 0.8900 - f1: 0.8899 - recall: 0.8966 - precision: 0.8856 - val_loss: 0.3719 - val_binary_accuracy: 0.8508 - val_f1: 0.8432 - val_recall: 0.7967 - val_precision: 0.8962\n",
      "Epoch 65/500\n",
      "1s - loss: 0.2478 - binary_accuracy: 0.8932 - f1: 0.8925 - recall: 0.8961 - precision: 0.8906 - val_loss: 0.3644 - val_binary_accuracy: 0.8612 - val_f1: 0.8590 - val_recall: 0.8383 - val_precision: 0.8815\n",
      "Epoch 66/500\n",
      "0s - loss: 0.2500 - binary_accuracy: 0.8922 - f1: 0.8916 - recall: 0.8942 - precision: 0.8909 - val_loss: 0.3419 - val_binary_accuracy: 0.8580 - val_f1: 0.8620 - val_recall: 0.8794 - val_precision: 0.8463\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2468 - binary_accuracy: 0.8933 - f1: 0.8934 - recall: 0.8986 - precision: 0.8902 - val_loss: 0.3594 - val_binary_accuracy: 0.8576 - val_f1: 0.8628 - val_recall: 0.8906 - val_precision: 0.8375\n",
      "Epoch 68/500\n",
      "0s - loss: 0.2514 - binary_accuracy: 0.8905 - f1: 0.8904 - recall: 0.8977 - precision: 0.8857 - val_loss: 0.3564 - val_binary_accuracy: 0.8522 - val_f1: 0.8613 - val_recall: 0.9119 - val_precision: 0.8168\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2498 - binary_accuracy: 0.8903 - f1: 0.8892 - recall: 0.8920 - precision: 0.8893 - val_loss: 0.3436 - val_binary_accuracy: 0.8657 - val_f1: 0.8684 - val_recall: 0.8793 - val_precision: 0.8585\n",
      "Epoch 70/500\n",
      "1s - loss: 0.2441 - binary_accuracy: 0.8919 - f1: 0.8908 - recall: 0.8951 - precision: 0.8885 - val_loss: 0.3498 - val_binary_accuracy: 0.8540 - val_f1: 0.8512 - val_recall: 0.8291 - val_precision: 0.8751\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2425 - binary_accuracy: 0.8945 - f1: 0.8941 - recall: 0.8973 - precision: 0.8927 - val_loss: 0.3570 - val_binary_accuracy: 0.8571 - val_f1: 0.8609 - val_recall: 0.8775 - val_precision: 0.8459\n",
      "Epoch 72/500\n",
      "1s - loss: 0.2423 - binary_accuracy: 0.8947 - f1: 0.8939 - recall: 0.8952 - precision: 0.8943 - val_loss: 0.3507 - val_binary_accuracy: 0.8558 - val_f1: 0.8614 - val_recall: 0.8908 - val_precision: 0.8349\n",
      "Epoch 73/500\n",
      "1s - loss: 0.2364 - binary_accuracy: 0.9015 - f1: 0.9013 - recall: 0.9044 - precision: 0.8994 - val_loss: 0.3534 - val_binary_accuracy: 0.8531 - val_f1: 0.8602 - val_recall: 0.8993 - val_precision: 0.8254\n",
      "Epoch 74/500\n",
      "0s - loss: 0.2362 - binary_accuracy: 0.8988 - f1: 0.8986 - recall: 0.9020 - precision: 0.8977 - val_loss: 0.3463 - val_binary_accuracy: 0.8585 - val_f1: 0.8608 - val_recall: 0.8669 - val_precision: 0.8557\n",
      "Epoch 75/500\n",
      "1s - loss: 0.2325 - binary_accuracy: 0.9015 - f1: 0.9016 - recall: 0.9074 - precision: 0.8966 - val_loss: 0.3466 - val_binary_accuracy: 0.8580 - val_f1: 0.8576 - val_recall: 0.8496 - val_precision: 0.8662\n",
      "Epoch 76/500\n",
      "1s - loss: 0.2305 - binary_accuracy: 0.9022 - f1: 0.9016 - recall: 0.9035 - precision: 0.9004 - val_loss: 0.3524 - val_binary_accuracy: 0.8522 - val_f1: 0.8546 - val_recall: 0.8613 - val_precision: 0.8487\n",
      "Epoch 77/500\n",
      "1s - loss: 0.2344 - binary_accuracy: 0.8994 - f1: 0.8985 - recall: 0.8992 - precision: 0.8998 - val_loss: 0.3564 - val_binary_accuracy: 0.8535 - val_f1: 0.8590 - val_recall: 0.8856 - val_precision: 0.8347\n",
      "Epoch 78/500\n",
      "1s - loss: 0.2349 - binary_accuracy: 0.9010 - f1: 0.9011 - recall: 0.9057 - precision: 0.8987 - val_loss: 0.3592 - val_binary_accuracy: 0.8490 - val_f1: 0.8524 - val_recall: 0.8640 - val_precision: 0.8415\n",
      "Epoch 79/500\n",
      "1s - loss: 0.2295 - binary_accuracy: 0.9010 - f1: 0.9004 - recall: 0.9029 - precision: 0.8992 - val_loss: 0.3601 - val_binary_accuracy: 0.8594 - val_f1: 0.8605 - val_recall: 0.8598 - val_precision: 0.8619\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2255 - binary_accuracy: 0.9047 - f1: 0.9042 - recall: 0.9074 - precision: 0.9022 - val_loss: 0.3587 - val_binary_accuracy: 0.8562 - val_f1: 0.8572 - val_recall: 0.8591 - val_precision: 0.8560\n",
      "Epoch 81/500\n",
      "1s - loss: 0.2339 - binary_accuracy: 0.9008 - f1: 0.9003 - recall: 0.9037 - precision: 0.8992 - val_loss: 0.3525 - val_binary_accuracy: 0.8590 - val_f1: 0.8658 - val_recall: 0.9025 - val_precision: 0.8329\n",
      "Epoch 82/500\n",
      "1s - loss: 0.2220 - binary_accuracy: 0.9071 - f1: 0.9068 - recall: 0.9099 - precision: 0.9053 - val_loss: 0.3572 - val_binary_accuracy: 0.8653 - val_f1: 0.8679 - val_recall: 0.8791 - val_precision: 0.8576\n",
      "Epoch 83/500\n",
      "1s - loss: 0.2255 - binary_accuracy: 0.9026 - f1: 0.9017 - recall: 0.9035 - precision: 0.9017 - val_loss: 0.3629 - val_binary_accuracy: 0.8562 - val_f1: 0.8561 - val_recall: 0.8480 - val_precision: 0.8651\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2225 - binary_accuracy: 0.9063 - f1: 0.9050 - recall: 0.9037 - precision: 0.9073 - val_loss: 0.3523 - val_binary_accuracy: 0.8639 - val_f1: 0.8661 - val_recall: 0.8732 - val_precision: 0.8600\n",
      "Epoch 85/500\n",
      "1s - loss: 0.2222 - binary_accuracy: 0.9060 - f1: 0.9059 - recall: 0.9125 - precision: 0.9016 - val_loss: 0.3579 - val_binary_accuracy: 0.8567 - val_f1: 0.8558 - val_recall: 0.8427 - val_precision: 0.8698\n",
      "Epoch 86/500\n",
      "0s - loss: 0.2146 - binary_accuracy: 0.9112 - f1: 0.9104 - recall: 0.9120 - precision: 0.9100 - val_loss: 0.3511 - val_binary_accuracy: 0.8599 - val_f1: 0.8627 - val_recall: 0.8751 - val_precision: 0.8520\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2132 - binary_accuracy: 0.9086 - f1: 0.9077 - recall: 0.9071 - precision: 0.9100 - val_loss: 0.3622 - val_binary_accuracy: 0.8531 - val_f1: 0.8583 - val_recall: 0.8829 - val_precision: 0.8357\n",
      "Epoch 88/500\n",
      "0s - loss: 0.2151 - binary_accuracy: 0.9095 - f1: 0.9087 - recall: 0.9092 - precision: 0.9092 - val_loss: 0.3549 - val_binary_accuracy: 0.8531 - val_f1: 0.8539 - val_recall: 0.8502 - val_precision: 0.8586\n",
      "Epoch 89/500\n",
      "0s - loss: 0.2096 - binary_accuracy: 0.9112 - f1: 0.9108 - recall: 0.9137 - precision: 0.9088 - val_loss: 0.3668 - val_binary_accuracy: 0.8590 - val_f1: 0.8571 - val_recall: 0.8398 - val_precision: 0.8759\n",
      "Epoch 90/500\n",
      "0s - loss: 0.2083 - binary_accuracy: 0.9134 - f1: 0.9128 - recall: 0.9138 - precision: 0.9132 - val_loss: 0.3800 - val_binary_accuracy: 0.8454 - val_f1: 0.8409 - val_recall: 0.8112 - val_precision: 0.8735\n",
      "Epoch 91/500\n",
      "0s - loss: 0.2104 - binary_accuracy: 0.9127 - f1: 0.9124 - recall: 0.9142 - precision: 0.9119 - val_loss: 0.3611 - val_binary_accuracy: 0.8504 - val_f1: 0.8564 - val_recall: 0.8853 - val_precision: 0.8303\n",
      "Epoch 92/500\n",
      "1s - loss: 0.2141 - binary_accuracy: 0.9100 - f1: 0.9094 - recall: 0.9092 - precision: 0.9124 - val_loss: 0.3623 - val_binary_accuracy: 0.8630 - val_f1: 0.8673 - val_recall: 0.8894 - val_precision: 0.8470\n",
      "Epoch 93/500\n",
      "1s - loss: 0.2087 - binary_accuracy: 0.9128 - f1: 0.9124 - recall: 0.9159 - precision: 0.9111 - val_loss: 0.3572 - val_binary_accuracy: 0.8585 - val_f1: 0.8615 - val_recall: 0.8746 - val_precision: 0.8497\n",
      "Epoch 94/500\n",
      "0s - loss: 0.2071 - binary_accuracy: 0.9132 - f1: 0.9125 - recall: 0.9113 - precision: 0.9149 - val_loss: 0.3671 - val_binary_accuracy: 0.8508 - val_f1: 0.8581 - val_recall: 0.8957 - val_precision: 0.8242\n",
      "Epoch 95/500\n",
      "1s - loss: 0.2040 - binary_accuracy: 0.9150 - f1: 0.9147 - recall: 0.9173 - precision: 0.9131 - val_loss: 0.3621 - val_binary_accuracy: 0.8590 - val_f1: 0.8588 - val_recall: 0.8516 - val_precision: 0.8668\n",
      "Epoch 96/500\n",
      "1s - loss: 0.2042 - binary_accuracy: 0.9134 - f1: 0.9127 - recall: 0.9119 - precision: 0.9145 - val_loss: 0.3704 - val_binary_accuracy: 0.8454 - val_f1: 0.8530 - val_recall: 0.8882 - val_precision: 0.8214\n",
      "Epoch 97/500\n",
      "1s - loss: 0.2020 - binary_accuracy: 0.9180 - f1: 0.9175 - recall: 0.9163 - precision: 0.9200 - val_loss: 0.3664 - val_binary_accuracy: 0.8590 - val_f1: 0.8628 - val_recall: 0.8803 - val_precision: 0.8469\n",
      "Epoch 98/500\n",
      "0s - loss: 0.1987 - binary_accuracy: 0.9196 - f1: 0.9194 - recall: 0.9237 - precision: 0.9172 - val_loss: 0.3812 - val_binary_accuracy: 0.8472 - val_f1: 0.8414 - val_recall: 0.8049 - val_precision: 0.8823\n",
      "Epoch 99/500\n",
      "1s - loss: 0.1986 - binary_accuracy: 0.9191 - f1: 0.9182 - recall: 0.9132 - precision: 0.9244 - val_loss: 0.3651 - val_binary_accuracy: 0.8580 - val_f1: 0.8619 - val_recall: 0.8790 - val_precision: 0.8461\n",
      "Epoch 100/500\n",
      "1s - loss: 0.1926 - binary_accuracy: 0.9192 - f1: 0.9186 - recall: 0.9208 - precision: 0.9178 - val_loss: 0.3776 - val_binary_accuracy: 0.8490 - val_f1: 0.8509 - val_recall: 0.8549 - val_precision: 0.8478\n",
      "Epoch 101/500\n",
      "1s - loss: 0.1937 - binary_accuracy: 0.9182 - f1: 0.9179 - recall: 0.9222 - precision: 0.9149 - val_loss: 0.3731 - val_binary_accuracy: 0.8621 - val_f1: 0.8630 - val_recall: 0.8608 - val_precision: 0.8657\n",
      "Epoch 102/500\n",
      "1s - loss: 0.1967 - binary_accuracy: 0.9189 - f1: 0.9183 - recall: 0.9211 - precision: 0.9180 - val_loss: 0.3760 - val_binary_accuracy: 0.8635 - val_f1: 0.8631 - val_recall: 0.8564 - val_precision: 0.8707\n",
      "Epoch 103/500\n",
      "1s - loss: 0.1912 - binary_accuracy: 0.9224 - f1: 0.9219 - recall: 0.9210 - precision: 0.9234 - val_loss: 0.3793 - val_binary_accuracy: 0.8386 - val_f1: 0.8386 - val_recall: 0.8330 - val_precision: 0.8449\n",
      "Epoch 104/500\n",
      "1s - loss: 0.1917 - binary_accuracy: 0.9223 - f1: 0.9215 - recall: 0.9188 - precision: 0.9253 - val_loss: 0.3772 - val_binary_accuracy: 0.8540 - val_f1: 0.8555 - val_recall: 0.8583 - val_precision: 0.8533\n",
      "Epoch 105/500\n",
      "0s - loss: 0.1838 - binary_accuracy: 0.9254 - f1: 0.9247 - recall: 0.9254 - precision: 0.9250 - val_loss: 0.3847 - val_binary_accuracy: 0.8481 - val_f1: 0.8446 - val_recall: 0.8207 - val_precision: 0.8711\n",
      "Epoch 106/500\n",
      "0s - loss: 0.1941 - binary_accuracy: 0.9182 - f1: 0.9171 - recall: 0.9159 - precision: 0.9204 - val_loss: 0.3883 - val_binary_accuracy: 0.8621 - val_f1: 0.8655 - val_recall: 0.8795 - val_precision: 0.8527\n",
      "Epoch 107/500\n",
      "0s - loss: 0.1877 - binary_accuracy: 0.9224 - f1: 0.9217 - recall: 0.9224 - precision: 0.9227 - val_loss: 0.3823 - val_binary_accuracy: 0.8495 - val_f1: 0.8491 - val_recall: 0.8405 - val_precision: 0.8584\n",
      "Epoch 108/500\n",
      "1s - loss: 0.1862 - binary_accuracy: 0.9226 - f1: 0.9221 - recall: 0.9221 - precision: 0.9238 - val_loss: 0.3715 - val_binary_accuracy: 0.8513 - val_f1: 0.8517 - val_recall: 0.8492 - val_precision: 0.8554\n",
      "Epoch 109/500\n",
      "0s - loss: 0.1773 - binary_accuracy: 0.9314 - f1: 0.9309 - recall: 0.9299 - precision: 0.9328 - val_loss: 0.3862 - val_binary_accuracy: 0.8427 - val_f1: 0.8461 - val_recall: 0.8569 - val_precision: 0.8368\n",
      "Epoch 110/500\n",
      "0s - loss: 0.1811 - binary_accuracy: 0.9275 - f1: 0.9266 - recall: 0.9247 - precision: 0.9291 - val_loss: 0.3855 - val_binary_accuracy: 0.8522 - val_f1: 0.8582 - val_recall: 0.8857 - val_precision: 0.8333\n",
      "Epoch 111/500\n",
      "0s - loss: 0.1788 - binary_accuracy: 0.9282 - f1: 0.9277 - recall: 0.9272 - precision: 0.9294 - val_loss: 0.3849 - val_binary_accuracy: 0.8449 - val_f1: 0.8523 - val_recall: 0.8860 - val_precision: 0.8220\n",
      "Epoch 112/500\n",
      "0s - loss: 0.1766 - binary_accuracy: 0.9311 - f1: 0.9307 - recall: 0.9332 - precision: 0.9293 - val_loss: 0.3772 - val_binary_accuracy: 0.8562 - val_f1: 0.8578 - val_recall: 0.8610 - val_precision: 0.8552\n",
      "Epoch 113/500\n",
      "0s - loss: 0.1747 - binary_accuracy: 0.9306 - f1: 0.9300 - recall: 0.9293 - precision: 0.9323 - val_loss: 0.3860 - val_binary_accuracy: 0.8454 - val_f1: 0.8477 - val_recall: 0.8560 - val_precision: 0.8401\n",
      "Epoch 114/500\n",
      "0s - loss: 0.1709 - binary_accuracy: 0.9307 - f1: 0.9306 - recall: 0.9340 - precision: 0.9286 - val_loss: 0.3888 - val_binary_accuracy: 0.8522 - val_f1: 0.8535 - val_recall: 0.8564 - val_precision: 0.8516\n",
      "Epoch 115/500\n",
      "0s - loss: 0.1763 - binary_accuracy: 0.9263 - f1: 0.9256 - recall: 0.9246 - precision: 0.9289 - val_loss: 0.3930 - val_binary_accuracy: 0.8576 - val_f1: 0.8575 - val_recall: 0.8511 - val_precision: 0.8647\n",
      "Epoch 116/500\n",
      "0s - loss: 0.1690 - binary_accuracy: 0.9332 - f1: 0.9323 - recall: 0.9315 - precision: 0.9338 - val_loss: 0.3890 - val_binary_accuracy: 0.8526 - val_f1: 0.8538 - val_recall: 0.8531 - val_precision: 0.8553\n",
      "Epoch 117/500\n",
      "0s - loss: 0.1695 - binary_accuracy: 0.9344 - f1: 0.9338 - recall: 0.9308 - precision: 0.9375 - val_loss: 0.3955 - val_binary_accuracy: 0.8585 - val_f1: 0.8608 - val_recall: 0.8690 - val_precision: 0.8533\n",
      "1984/2212 [=========================>....] - ETA: 0stn = 4036, fp = 305, fn = 264, tp = 4043\n",
      "y_pred: 0 = 4300 | 1 = 4348\n",
      "y_true: 0 = 4341 | 1 = 4307\n",
      "acc=0.9342|precision=0.9299|recall=0.9387|f1=0.9343|auc=0.9841|aupr=0.9852|pos_acc=0.9387|neg_acc=0.9386\n",
      "tn = 922, fp = 167, fn = 146, tp = 977\n",
      "y_pred: 0 = 1068 | 1 = 1144\n",
      "y_true: 0 = 1089 | 1 = 1123\n",
      "acc=0.8585|precision=0.8540|recall=0.8700|f1=0.8619|auc=0.9317|aupr=0.9283|pos_acc=0.8700|neg_acc=0.8633\n",
      "----------------------- Fold =  3\n",
      "Train on 8793 samples, validate on 2067 samples\n",
      "Epoch 1/500\n",
      "3s - loss: 0.4046 - binary_accuracy: 0.8131 - f1: 0.7967 - recall: 0.7787 - precision: 0.8417 - val_loss: 0.3571 - val_binary_accuracy: 0.8418 - val_f1: 0.8386 - val_recall: 0.8590 - val_precision: 0.8216\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3516 - binary_accuracy: 0.8446 - f1: 0.8445 - recall: 0.8448 - precision: 0.8479 - val_loss: 0.3453 - val_binary_accuracy: 0.8447 - val_f1: 0.8373 - val_recall: 0.8367 - val_precision: 0.8402\n",
      "Epoch 3/500\n",
      "0s - loss: 0.3387 - binary_accuracy: 0.8520 - f1: 0.8522 - recall: 0.8514 - precision: 0.8542 - val_loss: 0.3363 - val_binary_accuracy: 0.8505 - val_f1: 0.8453 - val_recall: 0.8539 - val_precision: 0.8390\n",
      "Epoch 4/500\n",
      "0s - loss: 0.3359 - binary_accuracy: 0.8539 - f1: 0.8543 - recall: 0.8553 - precision: 0.8554 - val_loss: 0.3573 - val_binary_accuracy: 0.8428 - val_f1: 0.8235 - val_recall: 0.7635 - val_precision: 0.8963\n",
      "Epoch 5/500\n",
      "0s - loss: 0.3319 - binary_accuracy: 0.8557 - f1: 0.8560 - recall: 0.8616 - precision: 0.8541 - val_loss: 0.3496 - val_binary_accuracy: 0.8350 - val_f1: 0.8149 - val_recall: 0.7611 - val_precision: 0.8797\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3261 - binary_accuracy: 0.8589 - f1: 0.8596 - recall: 0.8625 - precision: 0.8576 - val_loss: 0.3378 - val_binary_accuracy: 0.8500 - val_f1: 0.8512 - val_recall: 0.8986 - val_precision: 0.8108\n",
      "Epoch 7/500\n",
      "0s - loss: 0.3264 - binary_accuracy: 0.8555 - f1: 0.8576 - recall: 0.8700 - precision: 0.8487 - val_loss: 0.3341 - val_binary_accuracy: 0.8539 - val_f1: 0.8422 - val_recall: 0.8161 - val_precision: 0.8728\n",
      "Epoch 8/500\n",
      "0s - loss: 0.3239 - binary_accuracy: 0.8567 - f1: 0.8570 - recall: 0.8558 - precision: 0.8602 - val_loss: 0.3307 - val_binary_accuracy: 0.8529 - val_f1: 0.8419 - val_recall: 0.8183 - val_precision: 0.8696\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3240 - binary_accuracy: 0.8578 - f1: 0.8600 - recall: 0.8692 - precision: 0.8538 - val_loss: 0.3342 - val_binary_accuracy: 0.8505 - val_f1: 0.8360 - val_recall: 0.7970 - val_precision: 0.8820\n",
      "Epoch 10/500\n",
      "0s - loss: 0.3240 - binary_accuracy: 0.8576 - f1: 0.8583 - recall: 0.8604 - precision: 0.8589 - val_loss: 0.3338 - val_binary_accuracy: 0.8607 - val_f1: 0.8592 - val_recall: 0.8923 - val_precision: 0.8310\n",
      "Epoch 11/500\n",
      "0s - loss: 0.3186 - binary_accuracy: 0.8613 - f1: 0.8628 - recall: 0.8685 - precision: 0.8592 - val_loss: 0.3245 - val_binary_accuracy: 0.8568 - val_f1: 0.8508 - val_recall: 0.8554 - val_precision: 0.8479\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3161 - binary_accuracy: 0.8625 - f1: 0.8640 - recall: 0.8698 - precision: 0.8602 - val_loss: 0.3315 - val_binary_accuracy: 0.8505 - val_f1: 0.8366 - val_recall: 0.8008 - val_precision: 0.8786\n",
      "Epoch 13/500\n",
      "0s - loss: 0.3169 - binary_accuracy: 0.8616 - f1: 0.8618 - recall: 0.8632 - precision: 0.8636 - val_loss: 0.3271 - val_binary_accuracy: 0.8573 - val_f1: 0.8495 - val_recall: 0.8424 - val_precision: 0.8583\n",
      "Epoch 14/500\n",
      "0s - loss: 0.3223 - binary_accuracy: 0.8585 - f1: 0.8587 - recall: 0.8605 - precision: 0.8612 - val_loss: 0.3333 - val_binary_accuracy: 0.8491 - val_f1: 0.8333 - val_recall: 0.7872 - val_precision: 0.8876\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3128 - binary_accuracy: 0.8646 - f1: 0.8649 - recall: 0.8668 - precision: 0.8641 - val_loss: 0.3269 - val_binary_accuracy: 0.8587 - val_f1: 0.8537 - val_recall: 0.8611 - val_precision: 0.8490\n",
      "Epoch 16/500\n",
      "0s - loss: 0.3137 - binary_accuracy: 0.8640 - f1: 0.8653 - recall: 0.8704 - precision: 0.8618 - val_loss: 0.3331 - val_binary_accuracy: 0.8549 - val_f1: 0.8544 - val_recall: 0.8911 - val_precision: 0.8219\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3134 - binary_accuracy: 0.8634 - f1: 0.8639 - recall: 0.8669 - precision: 0.8630 - val_loss: 0.3279 - val_binary_accuracy: 0.8500 - val_f1: 0.8359 - val_recall: 0.7977 - val_precision: 0.8802\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3084 - binary_accuracy: 0.8667 - f1: 0.8671 - recall: 0.8680 - precision: 0.8675 - val_loss: 0.3213 - val_binary_accuracy: 0.8587 - val_f1: 0.8550 - val_recall: 0.8709 - val_precision: 0.8416\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3075 - binary_accuracy: 0.8675 - f1: 0.8683 - recall: 0.8720 - precision: 0.8657 - val_loss: 0.3278 - val_binary_accuracy: 0.8534 - val_f1: 0.8471 - val_recall: 0.8473 - val_precision: 0.8489\n",
      "Epoch 20/500\n",
      "0s - loss: 0.3109 - binary_accuracy: 0.8641 - f1: 0.8661 - recall: 0.8728 - precision: 0.8609 - val_loss: 0.3201 - val_binary_accuracy: 0.8631 - val_f1: 0.8570 - val_recall: 0.8578 - val_precision: 0.8582\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3057 - binary_accuracy: 0.8664 - f1: 0.8674 - recall: 0.8730 - precision: 0.8635 - val_loss: 0.3283 - val_binary_accuracy: 0.8558 - val_f1: 0.8423 - val_recall: 0.8046 - val_precision: 0.8858\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3133 - binary_accuracy: 0.8630 - f1: 0.8636 - recall: 0.8653 - precision: 0.8653 - val_loss: 0.3283 - val_binary_accuracy: 0.8568 - val_f1: 0.8510 - val_recall: 0.8580 - val_precision: 0.8462\n",
      "Epoch 23/500\n",
      "0s - loss: 0.3064 - binary_accuracy: 0.8665 - f1: 0.8676 - recall: 0.8722 - precision: 0.8652 - val_loss: 0.3205 - val_binary_accuracy: 0.8621 - val_f1: 0.8563 - val_recall: 0.8573 - val_precision: 0.8575\n",
      "Epoch 24/500\n",
      "0s - loss: 0.3029 - binary_accuracy: 0.8680 - f1: 0.8683 - recall: 0.8701 - precision: 0.8679 - val_loss: 0.3192 - val_binary_accuracy: 0.8592 - val_f1: 0.8560 - val_recall: 0.8742 - val_precision: 0.8405\n",
      "Epoch 25/500\n",
      "0s - loss: 0.3021 - binary_accuracy: 0.8658 - f1: 0.8673 - recall: 0.8738 - precision: 0.8621 - val_loss: 0.3313 - val_binary_accuracy: 0.8515 - val_f1: 0.8367 - val_recall: 0.7958 - val_precision: 0.8851\n",
      "Epoch 26/500\n",
      "0s - loss: 0.3055 - binary_accuracy: 0.8660 - f1: 0.8663 - recall: 0.8680 - precision: 0.8679 - val_loss: 0.3226 - val_binary_accuracy: 0.8573 - val_f1: 0.8558 - val_recall: 0.8850 - val_precision: 0.8301\n",
      "Epoch 27/500\n",
      "0s - loss: 0.2987 - binary_accuracy: 0.8717 - f1: 0.8722 - recall: 0.8728 - precision: 0.8730 - val_loss: 0.3195 - val_binary_accuracy: 0.8592 - val_f1: 0.8515 - val_recall: 0.8451 - val_precision: 0.8595\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2983 - binary_accuracy: 0.8689 - f1: 0.8698 - recall: 0.8710 - precision: 0.8698 - val_loss: 0.3145 - val_binary_accuracy: 0.8616 - val_f1: 0.8552 - val_recall: 0.8536 - val_precision: 0.8587\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2984 - binary_accuracy: 0.8711 - f1: 0.8724 - recall: 0.8787 - precision: 0.8678 - val_loss: 0.3189 - val_binary_accuracy: 0.8592 - val_f1: 0.8512 - val_recall: 0.8419 - val_precision: 0.8627\n",
      "Epoch 30/500\n",
      "0s - loss: 0.2970 - binary_accuracy: 0.8698 - f1: 0.8708 - recall: 0.8746 - precision: 0.8689 - val_loss: 0.3177 - val_binary_accuracy: 0.8641 - val_f1: 0.8533 - val_recall: 0.8264 - val_precision: 0.8841\n",
      "Epoch 31/500\n",
      "0s - loss: 0.2951 - binary_accuracy: 0.8722 - f1: 0.8733 - recall: 0.8780 - precision: 0.8701 - val_loss: 0.3139 - val_binary_accuracy: 0.8607 - val_f1: 0.8575 - val_recall: 0.8732 - val_precision: 0.8440\n",
      "Epoch 32/500\n",
      "0s - loss: 0.2982 - binary_accuracy: 0.8710 - f1: 0.8716 - recall: 0.8728 - precision: 0.8733 - val_loss: 0.3166 - val_binary_accuracy: 0.8587 - val_f1: 0.8496 - val_recall: 0.8331 - val_precision: 0.8680\n",
      "Epoch 33/500\n",
      "0s - loss: 0.2935 - binary_accuracy: 0.8721 - f1: 0.8725 - recall: 0.8736 - precision: 0.8729 - val_loss: 0.3198 - val_binary_accuracy: 0.8587 - val_f1: 0.8472 - val_recall: 0.8193 - val_precision: 0.8791\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2916 - binary_accuracy: 0.8742 - f1: 0.8746 - recall: 0.8772 - precision: 0.8735 - val_loss: 0.3109 - val_binary_accuracy: 0.8636 - val_f1: 0.8579 - val_recall: 0.8596 - val_precision: 0.8576\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2916 - binary_accuracy: 0.8740 - f1: 0.8752 - recall: 0.8803 - precision: 0.8722 - val_loss: 0.3149 - val_binary_accuracy: 0.8650 - val_f1: 0.8605 - val_recall: 0.8705 - val_precision: 0.8523\n",
      "Epoch 36/500\n",
      "0s - loss: 0.2883 - binary_accuracy: 0.8756 - f1: 0.8760 - recall: 0.8764 - precision: 0.8770 - val_loss: 0.3150 - val_binary_accuracy: 0.8573 - val_f1: 0.8523 - val_recall: 0.8596 - val_precision: 0.8467\n",
      "Epoch 37/500\n",
      "0s - loss: 0.2866 - binary_accuracy: 0.8751 - f1: 0.8765 - recall: 0.8848 - precision: 0.8698 - val_loss: 0.3163 - val_binary_accuracy: 0.8616 - val_f1: 0.8519 - val_recall: 0.8284 - val_precision: 0.8791\n",
      "Epoch 38/500\n",
      "0s - loss: 0.2864 - binary_accuracy: 0.8765 - f1: 0.8767 - recall: 0.8790 - precision: 0.8764 - val_loss: 0.3208 - val_binary_accuracy: 0.8563 - val_f1: 0.8499 - val_recall: 0.8537 - val_precision: 0.8477\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2841 - binary_accuracy: 0.8783 - f1: 0.8787 - recall: 0.8801 - precision: 0.8786 - val_loss: 0.3216 - val_binary_accuracy: 0.8587 - val_f1: 0.8482 - val_recall: 0.8245 - val_precision: 0.8752\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2861 - binary_accuracy: 0.8760 - f1: 0.8766 - recall: 0.8780 - precision: 0.8767 - val_loss: 0.3218 - val_binary_accuracy: 0.8612 - val_f1: 0.8537 - val_recall: 0.8460 - val_precision: 0.8633\n",
      "Epoch 41/500\n",
      "0s - loss: 0.2836 - binary_accuracy: 0.8771 - f1: 0.8773 - recall: 0.8795 - precision: 0.8770 - val_loss: 0.3135 - val_binary_accuracy: 0.8631 - val_f1: 0.8596 - val_recall: 0.8760 - val_precision: 0.8457\n",
      "Epoch 42/500\n",
      "1s - loss: 0.2777 - binary_accuracy: 0.8809 - f1: 0.8823 - recall: 0.8870 - precision: 0.8783 - val_loss: 0.3182 - val_binary_accuracy: 0.8597 - val_f1: 0.8491 - val_recall: 0.8231 - val_precision: 0.8792\n",
      "Epoch 43/500\n",
      "1s - loss: 0.2778 - binary_accuracy: 0.8797 - f1: 0.8799 - recall: 0.8807 - precision: 0.8802 - val_loss: 0.3126 - val_binary_accuracy: 0.8674 - val_f1: 0.8658 - val_recall: 0.8953 - val_precision: 0.8395\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2766 - binary_accuracy: 0.8802 - f1: 0.8807 - recall: 0.8850 - precision: 0.8776 - val_loss: 0.3145 - val_binary_accuracy: 0.8607 - val_f1: 0.8508 - val_recall: 0.8280 - val_precision: 0.8765\n",
      "Epoch 45/500\n",
      "0s - loss: 0.2765 - binary_accuracy: 0.8796 - f1: 0.8797 - recall: 0.8786 - precision: 0.8826 - val_loss: 0.3147 - val_binary_accuracy: 0.8655 - val_f1: 0.8642 - val_recall: 0.8973 - val_precision: 0.8353\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2762 - binary_accuracy: 0.8813 - f1: 0.8821 - recall: 0.8866 - precision: 0.8793 - val_loss: 0.3160 - val_binary_accuracy: 0.8631 - val_f1: 0.8609 - val_recall: 0.8846 - val_precision: 0.8395\n",
      "Epoch 47/500\n",
      "0s - loss: 0.2822 - binary_accuracy: 0.8760 - f1: 0.8768 - recall: 0.8809 - precision: 0.8749 - val_loss: 0.3186 - val_binary_accuracy: 0.8641 - val_f1: 0.8545 - val_recall: 0.8323 - val_precision: 0.8803\n",
      "Epoch 48/500\n",
      "0s - loss: 0.2747 - binary_accuracy: 0.8829 - f1: 0.8838 - recall: 0.8872 - precision: 0.8828 - val_loss: 0.3271 - val_binary_accuracy: 0.8553 - val_f1: 0.8417 - val_recall: 0.8000 - val_precision: 0.8899\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2765 - binary_accuracy: 0.8806 - f1: 0.8808 - recall: 0.8822 - precision: 0.8817 - val_loss: 0.3104 - val_binary_accuracy: 0.8650 - val_f1: 0.8629 - val_recall: 0.8866 - val_precision: 0.8417\n",
      "Epoch 50/500\n",
      "0s - loss: 0.2694 - binary_accuracy: 0.8820 - f1: 0.8832 - recall: 0.8881 - precision: 0.8795 - val_loss: 0.3192 - val_binary_accuracy: 0.8578 - val_f1: 0.8465 - val_recall: 0.8169 - val_precision: 0.8806\n",
      "Epoch 51/500\n",
      "0s - loss: 0.2710 - binary_accuracy: 0.8825 - f1: 0.8835 - recall: 0.8893 - precision: 0.8804 - val_loss: 0.3097 - val_binary_accuracy: 0.8655 - val_f1: 0.8578 - val_recall: 0.8480 - val_precision: 0.8693\n",
      "Epoch 52/500\n",
      "0s - loss: 0.2668 - binary_accuracy: 0.8879 - f1: 0.8879 - recall: 0.8869 - precision: 0.8903 - val_loss: 0.3241 - val_binary_accuracy: 0.8631 - val_f1: 0.8610 - val_recall: 0.8833 - val_precision: 0.8409\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2704 - binary_accuracy: 0.8817 - f1: 0.8829 - recall: 0.8889 - precision: 0.8794 - val_loss: 0.3170 - val_binary_accuracy: 0.8674 - val_f1: 0.8594 - val_recall: 0.8442 - val_precision: 0.8768\n",
      "Epoch 54/500\n",
      "0s - loss: 0.2695 - binary_accuracy: 0.8875 - f1: 0.8874 - recall: 0.8849 - precision: 0.8938 - val_loss: 0.3125 - val_binary_accuracy: 0.8665 - val_f1: 0.8618 - val_recall: 0.8699 - val_precision: 0.8554\n",
      "Epoch 55/500\n",
      "1s - loss: 0.2618 - binary_accuracy: 0.8899 - f1: 0.8906 - recall: 0.8925 - precision: 0.8900 - val_loss: 0.3074 - val_binary_accuracy: 0.8674 - val_f1: 0.8614 - val_recall: 0.8597 - val_precision: 0.8645\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2589 - binary_accuracy: 0.8901 - f1: 0.8904 - recall: 0.8919 - precision: 0.8903 - val_loss: 0.3125 - val_binary_accuracy: 0.8612 - val_f1: 0.8555 - val_recall: 0.8550 - val_precision: 0.8581\n",
      "Epoch 57/500\n",
      "1s - loss: 0.2627 - binary_accuracy: 0.8870 - f1: 0.8873 - recall: 0.8904 - precision: 0.8858 - val_loss: 0.3231 - val_binary_accuracy: 0.8524 - val_f1: 0.8413 - val_recall: 0.8151 - val_precision: 0.8714\n",
      "Epoch 58/500\n",
      "0s - loss: 0.2632 - binary_accuracy: 0.8858 - f1: 0.8859 - recall: 0.8832 - precision: 0.8904 - val_loss: 0.3110 - val_binary_accuracy: 0.8612 - val_f1: 0.8552 - val_recall: 0.8564 - val_precision: 0.8554\n",
      "Epoch 59/500\n",
      "1s - loss: 0.2572 - binary_accuracy: 0.8895 - f1: 0.8902 - recall: 0.8937 - precision: 0.8876 - val_loss: 0.3111 - val_binary_accuracy: 0.8645 - val_f1: 0.8597 - val_recall: 0.8667 - val_precision: 0.8545\n",
      "Epoch 60/500\n",
      "1s - loss: 0.2550 - binary_accuracy: 0.8898 - f1: 0.8906 - recall: 0.8940 - precision: 0.8891 - val_loss: 0.3171 - val_binary_accuracy: 0.8621 - val_f1: 0.8543 - val_recall: 0.8429 - val_precision: 0.8679\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2556 - binary_accuracy: 0.8912 - f1: 0.8917 - recall: 0.8936 - precision: 0.8916 - val_loss: 0.3449 - val_binary_accuracy: 0.8582 - val_f1: 0.8630 - val_recall: 0.9362 - val_precision: 0.8019\n",
      "Epoch 62/500\n",
      "1s - loss: 0.2612 - binary_accuracy: 0.8896 - f1: 0.8906 - recall: 0.8938 - precision: 0.8891 - val_loss: 0.3172 - val_binary_accuracy: 0.8636 - val_f1: 0.8614 - val_recall: 0.8842 - val_precision: 0.8416\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2595 - binary_accuracy: 0.8879 - f1: 0.8883 - recall: 0.8895 - precision: 0.8898 - val_loss: 0.3288 - val_binary_accuracy: 0.8602 - val_f1: 0.8610 - val_recall: 0.9047 - val_precision: 0.8225\n",
      "Epoch 64/500\n",
      "1s - loss: 0.2539 - binary_accuracy: 0.8930 - f1: 0.8933 - recall: 0.8949 - precision: 0.8938 - val_loss: 0.3108 - val_binary_accuracy: 0.8684 - val_f1: 0.8641 - val_recall: 0.8727 - val_precision: 0.8573\n",
      "Epoch 65/500\n",
      "1s - loss: 0.2468 - binary_accuracy: 0.8945 - f1: 0.8953 - recall: 0.9000 - precision: 0.8922 - val_loss: 0.3145 - val_binary_accuracy: 0.8645 - val_f1: 0.8580 - val_recall: 0.8558 - val_precision: 0.8617\n",
      "Epoch 66/500\n",
      "1s - loss: 0.2490 - binary_accuracy: 0.8937 - f1: 0.8939 - recall: 0.8953 - precision: 0.8942 - val_loss: 0.3180 - val_binary_accuracy: 0.8626 - val_f1: 0.8612 - val_recall: 0.8949 - val_precision: 0.8314\n",
      "Epoch 67/500\n",
      "0s - loss: 0.2455 - binary_accuracy: 0.8951 - f1: 0.8959 - recall: 0.8956 - precision: 0.8979 - val_loss: 0.3161 - val_binary_accuracy: 0.8612 - val_f1: 0.8568 - val_recall: 0.8693 - val_precision: 0.8460\n",
      "Epoch 68/500\n",
      "1s - loss: 0.2505 - binary_accuracy: 0.8914 - f1: 0.8924 - recall: 0.8944 - precision: 0.8914 - val_loss: 0.3168 - val_binary_accuracy: 0.8650 - val_f1: 0.8589 - val_recall: 0.8528 - val_precision: 0.8667\n",
      "Epoch 69/500\n",
      "1s - loss: 0.2440 - binary_accuracy: 0.8975 - f1: 0.8985 - recall: 0.9019 - precision: 0.8960 - val_loss: 0.3112 - val_binary_accuracy: 0.8684 - val_f1: 0.8639 - val_recall: 0.8699 - val_precision: 0.8597\n",
      "Epoch 70/500\n",
      "1s - loss: 0.2364 - binary_accuracy: 0.9008 - f1: 0.9016 - recall: 0.9063 - precision: 0.8980 - val_loss: 0.3151 - val_binary_accuracy: 0.8587 - val_f1: 0.8502 - val_recall: 0.8342 - val_precision: 0.8689\n",
      "Epoch 71/500\n",
      "0s - loss: 0.2428 - binary_accuracy: 0.8949 - f1: 0.8952 - recall: 0.8950 - precision: 0.8975 - val_loss: 0.3140 - val_binary_accuracy: 0.8650 - val_f1: 0.8610 - val_recall: 0.8717 - val_precision: 0.8517\n",
      "Epoch 72/500\n",
      "0s - loss: 0.2335 - binary_accuracy: 0.9023 - f1: 0.9026 - recall: 0.9046 - precision: 0.9018 - val_loss: 0.3147 - val_binary_accuracy: 0.8641 - val_f1: 0.8582 - val_recall: 0.8562 - val_precision: 0.8618\n",
      "Epoch 73/500\n",
      "1s - loss: 0.2334 - binary_accuracy: 0.9003 - f1: 0.9005 - recall: 0.9017 - precision: 0.9009 - val_loss: 0.3117 - val_binary_accuracy: 0.8616 - val_f1: 0.8540 - val_recall: 0.8460 - val_precision: 0.8639\n",
      "Epoch 74/500\n",
      "1s - loss: 0.2324 - binary_accuracy: 0.9036 - f1: 0.9044 - recall: 0.9059 - precision: 0.9036 - val_loss: 0.3218 - val_binary_accuracy: 0.8612 - val_f1: 0.8564 - val_recall: 0.8599 - val_precision: 0.8549\n",
      "Epoch 75/500\n",
      "0s - loss: 0.2253 - binary_accuracy: 0.9058 - f1: 0.9062 - recall: 0.9067 - precision: 0.9064 - val_loss: 0.3120 - val_binary_accuracy: 0.8660 - val_f1: 0.8595 - val_recall: 0.8539 - val_precision: 0.8668\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2284 - binary_accuracy: 0.9037 - f1: 0.9039 - recall: 0.9053 - precision: 0.9039 - val_loss: 0.3231 - val_binary_accuracy: 0.8665 - val_f1: 0.8668 - val_recall: 0.9091 - val_precision: 0.8295\n",
      "Epoch 77/500\n",
      "0s - loss: 0.2255 - binary_accuracy: 0.9057 - f1: 0.9063 - recall: 0.9088 - precision: 0.9050 - val_loss: 0.3329 - val_binary_accuracy: 0.8636 - val_f1: 0.8566 - val_recall: 0.8488 - val_precision: 0.8660\n",
      "Epoch 78/500\n",
      "1s - loss: 0.2293 - binary_accuracy: 0.9041 - f1: 0.9046 - recall: 0.9063 - precision: 0.9053 - val_loss: 0.3294 - val_binary_accuracy: 0.8558 - val_f1: 0.8494 - val_recall: 0.8470 - val_precision: 0.8535\n",
      "Epoch 79/500\n",
      "0s - loss: 0.2242 - binary_accuracy: 0.9049 - f1: 0.9049 - recall: 0.9020 - precision: 0.9090 - val_loss: 0.3228 - val_binary_accuracy: 0.8592 - val_f1: 0.8585 - val_recall: 0.8925 - val_precision: 0.8287\n",
      "Epoch 80/500\n",
      "0s - loss: 0.2190 - binary_accuracy: 0.9080 - f1: 0.9088 - recall: 0.9113 - precision: 0.9075 - val_loss: 0.3203 - val_binary_accuracy: 0.8602 - val_f1: 0.8563 - val_recall: 0.8665 - val_precision: 0.8480\n",
      "Epoch 81/500\n",
      "1s - loss: 0.2178 - binary_accuracy: 0.9108 - f1: 0.9110 - recall: 0.9113 - precision: 0.9122 - val_loss: 0.3186 - val_binary_accuracy: 0.8616 - val_f1: 0.8597 - val_recall: 0.8848 - val_precision: 0.8376\n",
      "Epoch 82/500\n",
      "1s - loss: 0.2152 - binary_accuracy: 0.9097 - f1: 0.9100 - recall: 0.9088 - precision: 0.9124 - val_loss: 0.3449 - val_binary_accuracy: 0.8505 - val_f1: 0.8541 - val_recall: 0.9129 - val_precision: 0.8038\n",
      "Epoch 83/500\n",
      "1s - loss: 0.2208 - binary_accuracy: 0.9095 - f1: 0.9098 - recall: 0.9123 - precision: 0.9093 - val_loss: 0.3338 - val_binary_accuracy: 0.8510 - val_f1: 0.8510 - val_recall: 0.8892 - val_precision: 0.8174\n",
      "Epoch 84/500\n",
      "0s - loss: 0.2263 - binary_accuracy: 0.9042 - f1: 0.9046 - recall: 0.9071 - precision: 0.9040 - val_loss: 0.3272 - val_binary_accuracy: 0.8592 - val_f1: 0.8550 - val_recall: 0.8636 - val_precision: 0.8483\n",
      "Epoch 85/500\n",
      "0s - loss: 0.2116 - binary_accuracy: 0.9152 - f1: 0.9157 - recall: 0.9180 - precision: 0.9144 - val_loss: 0.3300 - val_binary_accuracy: 0.8631 - val_f1: 0.8567 - val_recall: 0.8505 - val_precision: 0.8646\n",
      "Epoch 86/500\n",
      "1s - loss: 0.2168 - binary_accuracy: 0.9117 - f1: 0.9114 - recall: 0.9076 - precision: 0.9176 - val_loss: 0.3298 - val_binary_accuracy: 0.8553 - val_f1: 0.8540 - val_recall: 0.8808 - val_precision: 0.8308\n",
      "Epoch 87/500\n",
      "0s - loss: 0.2118 - binary_accuracy: 0.9123 - f1: 0.9131 - recall: 0.9140 - precision: 0.9136 - val_loss: 0.3347 - val_binary_accuracy: 0.8597 - val_f1: 0.8527 - val_recall: 0.8435 - val_precision: 0.8637\n",
      "Epoch 88/500\n",
      "1s - loss: 0.2094 - binary_accuracy: 0.9130 - f1: 0.9135 - recall: 0.9143 - precision: 0.9138 - val_loss: 0.3269 - val_binary_accuracy: 0.8602 - val_f1: 0.8548 - val_recall: 0.8565 - val_precision: 0.8550\n",
      "Epoch 89/500\n",
      "1s - loss: 0.2047 - binary_accuracy: 0.9144 - f1: 0.9148 - recall: 0.9151 - precision: 0.9161 - val_loss: 0.3264 - val_binary_accuracy: 0.8616 - val_f1: 0.8521 - val_recall: 0.8310 - val_precision: 0.8763\n",
      "Epoch 90/500\n",
      "1s - loss: 0.2107 - binary_accuracy: 0.9129 - f1: 0.9130 - recall: 0.9115 - precision: 0.9168 - val_loss: 0.3456 - val_binary_accuracy: 0.8423 - val_f1: 0.8397 - val_recall: 0.8600 - val_precision: 0.8218\n",
      "Epoch 91/500\n",
      "1s - loss: 0.2071 - binary_accuracy: 0.9138 - f1: 0.9138 - recall: 0.9114 - precision: 0.9173 - val_loss: 0.3274 - val_binary_accuracy: 0.8621 - val_f1: 0.8589 - val_recall: 0.8759 - val_precision: 0.8444\n",
      "Epoch 92/500\n",
      "1s - loss: 0.1972 - binary_accuracy: 0.9194 - f1: 0.9196 - recall: 0.9188 - precision: 0.9216 - val_loss: 0.3226 - val_binary_accuracy: 0.8636 - val_f1: 0.8601 - val_recall: 0.8755 - val_precision: 0.8465\n",
      "Epoch 93/500\n",
      "0s - loss: 0.1982 - binary_accuracy: 0.9205 - f1: 0.9209 - recall: 0.9211 - precision: 0.9220 - val_loss: 0.3372 - val_binary_accuracy: 0.8597 - val_f1: 0.8521 - val_recall: 0.8414 - val_precision: 0.8654\n",
      "Epoch 94/500\n",
      "0s - loss: 0.1999 - binary_accuracy: 0.9205 - f1: 0.9207 - recall: 0.9191 - precision: 0.9234 - val_loss: 0.3252 - val_binary_accuracy: 0.8626 - val_f1: 0.8599 - val_recall: 0.8807 - val_precision: 0.8419\n",
      "Epoch 95/500\n",
      "0s - loss: 0.1980 - binary_accuracy: 0.9182 - f1: 0.9182 - recall: 0.9197 - precision: 0.9176 - val_loss: 0.3353 - val_binary_accuracy: 0.8636 - val_f1: 0.8593 - val_recall: 0.8643 - val_precision: 0.8553\n",
      "Epoch 96/500\n",
      "0s - loss: 0.2009 - binary_accuracy: 0.9174 - f1: 0.9176 - recall: 0.9179 - precision: 0.9199 - val_loss: 0.3355 - val_binary_accuracy: 0.8616 - val_f1: 0.8619 - val_recall: 0.9001 - val_precision: 0.8282\n",
      "Epoch 97/500\n",
      "1s - loss: 0.1956 - binary_accuracy: 0.9208 - f1: 0.9212 - recall: 0.9201 - precision: 0.9233 - val_loss: 0.3482 - val_binary_accuracy: 0.8505 - val_f1: 0.8501 - val_recall: 0.8878 - val_precision: 0.8168\n",
      "Epoch 98/500\n",
      "1s - loss: 0.1886 - binary_accuracy: 0.9241 - f1: 0.9245 - recall: 0.9239 - precision: 0.9262 - val_loss: 0.3312 - val_binary_accuracy: 0.8650 - val_f1: 0.8633 - val_recall: 0.8865 - val_precision: 0.8431\n",
      "Epoch 99/500\n",
      "0s - loss: 0.1942 - binary_accuracy: 0.9213 - f1: 0.9217 - recall: 0.9216 - precision: 0.9231 - val_loss: 0.3297 - val_binary_accuracy: 0.8645 - val_f1: 0.8600 - val_recall: 0.8671 - val_precision: 0.8550\n",
      "Epoch 100/500\n",
      "0s - loss: 0.1872 - binary_accuracy: 0.9251 - f1: 0.9252 - recall: 0.9257 - precision: 0.9259 - val_loss: 0.3400 - val_binary_accuracy: 0.8544 - val_f1: 0.8468 - val_recall: 0.8404 - val_precision: 0.8547\n",
      "Epoch 101/500\n",
      "1s - loss: 0.1829 - binary_accuracy: 0.9262 - f1: 0.9261 - recall: 0.9224 - precision: 0.9309 - val_loss: 0.3419 - val_binary_accuracy: 0.8602 - val_f1: 0.8538 - val_recall: 0.8493 - val_precision: 0.8606\n",
      "Epoch 102/500\n",
      "0s - loss: 0.1807 - binary_accuracy: 0.9287 - f1: 0.9294 - recall: 0.9306 - precision: 0.9292 - val_loss: 0.3541 - val_binary_accuracy: 0.8544 - val_f1: 0.8437 - val_recall: 0.8164 - val_precision: 0.8748\n",
      "Epoch 103/500\n",
      "0s - loss: 0.1825 - binary_accuracy: 0.9280 - f1: 0.9283 - recall: 0.9244 - precision: 0.9335 - val_loss: 0.3433 - val_binary_accuracy: 0.8524 - val_f1: 0.8499 - val_recall: 0.8702 - val_precision: 0.8321\n",
      "Epoch 104/500\n",
      "1s - loss: 0.1860 - binary_accuracy: 0.9265 - f1: 0.9267 - recall: 0.9272 - precision: 0.9273 - val_loss: 0.3382 - val_binary_accuracy: 0.8650 - val_f1: 0.8610 - val_recall: 0.8751 - val_precision: 0.8493\n",
      "Epoch 105/500\n",
      "1s - loss: 0.1805 - binary_accuracy: 0.9264 - f1: 0.9266 - recall: 0.9235 - precision: 0.9310 - val_loss: 0.3461 - val_binary_accuracy: 0.8641 - val_f1: 0.8578 - val_recall: 0.8538 - val_precision: 0.8632\n",
      "Epoch 106/500\n",
      "0s - loss: 0.1765 - binary_accuracy: 0.9290 - f1: 0.9293 - recall: 0.9279 - precision: 0.9316 - val_loss: 0.3415 - val_binary_accuracy: 0.8597 - val_f1: 0.8570 - val_recall: 0.8794 - val_precision: 0.8371\n",
      "1984/2067 [===========================>..] - ETA: 0stn = 4025, fp = 339, fn = 217, tp = 4212\n",
      "y_pred: 0 = 4242 | 1 = 4551\n",
      "y_true: 0 = 4364 | 1 = 4429\n",
      "acc=0.9368|precision=0.9255|recall=0.9510|f1=0.9381|auc=0.9856|aupr=0.9864|pos_acc=0.9510|neg_acc=0.9488\n",
      "tn = 897, fp = 169, fn = 121, tp = 880\n",
      "y_pred: 0 = 1018 | 1 = 1049\n",
      "y_true: 0 = 1066 | 1 = 1001\n",
      "acc=0.8597|precision=0.8389|recall=0.8791|f1=0.8585|auc=0.9359|aupr=0.9282|pos_acc=0.8791|neg_acc=0.8811\n",
      "----------------------- Fold =  4\n",
      "Train on 9044 samples, validate on 1816 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.3952 - binary_accuracy: 0.8289 - f1: 0.8291 - recall: 0.8207 - precision: 0.8491 - val_loss: 0.3581 - val_binary_accuracy: 0.8403 - val_f1: 0.8209 - val_recall: 0.7793 - val_precision: 0.8687\n",
      "Epoch 2/500\n",
      "0s - loss: 0.3508 - binary_accuracy: 0.8413 - f1: 0.8424 - recall: 0.8427 - precision: 0.8449 - val_loss: 0.3376 - val_binary_accuracy: 0.8585 - val_f1: 0.8483 - val_recall: 0.8408 - val_precision: 0.8569\n",
      "Epoch 3/500\n",
      "1s - loss: 0.3426 - binary_accuracy: 0.8501 - f1: 0.8508 - recall: 0.8483 - precision: 0.8559 - val_loss: 0.3423 - val_binary_accuracy: 0.8475 - val_f1: 0.8365 - val_recall: 0.8284 - val_precision: 0.8457\n",
      "Epoch 4/500\n",
      "1s - loss: 0.3366 - binary_accuracy: 0.8518 - f1: 0.8541 - recall: 0.8596 - precision: 0.8514 - val_loss: 0.3530 - val_binary_accuracy: 0.8331 - val_f1: 0.8035 - val_recall: 0.7234 - val_precision: 0.9055\n",
      "Epoch 5/500\n",
      "1s - loss: 0.3404 - binary_accuracy: 0.8496 - f1: 0.8509 - recall: 0.8529 - precision: 0.8542 - val_loss: 0.3294 - val_binary_accuracy: 0.8552 - val_f1: 0.8391 - val_recall: 0.8009 - val_precision: 0.8824\n",
      "Epoch 6/500\n",
      "0s - loss: 0.3314 - binary_accuracy: 0.8545 - f1: 0.8556 - recall: 0.8565 - precision: 0.8577 - val_loss: 0.3411 - val_binary_accuracy: 0.8519 - val_f1: 0.8320 - val_recall: 0.7795 - val_precision: 0.8932\n",
      "Epoch 7/500\n",
      "1s - loss: 0.3319 - binary_accuracy: 0.8555 - f1: 0.8573 - recall: 0.8637 - precision: 0.8542 - val_loss: 0.3280 - val_binary_accuracy: 0.8590 - val_f1: 0.8496 - val_recall: 0.8427 - val_precision: 0.8571\n",
      "Epoch 8/500\n",
      "1s - loss: 0.3245 - binary_accuracy: 0.8575 - f1: 0.8587 - recall: 0.8598 - precision: 0.8598 - val_loss: 0.3211 - val_binary_accuracy: 0.8645 - val_f1: 0.8534 - val_recall: 0.8379 - val_precision: 0.8706\n",
      "Epoch 9/500\n",
      "0s - loss: 0.3232 - binary_accuracy: 0.8569 - f1: 0.8586 - recall: 0.8628 - precision: 0.8559 - val_loss: 0.3272 - val_binary_accuracy: 0.8546 - val_f1: 0.8384 - val_recall: 0.7990 - val_precision: 0.8833\n",
      "Epoch 10/500\n",
      "1s - loss: 0.3247 - binary_accuracy: 0.8563 - f1: 0.8573 - recall: 0.8589 - precision: 0.8589 - val_loss: 0.3205 - val_binary_accuracy: 0.8673 - val_f1: 0.8569 - val_recall: 0.8426 - val_precision: 0.8726\n",
      "Epoch 11/500\n",
      "1s - loss: 0.3178 - binary_accuracy: 0.8603 - f1: 0.8624 - recall: 0.8687 - precision: 0.8575 - val_loss: 0.3178 - val_binary_accuracy: 0.8651 - val_f1: 0.8553 - val_recall: 0.8464 - val_precision: 0.8654\n",
      "Epoch 12/500\n",
      "0s - loss: 0.3163 - binary_accuracy: 0.8651 - f1: 0.8666 - recall: 0.8703 - precision: 0.8642 - val_loss: 0.3157 - val_binary_accuracy: 0.8667 - val_f1: 0.8587 - val_recall: 0.8604 - val_precision: 0.8581\n",
      "Epoch 13/500\n",
      "1s - loss: 0.3214 - binary_accuracy: 0.8585 - f1: 0.8594 - recall: 0.8608 - precision: 0.8610 - val_loss: 0.3250 - val_binary_accuracy: 0.8601 - val_f1: 0.8540 - val_recall: 0.8671 - val_precision: 0.8420\n",
      "Epoch 14/500\n",
      "1s - loss: 0.3132 - binary_accuracy: 0.8618 - f1: 0.8636 - recall: 0.8689 - precision: 0.8600 - val_loss: 0.3341 - val_binary_accuracy: 0.8541 - val_f1: 0.8369 - val_recall: 0.7950 - val_precision: 0.8849\n",
      "Epoch 15/500\n",
      "0s - loss: 0.3193 - binary_accuracy: 0.8649 - f1: 0.8660 - recall: 0.8700 - precision: 0.8661 - val_loss: 0.3229 - val_binary_accuracy: 0.8585 - val_f1: 0.8518 - val_recall: 0.8624 - val_precision: 0.8423\n",
      "Epoch 16/500\n",
      "1s - loss: 0.3114 - binary_accuracy: 0.8638 - f1: 0.8658 - recall: 0.8714 - precision: 0.8619 - val_loss: 0.3352 - val_binary_accuracy: 0.8535 - val_f1: 0.8354 - val_recall: 0.7923 - val_precision: 0.8849\n",
      "Epoch 17/500\n",
      "0s - loss: 0.3175 - binary_accuracy: 0.8586 - f1: 0.8605 - recall: 0.8646 - precision: 0.8593 - val_loss: 0.3164 - val_binary_accuracy: 0.8634 - val_f1: 0.8526 - val_recall: 0.8384 - val_precision: 0.8691\n",
      "Epoch 18/500\n",
      "0s - loss: 0.3079 - binary_accuracy: 0.8669 - f1: 0.8675 - recall: 0.8680 - precision: 0.8683 - val_loss: 0.3269 - val_binary_accuracy: 0.8563 - val_f1: 0.8415 - val_recall: 0.8101 - val_precision: 0.8766\n",
      "Epoch 19/500\n",
      "0s - loss: 0.3104 - binary_accuracy: 0.8662 - f1: 0.8675 - recall: 0.8723 - precision: 0.8647 - val_loss: 0.3241 - val_binary_accuracy: 0.8535 - val_f1: 0.8368 - val_recall: 0.7966 - val_precision: 0.8829\n",
      "Epoch 20/500\n",
      "1s - loss: 0.3068 - binary_accuracy: 0.8654 - f1: 0.8668 - recall: 0.8707 - precision: 0.8647 - val_loss: 0.3258 - val_binary_accuracy: 0.8557 - val_f1: 0.8425 - val_recall: 0.8177 - val_precision: 0.8704\n",
      "Epoch 21/500\n",
      "0s - loss: 0.3100 - binary_accuracy: 0.8631 - f1: 0.8646 - recall: 0.8671 - precision: 0.8644 - val_loss: 0.3160 - val_binary_accuracy: 0.8634 - val_f1: 0.8570 - val_recall: 0.8694 - val_precision: 0.8461\n",
      "Epoch 22/500\n",
      "0s - loss: 0.3060 - binary_accuracy: 0.8679 - f1: 0.8696 - recall: 0.8758 - precision: 0.8656 - val_loss: 0.3162 - val_binary_accuracy: 0.8590 - val_f1: 0.8457 - val_recall: 0.8224 - val_precision: 0.8720\n",
      "Epoch 23/500\n",
      "1s - loss: 0.3059 - binary_accuracy: 0.8674 - f1: 0.8683 - recall: 0.8712 - precision: 0.8682 - val_loss: 0.3164 - val_binary_accuracy: 0.8651 - val_f1: 0.8587 - val_recall: 0.8694 - val_precision: 0.8492\n",
      "Epoch 24/500\n",
      "0s - loss: 0.2995 - binary_accuracy: 0.8712 - f1: 0.8726 - recall: 0.8757 - precision: 0.8711 - val_loss: 0.3156 - val_binary_accuracy: 0.8596 - val_f1: 0.8470 - val_recall: 0.8253 - val_precision: 0.8718\n",
      "Epoch 25/500\n",
      "1s - loss: 0.3012 - binary_accuracy: 0.8672 - f1: 0.8684 - recall: 0.8714 - precision: 0.8674 - val_loss: 0.3158 - val_binary_accuracy: 0.8629 - val_f1: 0.8559 - val_recall: 0.8650 - val_precision: 0.8484\n",
      "Epoch 26/500\n",
      "1s - loss: 0.2994 - binary_accuracy: 0.8697 - f1: 0.8720 - recall: 0.8784 - precision: 0.8665 - val_loss: 0.3178 - val_binary_accuracy: 0.8579 - val_f1: 0.8461 - val_recall: 0.8311 - val_precision: 0.8636\n",
      "Epoch 27/500\n",
      "1s - loss: 0.2971 - binary_accuracy: 0.8711 - f1: 0.8722 - recall: 0.8762 - precision: 0.8697 - val_loss: 0.3147 - val_binary_accuracy: 0.8590 - val_f1: 0.8457 - val_recall: 0.8204 - val_precision: 0.8742\n",
      "Epoch 28/500\n",
      "0s - loss: 0.2969 - binary_accuracy: 0.8721 - f1: 0.8735 - recall: 0.8773 - precision: 0.8715 - val_loss: 0.3422 - val_binary_accuracy: 0.8469 - val_f1: 0.8268 - val_recall: 0.7785 - val_precision: 0.8839\n",
      "Epoch 29/500\n",
      "0s - loss: 0.2969 - binary_accuracy: 0.8710 - f1: 0.8716 - recall: 0.8744 - precision: 0.8714 - val_loss: 0.3178 - val_binary_accuracy: 0.8634 - val_f1: 0.8571 - val_recall: 0.8697 - val_precision: 0.8462\n",
      "Epoch 30/500\n",
      "1s - loss: 0.2956 - binary_accuracy: 0.8774 - f1: 0.8782 - recall: 0.8825 - precision: 0.8764 - val_loss: 0.3164 - val_binary_accuracy: 0.8607 - val_f1: 0.8504 - val_recall: 0.8414 - val_precision: 0.8610\n",
      "Epoch 31/500\n",
      "1s - loss: 0.3022 - binary_accuracy: 0.8682 - f1: 0.8697 - recall: 0.8757 - precision: 0.8679 - val_loss: 0.3191 - val_binary_accuracy: 0.8563 - val_f1: 0.8452 - val_recall: 0.8334 - val_precision: 0.8590\n",
      "Epoch 32/500\n",
      "1s - loss: 0.2954 - binary_accuracy: 0.8703 - f1: 0.8716 - recall: 0.8721 - precision: 0.8744 - val_loss: 0.3123 - val_binary_accuracy: 0.8585 - val_f1: 0.8492 - val_recall: 0.8461 - val_precision: 0.8537\n",
      "Epoch 33/500\n",
      "1s - loss: 0.2896 - binary_accuracy: 0.8746 - f1: 0.8757 - recall: 0.8792 - precision: 0.8743 - val_loss: 0.3158 - val_binary_accuracy: 0.8607 - val_f1: 0.8518 - val_recall: 0.8507 - val_precision: 0.8543\n",
      "Epoch 34/500\n",
      "0s - loss: 0.2958 - binary_accuracy: 0.8717 - f1: 0.8738 - recall: 0.8805 - precision: 0.8706 - val_loss: 0.3589 - val_binary_accuracy: 0.8398 - val_f1: 0.8127 - val_recall: 0.7383 - val_precision: 0.9062\n",
      "Epoch 35/500\n",
      "0s - loss: 0.2978 - binary_accuracy: 0.8713 - f1: 0.8716 - recall: 0.8708 - precision: 0.8770 - val_loss: 0.3194 - val_binary_accuracy: 0.8601 - val_f1: 0.8488 - val_recall: 0.8344 - val_precision: 0.8654\n",
      "Epoch 36/500\n",
      "1s - loss: 0.2859 - binary_accuracy: 0.8767 - f1: 0.8779 - recall: 0.8809 - precision: 0.8764 - val_loss: 0.3132 - val_binary_accuracy: 0.8585 - val_f1: 0.8494 - val_recall: 0.8473 - val_precision: 0.8527\n",
      "Epoch 37/500\n",
      "1s - loss: 0.2804 - binary_accuracy: 0.8815 - f1: 0.8824 - recall: 0.8831 - precision: 0.8829 - val_loss: 0.3194 - val_binary_accuracy: 0.8601 - val_f1: 0.8555 - val_recall: 0.8791 - val_precision: 0.8346\n",
      "Epoch 38/500\n",
      "1s - loss: 0.2829 - binary_accuracy: 0.8779 - f1: 0.8797 - recall: 0.8832 - precision: 0.8778 - val_loss: 0.3186 - val_binary_accuracy: 0.8585 - val_f1: 0.8480 - val_recall: 0.8388 - val_precision: 0.8589\n",
      "Epoch 39/500\n",
      "0s - loss: 0.2815 - binary_accuracy: 0.8793 - f1: 0.8810 - recall: 0.8853 - precision: 0.8783 - val_loss: 0.3236 - val_binary_accuracy: 0.8557 - val_f1: 0.8456 - val_recall: 0.8401 - val_precision: 0.8527\n",
      "Epoch 40/500\n",
      "0s - loss: 0.2818 - binary_accuracy: 0.8794 - f1: 0.8810 - recall: 0.8877 - precision: 0.8759 - val_loss: 0.3190 - val_binary_accuracy: 0.8601 - val_f1: 0.8481 - val_recall: 0.8287 - val_precision: 0.8701\n",
      "Epoch 41/500\n",
      "1s - loss: 0.2793 - binary_accuracy: 0.8818 - f1: 0.8827 - recall: 0.8828 - precision: 0.8839 - val_loss: 0.3336 - val_binary_accuracy: 0.8442 - val_f1: 0.8285 - val_recall: 0.8057 - val_precision: 0.8548\n",
      "Epoch 42/500\n",
      "0s - loss: 0.2781 - binary_accuracy: 0.8785 - f1: 0.8794 - recall: 0.8818 - precision: 0.8778 - val_loss: 0.3223 - val_binary_accuracy: 0.8519 - val_f1: 0.8382 - val_recall: 0.8178 - val_precision: 0.8615\n",
      "Epoch 43/500\n",
      "0s - loss: 0.2815 - binary_accuracy: 0.8798 - f1: 0.8811 - recall: 0.8856 - precision: 0.8789 - val_loss: 0.3183 - val_binary_accuracy: 0.8574 - val_f1: 0.8518 - val_recall: 0.8705 - val_precision: 0.8346\n",
      "Epoch 44/500\n",
      "0s - loss: 0.2722 - binary_accuracy: 0.8857 - f1: 0.8868 - recall: 0.8930 - precision: 0.8816 - val_loss: 0.3266 - val_binary_accuracy: 0.8546 - val_f1: 0.8369 - val_recall: 0.7923 - val_precision: 0.8880\n",
      "Epoch 45/500\n",
      "1s - loss: 0.2854 - binary_accuracy: 0.8766 - f1: 0.8772 - recall: 0.8804 - precision: 0.8772 - val_loss: 0.3262 - val_binary_accuracy: 0.8552 - val_f1: 0.8420 - val_recall: 0.8174 - val_precision: 0.8693\n",
      "Epoch 46/500\n",
      "0s - loss: 0.2763 - binary_accuracy: 0.8820 - f1: 0.8832 - recall: 0.8842 - precision: 0.8840 - val_loss: 0.3194 - val_binary_accuracy: 0.8552 - val_f1: 0.8501 - val_recall: 0.8737 - val_precision: 0.8291\n",
      "Epoch 47/500\n",
      "1s - loss: 0.2711 - binary_accuracy: 0.8845 - f1: 0.8858 - recall: 0.8925 - precision: 0.8814 - val_loss: 0.3172 - val_binary_accuracy: 0.8596 - val_f1: 0.8512 - val_recall: 0.8519 - val_precision: 0.8516\n",
      "Epoch 48/500\n",
      "1s - loss: 0.2652 - binary_accuracy: 0.8874 - f1: 0.8884 - recall: 0.8900 - precision: 0.8880 - val_loss: 0.3182 - val_binary_accuracy: 0.8557 - val_f1: 0.8468 - val_recall: 0.8461 - val_precision: 0.8490\n",
      "Epoch 49/500\n",
      "0s - loss: 0.2660 - binary_accuracy: 0.8863 - f1: 0.8876 - recall: 0.8937 - precision: 0.8835 - val_loss: 0.3203 - val_binary_accuracy: 0.8546 - val_f1: 0.8411 - val_recall: 0.8169 - val_precision: 0.8680\n",
      "Epoch 50/500\n",
      "1s - loss: 0.2623 - binary_accuracy: 0.8881 - f1: 0.8894 - recall: 0.8933 - precision: 0.8870 - val_loss: 0.3303 - val_binary_accuracy: 0.8519 - val_f1: 0.8406 - val_recall: 0.8299 - val_precision: 0.8536\n",
      "Epoch 51/500\n",
      "1s - loss: 0.2628 - binary_accuracy: 0.8891 - f1: 0.8901 - recall: 0.8920 - precision: 0.8890 - val_loss: 0.3254 - val_binary_accuracy: 0.8563 - val_f1: 0.8481 - val_recall: 0.8541 - val_precision: 0.8438\n",
      "Epoch 52/500\n",
      "1s - loss: 0.2588 - binary_accuracy: 0.8915 - f1: 0.8928 - recall: 0.8967 - precision: 0.8901 - val_loss: 0.3297 - val_binary_accuracy: 0.8563 - val_f1: 0.8464 - val_recall: 0.8443 - val_precision: 0.8500\n",
      "Epoch 53/500\n",
      "0s - loss: 0.2603 - binary_accuracy: 0.8881 - f1: 0.8891 - recall: 0.8914 - precision: 0.8877 - val_loss: 0.3209 - val_binary_accuracy: 0.8607 - val_f1: 0.8550 - val_recall: 0.8738 - val_precision: 0.8386\n",
      "Epoch 54/500\n",
      "1s - loss: 0.2559 - binary_accuracy: 0.8915 - f1: 0.8929 - recall: 0.8997 - precision: 0.8880 - val_loss: 0.3346 - val_binary_accuracy: 0.8546 - val_f1: 0.8382 - val_recall: 0.8003 - val_precision: 0.8812\n",
      "Epoch 55/500\n",
      "1s - loss: 0.2541 - binary_accuracy: 0.8893 - f1: 0.8904 - recall: 0.8932 - precision: 0.8890 - val_loss: 0.3225 - val_binary_accuracy: 0.8579 - val_f1: 0.8489 - val_recall: 0.8506 - val_precision: 0.8489\n",
      "Epoch 56/500\n",
      "0s - loss: 0.2547 - binary_accuracy: 0.8897 - f1: 0.8906 - recall: 0.8927 - precision: 0.8895 - val_loss: 0.3223 - val_binary_accuracy: 0.8607 - val_f1: 0.8536 - val_recall: 0.8655 - val_precision: 0.8433\n",
      "Epoch 57/500\n",
      "1s - loss: 0.2542 - binary_accuracy: 0.8915 - f1: 0.8925 - recall: 0.8943 - precision: 0.8923 - val_loss: 0.3224 - val_binary_accuracy: 0.8590 - val_f1: 0.8487 - val_recall: 0.8421 - val_precision: 0.8566\n",
      "Epoch 58/500\n",
      "1s - loss: 0.2572 - binary_accuracy: 0.8872 - f1: 0.8881 - recall: 0.8894 - precision: 0.8889 - val_loss: 0.3449 - val_binary_accuracy: 0.8475 - val_f1: 0.8387 - val_recall: 0.8452 - val_precision: 0.8332\n",
      "Epoch 59/500\n",
      "1s - loss: 0.2575 - binary_accuracy: 0.8910 - f1: 0.8922 - recall: 0.8956 - precision: 0.8903 - val_loss: 0.3367 - val_binary_accuracy: 0.8557 - val_f1: 0.8422 - val_recall: 0.8239 - val_precision: 0.8631\n",
      "Epoch 60/500\n",
      "0s - loss: 0.2471 - binary_accuracy: 0.8974 - f1: 0.8990 - recall: 0.9044 - precision: 0.8948 - val_loss: 0.3399 - val_binary_accuracy: 0.8563 - val_f1: 0.8402 - val_recall: 0.8027 - val_precision: 0.8824\n",
      "Epoch 61/500\n",
      "0s - loss: 0.2500 - binary_accuracy: 0.8942 - f1: 0.8956 - recall: 0.8992 - precision: 0.8943 - val_loss: 0.3275 - val_binary_accuracy: 0.8596 - val_f1: 0.8471 - val_recall: 0.8299 - val_precision: 0.8661\n",
      "Epoch 62/500\n",
      "0s - loss: 0.2475 - binary_accuracy: 0.8921 - f1: 0.8935 - recall: 0.8972 - precision: 0.8908 - val_loss: 0.3321 - val_binary_accuracy: 0.8568 - val_f1: 0.8448 - val_recall: 0.8284 - val_precision: 0.8631\n",
      "Epoch 63/500\n",
      "0s - loss: 0.2503 - binary_accuracy: 0.8918 - f1: 0.8932 - recall: 0.8975 - precision: 0.8905 - val_loss: 0.3396 - val_binary_accuracy: 0.8497 - val_f1: 0.8444 - val_recall: 0.8675 - val_precision: 0.8232\n",
      "Epoch 64/500\n",
      "0s - loss: 0.2458 - binary_accuracy: 0.8964 - f1: 0.8979 - recall: 0.9037 - precision: 0.8937 - val_loss: 0.3305 - val_binary_accuracy: 0.8508 - val_f1: 0.8347 - val_recall: 0.8006 - val_precision: 0.8730\n",
      "Epoch 65/500\n",
      "1s - loss: 0.2464 - binary_accuracy: 0.8966 - f1: 0.8978 - recall: 0.9009 - precision: 0.8963 - val_loss: 0.3225 - val_binary_accuracy: 0.8618 - val_f1: 0.8528 - val_recall: 0.8555 - val_precision: 0.8513\n",
      "Epoch 66/500\n",
      "1s - loss: 0.2384 - binary_accuracy: 0.8985 - f1: 0.8993 - recall: 0.9026 - precision: 0.8968 - val_loss: 0.3423 - val_binary_accuracy: 0.8524 - val_f1: 0.8369 - val_recall: 0.8030 - val_precision: 0.8747\n",
      "Epoch 67/500\n",
      "1s - loss: 0.2412 - binary_accuracy: 0.8977 - f1: 0.8984 - recall: 0.8988 - precision: 0.8991 - val_loss: 0.3499 - val_binary_accuracy: 0.8502 - val_f1: 0.8341 - val_recall: 0.8018 - val_precision: 0.8706\n",
      "Epoch 68/500\n",
      "1s - loss: 0.2434 - binary_accuracy: 0.8998 - f1: 0.9004 - recall: 0.9017 - precision: 0.9009 - val_loss: 0.3401 - val_binary_accuracy: 0.8480 - val_f1: 0.8414 - val_recall: 0.8585 - val_precision: 0.8257\n",
      "Epoch 69/500\n",
      "0s - loss: 0.2397 - binary_accuracy: 0.8984 - f1: 0.8995 - recall: 0.9020 - precision: 0.8993 - val_loss: 0.3280 - val_binary_accuracy: 0.8568 - val_f1: 0.8441 - val_recall: 0.8275 - val_precision: 0.8629\n",
      "Epoch 70/500\n",
      "1s - loss: 0.2330 - binary_accuracy: 0.8998 - f1: 0.9010 - recall: 0.9046 - precision: 0.8985 - val_loss: 0.3437 - val_binary_accuracy: 0.8563 - val_f1: 0.8474 - val_recall: 0.8474 - val_precision: 0.8486\n",
      "Epoch 71/500\n",
      "1s - loss: 0.2364 - binary_accuracy: 0.9000 - f1: 0.9011 - recall: 0.9063 - precision: 0.8977 - val_loss: 0.3333 - val_binary_accuracy: 0.8557 - val_f1: 0.8442 - val_recall: 0.8288 - val_precision: 0.8615\n",
      "Epoch 72/500\n",
      "1s - loss: 0.2305 - binary_accuracy: 0.9016 - f1: 0.9028 - recall: 0.9057 - precision: 0.9008 - val_loss: 0.3297 - val_binary_accuracy: 0.8579 - val_f1: 0.8524 - val_recall: 0.8735 - val_precision: 0.8334\n",
      "Epoch 73/500\n",
      "0s - loss: 0.2312 - binary_accuracy: 0.9033 - f1: 0.9043 - recall: 0.9106 - precision: 0.8992 - val_loss: 0.3396 - val_binary_accuracy: 0.8464 - val_f1: 0.8283 - val_recall: 0.7865 - val_precision: 0.8760\n",
      "Epoch 74/500\n",
      "1s - loss: 0.2262 - binary_accuracy: 0.9065 - f1: 0.9067 - recall: 0.9049 - precision: 0.9104 - val_loss: 0.3333 - val_binary_accuracy: 0.8568 - val_f1: 0.8493 - val_recall: 0.8614 - val_precision: 0.8386\n",
      "Epoch 75/500\n",
      "1s - loss: 0.2308 - binary_accuracy: 0.9020 - f1: 0.9032 - recall: 0.9051 - precision: 0.9028 - val_loss: 0.3475 - val_binary_accuracy: 0.8524 - val_f1: 0.8372 - val_recall: 0.8094 - val_precision: 0.8684\n",
      "Epoch 76/500\n",
      "0s - loss: 0.2270 - binary_accuracy: 0.9065 - f1: 0.9076 - recall: 0.9100 - precision: 0.9061 - val_loss: 0.3496 - val_binary_accuracy: 0.8491 - val_f1: 0.8456 - val_recall: 0.8780 - val_precision: 0.8165\n",
      "Epoch 77/500\n",
      "1s - loss: 0.2270 - binary_accuracy: 0.9066 - f1: 0.9076 - recall: 0.9113 - precision: 0.9058 - val_loss: 0.3442 - val_binary_accuracy: 0.8464 - val_f1: 0.8287 - val_recall: 0.7903 - val_precision: 0.8721\n",
      "Epoch 78/500\n",
      "1s - loss: 0.2202 - binary_accuracy: 0.9079 - f1: 0.9086 - recall: 0.9092 - precision: 0.9096 - val_loss: 0.3332 - val_binary_accuracy: 0.8574 - val_f1: 0.8471 - val_recall: 0.8401 - val_precision: 0.8553\n",
      "Epoch 79/500\n",
      "1s - loss: 0.2177 - binary_accuracy: 0.9082 - f1: 0.9089 - recall: 0.9086 - precision: 0.9107 - val_loss: 0.3640 - val_binary_accuracy: 0.8513 - val_f1: 0.8509 - val_recall: 0.9020 - val_precision: 0.8059\n",
      "Epoch 80/500\n",
      "1s - loss: 0.2231 - binary_accuracy: 0.9069 - f1: 0.9083 - recall: 0.9126 - precision: 0.9061 - val_loss: 0.3414 - val_binary_accuracy: 0.8541 - val_f1: 0.8463 - val_recall: 0.8528 - val_precision: 0.8409\n",
      "Epoch 81/500\n",
      "1s - loss: 0.2158 - binary_accuracy: 0.9121 - f1: 0.9129 - recall: 0.9168 - precision: 0.9104 - val_loss: 0.3448 - val_binary_accuracy: 0.8535 - val_f1: 0.8497 - val_recall: 0.8814 - val_precision: 0.8209\n",
      "Epoch 82/500\n",
      "0s - loss: 0.2212 - binary_accuracy: 0.9103 - f1: 0.9114 - recall: 0.9155 - precision: 0.9095 - val_loss: 0.3724 - val_binary_accuracy: 0.8546 - val_f1: 0.8361 - val_recall: 0.7886 - val_precision: 0.8913\n",
      "Epoch 83/500\n",
      "0s - loss: 0.2242 - binary_accuracy: 0.9054 - f1: 0.9061 - recall: 0.9095 - precision: 0.9051 - val_loss: 0.3499 - val_binary_accuracy: 0.8568 - val_f1: 0.8436 - val_recall: 0.8252 - val_precision: 0.8645\n",
      "1728/1816 [===========================>..] - ETA: 0stn = 4123, fp = 349, fn = 448, tp = 4124\n",
      "y_pred: 0 = 4571 | 1 = 4473\n",
      "y_true: 0 = 4472 | 1 = 4572\n",
      "acc=0.9119|precision=0.9220|recall=0.9020|f1=0.9119|auc=0.9726|aupr=0.9740|pos_acc=0.9020|neg_acc=0.9020\n",
      "tn = 847, fp = 111, fn = 149, tp = 709\n",
      "y_pred: 0 = 996 | 1 = 820\n",
      "y_true: 0 = 958 | 1 = 858\n",
      "acc=0.8568|precision=0.8646|recall=0.8263|f1=0.8451|auc=0.9379|aupr=0.9274|pos_acc=0.8263|neg_acc=0.8504\n",
      "# miRNA = 495 | Disease = 383\n",
      "# Test: miRNA = 99 | Disease = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 27.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== isbalance = False | task = Tp\n",
      "-------Fold  0\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  1\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  2\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  3\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  4\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "----------------------- Fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "18s - loss: 0.0836 - binary_accuracy: 0.9728 - f1: 0.2595 - recall: 0.1874 - precision: 0.5294 - val_loss: 0.0761 - val_binary_accuracy: 0.9750 - val_f1: 0.1471 - val_recall: 0.1105 - val_precision: 0.2657\n",
      "Epoch 2/500\n",
      "18s - loss: 0.0792 - binary_accuracy: 0.9748 - f1: 0.3259 - recall: 0.2397 - precision: 0.6152 - val_loss: 0.0744 - val_binary_accuracy: 0.9755 - val_f1: 0.1110 - val_recall: 0.0765 - val_precision: 0.2868\n",
      "Epoch 3/500\n",
      "18s - loss: 0.0784 - binary_accuracy: 0.9749 - f1: 0.3334 - recall: 0.2482 - precision: 0.6181 - val_loss: 0.0765 - val_binary_accuracy: 0.9756 - val_f1: 0.1156 - val_recall: 0.0800 - val_precision: 0.2759\n",
      "Epoch 4/500\n",
      "18s - loss: 0.0779 - binary_accuracy: 0.9752 - f1: 0.3411 - recall: 0.2507 - precision: 0.6427 - val_loss: 0.0775 - val_binary_accuracy: 0.9747 - val_f1: 0.2577 - val_recall: 0.2397 - val_precision: 0.3379\n",
      "Epoch 5/500\n",
      "14s - loss: 0.0769 - binary_accuracy: 0.9756 - f1: 0.3627 - recall: 0.2729 - precision: 0.6663 - val_loss: 0.0748 - val_binary_accuracy: 0.9763 - val_f1: 0.2004 - val_recall: 0.1602 - val_precision: 0.3320\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0764 - binary_accuracy: 0.9758 - f1: 0.3659 - recall: 0.2756 - precision: 0.6572 - val_loss: 0.0725 - val_binary_accuracy: 0.9763 - val_f1: 0.1795 - val_recall: 0.1325 - val_precision: 0.3416\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0755 - binary_accuracy: 0.9759 - f1: 0.3717 - recall: 0.2788 - precision: 0.6692 - val_loss: 0.0721 - val_binary_accuracy: 0.9767 - val_f1: 0.1591 - val_recall: 0.1167 - val_precision: 0.3039\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0746 - binary_accuracy: 0.9761 - f1: 0.3806 - recall: 0.2882 - precision: 0.6659 - val_loss: 0.0743 - val_binary_accuracy: 0.9758 - val_f1: 0.2704 - val_recall: 0.2272 - val_precision: 0.3954\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0741 - binary_accuracy: 0.9765 - f1: 0.3996 - recall: 0.3036 - precision: 0.7035 - val_loss: 0.0716 - val_binary_accuracy: 0.9770 - val_f1: 0.2231 - val_recall: 0.1720 - val_precision: 0.3867\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0735 - binary_accuracy: 0.9765 - f1: 0.3994 - recall: 0.3062 - precision: 0.6792 - val_loss: 0.0715 - val_binary_accuracy: 0.9766 - val_f1: 0.1847 - val_recall: 0.1291 - val_precision: 0.3989\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0728 - binary_accuracy: 0.9768 - f1: 0.4103 - recall: 0.3148 - precision: 0.6899 - val_loss: 0.0721 - val_binary_accuracy: 0.9770 - val_f1: 0.1730 - val_recall: 0.1265 - val_precision: 0.3460\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0720 - binary_accuracy: 0.9770 - f1: 0.4184 - recall: 0.3207 - precision: 0.7029 - val_loss: 0.0708 - val_binary_accuracy: 0.9773 - val_f1: 0.2193 - val_recall: 0.1625 - val_precision: 0.4028\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0716 - binary_accuracy: 0.9773 - f1: 0.4301 - recall: 0.3340 - precision: 0.7120 - val_loss: 0.0730 - val_binary_accuracy: 0.9764 - val_f1: 0.2752 - val_recall: 0.2385 - val_precision: 0.3763\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0708 - binary_accuracy: 0.9775 - f1: 0.4329 - recall: 0.3383 - precision: 0.7076 - val_loss: 0.0716 - val_binary_accuracy: 0.9773 - val_f1: 0.2027 - val_recall: 0.1479 - val_precision: 0.3941\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0699 - binary_accuracy: 0.9778 - f1: 0.4478 - recall: 0.3489 - precision: 0.7169 - val_loss: 0.0697 - val_binary_accuracy: 0.9776 - val_f1: 0.2538 - val_recall: 0.1926 - val_precision: 0.4378\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0694 - binary_accuracy: 0.9780 - f1: 0.4553 - recall: 0.3527 - precision: 0.7352 - val_loss: 0.0706 - val_binary_accuracy: 0.9771 - val_f1: 0.2573 - val_recall: 0.2116 - val_precision: 0.3986\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0690 - binary_accuracy: 0.9781 - f1: 0.4567 - recall: 0.3604 - precision: 0.7337 - val_loss: 0.0699 - val_binary_accuracy: 0.9773 - val_f1: 0.2876 - val_recall: 0.2405 - val_precision: 0.4264\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0681 - binary_accuracy: 0.9783 - f1: 0.4677 - recall: 0.3656 - precision: 0.7427 - val_loss: 0.0713 - val_binary_accuracy: 0.9770 - val_f1: 0.3003 - val_recall: 0.2635 - val_precision: 0.3973\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0673 - binary_accuracy: 0.9786 - f1: 0.4809 - recall: 0.3793 - precision: 0.7643 - val_loss: 0.0690 - val_binary_accuracy: 0.9779 - val_f1: 0.2784 - val_recall: 0.2184 - val_precision: 0.4733\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0669 - binary_accuracy: 0.9787 - f1: 0.4804 - recall: 0.3792 - precision: 0.7435 - val_loss: 0.0698 - val_binary_accuracy: 0.9776 - val_f1: 0.2627 - val_recall: 0.2012 - val_precision: 0.4517\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0662 - binary_accuracy: 0.9791 - f1: 0.4901 - recall: 0.3891 - precision: 0.7585 - val_loss: 0.0698 - val_binary_accuracy: 0.9779 - val_f1: 0.3294 - val_recall: 0.2814 - val_precision: 0.4568\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0651 - binary_accuracy: 0.9794 - f1: 0.4969 - recall: 0.3958 - precision: 0.7532 - val_loss: 0.0689 - val_binary_accuracy: 0.9776 - val_f1: 0.3153 - val_recall: 0.2710 - val_precision: 0.4505\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0644 - binary_accuracy: 0.9795 - f1: 0.5087 - recall: 0.4057 - precision: 0.7715 - val_loss: 0.0685 - val_binary_accuracy: 0.9777 - val_f1: 0.3078 - val_recall: 0.2582 - val_precision: 0.4414\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0637 - binary_accuracy: 0.9797 - f1: 0.5096 - recall: 0.4067 - precision: 0.7745 - val_loss: 0.0680 - val_binary_accuracy: 0.9780 - val_f1: 0.3186 - val_recall: 0.2625 - val_precision: 0.4693\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0630 - binary_accuracy: 0.9800 - f1: 0.5246 - recall: 0.4206 - precision: 0.7857 - val_loss: 0.0682 - val_binary_accuracy: 0.9782 - val_f1: 0.2978 - val_recall: 0.2499 - val_precision: 0.4397\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0622 - binary_accuracy: 0.9803 - f1: 0.5252 - recall: 0.4209 - precision: 0.7835 - val_loss: 0.0682 - val_binary_accuracy: 0.9783 - val_f1: 0.3318 - val_recall: 0.2801 - val_precision: 0.4730\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0621 - binary_accuracy: 0.9802 - f1: 0.5298 - recall: 0.4298 - precision: 0.7796 - val_loss: 0.0704 - val_binary_accuracy: 0.9769 - val_f1: 0.3097 - val_recall: 0.2728 - val_precision: 0.4159\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0617 - binary_accuracy: 0.9805 - f1: 0.5319 - recall: 0.4331 - precision: 0.7744 - val_loss: 0.0681 - val_binary_accuracy: 0.9784 - val_f1: 0.2983 - val_recall: 0.2399 - val_precision: 0.4639\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0604 - binary_accuracy: 0.9809 - f1: 0.5458 - recall: 0.4429 - precision: 0.7987 - val_loss: 0.0693 - val_binary_accuracy: 0.9783 - val_f1: 0.3295 - val_recall: 0.2784 - val_precision: 0.4873\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0597 - binary_accuracy: 0.9811 - f1: 0.5547 - recall: 0.4551 - precision: 0.7937 - val_loss: 0.0687 - val_binary_accuracy: 0.9783 - val_f1: 0.3657 - val_recall: 0.3227 - val_precision: 0.4865\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0593 - binary_accuracy: 0.9811 - f1: 0.5523 - recall: 0.4514 - precision: 0.7971 - val_loss: 0.0672 - val_binary_accuracy: 0.9788 - val_f1: 0.3186 - val_recall: 0.2578 - val_precision: 0.4908\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0584 - binary_accuracy: 0.9817 - f1: 0.5725 - recall: 0.4679 - precision: 0.8195 - val_loss: 0.0676 - val_binary_accuracy: 0.9786 - val_f1: 0.3379 - val_recall: 0.2924 - val_precision: 0.4741\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0577 - binary_accuracy: 0.9817 - f1: 0.5739 - recall: 0.4729 - precision: 0.8061 - val_loss: 0.0669 - val_binary_accuracy: 0.9785 - val_f1: 0.3352 - val_recall: 0.2810 - val_precision: 0.4977\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0569 - binary_accuracy: 0.9819 - f1: 0.5798 - recall: 0.4775 - precision: 0.8177 - val_loss: 0.0690 - val_binary_accuracy: 0.9774 - val_f1: 0.3526 - val_recall: 0.3200 - val_precision: 0.4663\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0564 - binary_accuracy: 0.9820 - f1: 0.5819 - recall: 0.4798 - precision: 0.8145 - val_loss: 0.0668 - val_binary_accuracy: 0.9787 - val_f1: 0.3680 - val_recall: 0.3197 - val_precision: 0.4997\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0557 - binary_accuracy: 0.9825 - f1: 0.5975 - recall: 0.4954 - precision: 0.8247 - val_loss: 0.0676 - val_binary_accuracy: 0.9792 - val_f1: 0.3517 - val_recall: 0.2916 - val_precision: 0.5128\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0550 - binary_accuracy: 0.9824 - f1: 0.5861 - recall: 0.4898 - precision: 0.8082 - val_loss: 0.0694 - val_binary_accuracy: 0.9776 - val_f1: 0.3509 - val_recall: 0.3047 - val_precision: 0.4923\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0543 - binary_accuracy: 0.9827 - f1: 0.5935 - recall: 0.4910 - precision: 0.8161 - val_loss: 0.0709 - val_binary_accuracy: 0.9783 - val_f1: 0.3967 - val_recall: 0.3662 - val_precision: 0.4850\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0538 - binary_accuracy: 0.9829 - f1: 0.6084 - recall: 0.5101 - precision: 0.8288 - val_loss: 0.0676 - val_binary_accuracy: 0.9789 - val_f1: 0.3413 - val_recall: 0.2818 - val_precision: 0.5096\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0532 - binary_accuracy: 0.9833 - f1: 0.6208 - recall: 0.5163 - precision: 0.8461 - val_loss: 0.0675 - val_binary_accuracy: 0.9789 - val_f1: 0.3821 - val_recall: 0.3348 - val_precision: 0.5150\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0522 - binary_accuracy: 0.9833 - f1: 0.6195 - recall: 0.5180 - precision: 0.8373 - val_loss: 0.0681 - val_binary_accuracy: 0.9786 - val_f1: 0.3715 - val_recall: 0.3167 - val_precision: 0.5297\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0518 - binary_accuracy: 0.9837 - f1: 0.6287 - recall: 0.5325 - precision: 0.8345 - val_loss: 0.0682 - val_binary_accuracy: 0.9790 - val_f1: 0.3696 - val_recall: 0.3124 - val_precision: 0.5195\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0515 - binary_accuracy: 0.9836 - f1: 0.6249 - recall: 0.5280 - precision: 0.8366 - val_loss: 0.0686 - val_binary_accuracy: 0.9794 - val_f1: 0.4114 - val_recall: 0.3623 - val_precision: 0.5511\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0501 - binary_accuracy: 0.9841 - f1: 0.6390 - recall: 0.5452 - precision: 0.8447 - val_loss: 0.0684 - val_binary_accuracy: 0.9790 - val_f1: 0.4146 - val_recall: 0.3668 - val_precision: 0.5480\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0499 - binary_accuracy: 0.9843 - f1: 0.6454 - recall: 0.5451 - precision: 0.8588 - val_loss: 0.0689 - val_binary_accuracy: 0.9795 - val_f1: 0.3915 - val_recall: 0.3336 - val_precision: 0.5567\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0491 - binary_accuracy: 0.9845 - f1: 0.6465 - recall: 0.5480 - precision: 0.8508 - val_loss: 0.0693 - val_binary_accuracy: 0.9790 - val_f1: 0.4096 - val_recall: 0.3611 - val_precision: 0.5384\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0485 - binary_accuracy: 0.9846 - f1: 0.6496 - recall: 0.5536 - precision: 0.8511 - val_loss: 0.0684 - val_binary_accuracy: 0.9792 - val_f1: 0.3847 - val_recall: 0.3274 - val_precision: 0.5385\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0476 - binary_accuracy: 0.9849 - f1: 0.6602 - recall: 0.5618 - precision: 0.8619 - val_loss: 0.0717 - val_binary_accuracy: 0.9789 - val_f1: 0.4093 - val_recall: 0.3621 - val_precision: 0.5401\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0466 - binary_accuracy: 0.9852 - f1: 0.6711 - recall: 0.5744 - precision: 0.8651 - val_loss: 0.0710 - val_binary_accuracy: 0.9788 - val_f1: 0.4159 - val_recall: 0.3728 - val_precision: 0.5433\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0466 - binary_accuracy: 0.9852 - f1: 0.6610 - recall: 0.5672 - precision: 0.8482 - val_loss: 0.0704 - val_binary_accuracy: 0.9790 - val_f1: 0.4246 - val_recall: 0.3687 - val_precision: 0.5584\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0456 - binary_accuracy: 0.9857 - f1: 0.6815 - recall: 0.5919 - precision: 0.8682 - val_loss: 0.0728 - val_binary_accuracy: 0.9786 - val_f1: 0.4194 - val_recall: 0.3810 - val_precision: 0.5480\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0449 - binary_accuracy: 0.9856 - f1: 0.6812 - recall: 0.5868 - precision: 0.8685 - val_loss: 0.0718 - val_binary_accuracy: 0.9781 - val_f1: 0.3784 - val_recall: 0.3260 - val_precision: 0.5171\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0445 - binary_accuracy: 0.9860 - f1: 0.6960 - recall: 0.6033 - precision: 0.8766 - val_loss: 0.0732 - val_binary_accuracy: 0.9783 - val_f1: 0.4189 - val_recall: 0.3899 - val_precision: 0.5261\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0440 - binary_accuracy: 0.9860 - f1: 0.6920 - recall: 0.5988 - precision: 0.8820 - val_loss: 0.0726 - val_binary_accuracy: 0.9787 - val_f1: 0.4023 - val_recall: 0.3484 - val_precision: 0.5572\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0431 - binary_accuracy: 0.9863 - f1: 0.7035 - recall: 0.6144 - precision: 0.8753 - val_loss: 0.0711 - val_binary_accuracy: 0.9785 - val_f1: 0.4253 - val_recall: 0.3920 - val_precision: 0.5363\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0425 - binary_accuracy: 0.9866 - f1: 0.7124 - recall: 0.6191 - precision: 0.8895 - val_loss: 0.0712 - val_binary_accuracy: 0.9781 - val_f1: 0.3960 - val_recall: 0.3539 - val_precision: 0.5183\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0417 - binary_accuracy: 0.9867 - f1: 0.7066 - recall: 0.6152 - precision: 0.8824 - val_loss: 0.0756 - val_binary_accuracy: 0.9789 - val_f1: 0.3891 - val_recall: 0.3384 - val_precision: 0.5245\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0412 - binary_accuracy: 0.9867 - f1: 0.7110 - recall: 0.6219 - precision: 0.8812 - val_loss: 0.0764 - val_binary_accuracy: 0.9786 - val_f1: 0.3748 - val_recall: 0.3322 - val_precision: 0.5004\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0409 - binary_accuracy: 0.9871 - f1: 0.7152 - recall: 0.6246 - precision: 0.8868 - val_loss: 0.0758 - val_binary_accuracy: 0.9787 - val_f1: 0.4074 - val_recall: 0.3639 - val_precision: 0.5407\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0396 - binary_accuracy: 0.9873 - f1: 0.7280 - recall: 0.6437 - precision: 0.8855 - val_loss: 0.0778 - val_binary_accuracy: 0.9774 - val_f1: 0.4146 - val_recall: 0.3900 - val_precision: 0.5142\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0392 - binary_accuracy: 0.9876 - f1: 0.7328 - recall: 0.6446 - precision: 0.9001 - val_loss: 0.0763 - val_binary_accuracy: 0.9781 - val_f1: 0.3939 - val_recall: 0.3546 - val_precision: 0.5068\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0384 - binary_accuracy: 0.9876 - f1: 0.7336 - recall: 0.6520 - precision: 0.8901 - val_loss: 0.0773 - val_binary_accuracy: 0.9775 - val_f1: 0.3907 - val_recall: 0.3633 - val_precision: 0.4780\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0379 - binary_accuracy: 0.9878 - f1: 0.7382 - recall: 0.6515 - precision: 0.8978 - val_loss: 0.0754 - val_binary_accuracy: 0.9794 - val_f1: 0.3950 - val_recall: 0.3451 - val_precision: 0.5205\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0374 - binary_accuracy: 0.9880 - f1: 0.7400 - recall: 0.6552 - precision: 0.8981 - val_loss: 0.0794 - val_binary_accuracy: 0.9782 - val_f1: 0.3928 - val_recall: 0.3468 - val_precision: 0.5149\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0362 - binary_accuracy: 0.9883 - f1: 0.7508 - recall: 0.6714 - precision: 0.8969 - val_loss: 0.0789 - val_binary_accuracy: 0.9771 - val_f1: 0.4195 - val_recall: 0.3999 - val_precision: 0.5126\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0361 - binary_accuracy: 0.9884 - f1: 0.7541 - recall: 0.6738 - precision: 0.9021 - val_loss: 0.0777 - val_binary_accuracy: 0.9790 - val_f1: 0.4218 - val_recall: 0.3661 - val_precision: 0.5716\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0355 - binary_accuracy: 0.9887 - f1: 0.7602 - recall: 0.6827 - precision: 0.9039 - val_loss: 0.0783 - val_binary_accuracy: 0.9783 - val_f1: 0.4028 - val_recall: 0.3691 - val_precision: 0.4996\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0349 - binary_accuracy: 0.9889 - f1: 0.7626 - recall: 0.6797 - precision: 0.9070 - val_loss: 0.0794 - val_binary_accuracy: 0.9791 - val_f1: 0.4212 - val_recall: 0.3707 - val_precision: 0.5576\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0342 - binary_accuracy: 0.9892 - f1: 0.7720 - recall: 0.6894 - precision: 0.9173 - val_loss: 0.0792 - val_binary_accuracy: 0.9787 - val_f1: 0.4197 - val_recall: 0.3718 - val_precision: 0.5502\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0333 - binary_accuracy: 0.9891 - f1: 0.7690 - recall: 0.6892 - precision: 0.9102 - val_loss: 0.0816 - val_binary_accuracy: 0.9774 - val_f1: 0.4350 - val_recall: 0.4259 - val_precision: 0.5011\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0329 - binary_accuracy: 0.9896 - f1: 0.7806 - recall: 0.7110 - precision: 0.9117 - val_loss: 0.0811 - val_binary_accuracy: 0.9782 - val_f1: 0.4130 - val_recall: 0.3803 - val_precision: 0.5160\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0320 - binary_accuracy: 0.9896 - f1: 0.7833 - recall: 0.7084 - precision: 0.9130 - val_loss: 0.0830 - val_binary_accuracy: 0.9786 - val_f1: 0.4283 - val_recall: 0.3862 - val_precision: 0.5533\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0314 - binary_accuracy: 0.9899 - f1: 0.7895 - recall: 0.7151 - precision: 0.9177 - val_loss: 0.0819 - val_binary_accuracy: 0.9791 - val_f1: 0.4334 - val_recall: 0.3899 - val_precision: 0.5518\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0309 - binary_accuracy: 0.9902 - f1: 0.7908 - recall: 0.7203 - precision: 0.9176 - val_loss: 0.0875 - val_binary_accuracy: 0.9776 - val_f1: 0.3709 - val_recall: 0.3296 - val_precision: 0.4890\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0313 - binary_accuracy: 0.9898 - f1: 0.7850 - recall: 0.7138 - precision: 0.9112 - val_loss: 0.0838 - val_binary_accuracy: 0.9788 - val_f1: 0.4398 - val_recall: 0.4074 - val_precision: 0.5296\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0300 - binary_accuracy: 0.9905 - f1: 0.8016 - recall: 0.7323 - precision: 0.9185 - val_loss: 0.0857 - val_binary_accuracy: 0.9786 - val_f1: 0.4333 - val_recall: 0.3922 - val_precision: 0.5409\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0292 - binary_accuracy: 0.9908 - f1: 0.8087 - recall: 0.7402 - precision: 0.9252 - val_loss: 0.0867 - val_binary_accuracy: 0.9774 - val_f1: 0.4201 - val_recall: 0.3993 - val_precision: 0.5068\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0289 - binary_accuracy: 0.9907 - f1: 0.8085 - recall: 0.7422 - precision: 0.9239 - val_loss: 0.0903 - val_binary_accuracy: 0.9787 - val_f1: 0.4186 - val_recall: 0.3732 - val_precision: 0.5400\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0283 - binary_accuracy: 0.9912 - f1: 0.8148 - recall: 0.7496 - precision: 0.9229 - val_loss: 0.0906 - val_binary_accuracy: 0.9774 - val_f1: 0.4339 - val_recall: 0.4115 - val_precision: 0.5135\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0280 - binary_accuracy: 0.9910 - f1: 0.8165 - recall: 0.7463 - precision: 0.9309 - val_loss: 0.0903 - val_binary_accuracy: 0.9772 - val_f1: 0.4282 - val_recall: 0.4063 - val_precision: 0.5042\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0270 - binary_accuracy: 0.9914 - f1: 0.8243 - recall: 0.7623 - precision: 0.9312 - val_loss: 0.0930 - val_binary_accuracy: 0.9770 - val_f1: 0.4354 - val_recall: 0.4162 - val_precision: 0.5159\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9911 - f1: 0.8119 - recall: 0.7495 - precision: 0.9206 - val_loss: 0.0909 - val_binary_accuracy: 0.9783 - val_f1: 0.4159 - val_recall: 0.3777 - val_precision: 0.5312\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0257 - binary_accuracy: 0.9918 - f1: 0.8293 - recall: 0.7674 - precision: 0.9358 - val_loss: 0.0931 - val_binary_accuracy: 0.9773 - val_f1: 0.4335 - val_recall: 0.4073 - val_precision: 0.5180\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0255 - binary_accuracy: 0.9920 - f1: 0.8348 - recall: 0.7739 - precision: 0.9330 - val_loss: 0.0945 - val_binary_accuracy: 0.9789 - val_f1: 0.4415 - val_recall: 0.3970 - val_precision: 0.5601\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0255 - binary_accuracy: 0.9919 - f1: 0.8339 - recall: 0.7722 - precision: 0.9373 - val_loss: 0.0932 - val_binary_accuracy: 0.9786 - val_f1: 0.4195 - val_recall: 0.3842 - val_precision: 0.5238\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0245 - binary_accuracy: 0.9923 - f1: 0.8415 - recall: 0.7843 - precision: 0.9375 - val_loss: 0.0989 - val_binary_accuracy: 0.9784 - val_f1: 0.3878 - val_recall: 0.3352 - val_precision: 0.5229\n",
      "37568/37917 [============================>.] - ETA: 0stn = 147188, fp = 105, fn = 1188, tp = 3187\n",
      "y_pred: 0 = 148376 | 1 = 3292\n",
      "y_true: 0 = 147293 | 1 = 4375\n",
      "acc=0.9915|precision=0.9681|recall=0.7285|f1=0.8314|auc=0.9939|aupr=0.9277|pos_acc=0.7285|neg_acc=0.9920\n",
      "tn = 36665, fp = 197, fn = 623, tp = 432\n",
      "y_pred: 0 = 37288 | 1 = 629\n",
      "y_true: 0 = 36862 | 1 = 1055\n",
      "acc=0.9784|precision=0.6868|recall=0.4095|f1=0.5131|auc=0.8979|aupr=0.5265|pos_acc=0.4095|neg_acc=0.9833\n",
      "----------------------- Fold =  1\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0841 - binary_accuracy: 0.9720 - f1: 0.2557 - recall: 0.1862 - precision: 0.5044 - val_loss: 0.0770 - val_binary_accuracy: 0.9759 - val_f1: 0.1046 - val_recall: 0.0733 - val_precision: 0.2021\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0789 - binary_accuracy: 0.9744 - f1: 0.3201 - recall: 0.2378 - precision: 0.6049 - val_loss: 0.0759 - val_binary_accuracy: 0.9763 - val_f1: 0.1571 - val_recall: 0.1219 - val_precision: 0.2460\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0782 - binary_accuracy: 0.9747 - f1: 0.3414 - recall: 0.2560 - precision: 0.6294 - val_loss: 0.0748 - val_binary_accuracy: 0.9762 - val_f1: 0.1738 - val_recall: 0.1409 - val_precision: 0.2471\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0775 - binary_accuracy: 0.9751 - f1: 0.3578 - recall: 0.2695 - precision: 0.6455 - val_loss: 0.0739 - val_binary_accuracy: 0.9769 - val_f1: 0.1604 - val_recall: 0.1160 - val_precision: 0.2879\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0771 - binary_accuracy: 0.9754 - f1: 0.3564 - recall: 0.2673 - precision: 0.6544 - val_loss: 0.0735 - val_binary_accuracy: 0.9774 - val_f1: 0.1613 - val_recall: 0.1174 - val_precision: 0.2890\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0764 - binary_accuracy: 0.9755 - f1: 0.3640 - recall: 0.2762 - precision: 0.6426 - val_loss: 0.0724 - val_binary_accuracy: 0.9772 - val_f1: 0.1895 - val_recall: 0.1442 - val_precision: 0.3066\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0757 - binary_accuracy: 0.9757 - f1: 0.3726 - recall: 0.2787 - precision: 0.6705 - val_loss: 0.0722 - val_binary_accuracy: 0.9772 - val_f1: 0.1819 - val_recall: 0.1303 - val_precision: 0.3370\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0749 - binary_accuracy: 0.9760 - f1: 0.3855 - recall: 0.2894 - precision: 0.6820 - val_loss: 0.0716 - val_binary_accuracy: 0.9777 - val_f1: 0.2303 - val_recall: 0.1806 - val_precision: 0.3565\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0741 - binary_accuracy: 0.9762 - f1: 0.3943 - recall: 0.3056 - precision: 0.6791 - val_loss: 0.0725 - val_binary_accuracy: 0.9771 - val_f1: 0.2279 - val_recall: 0.1818 - val_precision: 0.3506\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0732 - binary_accuracy: 0.9764 - f1: 0.4074 - recall: 0.3105 - precision: 0.6964 - val_loss: 0.0714 - val_binary_accuracy: 0.9771 - val_f1: 0.2352 - val_recall: 0.1967 - val_precision: 0.3272\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0729 - binary_accuracy: 0.9768 - f1: 0.4129 - recall: 0.3171 - precision: 0.6991 - val_loss: 0.0708 - val_binary_accuracy: 0.9775 - val_f1: 0.2234 - val_recall: 0.1731 - val_precision: 0.3489\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0720 - binary_accuracy: 0.9769 - f1: 0.4253 - recall: 0.3290 - precision: 0.7014 - val_loss: 0.0701 - val_binary_accuracy: 0.9781 - val_f1: 0.1978 - val_recall: 0.1464 - val_precision: 0.3434\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0713 - binary_accuracy: 0.9770 - f1: 0.4244 - recall: 0.3295 - precision: 0.6986 - val_loss: 0.0704 - val_binary_accuracy: 0.9778 - val_f1: 0.2667 - val_recall: 0.2179 - val_precision: 0.3895\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0706 - binary_accuracy: 0.9775 - f1: 0.4373 - recall: 0.3366 - precision: 0.7237 - val_loss: 0.0700 - val_binary_accuracy: 0.9773 - val_f1: 0.2256 - val_recall: 0.1841 - val_precision: 0.3258\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0701 - binary_accuracy: 0.9776 - f1: 0.4524 - recall: 0.3528 - precision: 0.7283 - val_loss: 0.0700 - val_binary_accuracy: 0.9778 - val_f1: 0.2866 - val_recall: 0.2454 - val_precision: 0.3786\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0695 - binary_accuracy: 0.9779 - f1: 0.4564 - recall: 0.3550 - precision: 0.7245 - val_loss: 0.0712 - val_binary_accuracy: 0.9774 - val_f1: 0.2315 - val_recall: 0.1826 - val_precision: 0.3647\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0688 - binary_accuracy: 0.9782 - f1: 0.4645 - recall: 0.3674 - precision: 0.7335 - val_loss: 0.0700 - val_binary_accuracy: 0.9781 - val_f1: 0.2612 - val_recall: 0.2091 - val_precision: 0.3902\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0676 - binary_accuracy: 0.9785 - f1: 0.4736 - recall: 0.3734 - precision: 0.7397 - val_loss: 0.0687 - val_binary_accuracy: 0.9782 - val_f1: 0.2556 - val_recall: 0.2080 - val_precision: 0.3747\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0675 - binary_accuracy: 0.9785 - f1: 0.4796 - recall: 0.3801 - precision: 0.7504 - val_loss: 0.0698 - val_binary_accuracy: 0.9781 - val_f1: 0.2320 - val_recall: 0.1841 - val_precision: 0.3607\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0667 - binary_accuracy: 0.9788 - f1: 0.4857 - recall: 0.3844 - precision: 0.7537 - val_loss: 0.0755 - val_binary_accuracy: 0.9753 - val_f1: 0.3418 - val_recall: 0.3517 - val_precision: 0.3689\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0661 - binary_accuracy: 0.9792 - f1: 0.5020 - recall: 0.3999 - precision: 0.7701 - val_loss: 0.0667 - val_binary_accuracy: 0.9789 - val_f1: 0.2623 - val_recall: 0.2014 - val_precision: 0.4241\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0652 - binary_accuracy: 0.9794 - f1: 0.5063 - recall: 0.4030 - precision: 0.7742 - val_loss: 0.0682 - val_binary_accuracy: 0.9785 - val_f1: 0.2283 - val_recall: 0.1741 - val_precision: 0.3800\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0645 - binary_accuracy: 0.9795 - f1: 0.5106 - recall: 0.4123 - precision: 0.7633 - val_loss: 0.0674 - val_binary_accuracy: 0.9785 - val_f1: 0.2983 - val_recall: 0.2434 - val_precision: 0.4373\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0638 - binary_accuracy: 0.9799 - f1: 0.5194 - recall: 0.4150 - precision: 0.7739 - val_loss: 0.0701 - val_binary_accuracy: 0.9780 - val_f1: 0.2961 - val_recall: 0.2490 - val_precision: 0.4167\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0629 - binary_accuracy: 0.9801 - f1: 0.5263 - recall: 0.4220 - precision: 0.7853 - val_loss: 0.0673 - val_binary_accuracy: 0.9792 - val_f1: 0.3309 - val_recall: 0.2829 - val_precision: 0.4463\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0624 - binary_accuracy: 0.9804 - f1: 0.5362 - recall: 0.4322 - precision: 0.7805 - val_loss: 0.0666 - val_binary_accuracy: 0.9786 - val_f1: 0.3299 - val_recall: 0.2818 - val_precision: 0.4485\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9805 - f1: 0.5432 - recall: 0.4401 - precision: 0.7948 - val_loss: 0.0677 - val_binary_accuracy: 0.9790 - val_f1: 0.2908 - val_recall: 0.2376 - val_precision: 0.4375\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0610 - binary_accuracy: 0.9806 - f1: 0.5429 - recall: 0.4435 - precision: 0.7839 - val_loss: 0.0667 - val_binary_accuracy: 0.9788 - val_f1: 0.3327 - val_recall: 0.2740 - val_precision: 0.4974\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0602 - binary_accuracy: 0.9810 - f1: 0.5554 - recall: 0.4520 - precision: 0.8063 - val_loss: 0.0684 - val_binary_accuracy: 0.9788 - val_f1: 0.3505 - val_recall: 0.3129 - val_precision: 0.4736\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0592 - binary_accuracy: 0.9813 - f1: 0.5601 - recall: 0.4592 - precision: 0.7977 - val_loss: 0.0675 - val_binary_accuracy: 0.9786 - val_f1: 0.3157 - val_recall: 0.2599 - val_precision: 0.4529\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0590 - binary_accuracy: 0.9815 - f1: 0.5687 - recall: 0.4662 - precision: 0.8044 - val_loss: 0.0668 - val_binary_accuracy: 0.9792 - val_f1: 0.3023 - val_recall: 0.2386 - val_precision: 0.4744\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0585 - binary_accuracy: 0.9817 - f1: 0.5700 - recall: 0.4677 - precision: 0.8088 - val_loss: 0.0664 - val_binary_accuracy: 0.9792 - val_f1: 0.3435 - val_recall: 0.3003 - val_precision: 0.4578\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0573 - binary_accuracy: 0.9819 - f1: 0.5771 - recall: 0.4739 - precision: 0.8126 - val_loss: 0.0664 - val_binary_accuracy: 0.9791 - val_f1: 0.3323 - val_recall: 0.2730 - val_precision: 0.4752\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0563 - binary_accuracy: 0.9821 - f1: 0.5867 - recall: 0.4851 - precision: 0.8234 - val_loss: 0.0673 - val_binary_accuracy: 0.9790 - val_f1: 0.3128 - val_recall: 0.2601 - val_precision: 0.4610\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0561 - binary_accuracy: 0.9822 - f1: 0.5920 - recall: 0.4893 - precision: 0.8265 - val_loss: 0.0664 - val_binary_accuracy: 0.9788 - val_f1: 0.3321 - val_recall: 0.2838 - val_precision: 0.4673\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0551 - binary_accuracy: 0.9825 - f1: 0.6040 - recall: 0.5035 - precision: 0.8254 - val_loss: 0.0674 - val_binary_accuracy: 0.9790 - val_f1: 0.3388 - val_recall: 0.2839 - val_precision: 0.4882\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0544 - binary_accuracy: 0.9829 - f1: 0.6070 - recall: 0.5059 - precision: 0.8305 - val_loss: 0.0670 - val_binary_accuracy: 0.9791 - val_f1: 0.3553 - val_recall: 0.3042 - val_precision: 0.4921\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0542 - binary_accuracy: 0.9828 - f1: 0.6044 - recall: 0.5046 - precision: 0.8265 - val_loss: 0.0660 - val_binary_accuracy: 0.9789 - val_f1: 0.3442 - val_recall: 0.2879 - val_precision: 0.4887\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0530 - binary_accuracy: 0.9829 - f1: 0.6118 - recall: 0.5128 - precision: 0.8261 - val_loss: 0.0668 - val_binary_accuracy: 0.9790 - val_f1: 0.3700 - val_recall: 0.3232 - val_precision: 0.4862\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0523 - binary_accuracy: 0.9834 - f1: 0.6307 - recall: 0.5340 - precision: 0.8459 - val_loss: 0.0666 - val_binary_accuracy: 0.9793 - val_f1: 0.3583 - val_recall: 0.3075 - val_precision: 0.4970\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0515 - binary_accuracy: 0.9836 - f1: 0.6259 - recall: 0.5299 - precision: 0.8323 - val_loss: 0.0703 - val_binary_accuracy: 0.9790 - val_f1: 0.3132 - val_recall: 0.2607 - val_precision: 0.4424\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0511 - binary_accuracy: 0.9837 - f1: 0.6369 - recall: 0.5403 - precision: 0.8380 - val_loss: 0.0663 - val_binary_accuracy: 0.9798 - val_f1: 0.3623 - val_recall: 0.3048 - val_precision: 0.5000\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0503 - binary_accuracy: 0.9841 - f1: 0.6374 - recall: 0.5412 - precision: 0.8451 - val_loss: 0.0715 - val_binary_accuracy: 0.9776 - val_f1: 0.3601 - val_recall: 0.3392 - val_precision: 0.4279\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0496 - binary_accuracy: 0.9844 - f1: 0.6527 - recall: 0.5543 - precision: 0.8535 - val_loss: 0.0664 - val_binary_accuracy: 0.9791 - val_f1: 0.3638 - val_recall: 0.3183 - val_precision: 0.4834\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0488 - binary_accuracy: 0.9846 - f1: 0.6571 - recall: 0.5642 - precision: 0.8482 - val_loss: 0.0689 - val_binary_accuracy: 0.9795 - val_f1: 0.3773 - val_recall: 0.3258 - val_precision: 0.5110\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0483 - binary_accuracy: 0.9847 - f1: 0.6581 - recall: 0.5621 - precision: 0.8583 - val_loss: 0.0704 - val_binary_accuracy: 0.9787 - val_f1: 0.3555 - val_recall: 0.3167 - val_precision: 0.4521\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0478 - binary_accuracy: 0.9846 - f1: 0.6534 - recall: 0.5548 - precision: 0.8484 - val_loss: 0.0703 - val_binary_accuracy: 0.9780 - val_f1: 0.3758 - val_recall: 0.3324 - val_precision: 0.4826\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0469 - binary_accuracy: 0.9849 - f1: 0.6666 - recall: 0.5687 - precision: 0.8653 - val_loss: 0.0691 - val_binary_accuracy: 0.9793 - val_f1: 0.4104 - val_recall: 0.3597 - val_precision: 0.5391\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0466 - binary_accuracy: 0.9851 - f1: 0.6710 - recall: 0.5776 - precision: 0.8589 - val_loss: 0.0685 - val_binary_accuracy: 0.9790 - val_f1: 0.3660 - val_recall: 0.3154 - val_precision: 0.4891\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0457 - binary_accuracy: 0.9852 - f1: 0.6778 - recall: 0.5826 - precision: 0.8671 - val_loss: 0.0688 - val_binary_accuracy: 0.9798 - val_f1: 0.3878 - val_recall: 0.3360 - val_precision: 0.5144\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0448 - binary_accuracy: 0.9857 - f1: 0.6867 - recall: 0.5938 - precision: 0.8763 - val_loss: 0.0724 - val_binary_accuracy: 0.9780 - val_f1: 0.3601 - val_recall: 0.3146 - val_precision: 0.4686\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0443 - binary_accuracy: 0.9858 - f1: 0.6878 - recall: 0.5934 - precision: 0.8680 - val_loss: 0.0701 - val_binary_accuracy: 0.9790 - val_f1: 0.3907 - val_recall: 0.3466 - val_precision: 0.4997\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0431 - binary_accuracy: 0.9862 - f1: 0.6978 - recall: 0.6033 - precision: 0.8770 - val_loss: 0.0696 - val_binary_accuracy: 0.9791 - val_f1: 0.3790 - val_recall: 0.3370 - val_precision: 0.4822\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0426 - binary_accuracy: 0.9863 - f1: 0.7023 - recall: 0.6132 - precision: 0.8758 - val_loss: 0.0709 - val_binary_accuracy: 0.9781 - val_f1: 0.3391 - val_recall: 0.2918 - val_precision: 0.4455\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9866 - f1: 0.7088 - recall: 0.6199 - precision: 0.8820 - val_loss: 0.0730 - val_binary_accuracy: 0.9788 - val_f1: 0.3647 - val_recall: 0.3179 - val_precision: 0.4830\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0415 - binary_accuracy: 0.9867 - f1: 0.7204 - recall: 0.6318 - precision: 0.8882 - val_loss: 0.0719 - val_binary_accuracy: 0.9790 - val_f1: 0.3888 - val_recall: 0.3418 - val_precision: 0.4999\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0405 - binary_accuracy: 0.9870 - f1: 0.7174 - recall: 0.6296 - precision: 0.8844 - val_loss: 0.0713 - val_binary_accuracy: 0.9794 - val_f1: 0.4012 - val_recall: 0.3515 - val_precision: 0.5235\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0399 - binary_accuracy: 0.9874 - f1: 0.7298 - recall: 0.6424 - precision: 0.8902 - val_loss: 0.0720 - val_binary_accuracy: 0.9788 - val_f1: 0.4004 - val_recall: 0.3580 - val_precision: 0.5052\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0391 - binary_accuracy: 0.9876 - f1: 0.7350 - recall: 0.6480 - precision: 0.8942 - val_loss: 0.0740 - val_binary_accuracy: 0.9786 - val_f1: 0.3669 - val_recall: 0.3245 - val_precision: 0.4663\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0390 - binary_accuracy: 0.9877 - f1: 0.7384 - recall: 0.6532 - precision: 0.8994 - val_loss: 0.0748 - val_binary_accuracy: 0.9785 - val_f1: 0.4064 - val_recall: 0.3721 - val_precision: 0.4954\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0378 - binary_accuracy: 0.9879 - f1: 0.7426 - recall: 0.6601 - precision: 0.8930 - val_loss: 0.0748 - val_binary_accuracy: 0.9777 - val_f1: 0.3824 - val_recall: 0.3408 - val_precision: 0.4894\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0373 - binary_accuracy: 0.9879 - f1: 0.7462 - recall: 0.6642 - precision: 0.8949 - val_loss: 0.0747 - val_binary_accuracy: 0.9777 - val_f1: 0.3898 - val_recall: 0.3547 - val_precision: 0.4834\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0363 - binary_accuracy: 0.9884 - f1: 0.7571 - recall: 0.6765 - precision: 0.9036 - val_loss: 0.0761 - val_binary_accuracy: 0.9776 - val_f1: 0.3949 - val_recall: 0.3697 - val_precision: 0.4701\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0358 - binary_accuracy: 0.9885 - f1: 0.7550 - recall: 0.6775 - precision: 0.8997 - val_loss: 0.0769 - val_binary_accuracy: 0.9784 - val_f1: 0.3688 - val_recall: 0.3177 - val_precision: 0.4846\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0355 - binary_accuracy: 0.9885 - f1: 0.7589 - recall: 0.6799 - precision: 0.9010 - val_loss: 0.0763 - val_binary_accuracy: 0.9792 - val_f1: 0.3592 - val_recall: 0.3026 - val_precision: 0.4832\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0341 - binary_accuracy: 0.9890 - f1: 0.7698 - recall: 0.6944 - precision: 0.9087 - val_loss: 0.0768 - val_binary_accuracy: 0.9785 - val_f1: 0.4036 - val_recall: 0.3809 - val_precision: 0.4781\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0336 - binary_accuracy: 0.9892 - f1: 0.7700 - recall: 0.6939 - precision: 0.9040 - val_loss: 0.0789 - val_binary_accuracy: 0.9789 - val_f1: 0.3985 - val_recall: 0.3608 - val_precision: 0.4867\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0334 - binary_accuracy: 0.9894 - f1: 0.7752 - recall: 0.7002 - precision: 0.9094 - val_loss: 0.0785 - val_binary_accuracy: 0.9781 - val_f1: 0.4154 - val_recall: 0.3934 - val_precision: 0.4918\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0330 - binary_accuracy: 0.9896 - f1: 0.7835 - recall: 0.7086 - precision: 0.9125 - val_loss: 0.0783 - val_binary_accuracy: 0.9784 - val_f1: 0.3859 - val_recall: 0.3457 - val_precision: 0.4909\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0319 - binary_accuracy: 0.9899 - f1: 0.7849 - recall: 0.7155 - precision: 0.9039 - val_loss: 0.0801 - val_binary_accuracy: 0.9785 - val_f1: 0.3770 - val_recall: 0.3348 - val_precision: 0.4853\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0317 - binary_accuracy: 0.9897 - f1: 0.7898 - recall: 0.7231 - precision: 0.9067 - val_loss: 0.0787 - val_binary_accuracy: 0.9783 - val_f1: 0.3870 - val_recall: 0.3528 - val_precision: 0.4817\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0305 - binary_accuracy: 0.9903 - f1: 0.8015 - recall: 0.7319 - precision: 0.9261 - val_loss: 0.0825 - val_binary_accuracy: 0.9769 - val_f1: 0.3956 - val_recall: 0.3811 - val_precision: 0.4526\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0300 - binary_accuracy: 0.9904 - f1: 0.8004 - recall: 0.7306 - precision: 0.9199 - val_loss: 0.0826 - val_binary_accuracy: 0.9785 - val_f1: 0.3994 - val_recall: 0.3667 - val_precision: 0.4853\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0290 - binary_accuracy: 0.9911 - f1: 0.8181 - recall: 0.7498 - precision: 0.9269 - val_loss: 0.0814 - val_binary_accuracy: 0.9779 - val_f1: 0.3868 - val_recall: 0.3477 - val_precision: 0.4809\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0292 - binary_accuracy: 0.9905 - f1: 0.8070 - recall: 0.7440 - precision: 0.9174 - val_loss: 0.0836 - val_binary_accuracy: 0.9775 - val_f1: 0.4360 - val_recall: 0.4378 - val_precision: 0.4789\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0283 - binary_accuracy: 0.9911 - f1: 0.8153 - recall: 0.7518 - precision: 0.9237 - val_loss: 0.0900 - val_binary_accuracy: 0.9778 - val_f1: 0.4000 - val_recall: 0.3663 - val_precision: 0.4947\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0280 - binary_accuracy: 0.9910 - f1: 0.8161 - recall: 0.7522 - precision: 0.9204 - val_loss: 0.0845 - val_binary_accuracy: 0.9787 - val_f1: 0.4097 - val_recall: 0.3785 - val_precision: 0.4894\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0272 - binary_accuracy: 0.9915 - f1: 0.8268 - recall: 0.7628 - precision: 0.9321 - val_loss: 0.0847 - val_binary_accuracy: 0.9777 - val_f1: 0.3883 - val_recall: 0.3500 - val_precision: 0.4881\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0265 - binary_accuracy: 0.9915 - f1: 0.8227 - recall: 0.7599 - precision: 0.9274 - val_loss: 0.0866 - val_binary_accuracy: 0.9774 - val_f1: 0.4609 - val_recall: 0.4718 - val_precision: 0.4904\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0262 - binary_accuracy: 0.9916 - f1: 0.8280 - recall: 0.7673 - precision: 0.9298 - val_loss: 0.0870 - val_binary_accuracy: 0.9791 - val_f1: 0.4141 - val_recall: 0.3677 - val_precision: 0.5288\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0252 - binary_accuracy: 0.9920 - f1: 0.8335 - recall: 0.7760 - precision: 0.9276 - val_loss: 0.0905 - val_binary_accuracy: 0.9785 - val_f1: 0.3789 - val_recall: 0.3381 - val_precision: 0.4869\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0246 - binary_accuracy: 0.9920 - f1: 0.8374 - recall: 0.7788 - precision: 0.9333 - val_loss: 0.0915 - val_binary_accuracy: 0.9772 - val_f1: 0.4253 - val_recall: 0.4325 - val_precision: 0.4643\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0251 - binary_accuracy: 0.9922 - f1: 0.8383 - recall: 0.7778 - precision: 0.9350 - val_loss: 0.0896 - val_binary_accuracy: 0.9781 - val_f1: 0.4220 - val_recall: 0.3847 - val_precision: 0.5066\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0237 - binary_accuracy: 0.9925 - f1: 0.8520 - recall: 0.7972 - precision: 0.9368 - val_loss: 0.0905 - val_binary_accuracy: 0.9778 - val_f1: 0.4225 - val_recall: 0.3954 - val_precision: 0.4962\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0234 - binary_accuracy: 0.9925 - f1: 0.8507 - recall: 0.7965 - precision: 0.9409 - val_loss: 0.0954 - val_binary_accuracy: 0.9761 - val_f1: 0.4325 - val_recall: 0.4372 - val_precision: 0.4714\n",
      "Epoch 86/500\n",
      "9s - loss: 0.0233 - binary_accuracy: 0.9927 - f1: 0.8556 - recall: 0.8067 - precision: 0.9389 - val_loss: 0.0939 - val_binary_accuracy: 0.9773 - val_f1: 0.4065 - val_recall: 0.3845 - val_precision: 0.4681\n",
      "Epoch 87/500\n",
      "9s - loss: 0.0225 - binary_accuracy: 0.9927 - f1: 0.8541 - recall: 0.8036 - precision: 0.9359 - val_loss: 0.0929 - val_binary_accuracy: 0.9782 - val_f1: 0.3899 - val_recall: 0.3505 - val_precision: 0.4793\n",
      "Epoch 88/500\n",
      "10s - loss: 0.0214 - binary_accuracy: 0.9934 - f1: 0.8684 - recall: 0.8150 - precision: 0.9539 - val_loss: 0.0958 - val_binary_accuracy: 0.9763 - val_f1: 0.4228 - val_recall: 0.4184 - val_precision: 0.4694\n",
      "Epoch 89/500\n",
      "9s - loss: 0.0225 - binary_accuracy: 0.9929 - f1: 0.8601 - recall: 0.8152 - precision: 0.9354 - val_loss: 0.0927 - val_binary_accuracy: 0.9774 - val_f1: 0.4299 - val_recall: 0.4132 - val_precision: 0.5037\n",
      "37888/37917 [============================>.] - ETA: 0stn = 147106, fp = 160, fn = 616, tp = 3786\n",
      "y_pred: 0 = 147722 | 1 = 3946\n",
      "y_true: 0 = 147266 | 1 = 4402\n",
      "acc=0.9949|precision=0.9595|recall=0.8601|f1=0.9070|auc=0.9970|aupr=0.9615|pos_acc=0.8601|neg_acc=0.9958\n",
      "tn = 36553, fp = 336, fn = 520, tp = 508\n",
      "y_pred: 0 = 37073 | 1 = 844\n",
      "y_true: 0 = 36889 | 1 = 1028\n",
      "acc=0.9774|precision=0.6019|recall=0.4942|f1=0.5427|auc=0.9078|aupr=0.5421|pos_acc=0.4942|neg_acc=0.9860\n",
      "----------------------- Fold =  2\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "10s - loss: 0.0824 - binary_accuracy: 0.9731 - f1: 0.2537 - recall: 0.1842 - precision: 0.5117 - val_loss: 0.0803 - val_binary_accuracy: 0.9737 - val_f1: 0.1773 - val_recall: 0.1427 - val_precision: 0.2647\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0778 - binary_accuracy: 0.9750 - f1: 0.3261 - recall: 0.2409 - precision: 0.6192 - val_loss: 0.0792 - val_binary_accuracy: 0.9742 - val_f1: 0.1460 - val_recall: 0.0994 - val_precision: 0.3210\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0768 - binary_accuracy: 0.9756 - f1: 0.3510 - recall: 0.2610 - precision: 0.6520 - val_loss: 0.0793 - val_binary_accuracy: 0.9743 - val_f1: 0.2253 - val_recall: 0.1868 - val_precision: 0.3185\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0765 - binary_accuracy: 0.9755 - f1: 0.3467 - recall: 0.2616 - precision: 0.6281 - val_loss: 0.0819 - val_binary_accuracy: 0.9739 - val_f1: 0.1157 - val_recall: 0.0726 - val_precision: 0.3320\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0754 - binary_accuracy: 0.9757 - f1: 0.3597 - recall: 0.2694 - precision: 0.6630 - val_loss: 0.0790 - val_binary_accuracy: 0.9749 - val_f1: 0.2429 - val_recall: 0.1980 - val_precision: 0.3683\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0750 - binary_accuracy: 0.9760 - f1: 0.3682 - recall: 0.2793 - precision: 0.6551 - val_loss: 0.0786 - val_binary_accuracy: 0.9753 - val_f1: 0.2080 - val_recall: 0.1547 - val_precision: 0.3718\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0740 - binary_accuracy: 0.9764 - f1: 0.3847 - recall: 0.2929 - precision: 0.6684 - val_loss: 0.0776 - val_binary_accuracy: 0.9754 - val_f1: 0.2205 - val_recall: 0.1677 - val_precision: 0.3857\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0734 - binary_accuracy: 0.9768 - f1: 0.3998 - recall: 0.3077 - precision: 0.6726 - val_loss: 0.0804 - val_binary_accuracy: 0.9749 - val_f1: 0.1687 - val_recall: 0.1217 - val_precision: 0.3285\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0728 - binary_accuracy: 0.9768 - f1: 0.4003 - recall: 0.3046 - precision: 0.6869 - val_loss: 0.0774 - val_binary_accuracy: 0.9755 - val_f1: 0.2085 - val_recall: 0.1655 - val_precision: 0.3263\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0719 - binary_accuracy: 0.9772 - f1: 0.4131 - recall: 0.3165 - precision: 0.6993 - val_loss: 0.0764 - val_binary_accuracy: 0.9759 - val_f1: 0.2195 - val_recall: 0.1659 - val_precision: 0.3924\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0715 - binary_accuracy: 0.9775 - f1: 0.4199 - recall: 0.3248 - precision: 0.7016 - val_loss: 0.0760 - val_binary_accuracy: 0.9756 - val_f1: 0.3220 - val_recall: 0.2728 - val_precision: 0.4379\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0707 - binary_accuracy: 0.9775 - f1: 0.4288 - recall: 0.3337 - precision: 0.6944 - val_loss: 0.0769 - val_binary_accuracy: 0.9758 - val_f1: 0.2215 - val_recall: 0.1660 - val_precision: 0.4127\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0698 - binary_accuracy: 0.9780 - f1: 0.4444 - recall: 0.3420 - precision: 0.7342 - val_loss: 0.0768 - val_binary_accuracy: 0.9754 - val_f1: 0.3016 - val_recall: 0.2502 - val_precision: 0.4315\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0697 - binary_accuracy: 0.9780 - f1: 0.4386 - recall: 0.3423 - precision: 0.7210 - val_loss: 0.0764 - val_binary_accuracy: 0.9759 - val_f1: 0.2435 - val_recall: 0.2004 - val_precision: 0.3636\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0688 - binary_accuracy: 0.9782 - f1: 0.4522 - recall: 0.3549 - precision: 0.7281 - val_loss: 0.0755 - val_binary_accuracy: 0.9762 - val_f1: 0.3147 - val_recall: 0.2587 - val_precision: 0.4719\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0679 - binary_accuracy: 0.9785 - f1: 0.4611 - recall: 0.3634 - precision: 0.7255 - val_loss: 0.0751 - val_binary_accuracy: 0.9763 - val_f1: 0.3319 - val_recall: 0.2831 - val_precision: 0.4503\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0675 - binary_accuracy: 0.9786 - f1: 0.4652 - recall: 0.3675 - precision: 0.7330 - val_loss: 0.0746 - val_binary_accuracy: 0.9767 - val_f1: 0.3058 - val_recall: 0.2406 - val_precision: 0.4958\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0667 - binary_accuracy: 0.9790 - f1: 0.4786 - recall: 0.3825 - precision: 0.7387 - val_loss: 0.0737 - val_binary_accuracy: 0.9765 - val_f1: 0.3227 - val_recall: 0.2645 - val_precision: 0.4884\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0659 - binary_accuracy: 0.9791 - f1: 0.4824 - recall: 0.3826 - precision: 0.7476 - val_loss: 0.0754 - val_binary_accuracy: 0.9766 - val_f1: 0.3252 - val_recall: 0.2666 - val_precision: 0.4895\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0652 - binary_accuracy: 0.9791 - f1: 0.4836 - recall: 0.3849 - precision: 0.7524 - val_loss: 0.0741 - val_binary_accuracy: 0.9768 - val_f1: 0.2914 - val_recall: 0.2281 - val_precision: 0.4796\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0643 - binary_accuracy: 0.9796 - f1: 0.5109 - recall: 0.4091 - precision: 0.7612 - val_loss: 0.0735 - val_binary_accuracy: 0.9768 - val_f1: 0.3386 - val_recall: 0.2826 - val_precision: 0.4751\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0642 - binary_accuracy: 0.9797 - f1: 0.4993 - recall: 0.3958 - precision: 0.7655 - val_loss: 0.0789 - val_binary_accuracy: 0.9755 - val_f1: 0.3581 - val_recall: 0.3144 - val_precision: 0.4888\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0633 - binary_accuracy: 0.9799 - f1: 0.5075 - recall: 0.4046 - precision: 0.7604 - val_loss: 0.0745 - val_binary_accuracy: 0.9767 - val_f1: 0.3807 - val_recall: 0.3388 - val_precision: 0.5172\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0628 - binary_accuracy: 0.9799 - f1: 0.5110 - recall: 0.4103 - precision: 0.7695 - val_loss: 0.0742 - val_binary_accuracy: 0.9768 - val_f1: 0.3349 - val_recall: 0.2721 - val_precision: 0.5242\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0615 - binary_accuracy: 0.9806 - f1: 0.5297 - recall: 0.4239 - precision: 0.7898 - val_loss: 0.0731 - val_binary_accuracy: 0.9774 - val_f1: 0.3551 - val_recall: 0.2980 - val_precision: 0.5094\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0612 - binary_accuracy: 0.9804 - f1: 0.5249 - recall: 0.4283 - precision: 0.7663 - val_loss: 0.0803 - val_binary_accuracy: 0.9730 - val_f1: 0.3552 - val_recall: 0.3224 - val_precision: 0.4460\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0606 - binary_accuracy: 0.9809 - f1: 0.5368 - recall: 0.4366 - precision: 0.7875 - val_loss: 0.0749 - val_binary_accuracy: 0.9757 - val_f1: 0.4119 - val_recall: 0.3816 - val_precision: 0.5129\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0594 - binary_accuracy: 0.9809 - f1: 0.5467 - recall: 0.4452 - precision: 0.7967 - val_loss: 0.0733 - val_binary_accuracy: 0.9777 - val_f1: 0.3791 - val_recall: 0.3217 - val_precision: 0.5672\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0590 - binary_accuracy: 0.9815 - f1: 0.5550 - recall: 0.4507 - precision: 0.8074 - val_loss: 0.0725 - val_binary_accuracy: 0.9772 - val_f1: 0.3891 - val_recall: 0.3374 - val_precision: 0.5417\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0582 - binary_accuracy: 0.9816 - f1: 0.5622 - recall: 0.4601 - precision: 0.8026 - val_loss: 0.0730 - val_binary_accuracy: 0.9767 - val_f1: 0.4000 - val_recall: 0.3482 - val_precision: 0.5487\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0574 - binary_accuracy: 0.9816 - f1: 0.5587 - recall: 0.4597 - precision: 0.7909 - val_loss: 0.0741 - val_binary_accuracy: 0.9772 - val_f1: 0.3233 - val_recall: 0.2604 - val_precision: 0.4892\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0567 - binary_accuracy: 0.9821 - f1: 0.5793 - recall: 0.4752 - precision: 0.8140 - val_loss: 0.0765 - val_binary_accuracy: 0.9772 - val_f1: 0.3544 - val_recall: 0.2928 - val_precision: 0.5335\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0565 - binary_accuracy: 0.9822 - f1: 0.5805 - recall: 0.4799 - precision: 0.8098 - val_loss: 0.0743 - val_binary_accuracy: 0.9772 - val_f1: 0.3971 - val_recall: 0.3399 - val_precision: 0.5535\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0552 - binary_accuracy: 0.9829 - f1: 0.5941 - recall: 0.4913 - precision: 0.8268 - val_loss: 0.0741 - val_binary_accuracy: 0.9762 - val_f1: 0.3947 - val_recall: 0.3431 - val_precision: 0.5235\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0548 - binary_accuracy: 0.9829 - f1: 0.5996 - recall: 0.4962 - precision: 0.8272 - val_loss: 0.0717 - val_binary_accuracy: 0.9781 - val_f1: 0.4403 - val_recall: 0.3809 - val_precision: 0.5995\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0537 - binary_accuracy: 0.9830 - f1: 0.6049 - recall: 0.5064 - precision: 0.8190 - val_loss: 0.0740 - val_binary_accuracy: 0.9774 - val_f1: 0.3405 - val_recall: 0.2733 - val_precision: 0.5251\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0534 - binary_accuracy: 0.9832 - f1: 0.6022 - recall: 0.5029 - precision: 0.8257 - val_loss: 0.0736 - val_binary_accuracy: 0.9776 - val_f1: 0.4163 - val_recall: 0.3507 - val_precision: 0.5919\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0527 - binary_accuracy: 0.9835 - f1: 0.6126 - recall: 0.5113 - precision: 0.8323 - val_loss: 0.0737 - val_binary_accuracy: 0.9765 - val_f1: 0.4226 - val_recall: 0.3754 - val_precision: 0.5444\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0520 - binary_accuracy: 0.9836 - f1: 0.6198 - recall: 0.5224 - precision: 0.8287 - val_loss: 0.0726 - val_binary_accuracy: 0.9776 - val_f1: 0.4389 - val_recall: 0.3918 - val_precision: 0.5770\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0516 - binary_accuracy: 0.9840 - f1: 0.6282 - recall: 0.5307 - precision: 0.8427 - val_loss: 0.0780 - val_binary_accuracy: 0.9776 - val_f1: 0.3267 - val_recall: 0.2583 - val_precision: 0.5367\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0508 - binary_accuracy: 0.9838 - f1: 0.6284 - recall: 0.5311 - precision: 0.8366 - val_loss: 0.0763 - val_binary_accuracy: 0.9776 - val_f1: 0.4163 - val_recall: 0.3587 - val_precision: 0.5704\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0501 - binary_accuracy: 0.9843 - f1: 0.6412 - recall: 0.5441 - precision: 0.8528 - val_loss: 0.0743 - val_binary_accuracy: 0.9768 - val_f1: 0.4240 - val_recall: 0.3795 - val_precision: 0.5520\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0495 - binary_accuracy: 0.9845 - f1: 0.6421 - recall: 0.5432 - precision: 0.8502 - val_loss: 0.0736 - val_binary_accuracy: 0.9778 - val_f1: 0.4345 - val_recall: 0.3800 - val_precision: 0.5762\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0490 - binary_accuracy: 0.9847 - f1: 0.6460 - recall: 0.5475 - precision: 0.8597 - val_loss: 0.0732 - val_binary_accuracy: 0.9777 - val_f1: 0.4277 - val_recall: 0.3629 - val_precision: 0.6004\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0484 - binary_accuracy: 0.9847 - f1: 0.6455 - recall: 0.5506 - precision: 0.8469 - val_loss: 0.0755 - val_binary_accuracy: 0.9774 - val_f1: 0.4334 - val_recall: 0.3736 - val_precision: 0.5745\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0477 - binary_accuracy: 0.9851 - f1: 0.6606 - recall: 0.5615 - precision: 0.8617 - val_loss: 0.0771 - val_binary_accuracy: 0.9778 - val_f1: 0.4237 - val_recall: 0.3607 - val_precision: 0.5837\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0470 - binary_accuracy: 0.9850 - f1: 0.6508 - recall: 0.5572 - precision: 0.8472 - val_loss: 0.0753 - val_binary_accuracy: 0.9782 - val_f1: 0.4359 - val_recall: 0.3736 - val_precision: 0.6103\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0460 - binary_accuracy: 0.9856 - f1: 0.6736 - recall: 0.5763 - precision: 0.8715 - val_loss: 0.0762 - val_binary_accuracy: 0.9774 - val_f1: 0.4322 - val_recall: 0.3748 - val_precision: 0.5897\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0458 - binary_accuracy: 0.9856 - f1: 0.6736 - recall: 0.5775 - precision: 0.8697 - val_loss: 0.0752 - val_binary_accuracy: 0.9776 - val_f1: 0.4319 - val_recall: 0.3738 - val_precision: 0.5818\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0450 - binary_accuracy: 0.9859 - f1: 0.6868 - recall: 0.5902 - precision: 0.8765 - val_loss: 0.0783 - val_binary_accuracy: 0.9771 - val_f1: 0.3986 - val_recall: 0.3434 - val_precision: 0.5638\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0442 - binary_accuracy: 0.9861 - f1: 0.6877 - recall: 0.5943 - precision: 0.8724 - val_loss: 0.0775 - val_binary_accuracy: 0.9775 - val_f1: 0.4073 - val_recall: 0.3443 - val_precision: 0.5814\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0435 - binary_accuracy: 0.9863 - f1: 0.6889 - recall: 0.5971 - precision: 0.8684 - val_loss: 0.0770 - val_binary_accuracy: 0.9776 - val_f1: 0.4695 - val_recall: 0.4198 - val_precision: 0.6128\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0430 - binary_accuracy: 0.9865 - f1: 0.7003 - recall: 0.6072 - precision: 0.8875 - val_loss: 0.0785 - val_binary_accuracy: 0.9771 - val_f1: 0.4131 - val_recall: 0.3545 - val_precision: 0.5650\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0422 - binary_accuracy: 0.9869 - f1: 0.7033 - recall: 0.6096 - precision: 0.8803 - val_loss: 0.0796 - val_binary_accuracy: 0.9769 - val_f1: 0.4511 - val_recall: 0.4069 - val_precision: 0.5763\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9867 - f1: 0.7034 - recall: 0.6154 - precision: 0.8730 - val_loss: 0.0780 - val_binary_accuracy: 0.9776 - val_f1: 0.4307 - val_recall: 0.3735 - val_precision: 0.5679\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0406 - binary_accuracy: 0.9871 - f1: 0.7199 - recall: 0.6321 - precision: 0.8915 - val_loss: 0.0802 - val_binary_accuracy: 0.9776 - val_f1: 0.4380 - val_recall: 0.3776 - val_precision: 0.5861\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0403 - binary_accuracy: 0.9871 - f1: 0.7102 - recall: 0.6223 - precision: 0.8809 - val_loss: 0.0800 - val_binary_accuracy: 0.9774 - val_f1: 0.4441 - val_recall: 0.3928 - val_precision: 0.5701\n",
      "Epoch 58/500\n",
      "9s - loss: 0.0394 - binary_accuracy: 0.9875 - f1: 0.7210 - recall: 0.6346 - precision: 0.8814 - val_loss: 0.0802 - val_binary_accuracy: 0.9763 - val_f1: 0.4141 - val_recall: 0.3716 - val_precision: 0.5273\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0394 - binary_accuracy: 0.9875 - f1: 0.7283 - recall: 0.6432 - precision: 0.8934 - val_loss: 0.0806 - val_binary_accuracy: 0.9777 - val_f1: 0.4340 - val_recall: 0.3752 - val_precision: 0.5879\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0385 - binary_accuracy: 0.9878 - f1: 0.7301 - recall: 0.6447 - precision: 0.8920 - val_loss: 0.0795 - val_binary_accuracy: 0.9776 - val_f1: 0.4419 - val_recall: 0.3853 - val_precision: 0.5803\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0379 - binary_accuracy: 0.9878 - f1: 0.7345 - recall: 0.6513 - precision: 0.8926 - val_loss: 0.0823 - val_binary_accuracy: 0.9773 - val_f1: 0.4555 - val_recall: 0.3998 - val_precision: 0.5990\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0373 - binary_accuracy: 0.9879 - f1: 0.7411 - recall: 0.6589 - precision: 0.8961 - val_loss: 0.0813 - val_binary_accuracy: 0.9784 - val_f1: 0.4913 - val_recall: 0.4441 - val_precision: 0.6176\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0364 - binary_accuracy: 0.9883 - f1: 0.7447 - recall: 0.6599 - precision: 0.9014 - val_loss: 0.0836 - val_binary_accuracy: 0.9772 - val_f1: 0.4475 - val_recall: 0.3979 - val_precision: 0.5674\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0357 - binary_accuracy: 0.9887 - f1: 0.7555 - recall: 0.6723 - precision: 0.9099 - val_loss: 0.0838 - val_binary_accuracy: 0.9766 - val_f1: 0.4545 - val_recall: 0.4168 - val_precision: 0.5501\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0358 - binary_accuracy: 0.9886 - f1: 0.7527 - recall: 0.6690 - precision: 0.9068 - val_loss: 0.0832 - val_binary_accuracy: 0.9774 - val_f1: 0.4849 - val_recall: 0.4390 - val_precision: 0.6043\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0348 - binary_accuracy: 0.9888 - f1: 0.7553 - recall: 0.6769 - precision: 0.8965 - val_loss: 0.0834 - val_binary_accuracy: 0.9776 - val_f1: 0.4541 - val_recall: 0.4042 - val_precision: 0.5809\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0337 - binary_accuracy: 0.9893 - f1: 0.7667 - recall: 0.6840 - precision: 0.9169 - val_loss: 0.0894 - val_binary_accuracy: 0.9773 - val_f1: 0.4209 - val_recall: 0.3646 - val_precision: 0.5710\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0334 - binary_accuracy: 0.9894 - f1: 0.7700 - recall: 0.6929 - precision: 0.9080 - val_loss: 0.0865 - val_binary_accuracy: 0.9775 - val_f1: 0.4434 - val_recall: 0.3925 - val_precision: 0.5671\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0329 - binary_accuracy: 0.9894 - f1: 0.7704 - recall: 0.6967 - precision: 0.8995 - val_loss: 0.0857 - val_binary_accuracy: 0.9781 - val_f1: 0.4786 - val_recall: 0.4238 - val_precision: 0.6143\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0319 - binary_accuracy: 0.9897 - f1: 0.7743 - recall: 0.6970 - precision: 0.9116 - val_loss: 0.0888 - val_binary_accuracy: 0.9775 - val_f1: 0.4711 - val_recall: 0.4341 - val_precision: 0.5605\n",
      "Epoch 71/500\n",
      "9s - loss: 0.0320 - binary_accuracy: 0.9901 - f1: 0.7869 - recall: 0.7097 - precision: 0.9206 - val_loss: 0.0872 - val_binary_accuracy: 0.9772 - val_f1: 0.4821 - val_recall: 0.4497 - val_precision: 0.5827\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0314 - binary_accuracy: 0.9899 - f1: 0.7839 - recall: 0.7117 - precision: 0.9097 - val_loss: 0.0882 - val_binary_accuracy: 0.9773 - val_f1: 0.4855 - val_recall: 0.4458 - val_precision: 0.5866\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0301 - binary_accuracy: 0.9902 - f1: 0.7948 - recall: 0.7209 - precision: 0.9200 - val_loss: 0.0913 - val_binary_accuracy: 0.9753 - val_f1: 0.4560 - val_recall: 0.4352 - val_precision: 0.5429\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0299 - binary_accuracy: 0.9905 - f1: 0.7938 - recall: 0.7236 - precision: 0.9137 - val_loss: 0.0972 - val_binary_accuracy: 0.9746 - val_f1: 0.4715 - val_recall: 0.4679 - val_precision: 0.5344\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0298 - binary_accuracy: 0.9904 - f1: 0.7983 - recall: 0.7279 - precision: 0.9163 - val_loss: 0.0914 - val_binary_accuracy: 0.9783 - val_f1: 0.4632 - val_recall: 0.4074 - val_precision: 0.5849\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0286 - binary_accuracy: 0.9907 - f1: 0.8037 - recall: 0.7364 - precision: 0.9196 - val_loss: 0.0931 - val_binary_accuracy: 0.9767 - val_f1: 0.4504 - val_recall: 0.4146 - val_precision: 0.5506\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0286 - binary_accuracy: 0.9908 - f1: 0.8060 - recall: 0.7384 - precision: 0.9216 - val_loss: 0.0976 - val_binary_accuracy: 0.9751 - val_f1: 0.4463 - val_recall: 0.4184 - val_precision: 0.5262\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0276 - binary_accuracy: 0.9912 - f1: 0.8147 - recall: 0.7519 - precision: 0.9226 - val_loss: 0.0948 - val_binary_accuracy: 0.9769 - val_f1: 0.4842 - val_recall: 0.4440 - val_precision: 0.5866\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9913 - f1: 0.8164 - recall: 0.7516 - precision: 0.9259 - val_loss: 0.0992 - val_binary_accuracy: 0.9770 - val_f1: 0.4590 - val_recall: 0.4094 - val_precision: 0.5925\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0272 - binary_accuracy: 0.9916 - f1: 0.8229 - recall: 0.7589 - precision: 0.9278 - val_loss: 0.0940 - val_binary_accuracy: 0.9768 - val_f1: 0.4720 - val_recall: 0.4336 - val_precision: 0.5716\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0261 - binary_accuracy: 0.9917 - f1: 0.8255 - recall: 0.7649 - precision: 0.9291 - val_loss: 0.0977 - val_binary_accuracy: 0.9774 - val_f1: 0.4453 - val_recall: 0.3939 - val_precision: 0.5722\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0255 - binary_accuracy: 0.9917 - f1: 0.8249 - recall: 0.7655 - precision: 0.9276 - val_loss: 0.1013 - val_binary_accuracy: 0.9753 - val_f1: 0.4743 - val_recall: 0.4573 - val_precision: 0.5473\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0256 - binary_accuracy: 0.9918 - f1: 0.8330 - recall: 0.7719 - precision: 0.9381 - val_loss: 0.0998 - val_binary_accuracy: 0.9762 - val_f1: 0.4743 - val_recall: 0.4490 - val_precision: 0.5503\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0242 - binary_accuracy: 0.9925 - f1: 0.8419 - recall: 0.7829 - precision: 0.9404 - val_loss: 0.1026 - val_binary_accuracy: 0.9764 - val_f1: 0.4714 - val_recall: 0.4363 - val_precision: 0.5750\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0244 - binary_accuracy: 0.9924 - f1: 0.8366 - recall: 0.7828 - precision: 0.9284 - val_loss: 0.0987 - val_binary_accuracy: 0.9764 - val_f1: 0.4742 - val_recall: 0.4396 - val_precision: 0.5589\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0239 - binary_accuracy: 0.9922 - f1: 0.8386 - recall: 0.7843 - precision: 0.9305 - val_loss: 0.1071 - val_binary_accuracy: 0.9760 - val_f1: 0.4701 - val_recall: 0.4406 - val_precision: 0.5591\n",
      "37917/37917 [==============================] - 3s     \n",
      "tn = 147050, fp = 307, fn = 796, tp = 3515\n",
      "y_pred: 0 = 147846 | 1 = 3822\n",
      "y_true: 0 = 147357 | 1 = 4311\n",
      "acc=0.9927|precision=0.9197|recall=0.8154|f1=0.8644|auc=0.9943|aupr=0.9286|pos_acc=0.8154|neg_acc=0.9946\n",
      "tn = 36476, fp = 322, fn = 588, tp = 531\n",
      "y_pred: 0 = 37064 | 1 = 853\n",
      "y_true: 0 = 36798 | 1 = 1119\n",
      "acc=0.9760|precision=0.6225|recall=0.4745|f1=0.5385|auc=0.8669|aupr=0.5337|pos_acc=0.4745|neg_acc=0.9841\n",
      "----------------------- Fold =  3\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "10s - loss: 0.0831 - binary_accuracy: 0.9724 - f1: 0.2638 - recall: 0.1920 - precision: 0.5432 - val_loss: 0.0816 - val_binary_accuracy: 0.9731 - val_f1: 0.1605 - val_recall: 0.1327 - val_precision: 0.2438\n",
      "Epoch 2/500\n",
      "9s - loss: 0.0779 - binary_accuracy: 0.9749 - f1: 0.3196 - recall: 0.2377 - precision: 0.6121 - val_loss: 0.0805 - val_binary_accuracy: 0.9739 - val_f1: 0.1610 - val_recall: 0.1204 - val_precision: 0.2862\n",
      "Epoch 3/500\n",
      "9s - loss: 0.0772 - binary_accuracy: 0.9755 - f1: 0.3447 - recall: 0.2553 - precision: 0.6503 - val_loss: 0.0817 - val_binary_accuracy: 0.9734 - val_f1: 0.2080 - val_recall: 0.1860 - val_precision: 0.2712\n",
      "Epoch 4/500\n",
      "9s - loss: 0.0764 - binary_accuracy: 0.9756 - f1: 0.3451 - recall: 0.2583 - precision: 0.6338 - val_loss: 0.0826 - val_binary_accuracy: 0.9737 - val_f1: 0.2567 - val_recall: 0.2290 - val_precision: 0.3356\n",
      "Epoch 5/500\n",
      "9s - loss: 0.0759 - binary_accuracy: 0.9758 - f1: 0.3575 - recall: 0.2698 - precision: 0.6375 - val_loss: 0.0785 - val_binary_accuracy: 0.9746 - val_f1: 0.1768 - val_recall: 0.1284 - val_precision: 0.3248\n",
      "Epoch 6/500\n",
      "9s - loss: 0.0754 - binary_accuracy: 0.9762 - f1: 0.3703 - recall: 0.2818 - precision: 0.6517 - val_loss: 0.0781 - val_binary_accuracy: 0.9747 - val_f1: 0.1573 - val_recall: 0.1160 - val_precision: 0.2875\n",
      "Epoch 7/500\n",
      "9s - loss: 0.0749 - binary_accuracy: 0.9763 - f1: 0.3665 - recall: 0.2711 - precision: 0.6673 - val_loss: 0.0782 - val_binary_accuracy: 0.9748 - val_f1: 0.1926 - val_recall: 0.1511 - val_precision: 0.3083\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0741 - binary_accuracy: 0.9766 - f1: 0.3851 - recall: 0.2941 - precision: 0.6730 - val_loss: 0.0767 - val_binary_accuracy: 0.9747 - val_f1: 0.1624 - val_recall: 0.1202 - val_precision: 0.3053\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0735 - binary_accuracy: 0.9769 - f1: 0.3951 - recall: 0.3026 - precision: 0.6844 - val_loss: 0.0789 - val_binary_accuracy: 0.9749 - val_f1: 0.1454 - val_recall: 0.1031 - val_precision: 0.2960\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0728 - binary_accuracy: 0.9770 - f1: 0.3899 - recall: 0.2967 - precision: 0.6738 - val_loss: 0.0759 - val_binary_accuracy: 0.9753 - val_f1: 0.2419 - val_recall: 0.1868 - val_precision: 0.3977\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0720 - binary_accuracy: 0.9771 - f1: 0.4089 - recall: 0.3111 - precision: 0.6904 - val_loss: 0.0775 - val_binary_accuracy: 0.9750 - val_f1: 0.2256 - val_recall: 0.1699 - val_precision: 0.4088\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0711 - binary_accuracy: 0.9775 - f1: 0.4220 - recall: 0.3222 - precision: 0.7132 - val_loss: 0.0759 - val_binary_accuracy: 0.9757 - val_f1: 0.2880 - val_recall: 0.2371 - val_precision: 0.4315\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0708 - binary_accuracy: 0.9777 - f1: 0.4254 - recall: 0.3276 - precision: 0.7053 - val_loss: 0.0757 - val_binary_accuracy: 0.9752 - val_f1: 0.2080 - val_recall: 0.1539 - val_precision: 0.3910\n",
      "Epoch 14/500\n",
      "9s - loss: 0.0697 - binary_accuracy: 0.9781 - f1: 0.4367 - recall: 0.3381 - precision: 0.7194 - val_loss: 0.0750 - val_binary_accuracy: 0.9757 - val_f1: 0.3152 - val_recall: 0.2690 - val_precision: 0.4388\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0695 - binary_accuracy: 0.9778 - f1: 0.4403 - recall: 0.3449 - precision: 0.7227 - val_loss: 0.0748 - val_binary_accuracy: 0.9762 - val_f1: 0.2608 - val_recall: 0.2034 - val_precision: 0.4420\n",
      "Epoch 16/500\n",
      "9s - loss: 0.0687 - binary_accuracy: 0.9783 - f1: 0.4507 - recall: 0.3545 - precision: 0.7229 - val_loss: 0.0734 - val_binary_accuracy: 0.9766 - val_f1: 0.2734 - val_recall: 0.2181 - val_precision: 0.4376\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0679 - binary_accuracy: 0.9786 - f1: 0.4557 - recall: 0.3569 - precision: 0.7341 - val_loss: 0.0725 - val_binary_accuracy: 0.9767 - val_f1: 0.2900 - val_recall: 0.2324 - val_precision: 0.4593\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0670 - binary_accuracy: 0.9789 - f1: 0.4720 - recall: 0.3705 - precision: 0.7495 - val_loss: 0.0736 - val_binary_accuracy: 0.9760 - val_f1: 0.2413 - val_recall: 0.1824 - val_precision: 0.4403\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0665 - binary_accuracy: 0.9792 - f1: 0.4757 - recall: 0.3707 - precision: 0.7604 - val_loss: 0.0728 - val_binary_accuracy: 0.9768 - val_f1: 0.3199 - val_recall: 0.2596 - val_precision: 0.4866\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0656 - binary_accuracy: 0.9793 - f1: 0.4852 - recall: 0.3810 - precision: 0.7552 - val_loss: 0.0731 - val_binary_accuracy: 0.9764 - val_f1: 0.2708 - val_recall: 0.2138 - val_precision: 0.4341\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0653 - binary_accuracy: 0.9793 - f1: 0.4848 - recall: 0.3842 - precision: 0.7419 - val_loss: 0.0721 - val_binary_accuracy: 0.9770 - val_f1: 0.3221 - val_recall: 0.2639 - val_precision: 0.4909\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0647 - binary_accuracy: 0.9796 - f1: 0.4912 - recall: 0.3920 - precision: 0.7597 - val_loss: 0.0714 - val_binary_accuracy: 0.9774 - val_f1: 0.3465 - val_recall: 0.2872 - val_precision: 0.5233\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0636 - binary_accuracy: 0.9803 - f1: 0.5171 - recall: 0.4147 - precision: 0.7816 - val_loss: 0.0731 - val_binary_accuracy: 0.9769 - val_f1: 0.3092 - val_recall: 0.2455 - val_precision: 0.4984\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0629 - binary_accuracy: 0.9802 - f1: 0.5197 - recall: 0.4158 - precision: 0.7855 - val_loss: 0.0717 - val_binary_accuracy: 0.9772 - val_f1: 0.2760 - val_recall: 0.2097 - val_precision: 0.4813\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0621 - binary_accuracy: 0.9803 - f1: 0.5196 - recall: 0.4194 - precision: 0.7719 - val_loss: 0.0713 - val_binary_accuracy: 0.9775 - val_f1: 0.3374 - val_recall: 0.2740 - val_precision: 0.5229\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0617 - binary_accuracy: 0.9804 - f1: 0.5264 - recall: 0.4278 - precision: 0.7699 - val_loss: 0.0716 - val_binary_accuracy: 0.9777 - val_f1: 0.3262 - val_recall: 0.2570 - val_precision: 0.5172\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0606 - binary_accuracy: 0.9809 - f1: 0.5424 - recall: 0.4401 - precision: 0.7941 - val_loss: 0.0746 - val_binary_accuracy: 0.9778 - val_f1: 0.3461 - val_recall: 0.2724 - val_precision: 0.5474\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0602 - binary_accuracy: 0.9813 - f1: 0.5457 - recall: 0.4426 - precision: 0.7971 - val_loss: 0.0714 - val_binary_accuracy: 0.9776 - val_f1: 0.3879 - val_recall: 0.3405 - val_precision: 0.5313\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0592 - binary_accuracy: 0.9815 - f1: 0.5528 - recall: 0.4468 - precision: 0.8119 - val_loss: 0.0734 - val_binary_accuracy: 0.9771 - val_f1: 0.3851 - val_recall: 0.3388 - val_precision: 0.5016\n",
      "Epoch 30/500\n",
      "9s - loss: 0.0587 - binary_accuracy: 0.9816 - f1: 0.5551 - recall: 0.4553 - precision: 0.7948 - val_loss: 0.0715 - val_binary_accuracy: 0.9771 - val_f1: 0.3292 - val_recall: 0.2735 - val_precision: 0.4823\n",
      "Epoch 31/500\n",
      "9s - loss: 0.0580 - binary_accuracy: 0.9817 - f1: 0.5643 - recall: 0.4612 - precision: 0.8056 - val_loss: 0.0716 - val_binary_accuracy: 0.9784 - val_f1: 0.3956 - val_recall: 0.3318 - val_precision: 0.5566\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0570 - binary_accuracy: 0.9820 - f1: 0.5675 - recall: 0.4626 - precision: 0.8119 - val_loss: 0.0716 - val_binary_accuracy: 0.9778 - val_f1: 0.4028 - val_recall: 0.3452 - val_precision: 0.5354\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0563 - binary_accuracy: 0.9823 - f1: 0.5793 - recall: 0.4779 - precision: 0.8209 - val_loss: 0.0706 - val_binary_accuracy: 0.9784 - val_f1: 0.3843 - val_recall: 0.3209 - val_precision: 0.5379\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0557 - binary_accuracy: 0.9824 - f1: 0.5816 - recall: 0.4812 - precision: 0.8160 - val_loss: 0.0700 - val_binary_accuracy: 0.9783 - val_f1: 0.4034 - val_recall: 0.3354 - val_precision: 0.5924\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0552 - binary_accuracy: 0.9826 - f1: 0.5855 - recall: 0.4860 - precision: 0.8170 - val_loss: 0.0699 - val_binary_accuracy: 0.9773 - val_f1: 0.3937 - val_recall: 0.3417 - val_precision: 0.5252\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0543 - binary_accuracy: 0.9829 - f1: 0.5925 - recall: 0.4880 - precision: 0.8287 - val_loss: 0.0708 - val_binary_accuracy: 0.9782 - val_f1: 0.4136 - val_recall: 0.3572 - val_precision: 0.5485\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0536 - binary_accuracy: 0.9828 - f1: 0.5979 - recall: 0.4966 - precision: 0.8243 - val_loss: 0.0697 - val_binary_accuracy: 0.9787 - val_f1: 0.4040 - val_recall: 0.3400 - val_precision: 0.5767\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0529 - binary_accuracy: 0.9833 - f1: 0.6130 - recall: 0.5129 - precision: 0.8345 - val_loss: 0.0707 - val_binary_accuracy: 0.9781 - val_f1: 0.4202 - val_recall: 0.3615 - val_precision: 0.5594\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0523 - binary_accuracy: 0.9835 - f1: 0.6108 - recall: 0.5128 - precision: 0.8204 - val_loss: 0.0702 - val_binary_accuracy: 0.9781 - val_f1: 0.4083 - val_recall: 0.3528 - val_precision: 0.5523\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0514 - binary_accuracy: 0.9838 - f1: 0.6225 - recall: 0.5204 - precision: 0.8456 - val_loss: 0.0704 - val_binary_accuracy: 0.9783 - val_f1: 0.4392 - val_recall: 0.3778 - val_precision: 0.6060\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0507 - binary_accuracy: 0.9839 - f1: 0.6265 - recall: 0.5283 - precision: 0.8321 - val_loss: 0.0725 - val_binary_accuracy: 0.9785 - val_f1: 0.4071 - val_recall: 0.3378 - val_precision: 0.5898\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0503 - binary_accuracy: 0.9841 - f1: 0.6279 - recall: 0.5283 - precision: 0.8481 - val_loss: 0.0714 - val_binary_accuracy: 0.9786 - val_f1: 0.4059 - val_recall: 0.3403 - val_precision: 0.5776\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0498 - binary_accuracy: 0.9844 - f1: 0.6395 - recall: 0.5402 - precision: 0.8478 - val_loss: 0.0720 - val_binary_accuracy: 0.9788 - val_f1: 0.4318 - val_recall: 0.3758 - val_precision: 0.5753\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0488 - binary_accuracy: 0.9846 - f1: 0.6415 - recall: 0.5459 - precision: 0.8419 - val_loss: 0.0705 - val_binary_accuracy: 0.9787 - val_f1: 0.4016 - val_recall: 0.3355 - val_precision: 0.5590\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0483 - binary_accuracy: 0.9847 - f1: 0.6439 - recall: 0.5486 - precision: 0.8481 - val_loss: 0.0726 - val_binary_accuracy: 0.9781 - val_f1: 0.3738 - val_recall: 0.3073 - val_precision: 0.5551\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0475 - binary_accuracy: 0.9848 - f1: 0.6518 - recall: 0.5543 - precision: 0.8534 - val_loss: 0.0741 - val_binary_accuracy: 0.9776 - val_f1: 0.3614 - val_recall: 0.2970 - val_precision: 0.5297\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0469 - binary_accuracy: 0.9849 - f1: 0.6527 - recall: 0.5555 - precision: 0.8499 - val_loss: 0.0723 - val_binary_accuracy: 0.9779 - val_f1: 0.4271 - val_recall: 0.3740 - val_precision: 0.5585\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0460 - binary_accuracy: 0.9852 - f1: 0.6621 - recall: 0.5649 - precision: 0.8565 - val_loss: 0.0725 - val_binary_accuracy: 0.9788 - val_f1: 0.4471 - val_recall: 0.4026 - val_precision: 0.5749\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0453 - binary_accuracy: 0.9856 - f1: 0.6740 - recall: 0.5796 - precision: 0.8664 - val_loss: 0.0731 - val_binary_accuracy: 0.9781 - val_f1: 0.4231 - val_recall: 0.3683 - val_precision: 0.5727\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0446 - binary_accuracy: 0.9857 - f1: 0.6787 - recall: 0.5858 - precision: 0.8641 - val_loss: 0.0739 - val_binary_accuracy: 0.9778 - val_f1: 0.4037 - val_recall: 0.3431 - val_precision: 0.5571\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0441 - binary_accuracy: 0.9862 - f1: 0.6878 - recall: 0.5954 - precision: 0.8720 - val_loss: 0.0732 - val_binary_accuracy: 0.9781 - val_f1: 0.4246 - val_recall: 0.3757 - val_precision: 0.5501\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0432 - binary_accuracy: 0.9860 - f1: 0.6920 - recall: 0.6046 - precision: 0.8671 - val_loss: 0.0741 - val_binary_accuracy: 0.9782 - val_f1: 0.4428 - val_recall: 0.3785 - val_precision: 0.5942\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0429 - binary_accuracy: 0.9864 - f1: 0.7030 - recall: 0.6139 - precision: 0.8762 - val_loss: 0.0759 - val_binary_accuracy: 0.9784 - val_f1: 0.4168 - val_recall: 0.3489 - val_precision: 0.5718\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9867 - f1: 0.7023 - recall: 0.6141 - precision: 0.8814 - val_loss: 0.0748 - val_binary_accuracy: 0.9787 - val_f1: 0.4432 - val_recall: 0.3887 - val_precision: 0.5878\n",
      "Epoch 55/500\n",
      "9s - loss: 0.0415 - binary_accuracy: 0.9866 - f1: 0.7006 - recall: 0.6103 - precision: 0.8803 - val_loss: 0.0769 - val_binary_accuracy: 0.9780 - val_f1: 0.4078 - val_recall: 0.3513 - val_precision: 0.5449\n",
      "Epoch 56/500\n",
      "9s - loss: 0.0412 - binary_accuracy: 0.9870 - f1: 0.7078 - recall: 0.6210 - precision: 0.8734 - val_loss: 0.0771 - val_binary_accuracy: 0.9777 - val_f1: 0.4310 - val_recall: 0.3813 - val_precision: 0.5576\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0404 - binary_accuracy: 0.9871 - f1: 0.7056 - recall: 0.6190 - precision: 0.8802 - val_loss: 0.0789 - val_binary_accuracy: 0.9771 - val_f1: 0.4447 - val_recall: 0.4007 - val_precision: 0.5651\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0399 - binary_accuracy: 0.9876 - f1: 0.7210 - recall: 0.6355 - precision: 0.8881 - val_loss: 0.0773 - val_binary_accuracy: 0.9779 - val_f1: 0.4345 - val_recall: 0.3805 - val_precision: 0.5717\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0388 - binary_accuracy: 0.9876 - f1: 0.7296 - recall: 0.6423 - precision: 0.8916 - val_loss: 0.0765 - val_binary_accuracy: 0.9773 - val_f1: 0.4114 - val_recall: 0.3609 - val_precision: 0.5307\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0378 - binary_accuracy: 0.9877 - f1: 0.7257 - recall: 0.6395 - precision: 0.8846 - val_loss: 0.0809 - val_binary_accuracy: 0.9785 - val_f1: 0.4006 - val_recall: 0.3354 - val_precision: 0.5595\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0378 - binary_accuracy: 0.9879 - f1: 0.7323 - recall: 0.6485 - precision: 0.8897 - val_loss: 0.0762 - val_binary_accuracy: 0.9783 - val_f1: 0.4429 - val_recall: 0.3904 - val_precision: 0.5679\n",
      "Epoch 62/500\n",
      "9s - loss: 0.0367 - binary_accuracy: 0.9881 - f1: 0.7385 - recall: 0.6590 - precision: 0.8836 - val_loss: 0.0794 - val_binary_accuracy: 0.9770 - val_f1: 0.4295 - val_recall: 0.3871 - val_precision: 0.5385\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0364 - binary_accuracy: 0.9883 - f1: 0.7435 - recall: 0.6637 - precision: 0.8878 - val_loss: 0.0830 - val_binary_accuracy: 0.9772 - val_f1: 0.4276 - val_recall: 0.3740 - val_precision: 0.5408\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0359 - binary_accuracy: 0.9884 - f1: 0.7461 - recall: 0.6686 - precision: 0.8896 - val_loss: 0.0816 - val_binary_accuracy: 0.9782 - val_f1: 0.4213 - val_recall: 0.3553 - val_precision: 0.5807\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0347 - binary_accuracy: 0.9889 - f1: 0.7570 - recall: 0.6786 - precision: 0.9006 - val_loss: 0.0817 - val_binary_accuracy: 0.9773 - val_f1: 0.4275 - val_recall: 0.3816 - val_precision: 0.5355\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0343 - binary_accuracy: 0.9892 - f1: 0.7625 - recall: 0.6802 - precision: 0.9102 - val_loss: 0.0828 - val_binary_accuracy: 0.9778 - val_f1: 0.4389 - val_recall: 0.3877 - val_precision: 0.5472\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0337 - binary_accuracy: 0.9891 - f1: 0.7656 - recall: 0.6887 - precision: 0.9035 - val_loss: 0.0829 - val_binary_accuracy: 0.9778 - val_f1: 0.4527 - val_recall: 0.4114 - val_precision: 0.5562\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0328 - binary_accuracy: 0.9894 - f1: 0.7670 - recall: 0.6929 - precision: 0.8993 - val_loss: 0.0832 - val_binary_accuracy: 0.9780 - val_f1: 0.4499 - val_recall: 0.4039 - val_precision: 0.5576\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0325 - binary_accuracy: 0.9896 - f1: 0.7741 - recall: 0.7014 - precision: 0.9038 - val_loss: 0.0833 - val_binary_accuracy: 0.9778 - val_f1: 0.4183 - val_recall: 0.3651 - val_precision: 0.5377\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0324 - binary_accuracy: 0.9897 - f1: 0.7736 - recall: 0.6975 - precision: 0.9104 - val_loss: 0.0839 - val_binary_accuracy: 0.9774 - val_f1: 0.4422 - val_recall: 0.3879 - val_precision: 0.5649\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0310 - binary_accuracy: 0.9900 - f1: 0.7832 - recall: 0.7096 - precision: 0.9152 - val_loss: 0.0863 - val_binary_accuracy: 0.9759 - val_f1: 0.4397 - val_recall: 0.4014 - val_precision: 0.5392\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0309 - binary_accuracy: 0.9900 - f1: 0.7846 - recall: 0.7153 - precision: 0.9056 - val_loss: 0.0855 - val_binary_accuracy: 0.9778 - val_f1: 0.4281 - val_recall: 0.3720 - val_precision: 0.5606\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0298 - binary_accuracy: 0.9904 - f1: 0.7960 - recall: 0.7257 - precision: 0.9156 - val_loss: 0.0849 - val_binary_accuracy: 0.9777 - val_f1: 0.4639 - val_recall: 0.4236 - val_precision: 0.5515\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0293 - binary_accuracy: 0.9909 - f1: 0.8054 - recall: 0.7321 - precision: 0.9304 - val_loss: 0.0891 - val_binary_accuracy: 0.9756 - val_f1: 0.4167 - val_recall: 0.4003 - val_precision: 0.4792\n",
      "Epoch 75/500\n",
      "9s - loss: 0.0293 - binary_accuracy: 0.9906 - f1: 0.7999 - recall: 0.7339 - precision: 0.9152 - val_loss: 0.0882 - val_binary_accuracy: 0.9775 - val_f1: 0.4380 - val_recall: 0.3840 - val_precision: 0.5658\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0281 - binary_accuracy: 0.9910 - f1: 0.8125 - recall: 0.7461 - precision: 0.9241 - val_loss: 0.0893 - val_binary_accuracy: 0.9767 - val_f1: 0.4117 - val_recall: 0.3602 - val_precision: 0.5290\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0284 - binary_accuracy: 0.9910 - f1: 0.8139 - recall: 0.7512 - precision: 0.9237 - val_loss: 0.0899 - val_binary_accuracy: 0.9778 - val_f1: 0.4686 - val_recall: 0.4334 - val_precision: 0.5670\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0274 - binary_accuracy: 0.9913 - f1: 0.8145 - recall: 0.7523 - precision: 0.9221 - val_loss: 0.0919 - val_binary_accuracy: 0.9776 - val_f1: 0.4345 - val_recall: 0.3709 - val_precision: 0.5833\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0275 - binary_accuracy: 0.9911 - f1: 0.8159 - recall: 0.7530 - precision: 0.9259 - val_loss: 0.0934 - val_binary_accuracy: 0.9780 - val_f1: 0.4725 - val_recall: 0.4261 - val_precision: 0.5976\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0262 - binary_accuracy: 0.9915 - f1: 0.8183 - recall: 0.7571 - precision: 0.9228 - val_loss: 0.0905 - val_binary_accuracy: 0.9773 - val_f1: 0.4148 - val_recall: 0.3670 - val_precision: 0.5233\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0250 - binary_accuracy: 0.9921 - f1: 0.8340 - recall: 0.7736 - precision: 0.9354 - val_loss: 0.0930 - val_binary_accuracy: 0.9780 - val_f1: 0.4326 - val_recall: 0.3702 - val_precision: 0.5637\n",
      "Epoch 82/500\n",
      "9s - loss: 0.0260 - binary_accuracy: 0.9918 - f1: 0.8286 - recall: 0.7668 - precision: 0.9298 - val_loss: 0.0945 - val_binary_accuracy: 0.9782 - val_f1: 0.4363 - val_recall: 0.3710 - val_precision: 0.5858\n",
      "Epoch 83/500\n",
      "9s - loss: 0.0244 - binary_accuracy: 0.9922 - f1: 0.8353 - recall: 0.7764 - precision: 0.9330 - val_loss: 0.0946 - val_binary_accuracy: 0.9761 - val_f1: 0.4751 - val_recall: 0.4527 - val_precision: 0.5496\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0245 - binary_accuracy: 0.9922 - f1: 0.8408 - recall: 0.7858 - precision: 0.9284 - val_loss: 0.0947 - val_binary_accuracy: 0.9771 - val_f1: 0.4665 - val_recall: 0.4285 - val_precision: 0.5654\n",
      "Epoch 85/500\n",
      "9s - loss: 0.0237 - binary_accuracy: 0.9925 - f1: 0.8463 - recall: 0.7895 - precision: 0.9391 - val_loss: 0.0953 - val_binary_accuracy: 0.9781 - val_f1: 0.4716 - val_recall: 0.4189 - val_precision: 0.5915\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0232 - binary_accuracy: 0.9928 - f1: 0.8495 - recall: 0.7984 - precision: 0.9378 - val_loss: 0.1045 - val_binary_accuracy: 0.9748 - val_f1: 0.4274 - val_recall: 0.4134 - val_precision: 0.4970\n",
      "Epoch 87/500\n",
      "10s - loss: 0.0233 - binary_accuracy: 0.9926 - f1: 0.8443 - recall: 0.7936 - precision: 0.9283 - val_loss: 0.0985 - val_binary_accuracy: 0.9758 - val_f1: 0.4529 - val_recall: 0.4254 - val_precision: 0.5337\n",
      "Epoch 88/500\n",
      "10s - loss: 0.0220 - binary_accuracy: 0.9932 - f1: 0.8557 - recall: 0.8026 - precision: 0.9383 - val_loss: 0.0987 - val_binary_accuracy: 0.9775 - val_f1: 0.4589 - val_recall: 0.4022 - val_precision: 0.5856\n",
      "37792/37917 [============================>.] - ETA: 0stn = 147200, fp = 163, fn = 794, tp = 3511\n",
      "y_pred: 0 = 147994 | 1 = 3674\n",
      "y_true: 0 = 147363 | 1 = 4305\n",
      "acc=0.9937|precision=0.9556|recall=0.8156|f1=0.8801|auc=0.9947|aupr=0.9394|pos_acc=0.8156|neg_acc=0.9946\n",
      "tn = 36525, fp = 267, fn = 587, tp = 538\n",
      "y_pred: 0 = 37112 | 1 = 805\n",
      "y_true: 0 = 36792 | 1 = 1125\n",
      "acc=0.9775|precision=0.6683|recall=0.4782|f1=0.5575|auc=0.9129|aupr=0.5593|pos_acc=0.4782|neg_acc=0.9842\n",
      "----------------------- Fold =  4\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0826 - binary_accuracy: 0.9729 - f1: 0.2673 - recall: 0.1944 - precision: 0.5361 - val_loss: 0.0796 - val_binary_accuracy: 0.9746 - val_f1: 0.1888 - val_recall: 0.1479 - val_precision: 0.2843\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0781 - binary_accuracy: 0.9748 - f1: 0.3245 - recall: 0.2435 - precision: 0.6069 - val_loss: 0.0782 - val_binary_accuracy: 0.9749 - val_f1: 0.1933 - val_recall: 0.1541 - val_precision: 0.2843\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0774 - binary_accuracy: 0.9753 - f1: 0.3387 - recall: 0.2537 - precision: 0.6366 - val_loss: 0.0778 - val_binary_accuracy: 0.9750 - val_f1: 0.1987 - val_recall: 0.1539 - val_precision: 0.3104\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0768 - binary_accuracy: 0.9758 - f1: 0.3620 - recall: 0.2733 - precision: 0.6710 - val_loss: 0.0777 - val_binary_accuracy: 0.9750 - val_f1: 0.2035 - val_recall: 0.1642 - val_precision: 0.2927\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0765 - binary_accuracy: 0.9754 - f1: 0.3450 - recall: 0.2591 - precision: 0.6244 - val_loss: 0.0771 - val_binary_accuracy: 0.9754 - val_f1: 0.2072 - val_recall: 0.1611 - val_precision: 0.3194\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0754 - binary_accuracy: 0.9759 - f1: 0.3629 - recall: 0.2720 - precision: 0.6562 - val_loss: 0.0769 - val_binary_accuracy: 0.9753 - val_f1: 0.2061 - val_recall: 0.1647 - val_precision: 0.3087\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0748 - binary_accuracy: 0.9763 - f1: 0.3769 - recall: 0.2849 - precision: 0.6774 - val_loss: 0.0776 - val_binary_accuracy: 0.9752 - val_f1: 0.1575 - val_recall: 0.1102 - val_precision: 0.3271\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0743 - binary_accuracy: 0.9765 - f1: 0.3876 - recall: 0.2947 - precision: 0.6933 - val_loss: 0.0780 - val_binary_accuracy: 0.9754 - val_f1: 0.2990 - val_recall: 0.2563 - val_precision: 0.3905\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0735 - binary_accuracy: 0.9767 - f1: 0.3921 - recall: 0.2984 - precision: 0.6827 - val_loss: 0.0768 - val_binary_accuracy: 0.9750 - val_f1: 0.1611 - val_recall: 0.1198 - val_precision: 0.2984\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0731 - binary_accuracy: 0.9768 - f1: 0.3992 - recall: 0.3067 - precision: 0.6905 - val_loss: 0.0751 - val_binary_accuracy: 0.9759 - val_f1: 0.2443 - val_recall: 0.2044 - val_precision: 0.3412\n",
      "Epoch 11/500\n",
      "9s - loss: 0.0726 - binary_accuracy: 0.9771 - f1: 0.4064 - recall: 0.3117 - precision: 0.6957 - val_loss: 0.0754 - val_binary_accuracy: 0.9762 - val_f1: 0.2191 - val_recall: 0.1651 - val_precision: 0.3704\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0718 - binary_accuracy: 0.9773 - f1: 0.4086 - recall: 0.3117 - precision: 0.7027 - val_loss: 0.0736 - val_binary_accuracy: 0.9759 - val_f1: 0.2347 - val_recall: 0.1911 - val_precision: 0.3434\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0713 - binary_accuracy: 0.9773 - f1: 0.4116 - recall: 0.3156 - precision: 0.6943 - val_loss: 0.0738 - val_binary_accuracy: 0.9763 - val_f1: 0.2652 - val_recall: 0.2169 - val_precision: 0.3877\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0707 - binary_accuracy: 0.9775 - f1: 0.4269 - recall: 0.3284 - precision: 0.7163 - val_loss: 0.0763 - val_binary_accuracy: 0.9755 - val_f1: 0.2131 - val_recall: 0.1719 - val_precision: 0.3292\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0701 - binary_accuracy: 0.9777 - f1: 0.4341 - recall: 0.3343 - precision: 0.7130 - val_loss: 0.0755 - val_binary_accuracy: 0.9760 - val_f1: 0.1823 - val_recall: 0.1363 - val_precision: 0.3222\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0696 - binary_accuracy: 0.9777 - f1: 0.4444 - recall: 0.3502 - precision: 0.7226 - val_loss: 0.0725 - val_binary_accuracy: 0.9763 - val_f1: 0.2414 - val_recall: 0.1938 - val_precision: 0.3598\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0689 - binary_accuracy: 0.9780 - f1: 0.4417 - recall: 0.3423 - precision: 0.7274 - val_loss: 0.0739 - val_binary_accuracy: 0.9764 - val_f1: 0.3350 - val_recall: 0.2836 - val_precision: 0.4523\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0683 - binary_accuracy: 0.9784 - f1: 0.4574 - recall: 0.3575 - precision: 0.7346 - val_loss: 0.0743 - val_binary_accuracy: 0.9766 - val_f1: 0.2298 - val_recall: 0.1809 - val_precision: 0.3545\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0676 - binary_accuracy: 0.9785 - f1: 0.4551 - recall: 0.3537 - precision: 0.7424 - val_loss: 0.0723 - val_binary_accuracy: 0.9764 - val_f1: 0.2602 - val_recall: 0.2105 - val_precision: 0.3924\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0673 - binary_accuracy: 0.9786 - f1: 0.4710 - recall: 0.3748 - precision: 0.7388 - val_loss: 0.0732 - val_binary_accuracy: 0.9767 - val_f1: 0.2539 - val_recall: 0.1996 - val_precision: 0.3933\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0667 - binary_accuracy: 0.9788 - f1: 0.4706 - recall: 0.3688 - precision: 0.7395 - val_loss: 0.0715 - val_binary_accuracy: 0.9769 - val_f1: 0.2385 - val_recall: 0.1809 - val_precision: 0.4087\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0659 - binary_accuracy: 0.9790 - f1: 0.4724 - recall: 0.3746 - precision: 0.7330 - val_loss: 0.0722 - val_binary_accuracy: 0.9776 - val_f1: 0.3257 - val_recall: 0.2722 - val_precision: 0.4481\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0653 - binary_accuracy: 0.9791 - f1: 0.4837 - recall: 0.3849 - precision: 0.7474 - val_loss: 0.0713 - val_binary_accuracy: 0.9772 - val_f1: 0.2933 - val_recall: 0.2446 - val_precision: 0.4111\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0646 - binary_accuracy: 0.9794 - f1: 0.5024 - recall: 0.3995 - precision: 0.7654 - val_loss: 0.0706 - val_binary_accuracy: 0.9772 - val_f1: 0.3143 - val_recall: 0.2649 - val_precision: 0.4331\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0640 - binary_accuracy: 0.9795 - f1: 0.4999 - recall: 0.3956 - precision: 0.7662 - val_loss: 0.0705 - val_binary_accuracy: 0.9774 - val_f1: 0.2935 - val_recall: 0.2440 - val_precision: 0.4236\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0632 - binary_accuracy: 0.9798 - f1: 0.5052 - recall: 0.4083 - precision: 0.7535 - val_loss: 0.0707 - val_binary_accuracy: 0.9777 - val_f1: 0.3733 - val_recall: 0.3209 - val_precision: 0.4909\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0629 - binary_accuracy: 0.9801 - f1: 0.5209 - recall: 0.4198 - precision: 0.7784 - val_loss: 0.0707 - val_binary_accuracy: 0.9770 - val_f1: 0.3364 - val_recall: 0.2920 - val_precision: 0.4367\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0620 - binary_accuracy: 0.9802 - f1: 0.5207 - recall: 0.4200 - precision: 0.7784 - val_loss: 0.0707 - val_binary_accuracy: 0.9773 - val_f1: 0.3751 - val_recall: 0.3238 - val_precision: 0.4886\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9806 - f1: 0.5280 - recall: 0.4276 - precision: 0.7798 - val_loss: 0.0717 - val_binary_accuracy: 0.9777 - val_f1: 0.2600 - val_recall: 0.2022 - val_precision: 0.4085\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0606 - binary_accuracy: 0.9808 - f1: 0.5381 - recall: 0.4379 - precision: 0.7851 - val_loss: 0.0717 - val_binary_accuracy: 0.9779 - val_f1: 0.3136 - val_recall: 0.2573 - val_precision: 0.4514\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0598 - binary_accuracy: 0.9811 - f1: 0.5468 - recall: 0.4476 - precision: 0.7936 - val_loss: 0.0757 - val_binary_accuracy: 0.9773 - val_f1: 0.3148 - val_recall: 0.2572 - val_precision: 0.4524\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0591 - binary_accuracy: 0.9813 - f1: 0.5531 - recall: 0.4500 - precision: 0.8006 - val_loss: 0.0699 - val_binary_accuracy: 0.9770 - val_f1: 0.3896 - val_recall: 0.3479 - val_precision: 0.4811\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0586 - binary_accuracy: 0.9816 - f1: 0.5640 - recall: 0.4639 - precision: 0.8056 - val_loss: 0.0690 - val_binary_accuracy: 0.9780 - val_f1: 0.3873 - val_recall: 0.3313 - val_precision: 0.5204\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0578 - binary_accuracy: 0.9817 - f1: 0.5678 - recall: 0.4660 - precision: 0.8143 - val_loss: 0.0711 - val_binary_accuracy: 0.9781 - val_f1: 0.3144 - val_recall: 0.2512 - val_precision: 0.4775\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0570 - binary_accuracy: 0.9819 - f1: 0.5707 - recall: 0.4731 - precision: 0.8037 - val_loss: 0.0699 - val_binary_accuracy: 0.9782 - val_f1: 0.3578 - val_recall: 0.2910 - val_precision: 0.5359\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0566 - binary_accuracy: 0.9820 - f1: 0.5725 - recall: 0.4700 - precision: 0.8070 - val_loss: 0.0696 - val_binary_accuracy: 0.9788 - val_f1: 0.3889 - val_recall: 0.3235 - val_precision: 0.5533\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0558 - binary_accuracy: 0.9823 - f1: 0.5774 - recall: 0.4744 - precision: 0.8107 - val_loss: 0.0711 - val_binary_accuracy: 0.9778 - val_f1: 0.3979 - val_recall: 0.3504 - val_precision: 0.5134\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0551 - binary_accuracy: 0.9828 - f1: 0.5999 - recall: 0.5034 - precision: 0.8212 - val_loss: 0.0691 - val_binary_accuracy: 0.9787 - val_f1: 0.3856 - val_recall: 0.3249 - val_precision: 0.5353\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0544 - binary_accuracy: 0.9830 - f1: 0.5981 - recall: 0.4958 - precision: 0.8268 - val_loss: 0.0721 - val_binary_accuracy: 0.9782 - val_f1: 0.3800 - val_recall: 0.3260 - val_precision: 0.5104\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0537 - binary_accuracy: 0.9833 - f1: 0.6073 - recall: 0.5082 - precision: 0.8276 - val_loss: 0.0703 - val_binary_accuracy: 0.9780 - val_f1: 0.3611 - val_recall: 0.3013 - val_precision: 0.5263\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0526 - binary_accuracy: 0.9832 - f1: 0.6131 - recall: 0.5148 - precision: 0.8362 - val_loss: 0.0711 - val_binary_accuracy: 0.9784 - val_f1: 0.4753 - val_recall: 0.4297 - val_precision: 0.5877\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0522 - binary_accuracy: 0.9836 - f1: 0.6126 - recall: 0.5156 - precision: 0.8302 - val_loss: 0.0701 - val_binary_accuracy: 0.9783 - val_f1: 0.3771 - val_recall: 0.3175 - val_precision: 0.5224\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0516 - binary_accuracy: 0.9840 - f1: 0.6276 - recall: 0.5282 - precision: 0.8385 - val_loss: 0.0693 - val_binary_accuracy: 0.9788 - val_f1: 0.3964 - val_recall: 0.3379 - val_precision: 0.5340\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0511 - binary_accuracy: 0.9840 - f1: 0.6273 - recall: 0.5256 - precision: 0.8423 - val_loss: 0.0740 - val_binary_accuracy: 0.9778 - val_f1: 0.3287 - val_recall: 0.2725 - val_precision: 0.4724\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9841 - f1: 0.6401 - recall: 0.5376 - precision: 0.8553 - val_loss: 0.0700 - val_binary_accuracy: 0.9789 - val_f1: 0.3964 - val_recall: 0.3375 - val_precision: 0.5310\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0495 - binary_accuracy: 0.9844 - f1: 0.6407 - recall: 0.5398 - precision: 0.8514 - val_loss: 0.0720 - val_binary_accuracy: 0.9787 - val_f1: 0.4505 - val_recall: 0.3899 - val_precision: 0.6023\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0486 - binary_accuracy: 0.9846 - f1: 0.6548 - recall: 0.5578 - precision: 0.8567 - val_loss: 0.0693 - val_binary_accuracy: 0.9785 - val_f1: 0.4127 - val_recall: 0.3539 - val_precision: 0.5380\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0485 - binary_accuracy: 0.9845 - f1: 0.6498 - recall: 0.5536 - precision: 0.8608 - val_loss: 0.0709 - val_binary_accuracy: 0.9780 - val_f1: 0.4169 - val_recall: 0.3660 - val_precision: 0.5541\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0476 - binary_accuracy: 0.9848 - f1: 0.6535 - recall: 0.5535 - precision: 0.8621 - val_loss: 0.0720 - val_binary_accuracy: 0.9781 - val_f1: 0.4234 - val_recall: 0.3710 - val_precision: 0.5453\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0470 - binary_accuracy: 0.9852 - f1: 0.6673 - recall: 0.5707 - precision: 0.8597 - val_loss: 0.0713 - val_binary_accuracy: 0.9783 - val_f1: 0.4389 - val_recall: 0.3848 - val_precision: 0.5696\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0461 - binary_accuracy: 0.9855 - f1: 0.6655 - recall: 0.5708 - precision: 0.8613 - val_loss: 0.0747 - val_binary_accuracy: 0.9770 - val_f1: 0.4246 - val_recall: 0.3841 - val_precision: 0.5186\n",
      "Epoch 52/500\n",
      "11s - loss: 0.0455 - binary_accuracy: 0.9857 - f1: 0.6759 - recall: 0.5834 - precision: 0.8646 - val_loss: 0.0731 - val_binary_accuracy: 0.9787 - val_f1: 0.4643 - val_recall: 0.4141 - val_precision: 0.5720\n",
      "Epoch 53/500\n",
      "11s - loss: 0.0447 - binary_accuracy: 0.9858 - f1: 0.6835 - recall: 0.5873 - precision: 0.8768 - val_loss: 0.0723 - val_binary_accuracy: 0.9782 - val_f1: 0.4606 - val_recall: 0.4099 - val_precision: 0.5834\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0439 - binary_accuracy: 0.9861 - f1: 0.6867 - recall: 0.5962 - precision: 0.8759 - val_loss: 0.0719 - val_binary_accuracy: 0.9793 - val_f1: 0.4619 - val_recall: 0.4009 - val_precision: 0.6161\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0432 - binary_accuracy: 0.9864 - f1: 0.6945 - recall: 0.5975 - precision: 0.8831 - val_loss: 0.0759 - val_binary_accuracy: 0.9780 - val_f1: 0.4429 - val_recall: 0.3905 - val_precision: 0.5668\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0425 - binary_accuracy: 0.9865 - f1: 0.6986 - recall: 0.6068 - precision: 0.8781 - val_loss: 0.0770 - val_binary_accuracy: 0.9783 - val_f1: 0.4385 - val_recall: 0.3790 - val_precision: 0.5833\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0420 - binary_accuracy: 0.9867 - f1: 0.7009 - recall: 0.6099 - precision: 0.8791 - val_loss: 0.0786 - val_binary_accuracy: 0.9779 - val_f1: 0.4702 - val_recall: 0.4339 - val_precision: 0.5585\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0415 - binary_accuracy: 0.9868 - f1: 0.7019 - recall: 0.6111 - precision: 0.8755 - val_loss: 0.0754 - val_binary_accuracy: 0.9778 - val_f1: 0.4394 - val_recall: 0.3897 - val_precision: 0.5677\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0410 - binary_accuracy: 0.9871 - f1: 0.7115 - recall: 0.6251 - precision: 0.8850 - val_loss: 0.0749 - val_binary_accuracy: 0.9781 - val_f1: 0.4838 - val_recall: 0.4440 - val_precision: 0.5801\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0397 - binary_accuracy: 0.9872 - f1: 0.7187 - recall: 0.6269 - precision: 0.8869 - val_loss: 0.0781 - val_binary_accuracy: 0.9779 - val_f1: 0.4852 - val_recall: 0.4574 - val_precision: 0.5662\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0392 - binary_accuracy: 0.9876 - f1: 0.7248 - recall: 0.6394 - precision: 0.8907 - val_loss: 0.0755 - val_binary_accuracy: 0.9786 - val_f1: 0.4788 - val_recall: 0.4306 - val_precision: 0.5865\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0386 - binary_accuracy: 0.9879 - f1: 0.7347 - recall: 0.6502 - precision: 0.8892 - val_loss: 0.0788 - val_binary_accuracy: 0.9785 - val_f1: 0.4619 - val_recall: 0.4129 - val_precision: 0.5870\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0378 - binary_accuracy: 0.9881 - f1: 0.7397 - recall: 0.6506 - precision: 0.9010 - val_loss: 0.0800 - val_binary_accuracy: 0.9780 - val_f1: 0.4435 - val_recall: 0.3999 - val_precision: 0.5455\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0375 - binary_accuracy: 0.9880 - f1: 0.7335 - recall: 0.6470 - precision: 0.8949 - val_loss: 0.0809 - val_binary_accuracy: 0.9762 - val_f1: 0.4628 - val_recall: 0.4359 - val_precision: 0.5461\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0365 - binary_accuracy: 0.9885 - f1: 0.7487 - recall: 0.6664 - precision: 0.9026 - val_loss: 0.0793 - val_binary_accuracy: 0.9782 - val_f1: 0.4679 - val_recall: 0.4193 - val_precision: 0.5870\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0356 - binary_accuracy: 0.9886 - f1: 0.7594 - recall: 0.6801 - precision: 0.9007 - val_loss: 0.0872 - val_binary_accuracy: 0.9783 - val_f1: 0.4372 - val_recall: 0.3893 - val_precision: 0.5533\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0353 - binary_accuracy: 0.9887 - f1: 0.7579 - recall: 0.6775 - precision: 0.9061 - val_loss: 0.0803 - val_binary_accuracy: 0.9768 - val_f1: 0.4602 - val_recall: 0.4222 - val_precision: 0.5621\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0342 - binary_accuracy: 0.9893 - f1: 0.7700 - recall: 0.6902 - precision: 0.9169 - val_loss: 0.0811 - val_binary_accuracy: 0.9778 - val_f1: 0.4832 - val_recall: 0.4312 - val_precision: 0.5966\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0337 - binary_accuracy: 0.9893 - f1: 0.7696 - recall: 0.6895 - precision: 0.9149 - val_loss: 0.0829 - val_binary_accuracy: 0.9782 - val_f1: 0.4610 - val_recall: 0.4126 - val_precision: 0.5863\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0335 - binary_accuracy: 0.9896 - f1: 0.7789 - recall: 0.6998 - precision: 0.9188 - val_loss: 0.0806 - val_binary_accuracy: 0.9778 - val_f1: 0.4908 - val_recall: 0.4487 - val_precision: 0.5934\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0324 - binary_accuracy: 0.9899 - f1: 0.7833 - recall: 0.7093 - precision: 0.9161 - val_loss: 0.0810 - val_binary_accuracy: 0.9776 - val_f1: 0.4783 - val_recall: 0.4378 - val_precision: 0.5788\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0325 - binary_accuracy: 0.9898 - f1: 0.7753 - recall: 0.7015 - precision: 0.9066 - val_loss: 0.0838 - val_binary_accuracy: 0.9782 - val_f1: 0.4827 - val_recall: 0.4337 - val_precision: 0.5996\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0310 - binary_accuracy: 0.9902 - f1: 0.7839 - recall: 0.7096 - precision: 0.9170 - val_loss: 0.0859 - val_binary_accuracy: 0.9769 - val_f1: 0.5026 - val_recall: 0.4759 - val_precision: 0.5791\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0312 - binary_accuracy: 0.9901 - f1: 0.7891 - recall: 0.7177 - precision: 0.9165 - val_loss: 0.0860 - val_binary_accuracy: 0.9777 - val_f1: 0.4475 - val_recall: 0.4068 - val_precision: 0.5445\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0302 - binary_accuracy: 0.9907 - f1: 0.8051 - recall: 0.7332 - precision: 0.9235 - val_loss: 0.0849 - val_binary_accuracy: 0.9780 - val_f1: 0.4628 - val_recall: 0.4020 - val_precision: 0.6091\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0305 - binary_accuracy: 0.9904 - f1: 0.7934 - recall: 0.7269 - precision: 0.9152 - val_loss: 0.0899 - val_binary_accuracy: 0.9782 - val_f1: 0.4756 - val_recall: 0.4290 - val_precision: 0.5959\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0290 - binary_accuracy: 0.9909 - f1: 0.8071 - recall: 0.7374 - precision: 0.9281 - val_loss: 0.0915 - val_binary_accuracy: 0.9770 - val_f1: 0.4371 - val_recall: 0.3857 - val_precision: 0.5711\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0285 - binary_accuracy: 0.9909 - f1: 0.8073 - recall: 0.7391 - precision: 0.9273 - val_loss: 0.0892 - val_binary_accuracy: 0.9766 - val_f1: 0.4859 - val_recall: 0.4544 - val_precision: 0.5626\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0280 - binary_accuracy: 0.9912 - f1: 0.8094 - recall: 0.7442 - precision: 0.9213 - val_loss: 0.0896 - val_binary_accuracy: 0.9768 - val_f1: 0.4759 - val_recall: 0.4433 - val_precision: 0.5587\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0277 - binary_accuracy: 0.9913 - f1: 0.8193 - recall: 0.7557 - precision: 0.9288 - val_loss: 0.0918 - val_binary_accuracy: 0.9765 - val_f1: 0.4934 - val_recall: 0.4739 - val_precision: 0.5506\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0268 - binary_accuracy: 0.9915 - f1: 0.8217 - recall: 0.7529 - precision: 0.9371 - val_loss: 0.0927 - val_binary_accuracy: 0.9776 - val_f1: 0.4594 - val_recall: 0.4139 - val_precision: 0.5689\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0264 - binary_accuracy: 0.9916 - f1: 0.8198 - recall: 0.7579 - precision: 0.9235 - val_loss: 0.0920 - val_binary_accuracy: 0.9777 - val_f1: 0.5075 - val_recall: 0.4633 - val_precision: 0.6080\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0258 - binary_accuracy: 0.9918 - f1: 0.8288 - recall: 0.7649 - precision: 0.9338 - val_loss: 0.0949 - val_binary_accuracy: 0.9774 - val_f1: 0.4696 - val_recall: 0.4242 - val_precision: 0.5828\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0256 - binary_accuracy: 0.9920 - f1: 0.8380 - recall: 0.7781 - precision: 0.9378 - val_loss: 0.0934 - val_binary_accuracy: 0.9778 - val_f1: 0.4787 - val_recall: 0.4347 - val_precision: 0.5798\n",
      "37888/37917 [============================>.] - ETA: 0stn = 147169, fp = 172, fn = 1006, tp = 3321\n",
      "y_pred: 0 = 148175 | 1 = 3493\n",
      "y_true: 0 = 147341 | 1 = 4327\n",
      "acc=0.9922|precision=0.9508|recall=0.7675|f1=0.8494|auc=0.9943|aupr=0.9295|pos_acc=0.7675|neg_acc=0.9932\n",
      "tn = 36532, fp = 282, fn = 558, tp = 545\n",
      "y_pred: 0 = 37090 | 1 = 827\n",
      "y_true: 0 = 36814 | 1 = 1103\n",
      "acc=0.9778|precision=0.6590|recall=0.4941|f1=0.5648|auc=0.9143|aupr=0.5863|pos_acc=0.4941|neg_acc=0.9850\n",
      "========== isbalance = False | task = Tm\n",
      "-------Fold  0\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  1\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  2\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  3\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "-------Fold  4\n",
      "# miRNA: Train = 396 | Test = 99\n",
      "# Pairs: Train = 151668 | Test = 37917\n",
      "----------------------- Fold =  0\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0805 - binary_accuracy: 0.9740 - f1: 0.2664 - recall: 0.1958 - precision: 0.5269 - val_loss: 0.0881 - val_binary_accuracy: 0.9729 - val_f1: 0.3110 - val_recall: 0.2228 - val_precision: 0.6129\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0767 - binary_accuracy: 0.9754 - f1: 0.3360 - recall: 0.2517 - precision: 0.6148 - val_loss: 0.0845 - val_binary_accuracy: 0.9725 - val_f1: 0.3864 - val_recall: 0.3079 - val_precision: 0.5936\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0758 - binary_accuracy: 0.9755 - f1: 0.3396 - recall: 0.2541 - precision: 0.6265 - val_loss: 0.0842 - val_binary_accuracy: 0.9728 - val_f1: 0.2579 - val_recall: 0.1723 - val_precision: 0.6322\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0749 - binary_accuracy: 0.9761 - f1: 0.3632 - recall: 0.2746 - precision: 0.6595 - val_loss: 0.0837 - val_binary_accuracy: 0.9733 - val_f1: 0.3848 - val_recall: 0.2976 - val_precision: 0.6284\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0744 - binary_accuracy: 0.9762 - f1: 0.3593 - recall: 0.2717 - precision: 0.6336 - val_loss: 0.0861 - val_binary_accuracy: 0.9727 - val_f1: 0.4110 - val_recall: 0.3361 - val_precision: 0.6006\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0739 - binary_accuracy: 0.9764 - f1: 0.3632 - recall: 0.2727 - precision: 0.6556 - val_loss: 0.0839 - val_binary_accuracy: 0.9734 - val_f1: 0.3015 - val_recall: 0.2090 - val_precision: 0.6627\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0729 - binary_accuracy: 0.9769 - f1: 0.3888 - recall: 0.2946 - precision: 0.6824 - val_loss: 0.0822 - val_binary_accuracy: 0.9743 - val_f1: 0.3712 - val_recall: 0.2748 - val_precision: 0.6738\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0723 - binary_accuracy: 0.9772 - f1: 0.4008 - recall: 0.3068 - precision: 0.6933 - val_loss: 0.0826 - val_binary_accuracy: 0.9730 - val_f1: 0.3125 - val_recall: 0.2229 - val_precision: 0.6441\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0713 - binary_accuracy: 0.9771 - f1: 0.3949 - recall: 0.3022 - precision: 0.6778 - val_loss: 0.0831 - val_binary_accuracy: 0.9733 - val_f1: 0.3893 - val_recall: 0.3051 - val_precision: 0.6082\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0705 - binary_accuracy: 0.9776 - f1: 0.4087 - recall: 0.3128 - precision: 0.6981 - val_loss: 0.0825 - val_binary_accuracy: 0.9735 - val_f1: 0.3599 - val_recall: 0.2679 - val_precision: 0.6418\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0700 - binary_accuracy: 0.9777 - f1: 0.4102 - recall: 0.3162 - precision: 0.6939 - val_loss: 0.0831 - val_binary_accuracy: 0.9729 - val_f1: 0.3827 - val_recall: 0.3021 - val_precision: 0.6101\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0690 - binary_accuracy: 0.9780 - f1: 0.4332 - recall: 0.3385 - precision: 0.7087 - val_loss: 0.0820 - val_binary_accuracy: 0.9737 - val_f1: 0.3703 - val_recall: 0.2820 - val_precision: 0.6384\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0686 - binary_accuracy: 0.9782 - f1: 0.4369 - recall: 0.3422 - precision: 0.7091 - val_loss: 0.0816 - val_binary_accuracy: 0.9740 - val_f1: 0.4109 - val_recall: 0.3247 - val_precision: 0.6483\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0674 - binary_accuracy: 0.9785 - f1: 0.4481 - recall: 0.3518 - precision: 0.7232 - val_loss: 0.0825 - val_binary_accuracy: 0.9730 - val_f1: 0.4613 - val_recall: 0.4057 - val_precision: 0.5811\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0670 - binary_accuracy: 0.9786 - f1: 0.4545 - recall: 0.3583 - precision: 0.7151 - val_loss: 0.0823 - val_binary_accuracy: 0.9739 - val_f1: 0.3669 - val_recall: 0.2746 - val_precision: 0.6669\n",
      "Epoch 16/500\n",
      "11s - loss: 0.0662 - binary_accuracy: 0.9789 - f1: 0.4713 - recall: 0.3741 - precision: 0.7324 - val_loss: 0.0802 - val_binary_accuracy: 0.9739 - val_f1: 0.3513 - val_recall: 0.2555 - val_precision: 0.6720\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0656 - binary_accuracy: 0.9792 - f1: 0.4734 - recall: 0.3758 - precision: 0.7508 - val_loss: 0.0814 - val_binary_accuracy: 0.9742 - val_f1: 0.3489 - val_recall: 0.2515 - val_precision: 0.6805\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0652 - binary_accuracy: 0.9793 - f1: 0.4829 - recall: 0.3820 - precision: 0.7500 - val_loss: 0.0801 - val_binary_accuracy: 0.9745 - val_f1: 0.3761 - val_recall: 0.2772 - val_precision: 0.6832\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0642 - binary_accuracy: 0.9798 - f1: 0.4944 - recall: 0.3920 - precision: 0.7631 - val_loss: 0.0806 - val_binary_accuracy: 0.9748 - val_f1: 0.4148 - val_recall: 0.3174 - val_precision: 0.6887\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0635 - binary_accuracy: 0.9797 - f1: 0.4892 - recall: 0.3906 - precision: 0.7464 - val_loss: 0.0788 - val_binary_accuracy: 0.9747 - val_f1: 0.4196 - val_recall: 0.3298 - val_precision: 0.6600\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0625 - binary_accuracy: 0.9802 - f1: 0.5062 - recall: 0.4032 - precision: 0.7730 - val_loss: 0.0814 - val_binary_accuracy: 0.9737 - val_f1: 0.3593 - val_recall: 0.2644 - val_precision: 0.6562\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0618 - binary_accuracy: 0.9805 - f1: 0.5175 - recall: 0.4148 - precision: 0.7870 - val_loss: 0.0802 - val_binary_accuracy: 0.9750 - val_f1: 0.4332 - val_recall: 0.3508 - val_precision: 0.6595\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9805 - f1: 0.5232 - recall: 0.4207 - precision: 0.7680 - val_loss: 0.0820 - val_binary_accuracy: 0.9742 - val_f1: 0.3643 - val_recall: 0.2667 - val_precision: 0.6719\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0604 - binary_accuracy: 0.9811 - f1: 0.5371 - recall: 0.4300 - precision: 0.7979 - val_loss: 0.0810 - val_binary_accuracy: 0.9749 - val_f1: 0.3983 - val_recall: 0.3009 - val_precision: 0.6901\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0596 - binary_accuracy: 0.9811 - f1: 0.5352 - recall: 0.4324 - precision: 0.7882 - val_loss: 0.0813 - val_binary_accuracy: 0.9743 - val_f1: 0.4198 - val_recall: 0.3300 - val_precision: 0.6680\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0593 - binary_accuracy: 0.9813 - f1: 0.5440 - recall: 0.4434 - precision: 0.7921 - val_loss: 0.0792 - val_binary_accuracy: 0.9746 - val_f1: 0.4155 - val_recall: 0.3258 - val_precision: 0.6479\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0585 - binary_accuracy: 0.9817 - f1: 0.5556 - recall: 0.4506 - precision: 0.8087 - val_loss: 0.0803 - val_binary_accuracy: 0.9747 - val_f1: 0.4476 - val_recall: 0.3636 - val_precision: 0.6519\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0579 - binary_accuracy: 0.9818 - f1: 0.5533 - recall: 0.4504 - precision: 0.8054 - val_loss: 0.0812 - val_binary_accuracy: 0.9743 - val_f1: 0.4282 - val_recall: 0.3417 - val_precision: 0.6565\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0572 - binary_accuracy: 0.9818 - f1: 0.5530 - recall: 0.4530 - precision: 0.7876 - val_loss: 0.0797 - val_binary_accuracy: 0.9745 - val_f1: 0.4573 - val_recall: 0.3796 - val_precision: 0.6348\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0564 - binary_accuracy: 0.9822 - f1: 0.5662 - recall: 0.4643 - precision: 0.8048 - val_loss: 0.0802 - val_binary_accuracy: 0.9747 - val_f1: 0.4573 - val_recall: 0.3758 - val_precision: 0.6526\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0556 - binary_accuracy: 0.9824 - f1: 0.5791 - recall: 0.4797 - precision: 0.8163 - val_loss: 0.0809 - val_binary_accuracy: 0.9745 - val_f1: 0.4599 - val_recall: 0.3816 - val_precision: 0.6606\n",
      "Epoch 32/500\n",
      "11s - loss: 0.0551 - binary_accuracy: 0.9826 - f1: 0.5795 - recall: 0.4833 - precision: 0.7977 - val_loss: 0.0808 - val_binary_accuracy: 0.9746 - val_f1: 0.3948 - val_recall: 0.2956 - val_precision: 0.6904\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0543 - binary_accuracy: 0.9828 - f1: 0.5853 - recall: 0.4837 - precision: 0.8147 - val_loss: 0.0824 - val_binary_accuracy: 0.9742 - val_f1: 0.4645 - val_recall: 0.3945 - val_precision: 0.6290\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0538 - binary_accuracy: 0.9830 - f1: 0.5949 - recall: 0.4928 - precision: 0.8255 - val_loss: 0.0831 - val_binary_accuracy: 0.9748 - val_f1: 0.4389 - val_recall: 0.3440 - val_precision: 0.6776\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0531 - binary_accuracy: 0.9831 - f1: 0.6004 - recall: 0.5007 - precision: 0.8268 - val_loss: 0.0831 - val_binary_accuracy: 0.9737 - val_f1: 0.4371 - val_recall: 0.3608 - val_precision: 0.6276\n",
      "Epoch 36/500\n",
      "11s - loss: 0.0527 - binary_accuracy: 0.9833 - f1: 0.5950 - recall: 0.4922 - precision: 0.8309 - val_loss: 0.0801 - val_binary_accuracy: 0.9747 - val_f1: 0.4689 - val_recall: 0.3935 - val_precision: 0.6541\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0516 - binary_accuracy: 0.9835 - f1: 0.6076 - recall: 0.5093 - precision: 0.8302 - val_loss: 0.0840 - val_binary_accuracy: 0.9741 - val_f1: 0.4425 - val_recall: 0.3604 - val_precision: 0.6437\n",
      "Epoch 38/500\n",
      "11s - loss: 0.0511 - binary_accuracy: 0.9837 - f1: 0.6110 - recall: 0.5122 - precision: 0.8330 - val_loss: 0.0819 - val_binary_accuracy: 0.9747 - val_f1: 0.4427 - val_recall: 0.3549 - val_precision: 0.6605\n",
      "Epoch 39/500\n",
      "11s - loss: 0.0505 - binary_accuracy: 0.9840 - f1: 0.6275 - recall: 0.5290 - precision: 0.8402 - val_loss: 0.0854 - val_binary_accuracy: 0.9740 - val_f1: 0.4123 - val_recall: 0.3207 - val_precision: 0.6731\n",
      "Epoch 40/500\n",
      "11s - loss: 0.0495 - binary_accuracy: 0.9844 - f1: 0.6351 - recall: 0.5366 - precision: 0.8442 - val_loss: 0.0805 - val_binary_accuracy: 0.9751 - val_f1: 0.4755 - val_recall: 0.3983 - val_precision: 0.6565\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0489 - binary_accuracy: 0.9845 - f1: 0.6328 - recall: 0.5328 - precision: 0.8473 - val_loss: 0.0833 - val_binary_accuracy: 0.9737 - val_f1: 0.4538 - val_recall: 0.3793 - val_precision: 0.6346\n",
      "Epoch 42/500\n",
      "11s - loss: 0.0486 - binary_accuracy: 0.9845 - f1: 0.6332 - recall: 0.5334 - precision: 0.8515 - val_loss: 0.0835 - val_binary_accuracy: 0.9752 - val_f1: 0.4740 - val_recall: 0.3928 - val_precision: 0.6762\n",
      "Epoch 43/500\n",
      "11s - loss: 0.0479 - binary_accuracy: 0.9848 - f1: 0.6448 - recall: 0.5477 - precision: 0.8573 - val_loss: 0.0844 - val_binary_accuracy: 0.9740 - val_f1: 0.4740 - val_recall: 0.4089 - val_precision: 0.6344\n",
      "Epoch 44/500\n",
      "11s - loss: 0.0470 - binary_accuracy: 0.9850 - f1: 0.6492 - recall: 0.5524 - precision: 0.8468 - val_loss: 0.0871 - val_binary_accuracy: 0.9734 - val_f1: 0.4585 - val_recall: 0.3940 - val_precision: 0.6110\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0468 - binary_accuracy: 0.9853 - f1: 0.6598 - recall: 0.5631 - precision: 0.8602 - val_loss: 0.0841 - val_binary_accuracy: 0.9744 - val_f1: 0.4651 - val_recall: 0.3880 - val_precision: 0.6444\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0457 - binary_accuracy: 0.9856 - f1: 0.6680 - recall: 0.5726 - precision: 0.8644 - val_loss: 0.0855 - val_binary_accuracy: 0.9744 - val_f1: 0.4610 - val_recall: 0.3891 - val_precision: 0.6304\n",
      "Epoch 47/500\n",
      "11s - loss: 0.0452 - binary_accuracy: 0.9856 - f1: 0.6701 - recall: 0.5803 - precision: 0.8545 - val_loss: 0.0849 - val_binary_accuracy: 0.9740 - val_f1: 0.4552 - val_recall: 0.3821 - val_precision: 0.6123\n",
      "Epoch 48/500\n",
      "11s - loss: 0.0451 - binary_accuracy: 0.9856 - f1: 0.6651 - recall: 0.5715 - precision: 0.8530 - val_loss: 0.0864 - val_binary_accuracy: 0.9748 - val_f1: 0.4538 - val_recall: 0.3695 - val_precision: 0.6553\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0441 - binary_accuracy: 0.9860 - f1: 0.6766 - recall: 0.5837 - precision: 0.8666 - val_loss: 0.0886 - val_binary_accuracy: 0.9747 - val_f1: 0.4461 - val_recall: 0.3589 - val_precision: 0.6542\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0431 - binary_accuracy: 0.9862 - f1: 0.6823 - recall: 0.5930 - precision: 0.8641 - val_loss: 0.0877 - val_binary_accuracy: 0.9750 - val_f1: 0.4552 - val_recall: 0.3665 - val_precision: 0.6737\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0428 - binary_accuracy: 0.9863 - f1: 0.6916 - recall: 0.5977 - precision: 0.8805 - val_loss: 0.0886 - val_binary_accuracy: 0.9739 - val_f1: 0.4751 - val_recall: 0.4086 - val_precision: 0.6426\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9864 - f1: 0.6992 - recall: 0.6045 - precision: 0.8857 - val_loss: 0.0880 - val_binary_accuracy: 0.9739 - val_f1: 0.4682 - val_recall: 0.4051 - val_precision: 0.6163\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0414 - binary_accuracy: 0.9867 - f1: 0.6997 - recall: 0.6127 - precision: 0.8736 - val_loss: 0.0905 - val_binary_accuracy: 0.9743 - val_f1: 0.4553 - val_recall: 0.3778 - val_precision: 0.6448\n",
      "Epoch 54/500\n",
      "11s - loss: 0.0413 - binary_accuracy: 0.9870 - f1: 0.7047 - recall: 0.6163 - precision: 0.8766 - val_loss: 0.0913 - val_binary_accuracy: 0.9740 - val_f1: 0.4466 - val_recall: 0.3663 - val_precision: 0.6395\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0404 - binary_accuracy: 0.9869 - f1: 0.7008 - recall: 0.6138 - precision: 0.8726 - val_loss: 0.0896 - val_binary_accuracy: 0.9737 - val_f1: 0.4538 - val_recall: 0.3805 - val_precision: 0.6231\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0403 - binary_accuracy: 0.9871 - f1: 0.7081 - recall: 0.6210 - precision: 0.8746 - val_loss: 0.0951 - val_binary_accuracy: 0.9741 - val_f1: 0.4709 - val_recall: 0.4087 - val_precision: 0.6289\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0391 - binary_accuracy: 0.9877 - f1: 0.7212 - recall: 0.6343 - precision: 0.8930 - val_loss: 0.0918 - val_binary_accuracy: 0.9727 - val_f1: 0.4643 - val_recall: 0.4123 - val_precision: 0.5817\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0387 - binary_accuracy: 0.9873 - f1: 0.7198 - recall: 0.6335 - precision: 0.8876 - val_loss: 0.0935 - val_binary_accuracy: 0.9744 - val_f1: 0.4501 - val_recall: 0.3732 - val_precision: 0.6287\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0378 - binary_accuracy: 0.9878 - f1: 0.7244 - recall: 0.6393 - precision: 0.8837 - val_loss: 0.0973 - val_binary_accuracy: 0.9731 - val_f1: 0.4410 - val_recall: 0.3742 - val_precision: 0.6085\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0376 - binary_accuracy: 0.9880 - f1: 0.7311 - recall: 0.6469 - precision: 0.8895 - val_loss: 0.0974 - val_binary_accuracy: 0.9724 - val_f1: 0.4567 - val_recall: 0.3993 - val_precision: 0.5872\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0368 - binary_accuracy: 0.9884 - f1: 0.7429 - recall: 0.6611 - precision: 0.8968 - val_loss: 0.1005 - val_binary_accuracy: 0.9723 - val_f1: 0.4475 - val_recall: 0.3904 - val_precision: 0.5872\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0363 - binary_accuracy: 0.9884 - f1: 0.7412 - recall: 0.6575 - precision: 0.8947 - val_loss: 0.0976 - val_binary_accuracy: 0.9738 - val_f1: 0.4771 - val_recall: 0.4200 - val_precision: 0.6047\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0358 - binary_accuracy: 0.9885 - f1: 0.7428 - recall: 0.6618 - precision: 0.8956 - val_loss: 0.1001 - val_binary_accuracy: 0.9742 - val_f1: 0.4139 - val_recall: 0.3236 - val_precision: 0.6552\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0351 - binary_accuracy: 0.9885 - f1: 0.7435 - recall: 0.6649 - precision: 0.8916 - val_loss: 0.1013 - val_binary_accuracy: 0.9733 - val_f1: 0.4671 - val_recall: 0.4090 - val_precision: 0.6061\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0346 - binary_accuracy: 0.9889 - f1: 0.7543 - recall: 0.6724 - precision: 0.9070 - val_loss: 0.0951 - val_binary_accuracy: 0.9734 - val_f1: 0.4702 - val_recall: 0.4106 - val_precision: 0.6071\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0336 - binary_accuracy: 0.9891 - f1: 0.7599 - recall: 0.6811 - precision: 0.9096 - val_loss: 0.0985 - val_binary_accuracy: 0.9740 - val_f1: 0.4649 - val_recall: 0.3960 - val_precision: 0.6247\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0333 - binary_accuracy: 0.9894 - f1: 0.7649 - recall: 0.6860 - precision: 0.9047 - val_loss: 0.1016 - val_binary_accuracy: 0.9725 - val_f1: 0.4416 - val_recall: 0.3823 - val_precision: 0.5863\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0323 - binary_accuracy: 0.9896 - f1: 0.7662 - recall: 0.6870 - precision: 0.9076 - val_loss: 0.1080 - val_binary_accuracy: 0.9719 - val_f1: 0.4617 - val_recall: 0.4228 - val_precision: 0.5634\n",
      "Epoch 69/500\n",
      "11s - loss: 0.0322 - binary_accuracy: 0.9897 - f1: 0.7822 - recall: 0.7105 - precision: 0.9128 - val_loss: 0.1033 - val_binary_accuracy: 0.9714 - val_f1: 0.4630 - val_recall: 0.4263 - val_precision: 0.5581\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0315 - binary_accuracy: 0.9898 - f1: 0.7816 - recall: 0.7087 - precision: 0.9109 - val_loss: 0.1072 - val_binary_accuracy: 0.9728 - val_f1: 0.4456 - val_recall: 0.3839 - val_precision: 0.6020\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0315 - binary_accuracy: 0.9898 - f1: 0.7809 - recall: 0.7086 - precision: 0.9141 - val_loss: 0.1010 - val_binary_accuracy: 0.9727 - val_f1: 0.4580 - val_recall: 0.4066 - val_precision: 0.5754\n",
      "37792/37917 [============================>.] - ETA: 0stn = 147189, fp = 227, fn = 1205, tp = 3047\n",
      "y_pred: 0 = 148394 | 1 = 3274\n",
      "y_true: 0 = 147416 | 1 = 4252\n",
      "acc=0.9906|precision=0.9307|recall=0.7166|f1=0.8097|auc=0.9889|aupr=0.8855|pos_acc=0.7166|neg_acc=0.9919\n",
      "tn = 36403, fp = 336, fn = 698, tp = 480\n",
      "y_pred: 0 = 37101 | 1 = 816\n",
      "y_true: 0 = 36739 | 1 = 1178\n",
      "acc=0.9727|precision=0.5882|recall=0.4075|f1=0.4814|auc=0.9158|aupr=0.5018|pos_acc=0.4075|neg_acc=0.9812\n",
      "----------------------- Fold =  1\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0846 - binary_accuracy: 0.9728 - f1: 0.2713 - recall: 0.1949 - precision: 0.5605 - val_loss: 0.0735 - val_binary_accuracy: 0.9775 - val_f1: 0.2133 - val_recall: 0.1454 - val_precision: 0.5012\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0803 - binary_accuracy: 0.9740 - f1: 0.3332 - recall: 0.2481 - precision: 0.6193 - val_loss: 0.0720 - val_binary_accuracy: 0.9781 - val_f1: 0.2347 - val_recall: 0.1619 - val_precision: 0.5293\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0791 - binary_accuracy: 0.9744 - f1: 0.3473 - recall: 0.2619 - precision: 0.6398 - val_loss: 0.0719 - val_binary_accuracy: 0.9782 - val_f1: 0.2279 - val_recall: 0.1569 - val_precision: 0.5212\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0789 - binary_accuracy: 0.9747 - f1: 0.3615 - recall: 0.2735 - precision: 0.6451 - val_loss: 0.0714 - val_binary_accuracy: 0.9786 - val_f1: 0.3110 - val_recall: 0.2308 - val_precision: 0.5852\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0784 - binary_accuracy: 0.9750 - f1: 0.3684 - recall: 0.2746 - precision: 0.6639 - val_loss: 0.0715 - val_binary_accuracy: 0.9780 - val_f1: 0.3485 - val_recall: 0.2784 - val_precision: 0.5585\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0776 - binary_accuracy: 0.9752 - f1: 0.3851 - recall: 0.2946 - precision: 0.6654 - val_loss: 0.0702 - val_binary_accuracy: 0.9790 - val_f1: 0.3369 - val_recall: 0.2518 - val_precision: 0.6076\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0763 - binary_accuracy: 0.9755 - f1: 0.3909 - recall: 0.2988 - precision: 0.6801 - val_loss: 0.0718 - val_binary_accuracy: 0.9780 - val_f1: 0.2050 - val_recall: 0.1365 - val_precision: 0.5081\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0760 - binary_accuracy: 0.9757 - f1: 0.3916 - recall: 0.2958 - precision: 0.6879 - val_loss: 0.0700 - val_binary_accuracy: 0.9789 - val_f1: 0.2758 - val_recall: 0.1932 - val_precision: 0.5949\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0752 - binary_accuracy: 0.9760 - f1: 0.4078 - recall: 0.3118 - precision: 0.7069 - val_loss: 0.0686 - val_binary_accuracy: 0.9785 - val_f1: 0.3066 - val_recall: 0.2259 - val_precision: 0.5937\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0744 - binary_accuracy: 0.9762 - f1: 0.4159 - recall: 0.3208 - precision: 0.6962 - val_loss: 0.0677 - val_binary_accuracy: 0.9791 - val_f1: 0.3288 - val_recall: 0.2475 - val_precision: 0.6072\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0734 - binary_accuracy: 0.9763 - f1: 0.4186 - recall: 0.3230 - precision: 0.6924 - val_loss: 0.0686 - val_binary_accuracy: 0.9791 - val_f1: 0.3633 - val_recall: 0.2859 - val_precision: 0.6180\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0732 - binary_accuracy: 0.9765 - f1: 0.4307 - recall: 0.3348 - precision: 0.7062 - val_loss: 0.0691 - val_binary_accuracy: 0.9792 - val_f1: 0.3123 - val_recall: 0.2271 - val_precision: 0.6168\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0721 - binary_accuracy: 0.9769 - f1: 0.4476 - recall: 0.3499 - precision: 0.7238 - val_loss: 0.0664 - val_binary_accuracy: 0.9796 - val_f1: 0.3431 - val_recall: 0.2556 - val_precision: 0.6331\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0716 - binary_accuracy: 0.9769 - f1: 0.4434 - recall: 0.3451 - precision: 0.7133 - val_loss: 0.0695 - val_binary_accuracy: 0.9788 - val_f1: 0.3687 - val_recall: 0.2956 - val_precision: 0.5892\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0712 - binary_accuracy: 0.9771 - f1: 0.4474 - recall: 0.3494 - precision: 0.7170 - val_loss: 0.0673 - val_binary_accuracy: 0.9790 - val_f1: 0.3919 - val_recall: 0.3200 - val_precision: 0.6100\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0703 - binary_accuracy: 0.9775 - f1: 0.4618 - recall: 0.3634 - precision: 0.7269 - val_loss: 0.0669 - val_binary_accuracy: 0.9798 - val_f1: 0.3320 - val_recall: 0.2388 - val_precision: 0.6528\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0701 - binary_accuracy: 0.9776 - f1: 0.4643 - recall: 0.3636 - precision: 0.7374 - val_loss: 0.0665 - val_binary_accuracy: 0.9794 - val_f1: 0.3778 - val_recall: 0.3019 - val_precision: 0.6088\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0693 - binary_accuracy: 0.9779 - f1: 0.4802 - recall: 0.3790 - precision: 0.7531 - val_loss: 0.0662 - val_binary_accuracy: 0.9792 - val_f1: 0.3684 - val_recall: 0.2935 - val_precision: 0.6076\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0686 - binary_accuracy: 0.9783 - f1: 0.4802 - recall: 0.3786 - precision: 0.7454 - val_loss: 0.0667 - val_binary_accuracy: 0.9796 - val_f1: 0.3705 - val_recall: 0.2881 - val_precision: 0.6322\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0679 - binary_accuracy: 0.9783 - f1: 0.4890 - recall: 0.3880 - precision: 0.7441 - val_loss: 0.0654 - val_binary_accuracy: 0.9801 - val_f1: 0.3939 - val_recall: 0.3101 - val_precision: 0.6500\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0673 - binary_accuracy: 0.9786 - f1: 0.5007 - recall: 0.3998 - precision: 0.7652 - val_loss: 0.0662 - val_binary_accuracy: 0.9797 - val_f1: 0.3639 - val_recall: 0.2734 - val_precision: 0.6435\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0665 - binary_accuracy: 0.9789 - f1: 0.5102 - recall: 0.4067 - precision: 0.7709 - val_loss: 0.0659 - val_binary_accuracy: 0.9799 - val_f1: 0.3992 - val_recall: 0.3244 - val_precision: 0.6258\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0660 - binary_accuracy: 0.9789 - f1: 0.5076 - recall: 0.4067 - precision: 0.7641 - val_loss: 0.0669 - val_binary_accuracy: 0.9797 - val_f1: 0.3555 - val_recall: 0.2729 - val_precision: 0.6508\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0654 - binary_accuracy: 0.9790 - f1: 0.5152 - recall: 0.4115 - precision: 0.7717 - val_loss: 0.0647 - val_binary_accuracy: 0.9801 - val_f1: 0.3653 - val_recall: 0.2740 - val_precision: 0.6579\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0647 - binary_accuracy: 0.9792 - f1: 0.5183 - recall: 0.4168 - precision: 0.7686 - val_loss: 0.0679 - val_binary_accuracy: 0.9805 - val_f1: 0.3812 - val_recall: 0.2930 - val_precision: 0.6564\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0640 - binary_accuracy: 0.9796 - f1: 0.5247 - recall: 0.4224 - precision: 0.7753 - val_loss: 0.0650 - val_binary_accuracy: 0.9805 - val_f1: 0.3951 - val_recall: 0.3051 - val_precision: 0.6478\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0637 - binary_accuracy: 0.9798 - f1: 0.5334 - recall: 0.4326 - precision: 0.7777 - val_loss: 0.0649 - val_binary_accuracy: 0.9810 - val_f1: 0.3984 - val_recall: 0.3071 - val_precision: 0.6666\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0626 - binary_accuracy: 0.9798 - f1: 0.5328 - recall: 0.4314 - precision: 0.7768 - val_loss: 0.0639 - val_binary_accuracy: 0.9805 - val_f1: 0.4129 - val_recall: 0.3308 - val_precision: 0.6478\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0621 - binary_accuracy: 0.9802 - f1: 0.5402 - recall: 0.4401 - precision: 0.7809 - val_loss: 0.0645 - val_binary_accuracy: 0.9803 - val_f1: 0.3889 - val_recall: 0.3022 - val_precision: 0.6406\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9803 - f1: 0.5470 - recall: 0.4483 - precision: 0.7832 - val_loss: 0.0669 - val_binary_accuracy: 0.9801 - val_f1: 0.4247 - val_recall: 0.3550 - val_precision: 0.6262\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0608 - binary_accuracy: 0.9807 - f1: 0.5626 - recall: 0.4575 - precision: 0.8059 - val_loss: 0.0698 - val_binary_accuracy: 0.9791 - val_f1: 0.4121 - val_recall: 0.3441 - val_precision: 0.5902\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0603 - binary_accuracy: 0.9807 - f1: 0.5583 - recall: 0.4596 - precision: 0.7828 - val_loss: 0.0657 - val_binary_accuracy: 0.9798 - val_f1: 0.4108 - val_recall: 0.3367 - val_precision: 0.6085\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0597 - binary_accuracy: 0.9812 - f1: 0.5751 - recall: 0.4733 - precision: 0.8108 - val_loss: 0.0655 - val_binary_accuracy: 0.9801 - val_f1: 0.4112 - val_recall: 0.3349 - val_precision: 0.6175\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0592 - binary_accuracy: 0.9811 - f1: 0.5760 - recall: 0.4729 - precision: 0.8175 - val_loss: 0.0643 - val_binary_accuracy: 0.9809 - val_f1: 0.4032 - val_recall: 0.3100 - val_precision: 0.6846\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0582 - binary_accuracy: 0.9814 - f1: 0.5846 - recall: 0.4836 - precision: 0.8165 - val_loss: 0.0650 - val_binary_accuracy: 0.9807 - val_f1: 0.4010 - val_recall: 0.3131 - val_precision: 0.6377\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0572 - binary_accuracy: 0.9817 - f1: 0.5876 - recall: 0.4887 - precision: 0.8088 - val_loss: 0.0661 - val_binary_accuracy: 0.9809 - val_f1: 0.3953 - val_recall: 0.3070 - val_precision: 0.6570\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0567 - binary_accuracy: 0.9819 - f1: 0.5919 - recall: 0.4926 - precision: 0.8177 - val_loss: 0.0635 - val_binary_accuracy: 0.9809 - val_f1: 0.4345 - val_recall: 0.3574 - val_precision: 0.6365\n",
      "Epoch 38/500\n",
      "9s - loss: 0.0558 - binary_accuracy: 0.9820 - f1: 0.5976 - recall: 0.4987 - precision: 0.8221 - val_loss: 0.0651 - val_binary_accuracy: 0.9812 - val_f1: 0.4177 - val_recall: 0.3302 - val_precision: 0.6677\n",
      "Epoch 39/500\n",
      "9s - loss: 0.0554 - binary_accuracy: 0.9821 - f1: 0.6083 - recall: 0.5065 - precision: 0.8261 - val_loss: 0.0651 - val_binary_accuracy: 0.9812 - val_f1: 0.3948 - val_recall: 0.2990 - val_precision: 0.6799\n",
      "Epoch 40/500\n",
      "9s - loss: 0.0547 - binary_accuracy: 0.9825 - f1: 0.6128 - recall: 0.5107 - precision: 0.8357 - val_loss: 0.0658 - val_binary_accuracy: 0.9810 - val_f1: 0.4381 - val_recall: 0.3496 - val_precision: 0.6867\n",
      "Epoch 41/500\n",
      "9s - loss: 0.0543 - binary_accuracy: 0.9826 - f1: 0.6178 - recall: 0.5176 - precision: 0.8335 - val_loss: 0.0637 - val_binary_accuracy: 0.9811 - val_f1: 0.4397 - val_recall: 0.3558 - val_precision: 0.6731\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0531 - binary_accuracy: 0.9833 - f1: 0.6328 - recall: 0.5347 - precision: 0.8407 - val_loss: 0.0650 - val_binary_accuracy: 0.9805 - val_f1: 0.4339 - val_recall: 0.3528 - val_precision: 0.6502\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0533 - binary_accuracy: 0.9829 - f1: 0.6234 - recall: 0.5262 - precision: 0.8311 - val_loss: 0.0645 - val_binary_accuracy: 0.9803 - val_f1: 0.4510 - val_recall: 0.3802 - val_precision: 0.6451\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0522 - binary_accuracy: 0.9833 - f1: 0.6333 - recall: 0.5353 - precision: 0.8414 - val_loss: 0.0676 - val_binary_accuracy: 0.9799 - val_f1: 0.4314 - val_recall: 0.3548 - val_precision: 0.6316\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0513 - binary_accuracy: 0.9836 - f1: 0.6403 - recall: 0.5431 - precision: 0.8444 - val_loss: 0.0696 - val_binary_accuracy: 0.9798 - val_f1: 0.4248 - val_recall: 0.3562 - val_precision: 0.5963\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0503 - binary_accuracy: 0.9839 - f1: 0.6473 - recall: 0.5498 - precision: 0.8515 - val_loss: 0.0654 - val_binary_accuracy: 0.9809 - val_f1: 0.4461 - val_recall: 0.3608 - val_precision: 0.6636\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0505 - binary_accuracy: 0.9838 - f1: 0.6513 - recall: 0.5565 - precision: 0.8528 - val_loss: 0.0667 - val_binary_accuracy: 0.9806 - val_f1: 0.4254 - val_recall: 0.3411 - val_precision: 0.6556\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0491 - binary_accuracy: 0.9844 - f1: 0.6583 - recall: 0.5639 - precision: 0.8536 - val_loss: 0.0675 - val_binary_accuracy: 0.9802 - val_f1: 0.4638 - val_recall: 0.4036 - val_precision: 0.6204\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0486 - binary_accuracy: 0.9845 - f1: 0.6649 - recall: 0.5715 - precision: 0.8590 - val_loss: 0.0663 - val_binary_accuracy: 0.9806 - val_f1: 0.4660 - val_recall: 0.3935 - val_precision: 0.6554\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0475 - binary_accuracy: 0.9849 - f1: 0.6815 - recall: 0.5898 - precision: 0.8613 - val_loss: 0.0676 - val_binary_accuracy: 0.9804 - val_f1: 0.4096 - val_recall: 0.3155 - val_precision: 0.6751\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0469 - binary_accuracy: 0.9850 - f1: 0.6771 - recall: 0.5849 - precision: 0.8655 - val_loss: 0.0672 - val_binary_accuracy: 0.9809 - val_f1: 0.4503 - val_recall: 0.3712 - val_precision: 0.6577\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0465 - binary_accuracy: 0.9851 - f1: 0.6772 - recall: 0.5831 - precision: 0.8632 - val_loss: 0.0699 - val_binary_accuracy: 0.9799 - val_f1: 0.4369 - val_recall: 0.3683 - val_precision: 0.6161\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0463 - binary_accuracy: 0.9852 - f1: 0.6893 - recall: 0.5970 - precision: 0.8649 - val_loss: 0.0722 - val_binary_accuracy: 0.9805 - val_f1: 0.4532 - val_recall: 0.3801 - val_precision: 0.6443\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0450 - binary_accuracy: 0.9854 - f1: 0.6927 - recall: 0.6055 - precision: 0.8719 - val_loss: 0.0694 - val_binary_accuracy: 0.9811 - val_f1: 0.4552 - val_recall: 0.3754 - val_precision: 0.6693\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0441 - binary_accuracy: 0.9858 - f1: 0.6919 - recall: 0.6038 - precision: 0.8616 - val_loss: 0.0694 - val_binary_accuracy: 0.9810 - val_f1: 0.4759 - val_recall: 0.4038 - val_precision: 0.6708\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0438 - binary_accuracy: 0.9858 - f1: 0.7027 - recall: 0.6144 - precision: 0.8715 - val_loss: 0.0704 - val_binary_accuracy: 0.9807 - val_f1: 0.4658 - val_recall: 0.3959 - val_precision: 0.6572\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0430 - binary_accuracy: 0.9863 - f1: 0.7112 - recall: 0.6194 - precision: 0.8874 - val_loss: 0.0695 - val_binary_accuracy: 0.9812 - val_f1: 0.4543 - val_recall: 0.3700 - val_precision: 0.6660\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0421 - binary_accuracy: 0.9865 - f1: 0.7110 - recall: 0.6210 - precision: 0.8880 - val_loss: 0.0711 - val_binary_accuracy: 0.9797 - val_f1: 0.4542 - val_recall: 0.3994 - val_precision: 0.5917\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0418 - binary_accuracy: 0.9865 - f1: 0.7169 - recall: 0.6282 - precision: 0.8847 - val_loss: 0.0721 - val_binary_accuracy: 0.9807 - val_f1: 0.4704 - val_recall: 0.4013 - val_precision: 0.6408\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0411 - binary_accuracy: 0.9868 - f1: 0.7188 - recall: 0.6337 - precision: 0.8805 - val_loss: 0.0712 - val_binary_accuracy: 0.9802 - val_f1: 0.4578 - val_recall: 0.3973 - val_precision: 0.6122\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0401 - binary_accuracy: 0.9870 - f1: 0.7273 - recall: 0.6405 - precision: 0.8866 - val_loss: 0.0714 - val_binary_accuracy: 0.9799 - val_f1: 0.4731 - val_recall: 0.4201 - val_precision: 0.6168\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0398 - binary_accuracy: 0.9873 - f1: 0.7352 - recall: 0.6518 - precision: 0.8890 - val_loss: 0.0750 - val_binary_accuracy: 0.9806 - val_f1: 0.4541 - val_recall: 0.3828 - val_precision: 0.6279\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0392 - binary_accuracy: 0.9875 - f1: 0.7371 - recall: 0.6530 - precision: 0.8904 - val_loss: 0.0755 - val_binary_accuracy: 0.9810 - val_f1: 0.4548 - val_recall: 0.3832 - val_precision: 0.6542\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0379 - binary_accuracy: 0.9876 - f1: 0.7389 - recall: 0.6530 - precision: 0.8934 - val_loss: 0.0757 - val_binary_accuracy: 0.9796 - val_f1: 0.4558 - val_recall: 0.3953 - val_precision: 0.6016\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0376 - binary_accuracy: 0.9878 - f1: 0.7442 - recall: 0.6618 - precision: 0.8916 - val_loss: 0.0762 - val_binary_accuracy: 0.9806 - val_f1: 0.4415 - val_recall: 0.3637 - val_precision: 0.6519\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0367 - binary_accuracy: 0.9881 - f1: 0.7550 - recall: 0.6776 - precision: 0.8985 - val_loss: 0.0764 - val_binary_accuracy: 0.9802 - val_f1: 0.4720 - val_recall: 0.4145 - val_precision: 0.6385\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0366 - binary_accuracy: 0.9883 - f1: 0.7630 - recall: 0.6844 - precision: 0.8993 - val_loss: 0.0754 - val_binary_accuracy: 0.9801 - val_f1: 0.4597 - val_recall: 0.3968 - val_precision: 0.6136\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0355 - binary_accuracy: 0.9886 - f1: 0.7673 - recall: 0.6882 - precision: 0.9058 - val_loss: 0.0730 - val_binary_accuracy: 0.9812 - val_f1: 0.4810 - val_recall: 0.4051 - val_precision: 0.6681\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0352 - binary_accuracy: 0.9886 - f1: 0.7604 - recall: 0.6861 - precision: 0.8978 - val_loss: 0.0812 - val_binary_accuracy: 0.9801 - val_f1: 0.4405 - val_recall: 0.3697 - val_precision: 0.6309\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0340 - binary_accuracy: 0.9890 - f1: 0.7709 - recall: 0.6983 - precision: 0.9037 - val_loss: 0.0779 - val_binary_accuracy: 0.9803 - val_f1: 0.4627 - val_recall: 0.3993 - val_precision: 0.6265\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0338 - binary_accuracy: 0.9888 - f1: 0.7714 - recall: 0.6938 - precision: 0.9071 - val_loss: 0.0783 - val_binary_accuracy: 0.9794 - val_f1: 0.4523 - val_recall: 0.3916 - val_precision: 0.6116\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0329 - binary_accuracy: 0.9893 - f1: 0.7845 - recall: 0.7112 - precision: 0.9139 - val_loss: 0.0808 - val_binary_accuracy: 0.9796 - val_f1: 0.4882 - val_recall: 0.4448 - val_precision: 0.6080\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0333 - binary_accuracy: 0.9891 - f1: 0.7786 - recall: 0.7062 - precision: 0.9025 - val_loss: 0.0795 - val_binary_accuracy: 0.9804 - val_f1: 0.4690 - val_recall: 0.4049 - val_precision: 0.6434\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0319 - binary_accuracy: 0.9895 - f1: 0.7863 - recall: 0.7171 - precision: 0.9065 - val_loss: 0.0837 - val_binary_accuracy: 0.9811 - val_f1: 0.4806 - val_recall: 0.4074 - val_precision: 0.6679\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0305 - binary_accuracy: 0.9901 - f1: 0.8016 - recall: 0.7326 - precision: 0.9187 - val_loss: 0.0861 - val_binary_accuracy: 0.9786 - val_f1: 0.4635 - val_recall: 0.4228 - val_precision: 0.5717\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0312 - binary_accuracy: 0.9897 - f1: 0.7944 - recall: 0.7266 - precision: 0.9099 - val_loss: 0.0828 - val_binary_accuracy: 0.9802 - val_f1: 0.4578 - val_recall: 0.3887 - val_precision: 0.6411\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0299 - binary_accuracy: 0.9901 - f1: 0.8050 - recall: 0.7393 - precision: 0.9148 - val_loss: 0.0816 - val_binary_accuracy: 0.9797 - val_f1: 0.4795 - val_recall: 0.4287 - val_precision: 0.6096\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0297 - binary_accuracy: 0.9905 - f1: 0.8091 - recall: 0.7420 - precision: 0.9210 - val_loss: 0.0840 - val_binary_accuracy: 0.9787 - val_f1: 0.4626 - val_recall: 0.4235 - val_precision: 0.5709\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0291 - binary_accuracy: 0.9906 - f1: 0.8119 - recall: 0.7464 - precision: 0.9234 - val_loss: 0.0875 - val_binary_accuracy: 0.9773 - val_f1: 0.4773 - val_recall: 0.4689 - val_precision: 0.5359\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0283 - binary_accuracy: 0.9908 - f1: 0.8166 - recall: 0.7514 - precision: 0.9283 - val_loss: 0.0867 - val_binary_accuracy: 0.9790 - val_f1: 0.4491 - val_recall: 0.3966 - val_precision: 0.5956\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9914 - f1: 0.8317 - recall: 0.7706 - precision: 0.9353 - val_loss: 0.0891 - val_binary_accuracy: 0.9776 - val_f1: 0.4785 - val_recall: 0.4716 - val_precision: 0.5476\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9913 - f1: 0.8297 - recall: 0.7675 - precision: 0.9298 - val_loss: 0.0886 - val_binary_accuracy: 0.9795 - val_f1: 0.4549 - val_recall: 0.4025 - val_precision: 0.6022\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0272 - binary_accuracy: 0.9910 - f1: 0.8199 - recall: 0.7610 - precision: 0.9155 - val_loss: 0.0929 - val_binary_accuracy: 0.9782 - val_f1: 0.4648 - val_recall: 0.4303 - val_precision: 0.5756\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0258 - binary_accuracy: 0.9918 - f1: 0.8374 - recall: 0.7789 - precision: 0.9311 - val_loss: 0.0939 - val_binary_accuracy: 0.9787 - val_f1: 0.4452 - val_recall: 0.3985 - val_precision: 0.5865\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0254 - binary_accuracy: 0.9918 - f1: 0.8407 - recall: 0.7826 - precision: 0.9334 - val_loss: 0.0890 - val_binary_accuracy: 0.9789 - val_f1: 0.4651 - val_recall: 0.4221 - val_precision: 0.5777\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0257 - binary_accuracy: 0.9916 - f1: 0.8364 - recall: 0.7820 - precision: 0.9288 - val_loss: 0.0930 - val_binary_accuracy: 0.9790 - val_f1: 0.4589 - val_recall: 0.4111 - val_precision: 0.5849\n",
      "Epoch 87/500\n",
      "10s - loss: 0.0253 - binary_accuracy: 0.9918 - f1: 0.8390 - recall: 0.7841 - precision: 0.9296 - val_loss: 0.0919 - val_binary_accuracy: 0.9799 - val_f1: 0.4855 - val_recall: 0.4375 - val_precision: 0.6114\n",
      "Epoch 88/500\n",
      "10s - loss: 0.0244 - binary_accuracy: 0.9921 - f1: 0.8457 - recall: 0.7948 - precision: 0.9306 - val_loss: 0.0959 - val_binary_accuracy: 0.9792 - val_f1: 0.4744 - val_recall: 0.4309 - val_precision: 0.5941\n",
      "37792/37917 [============================>.] - ETA: 0stn = 146978, fp = 187, fn = 866, tp = 3637\n",
      "y_pred: 0 = 147844 | 1 = 3824\n",
      "y_true: 0 = 147165 | 1 = 4503\n",
      "acc=0.9931|precision=0.9511|recall=0.8077|f1=0.8735|auc=0.9948|aupr=0.9377|pos_acc=0.8077|neg_acc=0.9941\n",
      "tn = 36727, fp = 263, fn = 526, tp = 401\n",
      "y_pred: 0 = 37253 | 1 = 664\n",
      "y_true: 0 = 36990 | 1 = 927\n",
      "acc=0.9792|precision=0.6039|recall=0.4326|f1=0.5041|auc=0.9042|aupr=0.4948|pos_acc=0.4326|neg_acc=0.9859\n",
      "----------------------- Fold =  2\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0800 - binary_accuracy: 0.9749 - f1: 0.2402 - recall: 0.1740 - precision: 0.4880 - val_loss: 0.0896 - val_binary_accuracy: 0.9697 - val_f1: 0.3278 - val_recall: 0.2360 - val_precision: 0.6253\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0761 - binary_accuracy: 0.9757 - f1: 0.3083 - recall: 0.2276 - precision: 0.6075 - val_loss: 0.0886 - val_binary_accuracy: 0.9701 - val_f1: 0.3934 - val_recall: 0.3096 - val_precision: 0.6177\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0748 - binary_accuracy: 0.9761 - f1: 0.3277 - recall: 0.2435 - precision: 0.6174 - val_loss: 0.0882 - val_binary_accuracy: 0.9705 - val_f1: 0.3958 - val_recall: 0.3078 - val_precision: 0.6329\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0746 - binary_accuracy: 0.9764 - f1: 0.3347 - recall: 0.2492 - precision: 0.6224 - val_loss: 0.0888 - val_binary_accuracy: 0.9709 - val_f1: 0.3848 - val_recall: 0.2892 - val_precision: 0.6611\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0739 - binary_accuracy: 0.9767 - f1: 0.3470 - recall: 0.2569 - precision: 0.6377 - val_loss: 0.0863 - val_binary_accuracy: 0.9711 - val_f1: 0.4014 - val_recall: 0.3088 - val_precision: 0.6643\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0732 - binary_accuracy: 0.9771 - f1: 0.3609 - recall: 0.2731 - precision: 0.6506 - val_loss: 0.0870 - val_binary_accuracy: 0.9711 - val_f1: 0.3596 - val_recall: 0.2581 - val_precision: 0.7087\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0727 - binary_accuracy: 0.9771 - f1: 0.3622 - recall: 0.2748 - precision: 0.6534 - val_loss: 0.0871 - val_binary_accuracy: 0.9708 - val_f1: 0.4668 - val_recall: 0.4048 - val_precision: 0.6048\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0719 - binary_accuracy: 0.9774 - f1: 0.3786 - recall: 0.2859 - precision: 0.6786 - val_loss: 0.0851 - val_binary_accuracy: 0.9709 - val_f1: 0.3955 - val_recall: 0.3032 - val_precision: 0.6636\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0716 - binary_accuracy: 0.9775 - f1: 0.3719 - recall: 0.2793 - precision: 0.6713 - val_loss: 0.0886 - val_binary_accuracy: 0.9712 - val_f1: 0.4482 - val_recall: 0.3715 - val_precision: 0.6366\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0708 - binary_accuracy: 0.9778 - f1: 0.3893 - recall: 0.2959 - precision: 0.6811 - val_loss: 0.0853 - val_binary_accuracy: 0.9715 - val_f1: 0.3641 - val_recall: 0.2632 - val_precision: 0.7172\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0701 - binary_accuracy: 0.9779 - f1: 0.3984 - recall: 0.3039 - precision: 0.6817 - val_loss: 0.0864 - val_binary_accuracy: 0.9700 - val_f1: 0.3690 - val_recall: 0.2838 - val_precision: 0.6185\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0693 - binary_accuracy: 0.9783 - f1: 0.4056 - recall: 0.3111 - precision: 0.6863 - val_loss: 0.0838 - val_binary_accuracy: 0.9714 - val_f1: 0.4144 - val_recall: 0.3216 - val_precision: 0.6680\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0691 - binary_accuracy: 0.9781 - f1: 0.3996 - recall: 0.3058 - precision: 0.6749 - val_loss: 0.0877 - val_binary_accuracy: 0.9707 - val_f1: 0.4382 - val_recall: 0.3647 - val_precision: 0.6098\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0684 - binary_accuracy: 0.9786 - f1: 0.4196 - recall: 0.3237 - precision: 0.7088 - val_loss: 0.0843 - val_binary_accuracy: 0.9722 - val_f1: 0.4381 - val_recall: 0.3449 - val_precision: 0.6834\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0679 - binary_accuracy: 0.9787 - f1: 0.4295 - recall: 0.3348 - precision: 0.7147 - val_loss: 0.0821 - val_binary_accuracy: 0.9721 - val_f1: 0.4395 - val_recall: 0.3495 - val_precision: 0.6699\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0672 - binary_accuracy: 0.9790 - f1: 0.4379 - recall: 0.3421 - precision: 0.7146 - val_loss: 0.0830 - val_binary_accuracy: 0.9711 - val_f1: 0.4330 - val_recall: 0.3582 - val_precision: 0.6127\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0668 - binary_accuracy: 0.9791 - f1: 0.4474 - recall: 0.3471 - precision: 0.7364 - val_loss: 0.0912 - val_binary_accuracy: 0.9698 - val_f1: 0.4086 - val_recall: 0.3364 - val_precision: 0.5928\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0661 - binary_accuracy: 0.9792 - f1: 0.4465 - recall: 0.3502 - precision: 0.7209 - val_loss: 0.0827 - val_binary_accuracy: 0.9719 - val_f1: 0.4033 - val_recall: 0.3038 - val_precision: 0.6974\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0657 - binary_accuracy: 0.9794 - f1: 0.4511 - recall: 0.3503 - precision: 0.7387 - val_loss: 0.0835 - val_binary_accuracy: 0.9723 - val_f1: 0.4587 - val_recall: 0.3762 - val_precision: 0.6549\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0647 - binary_accuracy: 0.9794 - f1: 0.4569 - recall: 0.3578 - precision: 0.7313 - val_loss: 0.0832 - val_binary_accuracy: 0.9720 - val_f1: 0.4632 - val_recall: 0.3849 - val_precision: 0.6466\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0641 - binary_accuracy: 0.9797 - f1: 0.4654 - recall: 0.3679 - precision: 0.7412 - val_loss: 0.0814 - val_binary_accuracy: 0.9725 - val_f1: 0.4568 - val_recall: 0.3698 - val_precision: 0.6702\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0634 - binary_accuracy: 0.9798 - f1: 0.4701 - recall: 0.3695 - precision: 0.7297 - val_loss: 0.0816 - val_binary_accuracy: 0.9711 - val_f1: 0.4813 - val_recall: 0.4282 - val_precision: 0.5950\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0628 - binary_accuracy: 0.9800 - f1: 0.4883 - recall: 0.3880 - precision: 0.7546 - val_loss: 0.0836 - val_binary_accuracy: 0.9719 - val_f1: 0.4783 - val_recall: 0.4125 - val_precision: 0.6223\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0623 - binary_accuracy: 0.9803 - f1: 0.4865 - recall: 0.3835 - precision: 0.7571 - val_loss: 0.0819 - val_binary_accuracy: 0.9726 - val_f1: 0.4027 - val_recall: 0.3008 - val_precision: 0.7263\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0615 - binary_accuracy: 0.9805 - f1: 0.4899 - recall: 0.3858 - precision: 0.7539 - val_loss: 0.0860 - val_binary_accuracy: 0.9699 - val_f1: 0.4848 - val_recall: 0.4530 - val_precision: 0.5579\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0607 - binary_accuracy: 0.9808 - f1: 0.5023 - recall: 0.3964 - precision: 0.7746 - val_loss: 0.0807 - val_binary_accuracy: 0.9718 - val_f1: 0.4830 - val_recall: 0.4226 - val_precision: 0.6122\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0600 - binary_accuracy: 0.9813 - f1: 0.5112 - recall: 0.4089 - precision: 0.7708 - val_loss: 0.0838 - val_binary_accuracy: 0.9709 - val_f1: 0.4601 - val_recall: 0.3977 - val_precision: 0.6045\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0596 - binary_accuracy: 0.9812 - f1: 0.5122 - recall: 0.4127 - precision: 0.7609 - val_loss: 0.0806 - val_binary_accuracy: 0.9727 - val_f1: 0.4912 - val_recall: 0.4214 - val_precision: 0.6470\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0587 - binary_accuracy: 0.9814 - f1: 0.5279 - recall: 0.4262 - precision: 0.7886 - val_loss: 0.0792 - val_binary_accuracy: 0.9736 - val_f1: 0.4808 - val_recall: 0.3924 - val_precision: 0.6907\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0580 - binary_accuracy: 0.9819 - f1: 0.5463 - recall: 0.4449 - precision: 0.8018 - val_loss: 0.0818 - val_binary_accuracy: 0.9726 - val_f1: 0.4941 - val_recall: 0.4302 - val_precision: 0.6301\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0573 - binary_accuracy: 0.9820 - f1: 0.5417 - recall: 0.4412 - precision: 0.7940 - val_loss: 0.0834 - val_binary_accuracy: 0.9719 - val_f1: 0.4915 - val_recall: 0.4390 - val_precision: 0.6057\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0568 - binary_accuracy: 0.9820 - f1: 0.5449 - recall: 0.4481 - precision: 0.7855 - val_loss: 0.0835 - val_binary_accuracy: 0.9726 - val_f1: 0.5282 - val_recall: 0.4868 - val_precision: 0.6254\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0564 - binary_accuracy: 0.9821 - f1: 0.5496 - recall: 0.4491 - precision: 0.7960 - val_loss: 0.0819 - val_binary_accuracy: 0.9728 - val_f1: 0.4937 - val_recall: 0.4284 - val_precision: 0.6448\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0552 - binary_accuracy: 0.9826 - f1: 0.5584 - recall: 0.4545 - precision: 0.8055 - val_loss: 0.0808 - val_binary_accuracy: 0.9730 - val_f1: 0.5271 - val_recall: 0.4777 - val_precision: 0.6334\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0547 - binary_accuracy: 0.9829 - f1: 0.5771 - recall: 0.4770 - precision: 0.8112 - val_loss: 0.0807 - val_binary_accuracy: 0.9736 - val_f1: 0.5303 - val_recall: 0.4730 - val_precision: 0.6522\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0539 - binary_accuracy: 0.9828 - f1: 0.5688 - recall: 0.4700 - precision: 0.8055 - val_loss: 0.0803 - val_binary_accuracy: 0.9742 - val_f1: 0.4990 - val_recall: 0.4110 - val_precision: 0.7112\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0535 - binary_accuracy: 0.9832 - f1: 0.5766 - recall: 0.4762 - precision: 0.8059 - val_loss: 0.0814 - val_binary_accuracy: 0.9726 - val_f1: 0.5125 - val_recall: 0.4673 - val_precision: 0.6228\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0524 - binary_accuracy: 0.9835 - f1: 0.5882 - recall: 0.4872 - precision: 0.8243 - val_loss: 0.0826 - val_binary_accuracy: 0.9739 - val_f1: 0.5364 - val_recall: 0.4844 - val_precision: 0.6491\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0519 - binary_accuracy: 0.9837 - f1: 0.5996 - recall: 0.4973 - precision: 0.8308 - val_loss: 0.0839 - val_binary_accuracy: 0.9726 - val_f1: 0.5434 - val_recall: 0.5100 - val_precision: 0.6294\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0510 - binary_accuracy: 0.9838 - f1: 0.6004 - recall: 0.4991 - precision: 0.8253 - val_loss: 0.0802 - val_binary_accuracy: 0.9735 - val_f1: 0.5122 - val_recall: 0.4433 - val_precision: 0.6598\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9841 - f1: 0.6089 - recall: 0.5114 - precision: 0.8352 - val_loss: 0.0897 - val_binary_accuracy: 0.9700 - val_f1: 0.5415 - val_recall: 0.5583 - val_precision: 0.5669\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0496 - binary_accuracy: 0.9845 - f1: 0.6143 - recall: 0.5141 - precision: 0.8405 - val_loss: 0.0830 - val_binary_accuracy: 0.9732 - val_f1: 0.5238 - val_recall: 0.4731 - val_precision: 0.6498\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0491 - binary_accuracy: 0.9846 - f1: 0.6253 - recall: 0.5262 - precision: 0.8486 - val_loss: 0.0840 - val_binary_accuracy: 0.9720 - val_f1: 0.5420 - val_recall: 0.5216 - val_precision: 0.6105\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0485 - binary_accuracy: 0.9847 - f1: 0.6345 - recall: 0.5358 - precision: 0.8533 - val_loss: 0.0881 - val_binary_accuracy: 0.9717 - val_f1: 0.5490 - val_recall: 0.5407 - val_precision: 0.6021\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0480 - binary_accuracy: 0.9849 - f1: 0.6327 - recall: 0.5336 - precision: 0.8432 - val_loss: 0.0844 - val_binary_accuracy: 0.9727 - val_f1: 0.5431 - val_recall: 0.5094 - val_precision: 0.6283\n",
      "Epoch 46/500\n",
      "9s - loss: 0.0471 - binary_accuracy: 0.9853 - f1: 0.6375 - recall: 0.5370 - precision: 0.8515 - val_loss: 0.0823 - val_binary_accuracy: 0.9734 - val_f1: 0.5353 - val_recall: 0.4845 - val_precision: 0.6481\n",
      "Epoch 47/500\n",
      "9s - loss: 0.0466 - binary_accuracy: 0.9853 - f1: 0.6373 - recall: 0.5415 - precision: 0.8417 - val_loss: 0.0858 - val_binary_accuracy: 0.9736 - val_f1: 0.5111 - val_recall: 0.4405 - val_precision: 0.6657\n",
      "Epoch 48/500\n",
      "9s - loss: 0.0459 - binary_accuracy: 0.9853 - f1: 0.6522 - recall: 0.5535 - precision: 0.8621 - val_loss: 0.0822 - val_binary_accuracy: 0.9742 - val_f1: 0.5523 - val_recall: 0.5021 - val_precision: 0.6699\n",
      "Epoch 49/500\n",
      "9s - loss: 0.0453 - binary_accuracy: 0.9856 - f1: 0.6491 - recall: 0.5538 - precision: 0.8557 - val_loss: 0.0892 - val_binary_accuracy: 0.9727 - val_f1: 0.5316 - val_recall: 0.4992 - val_precision: 0.6201\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0446 - binary_accuracy: 0.9858 - f1: 0.6587 - recall: 0.5634 - precision: 0.8579 - val_loss: 0.0897 - val_binary_accuracy: 0.9713 - val_f1: 0.5306 - val_recall: 0.5153 - val_precision: 0.5947\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0437 - binary_accuracy: 0.9862 - f1: 0.6720 - recall: 0.5771 - precision: 0.8774 - val_loss: 0.0869 - val_binary_accuracy: 0.9734 - val_f1: 0.5330 - val_recall: 0.4808 - val_precision: 0.6551\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0430 - binary_accuracy: 0.9865 - f1: 0.6757 - recall: 0.5788 - precision: 0.8732 - val_loss: 0.0868 - val_binary_accuracy: 0.9743 - val_f1: 0.5396 - val_recall: 0.4826 - val_precision: 0.6694\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0426 - binary_accuracy: 0.9868 - f1: 0.6865 - recall: 0.5932 - precision: 0.8743 - val_loss: 0.0878 - val_binary_accuracy: 0.9736 - val_f1: 0.5245 - val_recall: 0.4630 - val_precision: 0.6685\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9865 - f1: 0.6797 - recall: 0.5873 - precision: 0.8734 - val_loss: 0.0895 - val_binary_accuracy: 0.9718 - val_f1: 0.5493 - val_recall: 0.5490 - val_precision: 0.5966\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0414 - binary_accuracy: 0.9868 - f1: 0.6895 - recall: 0.5949 - precision: 0.8805 - val_loss: 0.0930 - val_binary_accuracy: 0.9708 - val_f1: 0.5331 - val_recall: 0.5295 - val_precision: 0.5852\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0408 - binary_accuracy: 0.9873 - f1: 0.7020 - recall: 0.6104 - precision: 0.8811 - val_loss: 0.0961 - val_binary_accuracy: 0.9705 - val_f1: 0.5214 - val_recall: 0.5175 - val_precision: 0.5689\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0400 - binary_accuracy: 0.9875 - f1: 0.7056 - recall: 0.6159 - precision: 0.8862 - val_loss: 0.0975 - val_binary_accuracy: 0.9697 - val_f1: 0.5330 - val_recall: 0.5453 - val_precision: 0.5596\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0396 - binary_accuracy: 0.9875 - f1: 0.7081 - recall: 0.6134 - precision: 0.8883 - val_loss: 0.0941 - val_binary_accuracy: 0.9707 - val_f1: 0.5248 - val_recall: 0.5133 - val_precision: 0.5781\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0387 - binary_accuracy: 0.9878 - f1: 0.7087 - recall: 0.6183 - precision: 0.8862 - val_loss: 0.0974 - val_binary_accuracy: 0.9690 - val_f1: 0.5382 - val_recall: 0.5695 - val_precision: 0.5468\n",
      "Epoch 60/500\n",
      "9s - loss: 0.0379 - binary_accuracy: 0.9879 - f1: 0.7170 - recall: 0.6278 - precision: 0.8925 - val_loss: 0.0954 - val_binary_accuracy: 0.9705 - val_f1: 0.5360 - val_recall: 0.5416 - val_precision: 0.5758\n",
      "Epoch 61/500\n",
      "9s - loss: 0.0376 - binary_accuracy: 0.9881 - f1: 0.7244 - recall: 0.6386 - precision: 0.8897 - val_loss: 0.1010 - val_binary_accuracy: 0.9695 - val_f1: 0.5278 - val_recall: 0.5365 - val_precision: 0.5548\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0370 - binary_accuracy: 0.9881 - f1: 0.7249 - recall: 0.6409 - precision: 0.8841 - val_loss: 0.0970 - val_binary_accuracy: 0.9720 - val_f1: 0.5472 - val_recall: 0.5311 - val_precision: 0.6067\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0357 - binary_accuracy: 0.9888 - f1: 0.7344 - recall: 0.6516 - precision: 0.8904 - val_loss: 0.1064 - val_binary_accuracy: 0.9669 - val_f1: 0.5435 - val_recall: 0.6100 - val_precision: 0.5226\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0358 - binary_accuracy: 0.9885 - f1: 0.7382 - recall: 0.6526 - precision: 0.9008 - val_loss: 0.0969 - val_binary_accuracy: 0.9715 - val_f1: 0.5345 - val_recall: 0.5215 - val_precision: 0.5942\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0350 - binary_accuracy: 0.9888 - f1: 0.7401 - recall: 0.6551 - precision: 0.9023 - val_loss: 0.1043 - val_binary_accuracy: 0.9686 - val_f1: 0.5277 - val_recall: 0.5469 - val_precision: 0.5454\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0345 - binary_accuracy: 0.9890 - f1: 0.7460 - recall: 0.6652 - precision: 0.8937 - val_loss: 0.1037 - val_binary_accuracy: 0.9712 - val_f1: 0.5430 - val_recall: 0.5356 - val_precision: 0.5975\n",
      "Epoch 67/500\n",
      "9s - loss: 0.0339 - binary_accuracy: 0.9892 - f1: 0.7526 - recall: 0.6730 - precision: 0.9030 - val_loss: 0.1034 - val_binary_accuracy: 0.9696 - val_f1: 0.5242 - val_recall: 0.5299 - val_precision: 0.5555\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0334 - binary_accuracy: 0.9893 - f1: 0.7546 - recall: 0.6793 - precision: 0.8937 - val_loss: 0.1015 - val_binary_accuracy: 0.9708 - val_f1: 0.5454 - val_recall: 0.5494 - val_precision: 0.5871\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0321 - binary_accuracy: 0.9899 - f1: 0.7699 - recall: 0.6892 - precision: 0.9154 - val_loss: 0.1029 - val_binary_accuracy: 0.9718 - val_f1: 0.5312 - val_recall: 0.5099 - val_precision: 0.6051\n",
      "Epoch 70/500\n",
      "9s - loss: 0.0319 - binary_accuracy: 0.9898 - f1: 0.7654 - recall: 0.6885 - precision: 0.9073 - val_loss: 0.1106 - val_binary_accuracy: 0.9709 - val_f1: 0.5316 - val_recall: 0.5132 - val_precision: 0.5944\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0313 - binary_accuracy: 0.9901 - f1: 0.7774 - recall: 0.7029 - precision: 0.9120 - val_loss: 0.1126 - val_binary_accuracy: 0.9688 - val_f1: 0.5403 - val_recall: 0.5733 - val_precision: 0.5418\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0305 - binary_accuracy: 0.9902 - f1: 0.7748 - recall: 0.6998 - precision: 0.9094 - val_loss: 0.1094 - val_binary_accuracy: 0.9686 - val_f1: 0.5232 - val_recall: 0.5437 - val_precision: 0.5392\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0302 - binary_accuracy: 0.9903 - f1: 0.7789 - recall: 0.7063 - precision: 0.9112 - val_loss: 0.1147 - val_binary_accuracy: 0.9679 - val_f1: 0.5191 - val_recall: 0.5458 - val_precision: 0.5329\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0298 - binary_accuracy: 0.9905 - f1: 0.7846 - recall: 0.7127 - precision: 0.9147 - val_loss: 0.1115 - val_binary_accuracy: 0.9695 - val_f1: 0.5363 - val_recall: 0.5594 - val_precision: 0.5589\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0293 - binary_accuracy: 0.9905 - f1: 0.7876 - recall: 0.7169 - precision: 0.9135 - val_loss: 0.1251 - val_binary_accuracy: 0.9648 - val_f1: 0.5008 - val_recall: 0.5573 - val_precision: 0.4880\n",
      "Epoch 76/500\n",
      "9s - loss: 0.0288 - binary_accuracy: 0.9910 - f1: 0.8050 - recall: 0.7379 - precision: 0.9222 - val_loss: 0.1150 - val_binary_accuracy: 0.9675 - val_f1: 0.5213 - val_recall: 0.5575 - val_precision: 0.5302\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0279 - binary_accuracy: 0.9911 - f1: 0.7999 - recall: 0.7332 - precision: 0.9204 - val_loss: 0.1176 - val_binary_accuracy: 0.9681 - val_f1: 0.5106 - val_recall: 0.5307 - val_precision: 0.5307\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9911 - f1: 0.8039 - recall: 0.7400 - precision: 0.9186 - val_loss: 0.1202 - val_binary_accuracy: 0.9676 - val_f1: 0.5182 - val_recall: 0.5496 - val_precision: 0.5295\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0278 - binary_accuracy: 0.9911 - f1: 0.7974 - recall: 0.7374 - precision: 0.9118 - val_loss: 0.1252 - val_binary_accuracy: 0.9661 - val_f1: 0.5077 - val_recall: 0.5509 - val_precision: 0.5048\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0263 - binary_accuracy: 0.9915 - f1: 0.8102 - recall: 0.7477 - precision: 0.9212 - val_loss: 0.1289 - val_binary_accuracy: 0.9675 - val_f1: 0.4619 - val_recall: 0.4489 - val_precision: 0.5244\n",
      "37792/37917 [============================>.] - ETA: 0stn = 147370, fp = 176, fn = 1190, tp = 2932\n",
      "y_pred: 0 = 148560 | 1 = 3108\n",
      "y_true: 0 = 147546 | 1 = 4122\n",
      "acc=0.9910|precision=0.9434|recall=0.7113|f1=0.8111|auc=0.9932|aupr=0.9077|pos_acc=0.7113|neg_acc=0.9920\n",
      "tn = 36102, fp = 507, fn = 725, tp = 583\n",
      "y_pred: 0 = 36827 | 1 = 1090\n",
      "y_true: 0 = 36609 | 1 = 1308\n",
      "acc=0.9675|precision=0.5349|recall=0.4457|f1=0.4862|auc=0.8916|aupr=0.4810|pos_acc=0.4457|neg_acc=0.9803\n",
      "----------------------- Fold =  3\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0848 - binary_accuracy: 0.9729 - f1: 0.2920 - recall: 0.2144 - precision: 0.5841 - val_loss: 0.0704 - val_binary_accuracy: 0.9777 - val_f1: 0.1870 - val_recall: 0.1255 - val_precision: 0.4472\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0810 - binary_accuracy: 0.9737 - f1: 0.3299 - recall: 0.2460 - precision: 0.6068 - val_loss: 0.0703 - val_binary_accuracy: 0.9764 - val_f1: 0.3847 - val_recall: 0.3407 - val_precision: 0.5074\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0798 - binary_accuracy: 0.9745 - f1: 0.3585 - recall: 0.2682 - precision: 0.6534 - val_loss: 0.0673 - val_binary_accuracy: 0.9784 - val_f1: 0.3036 - val_recall: 0.2195 - val_precision: 0.5784\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0789 - binary_accuracy: 0.9748 - f1: 0.3697 - recall: 0.2738 - precision: 0.6742 - val_loss: 0.0675 - val_binary_accuracy: 0.9779 - val_f1: 0.3857 - val_recall: 0.3232 - val_precision: 0.5529\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0781 - binary_accuracy: 0.9749 - f1: 0.3696 - recall: 0.2775 - precision: 0.6622 - val_loss: 0.0667 - val_binary_accuracy: 0.9780 - val_f1: 0.3705 - val_recall: 0.3013 - val_precision: 0.5670\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0773 - binary_accuracy: 0.9753 - f1: 0.3916 - recall: 0.2978 - precision: 0.6915 - val_loss: 0.0669 - val_binary_accuracy: 0.9789 - val_f1: 0.3820 - val_recall: 0.3025 - val_precision: 0.6053\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0768 - binary_accuracy: 0.9752 - f1: 0.3935 - recall: 0.3000 - precision: 0.6879 - val_loss: 0.0667 - val_binary_accuracy: 0.9790 - val_f1: 0.3637 - val_recall: 0.2809 - val_precision: 0.6129\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0759 - binary_accuracy: 0.9756 - f1: 0.4007 - recall: 0.3048 - precision: 0.6869 - val_loss: 0.0659 - val_binary_accuracy: 0.9792 - val_f1: 0.3559 - val_recall: 0.2691 - val_precision: 0.6372\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0750 - binary_accuracy: 0.9759 - f1: 0.4115 - recall: 0.3160 - precision: 0.6871 - val_loss: 0.0650 - val_binary_accuracy: 0.9793 - val_f1: 0.3416 - val_recall: 0.2562 - val_precision: 0.6290\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0740 - binary_accuracy: 0.9762 - f1: 0.4251 - recall: 0.3297 - precision: 0.7054 - val_loss: 0.0656 - val_binary_accuracy: 0.9791 - val_f1: 0.3378 - val_recall: 0.2526 - val_precision: 0.6342\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0736 - binary_accuracy: 0.9765 - f1: 0.4195 - recall: 0.3230 - precision: 0.6890 - val_loss: 0.0662 - val_binary_accuracy: 0.9789 - val_f1: 0.4007 - val_recall: 0.3295 - val_precision: 0.6077\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0728 - binary_accuracy: 0.9767 - f1: 0.4384 - recall: 0.3405 - precision: 0.7187 - val_loss: 0.0647 - val_binary_accuracy: 0.9799 - val_f1: 0.3654 - val_recall: 0.2763 - val_precision: 0.6637\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0723 - binary_accuracy: 0.9772 - f1: 0.4495 - recall: 0.3527 - precision: 0.7268 - val_loss: 0.0648 - val_binary_accuracy: 0.9796 - val_f1: 0.4270 - val_recall: 0.3545 - val_precision: 0.6355\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0712 - binary_accuracy: 0.9773 - f1: 0.4547 - recall: 0.3564 - precision: 0.7204 - val_loss: 0.0657 - val_binary_accuracy: 0.9796 - val_f1: 0.3941 - val_recall: 0.3114 - val_precision: 0.6471\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0706 - binary_accuracy: 0.9774 - f1: 0.4524 - recall: 0.3540 - precision: 0.7349 - val_loss: 0.0664 - val_binary_accuracy: 0.9793 - val_f1: 0.3531 - val_recall: 0.2731 - val_precision: 0.6239\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0703 - binary_accuracy: 0.9775 - f1: 0.4667 - recall: 0.3689 - precision: 0.7469 - val_loss: 0.0642 - val_binary_accuracy: 0.9798 - val_f1: 0.4401 - val_recall: 0.3752 - val_precision: 0.6388\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0694 - binary_accuracy: 0.9779 - f1: 0.4695 - recall: 0.3687 - precision: 0.7407 - val_loss: 0.0653 - val_binary_accuracy: 0.9795 - val_f1: 0.3745 - val_recall: 0.2880 - val_precision: 0.6412\n",
      "Epoch 18/500\n",
      "11s - loss: 0.0689 - binary_accuracy: 0.9781 - f1: 0.4872 - recall: 0.3870 - precision: 0.7465 - val_loss: 0.0636 - val_binary_accuracy: 0.9803 - val_f1: 0.4308 - val_recall: 0.3517 - val_precision: 0.6619\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0678 - binary_accuracy: 0.9783 - f1: 0.4984 - recall: 0.3949 - precision: 0.7652 - val_loss: 0.0655 - val_binary_accuracy: 0.9784 - val_f1: 0.4111 - val_recall: 0.3580 - val_precision: 0.5837\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0674 - binary_accuracy: 0.9786 - f1: 0.4939 - recall: 0.3905 - precision: 0.7658 - val_loss: 0.0631 - val_binary_accuracy: 0.9799 - val_f1: 0.4424 - val_recall: 0.3725 - val_precision: 0.6500\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0667 - binary_accuracy: 0.9786 - f1: 0.5047 - recall: 0.4039 - precision: 0.7651 - val_loss: 0.0639 - val_binary_accuracy: 0.9800 - val_f1: 0.4491 - val_recall: 0.3767 - val_precision: 0.6562\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0662 - binary_accuracy: 0.9790 - f1: 0.5106 - recall: 0.4100 - precision: 0.7625 - val_loss: 0.0640 - val_binary_accuracy: 0.9807 - val_f1: 0.4587 - val_recall: 0.3821 - val_precision: 0.6693\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0649 - binary_accuracy: 0.9795 - f1: 0.5202 - recall: 0.4197 - precision: 0.7787 - val_loss: 0.0635 - val_binary_accuracy: 0.9803 - val_f1: 0.4033 - val_recall: 0.3128 - val_precision: 0.6835\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0643 - binary_accuracy: 0.9791 - f1: 0.5194 - recall: 0.4230 - precision: 0.7689 - val_loss: 0.0628 - val_binary_accuracy: 0.9809 - val_f1: 0.4538 - val_recall: 0.3710 - val_precision: 0.6838\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0634 - binary_accuracy: 0.9798 - f1: 0.5405 - recall: 0.4392 - precision: 0.7949 - val_loss: 0.0631 - val_binary_accuracy: 0.9809 - val_f1: 0.4470 - val_recall: 0.3616 - val_precision: 0.6914\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0628 - binary_accuracy: 0.9800 - f1: 0.5407 - recall: 0.4418 - precision: 0.7795 - val_loss: 0.0649 - val_binary_accuracy: 0.9804 - val_f1: 0.4532 - val_recall: 0.3782 - val_precision: 0.6711\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0615 - binary_accuracy: 0.9803 - f1: 0.5444 - recall: 0.4407 - precision: 0.7874 - val_loss: 0.0626 - val_binary_accuracy: 0.9812 - val_f1: 0.4842 - val_recall: 0.4150 - val_precision: 0.6774\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0612 - binary_accuracy: 0.9805 - f1: 0.5564 - recall: 0.4512 - precision: 0.7950 - val_loss: 0.0639 - val_binary_accuracy: 0.9810 - val_f1: 0.4269 - val_recall: 0.3370 - val_precision: 0.6924\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0607 - binary_accuracy: 0.9806 - f1: 0.5642 - recall: 0.4649 - precision: 0.8009 - val_loss: 0.0617 - val_binary_accuracy: 0.9812 - val_f1: 0.4663 - val_recall: 0.3852 - val_precision: 0.7047\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0596 - binary_accuracy: 0.9810 - f1: 0.5694 - recall: 0.4654 - precision: 0.8091 - val_loss: 0.0620 - val_binary_accuracy: 0.9813 - val_f1: 0.4583 - val_recall: 0.3745 - val_precision: 0.6974\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0587 - binary_accuracy: 0.9815 - f1: 0.5857 - recall: 0.4847 - precision: 0.8209 - val_loss: 0.0636 - val_binary_accuracy: 0.9800 - val_f1: 0.4717 - val_recall: 0.4205 - val_precision: 0.6291\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0586 - binary_accuracy: 0.9812 - f1: 0.5750 - recall: 0.4746 - precision: 0.8077 - val_loss: 0.0615 - val_binary_accuracy: 0.9809 - val_f1: 0.4815 - val_recall: 0.4130 - val_precision: 0.6746\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0572 - binary_accuracy: 0.9816 - f1: 0.5857 - recall: 0.4849 - precision: 0.8176 - val_loss: 0.0624 - val_binary_accuracy: 0.9806 - val_f1: 0.4855 - val_recall: 0.4299 - val_precision: 0.6320\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0564 - binary_accuracy: 0.9820 - f1: 0.5929 - recall: 0.4911 - precision: 0.8168 - val_loss: 0.0621 - val_binary_accuracy: 0.9811 - val_f1: 0.5052 - val_recall: 0.4500 - val_precision: 0.6668\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0560 - binary_accuracy: 0.9821 - f1: 0.6029 - recall: 0.5007 - precision: 0.8240 - val_loss: 0.0631 - val_binary_accuracy: 0.9803 - val_f1: 0.4808 - val_recall: 0.4283 - val_precision: 0.6313\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0553 - binary_accuracy: 0.9824 - f1: 0.6140 - recall: 0.5158 - precision: 0.8282 - val_loss: 0.0628 - val_binary_accuracy: 0.9806 - val_f1: 0.4512 - val_recall: 0.3779 - val_precision: 0.6659\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0551 - binary_accuracy: 0.9823 - f1: 0.6120 - recall: 0.5113 - precision: 0.8272 - val_loss: 0.0618 - val_binary_accuracy: 0.9806 - val_f1: 0.4683 - val_recall: 0.4037 - val_precision: 0.6547\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0538 - binary_accuracy: 0.9826 - f1: 0.6177 - recall: 0.5165 - precision: 0.8348 - val_loss: 0.0607 - val_binary_accuracy: 0.9817 - val_f1: 0.4946 - val_recall: 0.4172 - val_precision: 0.7062\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0530 - binary_accuracy: 0.9831 - f1: 0.6281 - recall: 0.5259 - precision: 0.8474 - val_loss: 0.0654 - val_binary_accuracy: 0.9804 - val_f1: 0.4947 - val_recall: 0.4481 - val_precision: 0.6317\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0522 - binary_accuracy: 0.9833 - f1: 0.6329 - recall: 0.5360 - precision: 0.8366 - val_loss: 0.0639 - val_binary_accuracy: 0.9805 - val_f1: 0.4873 - val_recall: 0.4377 - val_precision: 0.6381\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0518 - binary_accuracy: 0.9836 - f1: 0.6410 - recall: 0.5478 - precision: 0.8370 - val_loss: 0.0643 - val_binary_accuracy: 0.9797 - val_f1: 0.4614 - val_recall: 0.4131 - val_precision: 0.6012\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9837 - f1: 0.6479 - recall: 0.5503 - precision: 0.8468 - val_loss: 0.0643 - val_binary_accuracy: 0.9801 - val_f1: 0.4768 - val_recall: 0.4249 - val_precision: 0.6218\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0501 - binary_accuracy: 0.9839 - f1: 0.6549 - recall: 0.5586 - precision: 0.8468 - val_loss: 0.0651 - val_binary_accuracy: 0.9811 - val_f1: 0.4759 - val_recall: 0.4035 - val_precision: 0.6844\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0498 - binary_accuracy: 0.9839 - f1: 0.6530 - recall: 0.5545 - precision: 0.8576 - val_loss: 0.0635 - val_binary_accuracy: 0.9805 - val_f1: 0.4860 - val_recall: 0.4352 - val_precision: 0.6361\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0490 - binary_accuracy: 0.9843 - f1: 0.6642 - recall: 0.5658 - precision: 0.8636 - val_loss: 0.0643 - val_binary_accuracy: 0.9798 - val_f1: 0.5019 - val_recall: 0.4788 - val_precision: 0.5917\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0479 - binary_accuracy: 0.9845 - f1: 0.6664 - recall: 0.5721 - precision: 0.8536 - val_loss: 0.0632 - val_binary_accuracy: 0.9809 - val_f1: 0.4932 - val_recall: 0.4445 - val_precision: 0.6520\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0477 - binary_accuracy: 0.9846 - f1: 0.6691 - recall: 0.5722 - precision: 0.8532 - val_loss: 0.0641 - val_binary_accuracy: 0.9807 - val_f1: 0.4859 - val_recall: 0.4317 - val_precision: 0.6385\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0468 - binary_accuracy: 0.9852 - f1: 0.6811 - recall: 0.5856 - precision: 0.8681 - val_loss: 0.0653 - val_binary_accuracy: 0.9801 - val_f1: 0.5084 - val_recall: 0.4817 - val_precision: 0.6035\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0461 - binary_accuracy: 0.9849 - f1: 0.6773 - recall: 0.5819 - precision: 0.8588 - val_loss: 0.0655 - val_binary_accuracy: 0.9806 - val_f1: 0.4858 - val_recall: 0.4298 - val_precision: 0.6413\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0453 - binary_accuracy: 0.9850 - f1: 0.6787 - recall: 0.5870 - precision: 0.8588 - val_loss: 0.0647 - val_binary_accuracy: 0.9804 - val_f1: 0.5159 - val_recall: 0.4865 - val_precision: 0.6102\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0448 - binary_accuracy: 0.9855 - f1: 0.6896 - recall: 0.6016 - precision: 0.8578 - val_loss: 0.0648 - val_binary_accuracy: 0.9804 - val_f1: 0.5000 - val_recall: 0.4620 - val_precision: 0.6123\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0440 - binary_accuracy: 0.9859 - f1: 0.6999 - recall: 0.6069 - precision: 0.8832 - val_loss: 0.0656 - val_binary_accuracy: 0.9806 - val_f1: 0.4899 - val_recall: 0.4336 - val_precision: 0.6467\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0431 - binary_accuracy: 0.9858 - f1: 0.7022 - recall: 0.6119 - precision: 0.8712 - val_loss: 0.0651 - val_binary_accuracy: 0.9817 - val_f1: 0.5011 - val_recall: 0.4330 - val_precision: 0.6970\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0428 - binary_accuracy: 0.9859 - f1: 0.7041 - recall: 0.6162 - precision: 0.8764 - val_loss: 0.0679 - val_binary_accuracy: 0.9809 - val_f1: 0.5114 - val_recall: 0.4721 - val_precision: 0.6397\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0422 - binary_accuracy: 0.9862 - f1: 0.7092 - recall: 0.6230 - precision: 0.8740 - val_loss: 0.0666 - val_binary_accuracy: 0.9808 - val_f1: 0.5103 - val_recall: 0.4719 - val_precision: 0.6286\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0417 - binary_accuracy: 0.9862 - f1: 0.7064 - recall: 0.6188 - precision: 0.8705 - val_loss: 0.0691 - val_binary_accuracy: 0.9790 - val_f1: 0.5090 - val_recall: 0.5081 - val_precision: 0.5665\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0405 - binary_accuracy: 0.9870 - f1: 0.7294 - recall: 0.6432 - precision: 0.8866 - val_loss: 0.0679 - val_binary_accuracy: 0.9811 - val_f1: 0.4987 - val_recall: 0.4427 - val_precision: 0.6576\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0401 - binary_accuracy: 0.9869 - f1: 0.7284 - recall: 0.6444 - precision: 0.8866 - val_loss: 0.0692 - val_binary_accuracy: 0.9810 - val_f1: 0.4959 - val_recall: 0.4401 - val_precision: 0.6474\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0391 - binary_accuracy: 0.9871 - f1: 0.7341 - recall: 0.6508 - precision: 0.8867 - val_loss: 0.0708 - val_binary_accuracy: 0.9794 - val_f1: 0.4968 - val_recall: 0.4739 - val_precision: 0.5889\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0389 - binary_accuracy: 0.9873 - f1: 0.7314 - recall: 0.6504 - precision: 0.8825 - val_loss: 0.0688 - val_binary_accuracy: 0.9804 - val_f1: 0.4669 - val_recall: 0.4025 - val_precision: 0.6438\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0382 - binary_accuracy: 0.9876 - f1: 0.7425 - recall: 0.6603 - precision: 0.8950 - val_loss: 0.0719 - val_binary_accuracy: 0.9788 - val_f1: 0.4902 - val_recall: 0.4731 - val_precision: 0.5712\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0376 - binary_accuracy: 0.9877 - f1: 0.7485 - recall: 0.6665 - precision: 0.8974 - val_loss: 0.0702 - val_binary_accuracy: 0.9799 - val_f1: 0.4906 - val_recall: 0.4565 - val_precision: 0.6002\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0365 - binary_accuracy: 0.9881 - f1: 0.7508 - recall: 0.6683 - precision: 0.9006 - val_loss: 0.0702 - val_binary_accuracy: 0.9795 - val_f1: 0.4988 - val_recall: 0.4757 - val_precision: 0.5848\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0357 - binary_accuracy: 0.9884 - f1: 0.7603 - recall: 0.6837 - precision: 0.8981 - val_loss: 0.0720 - val_binary_accuracy: 0.9794 - val_f1: 0.4987 - val_recall: 0.4803 - val_precision: 0.5825\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0350 - binary_accuracy: 0.9887 - f1: 0.7651 - recall: 0.6884 - precision: 0.9023 - val_loss: 0.0741 - val_binary_accuracy: 0.9795 - val_f1: 0.4866 - val_recall: 0.4579 - val_precision: 0.5899\n",
      "Epoch 66/500\n",
      "11s - loss: 0.0350 - binary_accuracy: 0.9886 - f1: 0.7698 - recall: 0.6962 - precision: 0.9033 - val_loss: 0.0758 - val_binary_accuracy: 0.9804 - val_f1: 0.4812 - val_recall: 0.4318 - val_precision: 0.6312\n",
      "Epoch 67/500\n",
      "10s - loss: 0.0348 - binary_accuracy: 0.9886 - f1: 0.7653 - recall: 0.6894 - precision: 0.9014 - val_loss: 0.0754 - val_binary_accuracy: 0.9785 - val_f1: 0.5133 - val_recall: 0.5235 - val_precision: 0.5559\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0333 - binary_accuracy: 0.9894 - f1: 0.7814 - recall: 0.7099 - precision: 0.9069 - val_loss: 0.0781 - val_binary_accuracy: 0.9796 - val_f1: 0.4904 - val_recall: 0.4499 - val_precision: 0.5990\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0327 - binary_accuracy: 0.9894 - f1: 0.7836 - recall: 0.7101 - precision: 0.9092 - val_loss: 0.0786 - val_binary_accuracy: 0.9793 - val_f1: 0.4849 - val_recall: 0.4528 - val_precision: 0.5969\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0323 - binary_accuracy: 0.9896 - f1: 0.7909 - recall: 0.7187 - precision: 0.9183 - val_loss: 0.0774 - val_binary_accuracy: 0.9793 - val_f1: 0.4851 - val_recall: 0.4523 - val_precision: 0.5803\n",
      "Epoch 71/500\n",
      "10s - loss: 0.0316 - binary_accuracy: 0.9899 - f1: 0.7965 - recall: 0.7272 - precision: 0.9136 - val_loss: 0.0777 - val_binary_accuracy: 0.9791 - val_f1: 0.4853 - val_recall: 0.4656 - val_precision: 0.5659\n",
      "Epoch 72/500\n",
      "10s - loss: 0.0307 - binary_accuracy: 0.9902 - f1: 0.8022 - recall: 0.7294 - precision: 0.9213 - val_loss: 0.0792 - val_binary_accuracy: 0.9797 - val_f1: 0.4917 - val_recall: 0.4624 - val_precision: 0.6002\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0301 - binary_accuracy: 0.9902 - f1: 0.8001 - recall: 0.7340 - precision: 0.9172 - val_loss: 0.0795 - val_binary_accuracy: 0.9794 - val_f1: 0.5071 - val_recall: 0.4826 - val_precision: 0.5985\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0299 - binary_accuracy: 0.9901 - f1: 0.8080 - recall: 0.7390 - precision: 0.9213 - val_loss: 0.0783 - val_binary_accuracy: 0.9790 - val_f1: 0.4935 - val_recall: 0.4774 - val_precision: 0.5659\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0288 - binary_accuracy: 0.9905 - f1: 0.8076 - recall: 0.7439 - precision: 0.9180 - val_loss: 0.0793 - val_binary_accuracy: 0.9801 - val_f1: 0.4989 - val_recall: 0.4608 - val_precision: 0.6204\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0282 - binary_accuracy: 0.9908 - f1: 0.8178 - recall: 0.7555 - precision: 0.9219 - val_loss: 0.0854 - val_binary_accuracy: 0.9755 - val_f1: 0.4961 - val_recall: 0.5486 - val_precision: 0.4930\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0282 - binary_accuracy: 0.9909 - f1: 0.8182 - recall: 0.7571 - precision: 0.9195 - val_loss: 0.0862 - val_binary_accuracy: 0.9770 - val_f1: 0.4657 - val_recall: 0.4666 - val_precision: 0.5136\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9913 - f1: 0.8296 - recall: 0.7716 - precision: 0.9275 - val_loss: 0.0846 - val_binary_accuracy: 0.9796 - val_f1: 0.4994 - val_recall: 0.4691 - val_precision: 0.6083\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0271 - binary_accuracy: 0.9911 - f1: 0.8247 - recall: 0.7661 - precision: 0.9227 - val_loss: 0.0842 - val_binary_accuracy: 0.9800 - val_f1: 0.4852 - val_recall: 0.4498 - val_precision: 0.5975\n",
      "Epoch 80/500\n",
      "10s - loss: 0.0256 - binary_accuracy: 0.9918 - f1: 0.8405 - recall: 0.7845 - precision: 0.9322 - val_loss: 0.0881 - val_binary_accuracy: 0.9780 - val_f1: 0.4915 - val_recall: 0.4876 - val_precision: 0.5560\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0257 - binary_accuracy: 0.9915 - f1: 0.8369 - recall: 0.7806 - precision: 0.9287 - val_loss: 0.0893 - val_binary_accuracy: 0.9772 - val_f1: 0.5026 - val_recall: 0.5235 - val_precision: 0.5228\n",
      "Epoch 82/500\n",
      "10s - loss: 0.0250 - binary_accuracy: 0.9919 - f1: 0.8453 - recall: 0.7921 - precision: 0.9339 - val_loss: 0.0885 - val_binary_accuracy: 0.9786 - val_f1: 0.4985 - val_recall: 0.4868 - val_precision: 0.5704\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0248 - binary_accuracy: 0.9920 - f1: 0.8364 - recall: 0.7801 - precision: 0.9317 - val_loss: 0.0900 - val_binary_accuracy: 0.9772 - val_f1: 0.4840 - val_recall: 0.4897 - val_precision: 0.5252\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0239 - binary_accuracy: 0.9922 - f1: 0.8476 - recall: 0.7957 - precision: 0.9339 - val_loss: 0.0896 - val_binary_accuracy: 0.9794 - val_f1: 0.4926 - val_recall: 0.4628 - val_precision: 0.6116\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0239 - binary_accuracy: 0.9924 - f1: 0.8489 - recall: 0.7972 - precision: 0.9352 - val_loss: 0.0874 - val_binary_accuracy: 0.9778 - val_f1: 0.4942 - val_recall: 0.4959 - val_precision: 0.5454\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0232 - binary_accuracy: 0.9926 - f1: 0.8538 - recall: 0.7990 - precision: 0.9437 - val_loss: 0.0965 - val_binary_accuracy: 0.9770 - val_f1: 0.4828 - val_recall: 0.4897 - val_precision: 0.5270\n",
      "Epoch 87/500\n",
      "10s - loss: 0.0230 - binary_accuracy: 0.9928 - f1: 0.8593 - recall: 0.8098 - precision: 0.9390 - val_loss: 0.0940 - val_binary_accuracy: 0.9792 - val_f1: 0.4854 - val_recall: 0.4573 - val_precision: 0.5853\n",
      "Epoch 88/500\n",
      "10s - loss: 0.0220 - binary_accuracy: 0.9930 - f1: 0.8649 - recall: 0.8151 - precision: 0.9423 - val_loss: 0.0940 - val_binary_accuracy: 0.9781 - val_f1: 0.4706 - val_recall: 0.4530 - val_precision: 0.5552\n",
      "Epoch 89/500\n",
      "10s - loss: 0.0220 - binary_accuracy: 0.9928 - f1: 0.8596 - recall: 0.8107 - precision: 0.9383 - val_loss: 0.0979 - val_binary_accuracy: 0.9773 - val_f1: 0.4926 - val_recall: 0.5070 - val_precision: 0.5270\n",
      "37344/37917 [============================>.] - ETA: 0stn = 146791, fp = 355, fn = 681, tp = 3841\n",
      "y_pred: 0 = 147472 | 1 = 4196\n",
      "y_true: 0 = 147146 | 1 = 4522\n",
      "acc=0.9932|precision=0.9154|recall=0.8494|f1=0.8812|auc=0.9957|aupr=0.9431|pos_acc=0.8494|neg_acc=0.9954\n",
      "tn = 36604, fp = 405, fn = 454, tp = 454\n",
      "y_pred: 0 = 37058 | 1 = 859\n",
      "y_true: 0 = 37009 | 1 = 908\n",
      "acc=0.9773|precision=0.5285|recall=0.5000|f1=0.5139|auc=0.9237|aupr=0.5218|pos_acc=0.5000|neg_acc=0.9877\n",
      "----------------------- Fold =  4\n",
      "Train on 151668 samples, validate on 37917 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0852 - binary_accuracy: 0.9716 - f1: 0.2496 - recall: 0.1860 - precision: 0.5025 - val_loss: 0.0790 - val_binary_accuracy: 0.9749 - val_f1: 0.3362 - val_recall: 0.2425 - val_precision: 0.6546\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0784 - binary_accuracy: 0.9747 - f1: 0.3223 - recall: 0.2393 - precision: 0.6083 - val_loss: 0.0772 - val_binary_accuracy: 0.9755 - val_f1: 0.3682 - val_recall: 0.2701 - val_precision: 0.6710\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0775 - binary_accuracy: 0.9752 - f1: 0.3364 - recall: 0.2519 - precision: 0.6062 - val_loss: 0.0775 - val_binary_accuracy: 0.9753 - val_f1: 0.4000 - val_recall: 0.3118 - val_precision: 0.6490\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0771 - binary_accuracy: 0.9752 - f1: 0.3384 - recall: 0.2520 - precision: 0.6247 - val_loss: 0.0774 - val_binary_accuracy: 0.9752 - val_f1: 0.3278 - val_recall: 0.2319 - val_precision: 0.6767\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0767 - binary_accuracy: 0.9753 - f1: 0.3500 - recall: 0.2638 - precision: 0.6404 - val_loss: 0.0774 - val_binary_accuracy: 0.9756 - val_f1: 0.3731 - val_recall: 0.2798 - val_precision: 0.6417\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0763 - binary_accuracy: 0.9755 - f1: 0.3551 - recall: 0.2671 - precision: 0.6433 - val_loss: 0.0787 - val_binary_accuracy: 0.9754 - val_f1: 0.3080 - val_recall: 0.2123 - val_precision: 0.6702\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0760 - binary_accuracy: 0.9758 - f1: 0.3614 - recall: 0.2728 - precision: 0.6385 - val_loss: 0.0776 - val_binary_accuracy: 0.9743 - val_f1: 0.4372 - val_recall: 0.3753 - val_precision: 0.5968\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0751 - binary_accuracy: 0.9759 - f1: 0.3674 - recall: 0.2778 - precision: 0.6476 - val_loss: 0.0750 - val_binary_accuracy: 0.9758 - val_f1: 0.4021 - val_recall: 0.3082 - val_precision: 0.6933\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0746 - binary_accuracy: 0.9762 - f1: 0.3787 - recall: 0.2866 - precision: 0.6708 - val_loss: 0.0765 - val_binary_accuracy: 0.9760 - val_f1: 0.4125 - val_recall: 0.3239 - val_precision: 0.6847\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0739 - binary_accuracy: 0.9765 - f1: 0.3922 - recall: 0.2994 - precision: 0.6710 - val_loss: 0.0808 - val_binary_accuracy: 0.9752 - val_f1: 0.4352 - val_recall: 0.3603 - val_precision: 0.6249\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0734 - binary_accuracy: 0.9768 - f1: 0.3979 - recall: 0.3029 - precision: 0.6872 - val_loss: 0.0754 - val_binary_accuracy: 0.9761 - val_f1: 0.4368 - val_recall: 0.3506 - val_precision: 0.6758\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0725 - binary_accuracy: 0.9768 - f1: 0.4044 - recall: 0.3116 - precision: 0.6862 - val_loss: 0.0749 - val_binary_accuracy: 0.9763 - val_f1: 0.3684 - val_recall: 0.2646 - val_precision: 0.7089\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0719 - binary_accuracy: 0.9773 - f1: 0.4152 - recall: 0.3213 - precision: 0.7032 - val_loss: 0.0733 - val_binary_accuracy: 0.9771 - val_f1: 0.4752 - val_recall: 0.3857 - val_precision: 0.7128\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0714 - binary_accuracy: 0.9772 - f1: 0.4163 - recall: 0.3236 - precision: 0.6934 - val_loss: 0.0729 - val_binary_accuracy: 0.9770 - val_f1: 0.4631 - val_recall: 0.3738 - val_precision: 0.6933\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0709 - binary_accuracy: 0.9774 - f1: 0.4211 - recall: 0.3254 - precision: 0.7088 - val_loss: 0.0726 - val_binary_accuracy: 0.9777 - val_f1: 0.4709 - val_recall: 0.3761 - val_precision: 0.7348\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0703 - binary_accuracy: 0.9776 - f1: 0.4362 - recall: 0.3394 - precision: 0.7024 - val_loss: 0.0742 - val_binary_accuracy: 0.9767 - val_f1: 0.3728 - val_recall: 0.2688 - val_precision: 0.7162\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0696 - binary_accuracy: 0.9777 - f1: 0.4380 - recall: 0.3434 - precision: 0.7063 - val_loss: 0.0726 - val_binary_accuracy: 0.9775 - val_f1: 0.4368 - val_recall: 0.3320 - val_precision: 0.7282\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0689 - binary_accuracy: 0.9778 - f1: 0.4415 - recall: 0.3469 - precision: 0.7088 - val_loss: 0.0722 - val_binary_accuracy: 0.9775 - val_f1: 0.4770 - val_recall: 0.3831 - val_precision: 0.7245\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0682 - binary_accuracy: 0.9781 - f1: 0.4486 - recall: 0.3504 - precision: 0.7168 - val_loss: 0.0712 - val_binary_accuracy: 0.9772 - val_f1: 0.4198 - val_recall: 0.3119 - val_precision: 0.7541\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0676 - binary_accuracy: 0.9785 - f1: 0.4608 - recall: 0.3621 - precision: 0.7265 - val_loss: 0.0703 - val_binary_accuracy: 0.9778 - val_f1: 0.4886 - val_recall: 0.4013 - val_precision: 0.7031\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0671 - binary_accuracy: 0.9786 - f1: 0.4675 - recall: 0.3717 - precision: 0.7274 - val_loss: 0.0706 - val_binary_accuracy: 0.9780 - val_f1: 0.5066 - val_recall: 0.4205 - val_precision: 0.7166\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0665 - binary_accuracy: 0.9791 - f1: 0.4821 - recall: 0.3822 - precision: 0.7479 - val_loss: 0.0700 - val_binary_accuracy: 0.9779 - val_f1: 0.4291 - val_recall: 0.3180 - val_precision: 0.7521\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0658 - binary_accuracy: 0.9791 - f1: 0.4856 - recall: 0.3843 - precision: 0.7494 - val_loss: 0.0709 - val_binary_accuracy: 0.9783 - val_f1: 0.4671 - val_recall: 0.3640 - val_precision: 0.7551\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0655 - binary_accuracy: 0.9792 - f1: 0.4852 - recall: 0.3848 - precision: 0.7430 - val_loss: 0.0703 - val_binary_accuracy: 0.9780 - val_f1: 0.4472 - val_recall: 0.3363 - val_precision: 0.7580\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0644 - binary_accuracy: 0.9796 - f1: 0.5002 - recall: 0.4018 - precision: 0.7619 - val_loss: 0.0705 - val_binary_accuracy: 0.9782 - val_f1: 0.4611 - val_recall: 0.3525 - val_precision: 0.7581\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0642 - binary_accuracy: 0.9796 - f1: 0.4995 - recall: 0.3981 - precision: 0.7653 - val_loss: 0.0705 - val_binary_accuracy: 0.9787 - val_f1: 0.5169 - val_recall: 0.4284 - val_precision: 0.7309\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0632 - binary_accuracy: 0.9799 - f1: 0.5080 - recall: 0.4052 - precision: 0.7654 - val_loss: 0.0717 - val_binary_accuracy: 0.9778 - val_f1: 0.4966 - val_recall: 0.4130 - val_precision: 0.6861\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0624 - binary_accuracy: 0.9802 - f1: 0.5130 - recall: 0.4113 - precision: 0.7671 - val_loss: 0.0695 - val_binary_accuracy: 0.9783 - val_f1: 0.4759 - val_recall: 0.3704 - val_precision: 0.7634\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9805 - f1: 0.5242 - recall: 0.4240 - precision: 0.7791 - val_loss: 0.0744 - val_binary_accuracy: 0.9779 - val_f1: 0.4767 - val_recall: 0.3832 - val_precision: 0.7230\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0614 - binary_accuracy: 0.9806 - f1: 0.5277 - recall: 0.4257 - precision: 0.7912 - val_loss: 0.0691 - val_binary_accuracy: 0.9786 - val_f1: 0.5180 - val_recall: 0.4297 - val_precision: 0.7373\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0608 - binary_accuracy: 0.9808 - f1: 0.5354 - recall: 0.4368 - precision: 0.7813 - val_loss: 0.0695 - val_binary_accuracy: 0.9788 - val_f1: 0.5024 - val_recall: 0.4035 - val_precision: 0.7507\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0599 - binary_accuracy: 0.9811 - f1: 0.5439 - recall: 0.4389 - precision: 0.8042 - val_loss: 0.0676 - val_binary_accuracy: 0.9793 - val_f1: 0.5160 - val_recall: 0.4140 - val_precision: 0.7800\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0593 - binary_accuracy: 0.9813 - f1: 0.5557 - recall: 0.4542 - precision: 0.8018 - val_loss: 0.0692 - val_binary_accuracy: 0.9788 - val_f1: 0.5162 - val_recall: 0.4197 - val_precision: 0.7521\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0586 - binary_accuracy: 0.9816 - f1: 0.5608 - recall: 0.4587 - precision: 0.7949 - val_loss: 0.0701 - val_binary_accuracy: 0.9792 - val_f1: 0.4941 - val_recall: 0.3870 - val_precision: 0.7695\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0575 - binary_accuracy: 0.9819 - f1: 0.5651 - recall: 0.4601 - precision: 0.8180 - val_loss: 0.0687 - val_binary_accuracy: 0.9791 - val_f1: 0.5028 - val_recall: 0.4008 - val_precision: 0.7770\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0572 - binary_accuracy: 0.9820 - f1: 0.5729 - recall: 0.4701 - precision: 0.8170 - val_loss: 0.0690 - val_binary_accuracy: 0.9788 - val_f1: 0.5030 - val_recall: 0.4047 - val_precision: 0.7455\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0566 - binary_accuracy: 0.9820 - f1: 0.5762 - recall: 0.4747 - precision: 0.8068 - val_loss: 0.0688 - val_binary_accuracy: 0.9789 - val_f1: 0.5282 - val_recall: 0.4429 - val_precision: 0.7324\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0559 - binary_accuracy: 0.9821 - f1: 0.5693 - recall: 0.4719 - precision: 0.7980 - val_loss: 0.0675 - val_binary_accuracy: 0.9793 - val_f1: 0.5419 - val_recall: 0.4621 - val_precision: 0.7234\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0553 - binary_accuracy: 0.9825 - f1: 0.5911 - recall: 0.4894 - precision: 0.8243 - val_loss: 0.0675 - val_binary_accuracy: 0.9792 - val_f1: 0.5262 - val_recall: 0.4347 - val_precision: 0.7491\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0547 - binary_accuracy: 0.9828 - f1: 0.5993 - recall: 0.4963 - precision: 0.8304 - val_loss: 0.0684 - val_binary_accuracy: 0.9783 - val_f1: 0.5277 - val_recall: 0.4510 - val_precision: 0.6977\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0539 - binary_accuracy: 0.9831 - f1: 0.6026 - recall: 0.5021 - precision: 0.8306 - val_loss: 0.0693 - val_binary_accuracy: 0.9791 - val_f1: 0.5077 - val_recall: 0.4096 - val_precision: 0.7494\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0530 - binary_accuracy: 0.9834 - f1: 0.6146 - recall: 0.5151 - precision: 0.8322 - val_loss: 0.0675 - val_binary_accuracy: 0.9792 - val_f1: 0.5337 - val_recall: 0.4477 - val_precision: 0.7315\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0526 - binary_accuracy: 0.9833 - f1: 0.6092 - recall: 0.5086 - precision: 0.8322 - val_loss: 0.0687 - val_binary_accuracy: 0.9790 - val_f1: 0.5165 - val_recall: 0.4211 - val_precision: 0.7449\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0520 - binary_accuracy: 0.9836 - f1: 0.6147 - recall: 0.5137 - precision: 0.8365 - val_loss: 0.0704 - val_binary_accuracy: 0.9793 - val_f1: 0.5086 - val_recall: 0.4109 - val_precision: 0.7470\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0515 - binary_accuracy: 0.9839 - f1: 0.6182 - recall: 0.5158 - precision: 0.8455 - val_loss: 0.0691 - val_binary_accuracy: 0.9800 - val_f1: 0.5381 - val_recall: 0.4371 - val_precision: 0.7748\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0512 - binary_accuracy: 0.9840 - f1: 0.6340 - recall: 0.5367 - precision: 0.8477 - val_loss: 0.0714 - val_binary_accuracy: 0.9791 - val_f1: 0.5341 - val_recall: 0.4503 - val_precision: 0.7223\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0499 - binary_accuracy: 0.9843 - f1: 0.6350 - recall: 0.5337 - precision: 0.8513 - val_loss: 0.0705 - val_binary_accuracy: 0.9786 - val_f1: 0.5294 - val_recall: 0.4561 - val_precision: 0.7028\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0499 - binary_accuracy: 0.9841 - f1: 0.6380 - recall: 0.5392 - precision: 0.8452 - val_loss: 0.0718 - val_binary_accuracy: 0.9780 - val_f1: 0.5124 - val_recall: 0.4411 - val_precision: 0.6824\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0487 - binary_accuracy: 0.9847 - f1: 0.6492 - recall: 0.5487 - precision: 0.8628 - val_loss: 0.0694 - val_binary_accuracy: 0.9797 - val_f1: 0.5463 - val_recall: 0.4684 - val_precision: 0.7349\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0481 - binary_accuracy: 0.9849 - f1: 0.6538 - recall: 0.5559 - precision: 0.8652 - val_loss: 0.0693 - val_binary_accuracy: 0.9793 - val_f1: 0.5493 - val_recall: 0.4739 - val_precision: 0.7166\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0476 - binary_accuracy: 0.9853 - f1: 0.6704 - recall: 0.5700 - precision: 0.8766 - val_loss: 0.0710 - val_binary_accuracy: 0.9795 - val_f1: 0.5230 - val_recall: 0.4216 - val_precision: 0.7630\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0470 - binary_accuracy: 0.9851 - f1: 0.6586 - recall: 0.5643 - precision: 0.8547 - val_loss: 0.0742 - val_binary_accuracy: 0.9796 - val_f1: 0.5409 - val_recall: 0.4554 - val_precision: 0.7340\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0459 - binary_accuracy: 0.9856 - f1: 0.6724 - recall: 0.5742 - precision: 0.8701 - val_loss: 0.0710 - val_binary_accuracy: 0.9787 - val_f1: 0.5437 - val_recall: 0.4797 - val_precision: 0.6937\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0456 - binary_accuracy: 0.9855 - f1: 0.6691 - recall: 0.5707 - precision: 0.8681 - val_loss: 0.0714 - val_binary_accuracy: 0.9799 - val_f1: 0.5478 - val_recall: 0.4613 - val_precision: 0.7554\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0445 - binary_accuracy: 0.9860 - f1: 0.6839 - recall: 0.5888 - precision: 0.8824 - val_loss: 0.0734 - val_binary_accuracy: 0.9789 - val_f1: 0.5473 - val_recall: 0.4708 - val_precision: 0.7194\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0445 - binary_accuracy: 0.9861 - f1: 0.6844 - recall: 0.5892 - precision: 0.8735 - val_loss: 0.0695 - val_binary_accuracy: 0.9802 - val_f1: 0.5662 - val_recall: 0.4825 - val_precision: 0.7484\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0435 - binary_accuracy: 0.9863 - f1: 0.6962 - recall: 0.6008 - precision: 0.8855 - val_loss: 0.0730 - val_binary_accuracy: 0.9795 - val_f1: 0.5493 - val_recall: 0.4723 - val_precision: 0.7215\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0427 - binary_accuracy: 0.9867 - f1: 0.7033 - recall: 0.6096 - precision: 0.8840 - val_loss: 0.0740 - val_binary_accuracy: 0.9793 - val_f1: 0.5391 - val_recall: 0.4549 - val_precision: 0.7242\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0420 - binary_accuracy: 0.9866 - f1: 0.7087 - recall: 0.6197 - precision: 0.8847 - val_loss: 0.0736 - val_binary_accuracy: 0.9799 - val_f1: 0.5442 - val_recall: 0.4555 - val_precision: 0.7672\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0416 - binary_accuracy: 0.9870 - f1: 0.7084 - recall: 0.6168 - precision: 0.8870 - val_loss: 0.0746 - val_binary_accuracy: 0.9800 - val_f1: 0.5428 - val_recall: 0.4515 - val_precision: 0.7457\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0407 - binary_accuracy: 0.9871 - f1: 0.7150 - recall: 0.6240 - precision: 0.8896 - val_loss: 0.0737 - val_binary_accuracy: 0.9795 - val_f1: 0.5426 - val_recall: 0.4546 - val_precision: 0.7303\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0401 - binary_accuracy: 0.9873 - f1: 0.7188 - recall: 0.6321 - precision: 0.8861 - val_loss: 0.0772 - val_binary_accuracy: 0.9782 - val_f1: 0.5290 - val_recall: 0.4676 - val_precision: 0.6647\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0393 - binary_accuracy: 0.9876 - f1: 0.7262 - recall: 0.6395 - precision: 0.8940 - val_loss: 0.0755 - val_binary_accuracy: 0.9785 - val_f1: 0.5335 - val_recall: 0.4575 - val_precision: 0.7064\n",
      "Epoch 64/500\n",
      "10s - loss: 0.0386 - binary_accuracy: 0.9878 - f1: 0.7351 - recall: 0.6441 - precision: 0.9061 - val_loss: 0.0803 - val_binary_accuracy: 0.9791 - val_f1: 0.5152 - val_recall: 0.4190 - val_precision: 0.7419\n",
      "Epoch 65/500\n",
      "10s - loss: 0.0382 - binary_accuracy: 0.9877 - f1: 0.7250 - recall: 0.6388 - precision: 0.8867 - val_loss: 0.0807 - val_binary_accuracy: 0.9800 - val_f1: 0.5193 - val_recall: 0.4133 - val_precision: 0.7919\n",
      "Epoch 66/500\n",
      "10s - loss: 0.0373 - binary_accuracy: 0.9882 - f1: 0.7345 - recall: 0.6470 - precision: 0.8952 - val_loss: 0.0779 - val_binary_accuracy: 0.9795 - val_f1: 0.5428 - val_recall: 0.4618 - val_precision: 0.7287\n",
      "Epoch 67/500\n",
      "11s - loss: 0.0369 - binary_accuracy: 0.9884 - f1: 0.7461 - recall: 0.6606 - precision: 0.9034 - val_loss: 0.0796 - val_binary_accuracy: 0.9792 - val_f1: 0.5458 - val_recall: 0.4702 - val_precision: 0.7116\n",
      "Epoch 68/500\n",
      "10s - loss: 0.0365 - binary_accuracy: 0.9882 - f1: 0.7439 - recall: 0.6631 - precision: 0.8960 - val_loss: 0.0792 - val_binary_accuracy: 0.9799 - val_f1: 0.5435 - val_recall: 0.4530 - val_precision: 0.7481\n",
      "Epoch 69/500\n",
      "10s - loss: 0.0353 - binary_accuracy: 0.9887 - f1: 0.7529 - recall: 0.6706 - precision: 0.9049 - val_loss: 0.0775 - val_binary_accuracy: 0.9796 - val_f1: 0.5439 - val_recall: 0.4619 - val_precision: 0.7327\n",
      "Epoch 70/500\n",
      "10s - loss: 0.0350 - binary_accuracy: 0.9890 - f1: 0.7632 - recall: 0.6837 - precision: 0.9124 - val_loss: 0.0776 - val_binary_accuracy: 0.9792 - val_f1: 0.5649 - val_recall: 0.5021 - val_precision: 0.7075\n",
      "Epoch 71/500\n",
      "11s - loss: 0.0344 - binary_accuracy: 0.9890 - f1: 0.7685 - recall: 0.6887 - precision: 0.9077 - val_loss: 0.0808 - val_binary_accuracy: 0.9798 - val_f1: 0.5598 - val_recall: 0.4891 - val_precision: 0.7119\n",
      "Epoch 72/500\n",
      "11s - loss: 0.0346 - binary_accuracy: 0.9890 - f1: 0.7636 - recall: 0.6842 - precision: 0.9074 - val_loss: 0.0789 - val_binary_accuracy: 0.9798 - val_f1: 0.5634 - val_recall: 0.4922 - val_precision: 0.7169\n",
      "Epoch 73/500\n",
      "10s - loss: 0.0332 - binary_accuracy: 0.9893 - f1: 0.7715 - recall: 0.6955 - precision: 0.9091 - val_loss: 0.0802 - val_binary_accuracy: 0.9790 - val_f1: 0.5548 - val_recall: 0.4878 - val_precision: 0.7065\n",
      "Epoch 74/500\n",
      "10s - loss: 0.0324 - binary_accuracy: 0.9897 - f1: 0.7800 - recall: 0.7019 - precision: 0.9157 - val_loss: 0.0808 - val_binary_accuracy: 0.9786 - val_f1: 0.5630 - val_recall: 0.5146 - val_precision: 0.6794\n",
      "Epoch 75/500\n",
      "10s - loss: 0.0314 - binary_accuracy: 0.9899 - f1: 0.7829 - recall: 0.7083 - precision: 0.9128 - val_loss: 0.0868 - val_binary_accuracy: 0.9795 - val_f1: 0.5247 - val_recall: 0.4270 - val_precision: 0.7633\n",
      "Epoch 76/500\n",
      "10s - loss: 0.0311 - binary_accuracy: 0.9900 - f1: 0.7844 - recall: 0.7058 - precision: 0.9240 - val_loss: 0.0860 - val_binary_accuracy: 0.9786 - val_f1: 0.5285 - val_recall: 0.4536 - val_precision: 0.7056\n",
      "Epoch 77/500\n",
      "10s - loss: 0.0308 - binary_accuracy: 0.9902 - f1: 0.7923 - recall: 0.7192 - precision: 0.9176 - val_loss: 0.0843 - val_binary_accuracy: 0.9782 - val_f1: 0.5451 - val_recall: 0.4920 - val_precision: 0.6718\n",
      "Epoch 78/500\n",
      "10s - loss: 0.0294 - binary_accuracy: 0.9908 - f1: 0.8064 - recall: 0.7326 - precision: 0.9320 - val_loss: 0.0852 - val_binary_accuracy: 0.9799 - val_f1: 0.5308 - val_recall: 0.4352 - val_precision: 0.7651\n",
      "Epoch 79/500\n",
      "10s - loss: 0.0292 - binary_accuracy: 0.9908 - f1: 0.8047 - recall: 0.7330 - precision: 0.9292 - val_loss: 0.0873 - val_binary_accuracy: 0.9785 - val_f1: 0.5422 - val_recall: 0.4920 - val_precision: 0.6678\n",
      "Epoch 80/500\n",
      "11s - loss: 0.0292 - binary_accuracy: 0.9907 - f1: 0.7985 - recall: 0.7276 - precision: 0.9246 - val_loss: 0.0880 - val_binary_accuracy: 0.9795 - val_f1: 0.5398 - val_recall: 0.4497 - val_precision: 0.7345\n",
      "Epoch 81/500\n",
      "10s - loss: 0.0282 - binary_accuracy: 0.9909 - f1: 0.8102 - recall: 0.7428 - precision: 0.9292 - val_loss: 0.0861 - val_binary_accuracy: 0.9801 - val_f1: 0.5602 - val_recall: 0.4792 - val_precision: 0.7397\n",
      "Epoch 82/500\n",
      "11s - loss: 0.0275 - binary_accuracy: 0.9911 - f1: 0.8159 - recall: 0.7475 - precision: 0.9316 - val_loss: 0.0880 - val_binary_accuracy: 0.9796 - val_f1: 0.5598 - val_recall: 0.4915 - val_precision: 0.7049\n",
      "Epoch 83/500\n",
      "10s - loss: 0.0273 - binary_accuracy: 0.9912 - f1: 0.8190 - recall: 0.7515 - precision: 0.9329 - val_loss: 0.0894 - val_binary_accuracy: 0.9783 - val_f1: 0.5481 - val_recall: 0.4921 - val_precision: 0.6762\n",
      "Epoch 84/500\n",
      "10s - loss: 0.0269 - binary_accuracy: 0.9916 - f1: 0.8220 - recall: 0.7566 - precision: 0.9330 - val_loss: 0.0921 - val_binary_accuracy: 0.9792 - val_f1: 0.5296 - val_recall: 0.4446 - val_precision: 0.7220\n",
      "Epoch 85/500\n",
      "10s - loss: 0.0262 - binary_accuracy: 0.9914 - f1: 0.8187 - recall: 0.7532 - precision: 0.9282 - val_loss: 0.0971 - val_binary_accuracy: 0.9797 - val_f1: 0.5512 - val_recall: 0.4708 - val_precision: 0.7317\n",
      "Epoch 86/500\n",
      "10s - loss: 0.0255 - binary_accuracy: 0.9917 - f1: 0.8254 - recall: 0.7595 - precision: 0.9323 - val_loss: 0.0943 - val_binary_accuracy: 0.9793 - val_f1: 0.5553 - val_recall: 0.4870 - val_precision: 0.7005\n",
      "Epoch 87/500\n",
      "10s - loss: 0.0253 - binary_accuracy: 0.9920 - f1: 0.8363 - recall: 0.7765 - precision: 0.9347 - val_loss: 0.0933 - val_binary_accuracy: 0.9792 - val_f1: 0.5356 - val_recall: 0.4568 - val_precision: 0.7148\n",
      "Epoch 88/500\n",
      "10s - loss: 0.0236 - binary_accuracy: 0.9925 - f1: 0.8443 - recall: 0.7814 - precision: 0.9433 - val_loss: 0.0931 - val_binary_accuracy: 0.9786 - val_f1: 0.5397 - val_recall: 0.4774 - val_precision: 0.6779\n",
      "Epoch 89/500\n",
      "10s - loss: 0.0245 - binary_accuracy: 0.9921 - f1: 0.8316 - recall: 0.7760 - precision: 0.9277 - val_loss: 0.0972 - val_binary_accuracy: 0.9791 - val_f1: 0.5453 - val_recall: 0.4685 - val_precision: 0.7230\n",
      "Epoch 90/500\n",
      "10s - loss: 0.0232 - binary_accuracy: 0.9926 - f1: 0.8474 - recall: 0.7889 - precision: 0.9436 - val_loss: 0.0985 - val_binary_accuracy: 0.9792 - val_f1: 0.5494 - val_recall: 0.4782 - val_precision: 0.7001\n",
      "Epoch 91/500\n",
      "10s - loss: 0.0232 - binary_accuracy: 0.9927 - f1: 0.8452 - recall: 0.7887 - precision: 0.9407 - val_loss: 0.0990 - val_binary_accuracy: 0.9776 - val_f1: 0.5520 - val_recall: 0.5095 - val_precision: 0.6479\n",
      "Epoch 92/500\n",
      "10s - loss: 0.0221 - binary_accuracy: 0.9929 - f1: 0.8524 - recall: 0.7982 - precision: 0.9431 - val_loss: 0.0987 - val_binary_accuracy: 0.9773 - val_f1: 0.5353 - val_recall: 0.4843 - val_precision: 0.6493\n",
      "Epoch 93/500\n",
      "10s - loss: 0.0211 - binary_accuracy: 0.9933 - f1: 0.8627 - recall: 0.8071 - precision: 0.9487 - val_loss: 0.1005 - val_binary_accuracy: 0.9772 - val_f1: 0.5466 - val_recall: 0.5108 - val_precision: 0.6427\n",
      "37568/37917 [============================>.] - ETA: 0stn = 146984, fp = 363, fn = 599, tp = 3722\n",
      "y_pred: 0 = 147583 | 1 = 4085\n",
      "y_true: 0 = 147347 | 1 = 4321\n",
      "acc=0.9937|precision=0.9111|recall=0.8614|f1=0.8856|auc=0.9957|aupr=0.9446|pos_acc=0.8614|neg_acc=0.9959\n",
      "tn = 36483, fp = 325, fn = 539, tp = 570\n",
      "y_pred: 0 = 37022 | 1 = 895\n",
      "y_true: 0 = 36808 | 1 = 1109\n",
      "acc=0.9772|precision=0.6369|recall=0.5140|f1=0.5689|auc=0.9089|aupr=0.5936|pos_acc=0.5140|neg_acc=0.9854\n",
      "========== isbalance = False | task = Td\n",
      "-------Fold  0\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  1\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  2\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  3\n",
      "# disease: Train = 307 | Test = 76\n",
      "# Pairs: Train = 151965 | Test = 37620\n",
      "-------Fold  4\n",
      "# disease: Train = 304 | Test = 79\n",
      "# Pairs: Train = 150480 | Test = 39105\n",
      "----------------------- Fold =  0\n",
      "Train on 151965 samples, validate on 37620 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0863 - binary_accuracy: 0.9710 - f1: 0.2737 - recall: 0.2024 - precision: 0.5457 - val_loss: 0.0726 - val_binary_accuracy: 0.9781 - val_f1: 0.2452 - val_recall: 0.1730 - val_precision: 0.5326\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0798 - binary_accuracy: 0.9739 - f1: 0.3238 - recall: 0.2432 - precision: 0.6086 - val_loss: 0.0745 - val_binary_accuracy: 0.9779 - val_f1: 0.2577 - val_recall: 0.1816 - val_precision: 0.5467\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0786 - binary_accuracy: 0.9745 - f1: 0.3610 - recall: 0.2688 - precision: 0.6616 - val_loss: 0.0736 - val_binary_accuracy: 0.9780 - val_f1: 0.2766 - val_recall: 0.1987 - val_precision: 0.5612\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0780 - binary_accuracy: 0.9750 - f1: 0.3695 - recall: 0.2767 - precision: 0.6621 - val_loss: 0.0745 - val_binary_accuracy: 0.9769 - val_f1: 0.2583 - val_recall: 0.1874 - val_precision: 0.5081\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0773 - binary_accuracy: 0.9752 - f1: 0.3814 - recall: 0.2902 - precision: 0.6646 - val_loss: 0.0736 - val_binary_accuracy: 0.9776 - val_f1: 0.2267 - val_recall: 0.1582 - val_precision: 0.4956\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0767 - binary_accuracy: 0.9753 - f1: 0.3853 - recall: 0.2961 - precision: 0.6856 - val_loss: 0.0736 - val_binary_accuracy: 0.9779 - val_f1: 0.2772 - val_recall: 0.2026 - val_precision: 0.5338\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0759 - binary_accuracy: 0.9755 - f1: 0.3993 - recall: 0.3087 - precision: 0.6865 - val_loss: 0.0737 - val_binary_accuracy: 0.9781 - val_f1: 0.2747 - val_recall: 0.1981 - val_precision: 0.5391\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0750 - binary_accuracy: 0.9759 - f1: 0.3982 - recall: 0.3044 - precision: 0.6758 - val_loss: 0.0752 - val_binary_accuracy: 0.9770 - val_f1: 0.2406 - val_recall: 0.1700 - val_precision: 0.5130\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0742 - binary_accuracy: 0.9761 - f1: 0.4149 - recall: 0.3184 - precision: 0.7018 - val_loss: 0.0739 - val_binary_accuracy: 0.9773 - val_f1: 0.3354 - val_recall: 0.2626 - val_precision: 0.5524\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0736 - binary_accuracy: 0.9764 - f1: 0.4201 - recall: 0.3247 - precision: 0.7018 - val_loss: 0.0737 - val_binary_accuracy: 0.9778 - val_f1: 0.2523 - val_recall: 0.1812 - val_precision: 0.5083\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0729 - binary_accuracy: 0.9767 - f1: 0.4333 - recall: 0.3334 - precision: 0.7126 - val_loss: 0.0757 - val_binary_accuracy: 0.9762 - val_f1: 0.3148 - val_recall: 0.2542 - val_precision: 0.4931\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0721 - binary_accuracy: 0.9769 - f1: 0.4438 - recall: 0.3479 - precision: 0.7062 - val_loss: 0.0752 - val_binary_accuracy: 0.9766 - val_f1: 0.2775 - val_recall: 0.2129 - val_precision: 0.4878\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0712 - binary_accuracy: 0.9771 - f1: 0.4493 - recall: 0.3519 - precision: 0.7187 - val_loss: 0.0750 - val_binary_accuracy: 0.9771 - val_f1: 0.3109 - val_recall: 0.2412 - val_precision: 0.5278\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0705 - binary_accuracy: 0.9774 - f1: 0.4622 - recall: 0.3635 - precision: 0.7321 - val_loss: 0.0769 - val_binary_accuracy: 0.9756 - val_f1: 0.3214 - val_recall: 0.2559 - val_precision: 0.5097\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0699 - binary_accuracy: 0.9775 - f1: 0.4655 - recall: 0.3666 - precision: 0.7324 - val_loss: 0.0764 - val_binary_accuracy: 0.9760 - val_f1: 0.3289 - val_recall: 0.2720 - val_precision: 0.4963\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0686 - binary_accuracy: 0.9779 - f1: 0.4754 - recall: 0.3727 - precision: 0.7434 - val_loss: 0.0752 - val_binary_accuracy: 0.9765 - val_f1: 0.3207 - val_recall: 0.2592 - val_precision: 0.4995\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0680 - binary_accuracy: 0.9783 - f1: 0.4938 - recall: 0.3934 - precision: 0.7584 - val_loss: 0.0775 - val_binary_accuracy: 0.9752 - val_f1: 0.3021 - val_recall: 0.2412 - val_precision: 0.4816\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0673 - binary_accuracy: 0.9782 - f1: 0.4966 - recall: 0.3972 - precision: 0.7488 - val_loss: 0.0742 - val_binary_accuracy: 0.9777 - val_f1: 0.2773 - val_recall: 0.2057 - val_precision: 0.5200\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0664 - binary_accuracy: 0.9788 - f1: 0.5048 - recall: 0.4043 - precision: 0.7605 - val_loss: 0.0760 - val_binary_accuracy: 0.9768 - val_f1: 0.3294 - val_recall: 0.2626 - val_precision: 0.5360\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0657 - binary_accuracy: 0.9789 - f1: 0.5098 - recall: 0.4079 - precision: 0.7622 - val_loss: 0.0756 - val_binary_accuracy: 0.9770 - val_f1: 0.3416 - val_recall: 0.2757 - val_precision: 0.5304\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0647 - binary_accuracy: 0.9793 - f1: 0.5194 - recall: 0.4170 - precision: 0.7848 - val_loss: 0.0777 - val_binary_accuracy: 0.9762 - val_f1: 0.3029 - val_recall: 0.2411 - val_precision: 0.4846\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0641 - binary_accuracy: 0.9797 - f1: 0.5287 - recall: 0.4247 - precision: 0.7817 - val_loss: 0.0787 - val_binary_accuracy: 0.9762 - val_f1: 0.3269 - val_recall: 0.2647 - val_precision: 0.5153\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0629 - binary_accuracy: 0.9800 - f1: 0.5422 - recall: 0.4394 - precision: 0.7897 - val_loss: 0.0762 - val_binary_accuracy: 0.9766 - val_f1: 0.3336 - val_recall: 0.2681 - val_precision: 0.5392\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0622 - binary_accuracy: 0.9803 - f1: 0.5496 - recall: 0.4474 - precision: 0.8055 - val_loss: 0.0773 - val_binary_accuracy: 0.9763 - val_f1: 0.3152 - val_recall: 0.2534 - val_precision: 0.5015\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0612 - binary_accuracy: 0.9804 - f1: 0.5552 - recall: 0.4525 - precision: 0.8009 - val_loss: 0.0812 - val_binary_accuracy: 0.9756 - val_f1: 0.3105 - val_recall: 0.2522 - val_precision: 0.4866\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0605 - binary_accuracy: 0.9809 - f1: 0.5687 - recall: 0.4634 - precision: 0.8139 - val_loss: 0.0793 - val_binary_accuracy: 0.9753 - val_f1: 0.3151 - val_recall: 0.2622 - val_precision: 0.4801\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0600 - binary_accuracy: 0.9809 - f1: 0.5661 - recall: 0.4650 - precision: 0.8043 - val_loss: 0.0790 - val_binary_accuracy: 0.9754 - val_f1: 0.3266 - val_recall: 0.2717 - val_precision: 0.4792\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0591 - binary_accuracy: 0.9814 - f1: 0.5799 - recall: 0.4778 - precision: 0.8174 - val_loss: 0.0811 - val_binary_accuracy: 0.9762 - val_f1: 0.2964 - val_recall: 0.2267 - val_precision: 0.5114\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0585 - binary_accuracy: 0.9813 - f1: 0.5793 - recall: 0.4798 - precision: 0.8073 - val_loss: 0.0828 - val_binary_accuracy: 0.9761 - val_f1: 0.3286 - val_recall: 0.2717 - val_precision: 0.4883\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0578 - binary_accuracy: 0.9814 - f1: 0.5832 - recall: 0.4846 - precision: 0.8136 - val_loss: 0.0790 - val_binary_accuracy: 0.9766 - val_f1: 0.3006 - val_recall: 0.2324 - val_precision: 0.5254\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0569 - binary_accuracy: 0.9821 - f1: 0.5934 - recall: 0.4943 - precision: 0.8155 - val_loss: 0.0812 - val_binary_accuracy: 0.9766 - val_f1: 0.2981 - val_recall: 0.2375 - val_precision: 0.4910\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0563 - binary_accuracy: 0.9823 - f1: 0.6078 - recall: 0.5055 - precision: 0.8393 - val_loss: 0.0818 - val_binary_accuracy: 0.9756 - val_f1: 0.3206 - val_recall: 0.2622 - val_precision: 0.4781\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0554 - binary_accuracy: 0.9826 - f1: 0.6065 - recall: 0.5045 - precision: 0.8287 - val_loss: 0.0843 - val_binary_accuracy: 0.9744 - val_f1: 0.3431 - val_recall: 0.3059 - val_precision: 0.4568\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0546 - binary_accuracy: 0.9830 - f1: 0.6199 - recall: 0.5189 - precision: 0.8431 - val_loss: 0.0852 - val_binary_accuracy: 0.9746 - val_f1: 0.2951 - val_recall: 0.2435 - val_precision: 0.4405\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0540 - binary_accuracy: 0.9829 - f1: 0.6168 - recall: 0.5145 - precision: 0.8437 - val_loss: 0.0867 - val_binary_accuracy: 0.9756 - val_f1: 0.3354 - val_recall: 0.2844 - val_precision: 0.4726\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0537 - binary_accuracy: 0.9829 - f1: 0.6248 - recall: 0.5252 - precision: 0.8389 - val_loss: 0.0851 - val_binary_accuracy: 0.9755 - val_f1: 0.3266 - val_recall: 0.2750 - val_precision: 0.4694\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0528 - binary_accuracy: 0.9832 - f1: 0.6302 - recall: 0.5318 - precision: 0.8410 - val_loss: 0.0847 - val_binary_accuracy: 0.9749 - val_f1: 0.2972 - val_recall: 0.2475 - val_precision: 0.4383\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0518 - binary_accuracy: 0.9837 - f1: 0.6415 - recall: 0.5412 - precision: 0.8561 - val_loss: 0.0856 - val_binary_accuracy: 0.9753 - val_f1: 0.3243 - val_recall: 0.2735 - val_precision: 0.4745\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0513 - binary_accuracy: 0.9839 - f1: 0.6469 - recall: 0.5455 - precision: 0.8579 - val_loss: 0.0894 - val_binary_accuracy: 0.9742 - val_f1: 0.3446 - val_recall: 0.3115 - val_precision: 0.4453\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0504 - binary_accuracy: 0.9839 - f1: 0.6442 - recall: 0.5489 - precision: 0.8511 - val_loss: 0.0978 - val_binary_accuracy: 0.9736 - val_f1: 0.3122 - val_recall: 0.2733 - val_precision: 0.4155\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0503 - binary_accuracy: 0.9840 - f1: 0.6529 - recall: 0.5562 - precision: 0.8541 - val_loss: 0.0966 - val_binary_accuracy: 0.9732 - val_f1: 0.3473 - val_recall: 0.3228 - val_precision: 0.4268\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0495 - binary_accuracy: 0.9842 - f1: 0.6565 - recall: 0.5605 - precision: 0.8558 - val_loss: 0.0940 - val_binary_accuracy: 0.9727 - val_f1: 0.3435 - val_recall: 0.3274 - val_precision: 0.4122\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0488 - binary_accuracy: 0.9845 - f1: 0.6676 - recall: 0.5699 - precision: 0.8656 - val_loss: 0.0882 - val_binary_accuracy: 0.9761 - val_f1: 0.3254 - val_recall: 0.2717 - val_precision: 0.4782\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0477 - binary_accuracy: 0.9848 - f1: 0.6723 - recall: 0.5744 - precision: 0.8752 - val_loss: 0.1016 - val_binary_accuracy: 0.9718 - val_f1: 0.3356 - val_recall: 0.3191 - val_precision: 0.3956\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0473 - binary_accuracy: 0.9849 - f1: 0.6755 - recall: 0.5784 - precision: 0.8740 - val_loss: 0.0925 - val_binary_accuracy: 0.9752 - val_f1: 0.3487 - val_recall: 0.3013 - val_precision: 0.4787\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0465 - binary_accuracy: 0.9853 - f1: 0.6821 - recall: 0.5865 - precision: 0.8786 - val_loss: 0.0919 - val_binary_accuracy: 0.9752 - val_f1: 0.3373 - val_recall: 0.2880 - val_precision: 0.4767\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0459 - binary_accuracy: 0.9854 - f1: 0.6846 - recall: 0.5894 - precision: 0.8711 - val_loss: 0.0971 - val_binary_accuracy: 0.9746 - val_f1: 0.3207 - val_recall: 0.2752 - val_precision: 0.4418\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0455 - binary_accuracy: 0.9856 - f1: 0.6829 - recall: 0.5855 - precision: 0.8759 - val_loss: 0.0985 - val_binary_accuracy: 0.9737 - val_f1: 0.3510 - val_recall: 0.3190 - val_precision: 0.4453\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0446 - binary_accuracy: 0.9858 - f1: 0.6983 - recall: 0.6056 - precision: 0.8783 - val_loss: 0.0951 - val_binary_accuracy: 0.9747 - val_f1: 0.3340 - val_recall: 0.2925 - val_precision: 0.4593\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0439 - binary_accuracy: 0.9861 - f1: 0.7032 - recall: 0.6110 - precision: 0.8820 - val_loss: 0.0935 - val_binary_accuracy: 0.9728 - val_f1: 0.3430 - val_recall: 0.3303 - val_precision: 0.4098\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0431 - binary_accuracy: 0.9863 - f1: 0.7081 - recall: 0.6184 - precision: 0.8844 - val_loss: 0.0988 - val_binary_accuracy: 0.9742 - val_f1: 0.3428 - val_recall: 0.3091 - val_precision: 0.4362\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0424 - binary_accuracy: 0.9864 - f1: 0.7101 - recall: 0.6200 - precision: 0.8818 - val_loss: 0.1034 - val_binary_accuracy: 0.9728 - val_f1: 0.3447 - val_recall: 0.3236 - val_precision: 0.4214\n",
      "37408/37620 [============================>.] - ETA: 0stn = 147066, fp = 386, fn = 1519, tp = 2994\n",
      "y_pred: 0 = 148585 | 1 = 3380\n",
      "y_true: 0 = 147452 | 1 = 4513\n",
      "acc=0.9875|precision=0.8858|recall=0.6634|f1=0.7586|auc=0.9825|aupr=0.8359|pos_acc=0.6634|neg_acc=0.9898\n",
      "tn = 36302, fp = 401, fn = 621, tp = 296\n",
      "y_pred: 0 = 36923 | 1 = 697\n",
      "y_true: 0 = 36703 | 1 = 917\n",
      "acc=0.9728|precision=0.4247|recall=0.3228|f1=0.3668|auc=0.8828|aupr=0.2992|pos_acc=0.3228|neg_acc=0.9832\n",
      "----------------------- Fold =  1\n",
      "Train on 151965 samples, validate on 37620 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0816 - binary_accuracy: 0.9740 - f1: 0.2842 - recall: 0.2073 - precision: 0.5536 - val_loss: 0.0849 - val_binary_accuracy: 0.9721 - val_f1: 0.3505 - val_recall: 0.2824 - val_precision: 0.5297\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0775 - binary_accuracy: 0.9754 - f1: 0.3503 - recall: 0.2645 - precision: 0.6417 - val_loss: 0.0834 - val_binary_accuracy: 0.9721 - val_f1: 0.3509 - val_recall: 0.2843 - val_precision: 0.5278\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0762 - binary_accuracy: 0.9758 - f1: 0.3661 - recall: 0.2794 - precision: 0.6500 - val_loss: 0.0882 - val_binary_accuracy: 0.9700 - val_f1: 0.3937 - val_recall: 0.3602 - val_precision: 0.4840\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0755 - binary_accuracy: 0.9758 - f1: 0.3630 - recall: 0.2789 - precision: 0.6427 - val_loss: 0.0824 - val_binary_accuracy: 0.9723 - val_f1: 0.3081 - val_recall: 0.2316 - val_precision: 0.5301\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0750 - binary_accuracy: 0.9761 - f1: 0.3737 - recall: 0.2808 - precision: 0.6697 - val_loss: 0.0832 - val_binary_accuracy: 0.9714 - val_f1: 0.3773 - val_recall: 0.3216 - val_precision: 0.5229\n",
      "Epoch 6/500\n",
      "11s - loss: 0.0741 - binary_accuracy: 0.9765 - f1: 0.3769 - recall: 0.2872 - precision: 0.6555 - val_loss: 0.0811 - val_binary_accuracy: 0.9725 - val_f1: 0.3189 - val_recall: 0.2397 - val_precision: 0.5433\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0736 - binary_accuracy: 0.9767 - f1: 0.3893 - recall: 0.2956 - precision: 0.6773 - val_loss: 0.0847 - val_binary_accuracy: 0.9708 - val_f1: 0.3964 - val_recall: 0.3524 - val_precision: 0.5040\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0727 - binary_accuracy: 0.9769 - f1: 0.3963 - recall: 0.3068 - precision: 0.6742 - val_loss: 0.0833 - val_binary_accuracy: 0.9717 - val_f1: 0.4024 - val_recall: 0.3494 - val_precision: 0.5340\n",
      "Epoch 9/500\n",
      "11s - loss: 0.0717 - binary_accuracy: 0.9773 - f1: 0.4130 - recall: 0.3172 - precision: 0.7026 - val_loss: 0.0815 - val_binary_accuracy: 0.9719 - val_f1: 0.3350 - val_recall: 0.2639 - val_precision: 0.5329\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0714 - binary_accuracy: 0.9775 - f1: 0.4297 - recall: 0.3345 - precision: 0.7201 - val_loss: 0.0817 - val_binary_accuracy: 0.9721 - val_f1: 0.2628 - val_recall: 0.1876 - val_precision: 0.5260\n",
      "Epoch 11/500\n",
      "11s - loss: 0.0707 - binary_accuracy: 0.9777 - f1: 0.4312 - recall: 0.3323 - precision: 0.7139 - val_loss: 0.0820 - val_binary_accuracy: 0.9719 - val_f1: 0.3548 - val_recall: 0.2856 - val_precision: 0.5324\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0699 - binary_accuracy: 0.9780 - f1: 0.4440 - recall: 0.3430 - precision: 0.7198 - val_loss: 0.0803 - val_binary_accuracy: 0.9730 - val_f1: 0.2912 - val_recall: 0.2094 - val_precision: 0.5732\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0695 - binary_accuracy: 0.9781 - f1: 0.4437 - recall: 0.3447 - precision: 0.7312 - val_loss: 0.0812 - val_binary_accuracy: 0.9721 - val_f1: 0.2515 - val_recall: 0.1766 - val_precision: 0.5220\n",
      "Epoch 14/500\n",
      "11s - loss: 0.0685 - binary_accuracy: 0.9785 - f1: 0.4537 - recall: 0.3515 - precision: 0.7304 - val_loss: 0.0815 - val_binary_accuracy: 0.9722 - val_f1: 0.3618 - val_recall: 0.2895 - val_precision: 0.5396\n",
      "Epoch 15/500\n",
      "11s - loss: 0.0677 - binary_accuracy: 0.9786 - f1: 0.4654 - recall: 0.3640 - precision: 0.7367 - val_loss: 0.0818 - val_binary_accuracy: 0.9720 - val_f1: 0.2895 - val_recall: 0.2130 - val_precision: 0.5222\n",
      "Epoch 16/500\n",
      "11s - loss: 0.0670 - binary_accuracy: 0.9789 - f1: 0.4713 - recall: 0.3724 - precision: 0.7393 - val_loss: 0.0826 - val_binary_accuracy: 0.9722 - val_f1: 0.2985 - val_recall: 0.2189 - val_precision: 0.5442\n",
      "Epoch 17/500\n",
      "11s - loss: 0.0665 - binary_accuracy: 0.9790 - f1: 0.4757 - recall: 0.3780 - precision: 0.7403 - val_loss: 0.0823 - val_binary_accuracy: 0.9716 - val_f1: 0.3298 - val_recall: 0.2589 - val_precision: 0.5141\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0656 - binary_accuracy: 0.9794 - f1: 0.4909 - recall: 0.3902 - precision: 0.7660 - val_loss: 0.0843 - val_binary_accuracy: 0.9715 - val_f1: 0.3819 - val_recall: 0.3234 - val_precision: 0.5184\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0649 - binary_accuracy: 0.9798 - f1: 0.4975 - recall: 0.3958 - precision: 0.7576 - val_loss: 0.0825 - val_binary_accuracy: 0.9710 - val_f1: 0.2728 - val_recall: 0.2024 - val_precision: 0.4851\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0645 - binary_accuracy: 0.9797 - f1: 0.4993 - recall: 0.3990 - precision: 0.7569 - val_loss: 0.0834 - val_binary_accuracy: 0.9713 - val_f1: 0.3207 - val_recall: 0.2510 - val_precision: 0.5055\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0635 - binary_accuracy: 0.9801 - f1: 0.5055 - recall: 0.4039 - precision: 0.7714 - val_loss: 0.0834 - val_binary_accuracy: 0.9721 - val_f1: 0.3079 - val_recall: 0.2315 - val_precision: 0.5382\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0631 - binary_accuracy: 0.9804 - f1: 0.5165 - recall: 0.4141 - precision: 0.7769 - val_loss: 0.0824 - val_binary_accuracy: 0.9722 - val_f1: 0.3465 - val_recall: 0.2724 - val_precision: 0.5319\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0625 - binary_accuracy: 0.9804 - f1: 0.5297 - recall: 0.4255 - precision: 0.8021 - val_loss: 0.0849 - val_binary_accuracy: 0.9708 - val_f1: 0.3510 - val_recall: 0.2900 - val_precision: 0.4942\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0616 - binary_accuracy: 0.9806 - f1: 0.5253 - recall: 0.4226 - precision: 0.7846 - val_loss: 0.0885 - val_binary_accuracy: 0.9712 - val_f1: 0.4086 - val_recall: 0.3656 - val_precision: 0.5014\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0609 - binary_accuracy: 0.9811 - f1: 0.5457 - recall: 0.4428 - precision: 0.8014 - val_loss: 0.0868 - val_binary_accuracy: 0.9707 - val_f1: 0.3812 - val_recall: 0.3328 - val_precision: 0.4875\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0601 - binary_accuracy: 0.9814 - f1: 0.5495 - recall: 0.4465 - precision: 0.8070 - val_loss: 0.0877 - val_binary_accuracy: 0.9715 - val_f1: 0.3966 - val_recall: 0.3449 - val_precision: 0.5081\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0598 - binary_accuracy: 0.9813 - f1: 0.5486 - recall: 0.4476 - precision: 0.7967 - val_loss: 0.0834 - val_binary_accuracy: 0.9719 - val_f1: 0.3740 - val_recall: 0.3092 - val_precision: 0.5240\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0587 - binary_accuracy: 0.9815 - f1: 0.5575 - recall: 0.4549 - precision: 0.7949 - val_loss: 0.0865 - val_binary_accuracy: 0.9712 - val_f1: 0.3941 - val_recall: 0.3435 - val_precision: 0.5093\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0583 - binary_accuracy: 0.9819 - f1: 0.5686 - recall: 0.4655 - precision: 0.8047 - val_loss: 0.0867 - val_binary_accuracy: 0.9711 - val_f1: 0.3402 - val_recall: 0.2754 - val_precision: 0.5014\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0579 - binary_accuracy: 0.9821 - f1: 0.5728 - recall: 0.4692 - precision: 0.8172 - val_loss: 0.0859 - val_binary_accuracy: 0.9711 - val_f1: 0.3361 - val_recall: 0.2690 - val_precision: 0.5022\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0570 - binary_accuracy: 0.9821 - f1: 0.5785 - recall: 0.4783 - precision: 0.8119 - val_loss: 0.0863 - val_binary_accuracy: 0.9717 - val_f1: 0.3679 - val_recall: 0.3046 - val_precision: 0.5107\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0563 - binary_accuracy: 0.9825 - f1: 0.5839 - recall: 0.4831 - precision: 0.8117 - val_loss: 0.0907 - val_binary_accuracy: 0.9700 - val_f1: 0.3096 - val_recall: 0.2497 - val_precision: 0.4578\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0561 - binary_accuracy: 0.9826 - f1: 0.5902 - recall: 0.4930 - precision: 0.8175 - val_loss: 0.0876 - val_binary_accuracy: 0.9713 - val_f1: 0.2858 - val_recall: 0.2145 - val_precision: 0.5116\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0551 - binary_accuracy: 0.9830 - f1: 0.5963 - recall: 0.4983 - precision: 0.8254 - val_loss: 0.0888 - val_binary_accuracy: 0.9708 - val_f1: 0.3528 - val_recall: 0.2923 - val_precision: 0.4997\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0541 - binary_accuracy: 0.9833 - f1: 0.6092 - recall: 0.5102 - precision: 0.8331 - val_loss: 0.0936 - val_binary_accuracy: 0.9707 - val_f1: 0.3513 - val_recall: 0.2908 - val_precision: 0.4987\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0539 - binary_accuracy: 0.9835 - f1: 0.6110 - recall: 0.5085 - precision: 0.8410 - val_loss: 0.0924 - val_binary_accuracy: 0.9706 - val_f1: 0.3218 - val_recall: 0.2587 - val_precision: 0.4781\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0531 - binary_accuracy: 0.9835 - f1: 0.6145 - recall: 0.5142 - precision: 0.8354 - val_loss: 0.0941 - val_binary_accuracy: 0.9687 - val_f1: 0.3501 - val_recall: 0.3108 - val_precision: 0.4565\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0525 - binary_accuracy: 0.9836 - f1: 0.6245 - recall: 0.5231 - precision: 0.8473 - val_loss: 0.0949 - val_binary_accuracy: 0.9714 - val_f1: 0.3365 - val_recall: 0.2662 - val_precision: 0.5212\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0521 - binary_accuracy: 0.9837 - f1: 0.6210 - recall: 0.5226 - precision: 0.8370 - val_loss: 0.0943 - val_binary_accuracy: 0.9714 - val_f1: 0.3311 - val_recall: 0.2610 - val_precision: 0.5083\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0514 - binary_accuracy: 0.9840 - f1: 0.6334 - recall: 0.5365 - precision: 0.8490 - val_loss: 0.0952 - val_binary_accuracy: 0.9709 - val_f1: 0.3007 - val_recall: 0.2325 - val_precision: 0.4914\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9842 - f1: 0.6339 - recall: 0.5303 - precision: 0.8547 - val_loss: 0.0931 - val_binary_accuracy: 0.9706 - val_f1: 0.3765 - val_recall: 0.3247 - val_precision: 0.5000\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0499 - binary_accuracy: 0.9845 - f1: 0.6450 - recall: 0.5487 - precision: 0.8501 - val_loss: 0.0978 - val_binary_accuracy: 0.9697 - val_f1: 0.3817 - val_recall: 0.3447 - val_precision: 0.4717\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0494 - binary_accuracy: 0.9846 - f1: 0.6488 - recall: 0.5480 - precision: 0.8554 - val_loss: 0.0940 - val_binary_accuracy: 0.9695 - val_f1: 0.3517 - val_recall: 0.3019 - val_precision: 0.4679\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0488 - binary_accuracy: 0.9849 - f1: 0.6611 - recall: 0.5655 - precision: 0.8592 - val_loss: 0.0956 - val_binary_accuracy: 0.9696 - val_f1: 0.3582 - val_recall: 0.3101 - val_precision: 0.4705\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0479 - binary_accuracy: 0.9853 - f1: 0.6677 - recall: 0.5731 - precision: 0.8658 - val_loss: 0.0957 - val_binary_accuracy: 0.9710 - val_f1: 0.3377 - val_recall: 0.2738 - val_precision: 0.5008\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0474 - binary_accuracy: 0.9853 - f1: 0.6624 - recall: 0.5680 - precision: 0.8603 - val_loss: 0.0985 - val_binary_accuracy: 0.9705 - val_f1: 0.3385 - val_recall: 0.2774 - val_precision: 0.5091\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0468 - binary_accuracy: 0.9854 - f1: 0.6632 - recall: 0.5657 - precision: 0.8594 - val_loss: 0.1010 - val_binary_accuracy: 0.9688 - val_f1: 0.4105 - val_recall: 0.3911 - val_precision: 0.4747\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0465 - binary_accuracy: 0.9854 - f1: 0.6645 - recall: 0.5748 - precision: 0.8527 - val_loss: 0.0978 - val_binary_accuracy: 0.9709 - val_f1: 0.3608 - val_recall: 0.3013 - val_precision: 0.5066\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0462 - binary_accuracy: 0.9855 - f1: 0.6709 - recall: 0.5746 - precision: 0.8711 - val_loss: 0.0977 - val_binary_accuracy: 0.9697 - val_f1: 0.3236 - val_recall: 0.2652 - val_precision: 0.4756\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0450 - binary_accuracy: 0.9859 - f1: 0.6791 - recall: 0.5855 - precision: 0.8671 - val_loss: 0.0987 - val_binary_accuracy: 0.9692 - val_f1: 0.3593 - val_recall: 0.3105 - val_precision: 0.4803\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0447 - binary_accuracy: 0.9861 - f1: 0.6863 - recall: 0.5918 - precision: 0.8779 - val_loss: 0.1016 - val_binary_accuracy: 0.9703 - val_f1: 0.3308 - val_recall: 0.2674 - val_precision: 0.4860\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0436 - binary_accuracy: 0.9865 - f1: 0.6947 - recall: 0.5972 - precision: 0.8856 - val_loss: 0.1026 - val_binary_accuracy: 0.9680 - val_f1: 0.3636 - val_recall: 0.3262 - val_precision: 0.4511\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0433 - binary_accuracy: 0.9863 - f1: 0.6938 - recall: 0.6035 - precision: 0.8770 - val_loss: 0.1006 - val_binary_accuracy: 0.9688 - val_f1: 0.3581 - val_recall: 0.3193 - val_precision: 0.4563\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0425 - binary_accuracy: 0.9867 - f1: 0.7077 - recall: 0.6138 - precision: 0.8907 - val_loss: 0.1049 - val_binary_accuracy: 0.9705 - val_f1: 0.3547 - val_recall: 0.2968 - val_precision: 0.5048\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0418 - binary_accuracy: 0.9869 - f1: 0.7083 - recall: 0.6192 - precision: 0.8850 - val_loss: 0.1082 - val_binary_accuracy: 0.9701 - val_f1: 0.3653 - val_recall: 0.3141 - val_precision: 0.4901\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0416 - binary_accuracy: 0.9871 - f1: 0.7129 - recall: 0.6224 - precision: 0.8856 - val_loss: 0.1057 - val_binary_accuracy: 0.9685 - val_f1: 0.3590 - val_recall: 0.3197 - val_precision: 0.4579\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0407 - binary_accuracy: 0.9873 - f1: 0.7162 - recall: 0.6261 - precision: 0.8906 - val_loss: 0.1048 - val_binary_accuracy: 0.9705 - val_f1: 0.3796 - val_recall: 0.3282 - val_precision: 0.5023\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0400 - binary_accuracy: 0.9873 - f1: 0.7154 - recall: 0.6237 - precision: 0.8901 - val_loss: 0.1116 - val_binary_accuracy: 0.9690 - val_f1: 0.3290 - val_recall: 0.2789 - val_precision: 0.4491\n",
      "Epoch 59/500\n",
      "10s - loss: 0.0394 - binary_accuracy: 0.9874 - f1: 0.7204 - recall: 0.6318 - precision: 0.8861 - val_loss: 0.1132 - val_binary_accuracy: 0.9688 - val_f1: 0.3226 - val_recall: 0.2747 - val_precision: 0.4440\n",
      "Epoch 60/500\n",
      "10s - loss: 0.0387 - binary_accuracy: 0.9877 - f1: 0.7269 - recall: 0.6423 - precision: 0.8870 - val_loss: 0.1094 - val_binary_accuracy: 0.9691 - val_f1: 0.3645 - val_recall: 0.3252 - val_precision: 0.4649\n",
      "Epoch 61/500\n",
      "10s - loss: 0.0379 - binary_accuracy: 0.9881 - f1: 0.7369 - recall: 0.6476 - precision: 0.9026 - val_loss: 0.1107 - val_binary_accuracy: 0.9689 - val_f1: 0.3341 - val_recall: 0.2815 - val_precision: 0.4659\n",
      "Epoch 62/500\n",
      "10s - loss: 0.0377 - binary_accuracy: 0.9883 - f1: 0.7417 - recall: 0.6575 - precision: 0.8988 - val_loss: 0.1132 - val_binary_accuracy: 0.9685 - val_f1: 0.3652 - val_recall: 0.3257 - val_precision: 0.4592\n",
      "Epoch 63/500\n",
      "10s - loss: 0.0364 - binary_accuracy: 0.9885 - f1: 0.7498 - recall: 0.6650 - precision: 0.9043 - val_loss: 0.1178 - val_binary_accuracy: 0.9669 - val_f1: 0.3498 - val_recall: 0.3221 - val_precision: 0.4266\n",
      "37184/37620 [============================>.] - ETA: 0stn = 147357, fp = 294, fn = 1322, tp = 2992\n",
      "y_pred: 0 = 148679 | 1 = 3286\n",
      "y_true: 0 = 147651 | 1 = 4314\n",
      "acc=0.9894|precision=0.9105|recall=0.6936|f1=0.7874|auc=0.9874|aupr=0.8680|pos_acc=0.6936|neg_acc=0.9911\n",
      "tn = 36016, fp = 488, fn = 757, tp = 359\n",
      "y_pred: 0 = 36773 | 1 = 847\n",
      "y_true: 0 = 36504 | 1 = 1116\n",
      "acc=0.9669|precision=0.4238|recall=0.3217|f1=0.3658|auc=0.8938|aupr=0.3212|pos_acc=0.3217|neg_acc=0.9794\n",
      "----------------------- Fold =  2\n",
      "Train on 151965 samples, validate on 37620 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0837 - binary_accuracy: 0.9728 - f1: 0.2822 - recall: 0.2077 - precision: 0.5530 - val_loss: 0.0741 - val_binary_accuracy: 0.9764 - val_f1: 0.2966 - val_recall: 0.2289 - val_precision: 0.5234\n",
      "Epoch 2/500\n",
      "11s - loss: 0.0794 - binary_accuracy: 0.9743 - f1: 0.3345 - recall: 0.2473 - precision: 0.6240 - val_loss: 0.0741 - val_binary_accuracy: 0.9763 - val_f1: 0.1701 - val_recall: 0.1167 - val_precision: 0.4228\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0782 - binary_accuracy: 0.9747 - f1: 0.3598 - recall: 0.2693 - precision: 0.6476 - val_loss: 0.0735 - val_binary_accuracy: 0.9766 - val_f1: 0.2336 - val_recall: 0.1699 - val_precision: 0.4976\n",
      "Epoch 4/500\n",
      "10s - loss: 0.0774 - binary_accuracy: 0.9750 - f1: 0.3719 - recall: 0.2774 - precision: 0.6741 - val_loss: 0.0721 - val_binary_accuracy: 0.9773 - val_f1: 0.1970 - val_recall: 0.1312 - val_precision: 0.5127\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0765 - binary_accuracy: 0.9754 - f1: 0.3824 - recall: 0.2913 - precision: 0.6732 - val_loss: 0.0727 - val_binary_accuracy: 0.9768 - val_f1: 0.2115 - val_recall: 0.1474 - val_precision: 0.4845\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0759 - binary_accuracy: 0.9757 - f1: 0.3884 - recall: 0.2937 - precision: 0.6897 - val_loss: 0.0748 - val_binary_accuracy: 0.9776 - val_f1: 0.2882 - val_recall: 0.2078 - val_precision: 0.5838\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0749 - binary_accuracy: 0.9759 - f1: 0.4022 - recall: 0.3042 - precision: 0.6961 - val_loss: 0.0724 - val_binary_accuracy: 0.9772 - val_f1: 0.1929 - val_recall: 0.1276 - val_precision: 0.5007\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0740 - binary_accuracy: 0.9763 - f1: 0.4085 - recall: 0.3118 - precision: 0.6967 - val_loss: 0.0749 - val_binary_accuracy: 0.9768 - val_f1: 0.1465 - val_recall: 0.0919 - val_precision: 0.4403\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0735 - binary_accuracy: 0.9766 - f1: 0.4251 - recall: 0.3318 - precision: 0.7120 - val_loss: 0.0737 - val_binary_accuracy: 0.9772 - val_f1: 0.2133 - val_recall: 0.1460 - val_precision: 0.5091\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0726 - binary_accuracy: 0.9768 - f1: 0.4281 - recall: 0.3299 - precision: 0.7140 - val_loss: 0.0769 - val_binary_accuracy: 0.9771 - val_f1: 0.1857 - val_recall: 0.1246 - val_precision: 0.4618\n",
      "Epoch 11/500\n",
      "11s - loss: 0.0720 - binary_accuracy: 0.9768 - f1: 0.4283 - recall: 0.3306 - precision: 0.7117 - val_loss: 0.0772 - val_binary_accuracy: 0.9770 - val_f1: 0.1623 - val_recall: 0.1054 - val_precision: 0.4420\n",
      "Epoch 12/500\n",
      "12s - loss: 0.0716 - binary_accuracy: 0.9771 - f1: 0.4425 - recall: 0.3422 - precision: 0.7238 - val_loss: 0.0752 - val_binary_accuracy: 0.9768 - val_f1: 0.2132 - val_recall: 0.1463 - val_precision: 0.4987\n",
      "Epoch 13/500\n",
      "11s - loss: 0.0705 - binary_accuracy: 0.9774 - f1: 0.4477 - recall: 0.3501 - precision: 0.7153 - val_loss: 0.0747 - val_binary_accuracy: 0.9769 - val_f1: 0.2435 - val_recall: 0.1731 - val_precision: 0.5054\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0702 - binary_accuracy: 0.9776 - f1: 0.4585 - recall: 0.3579 - precision: 0.7314 - val_loss: 0.0744 - val_binary_accuracy: 0.9767 - val_f1: 0.2564 - val_recall: 0.1882 - val_precision: 0.5164\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0691 - binary_accuracy: 0.9778 - f1: 0.4613 - recall: 0.3636 - precision: 0.7176 - val_loss: 0.0739 - val_binary_accuracy: 0.9766 - val_f1: 0.2551 - val_recall: 0.1885 - val_precision: 0.5012\n",
      "Epoch 16/500\n",
      "11s - loss: 0.0681 - binary_accuracy: 0.9783 - f1: 0.4814 - recall: 0.3778 - precision: 0.7597 - val_loss: 0.0764 - val_binary_accuracy: 0.9765 - val_f1: 0.2603 - val_recall: 0.1932 - val_precision: 0.5004\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0672 - binary_accuracy: 0.9784 - f1: 0.4897 - recall: 0.3871 - precision: 0.7510 - val_loss: 0.0778 - val_binary_accuracy: 0.9773 - val_f1: 0.2874 - val_recall: 0.2119 - val_precision: 0.5667\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0666 - binary_accuracy: 0.9788 - f1: 0.4942 - recall: 0.3928 - precision: 0.7565 - val_loss: 0.0773 - val_binary_accuracy: 0.9765 - val_f1: 0.2326 - val_recall: 0.1633 - val_precision: 0.5038\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0658 - binary_accuracy: 0.9790 - f1: 0.5078 - recall: 0.4051 - precision: 0.7688 - val_loss: 0.0776 - val_binary_accuracy: 0.9763 - val_f1: 0.2507 - val_recall: 0.1859 - val_precision: 0.4787\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0650 - binary_accuracy: 0.9794 - f1: 0.5242 - recall: 0.4241 - precision: 0.7859 - val_loss: 0.0781 - val_binary_accuracy: 0.9762 - val_f1: 0.2616 - val_recall: 0.1943 - val_precision: 0.4957\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0642 - binary_accuracy: 0.9796 - f1: 0.5191 - recall: 0.4181 - precision: 0.7746 - val_loss: 0.0798 - val_binary_accuracy: 0.9769 - val_f1: 0.2772 - val_recall: 0.2047 - val_precision: 0.5265\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0630 - binary_accuracy: 0.9800 - f1: 0.5364 - recall: 0.4349 - precision: 0.7839 - val_loss: 0.0778 - val_binary_accuracy: 0.9762 - val_f1: 0.1876 - val_recall: 0.1276 - val_precision: 0.4558\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0627 - binary_accuracy: 0.9801 - f1: 0.5356 - recall: 0.4326 - precision: 0.7926 - val_loss: 0.0813 - val_binary_accuracy: 0.9752 - val_f1: 0.1846 - val_recall: 0.1326 - val_precision: 0.3971\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0617 - binary_accuracy: 0.9804 - f1: 0.5515 - recall: 0.4476 - precision: 0.8029 - val_loss: 0.0778 - val_binary_accuracy: 0.9769 - val_f1: 0.2896 - val_recall: 0.2217 - val_precision: 0.5101\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0614 - binary_accuracy: 0.9806 - f1: 0.5506 - recall: 0.4455 - precision: 0.7963 - val_loss: 0.0788 - val_binary_accuracy: 0.9762 - val_f1: 0.3487 - val_recall: 0.2880 - val_precision: 0.5185\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0603 - binary_accuracy: 0.9810 - f1: 0.5696 - recall: 0.4681 - precision: 0.8088 - val_loss: 0.0781 - val_binary_accuracy: 0.9760 - val_f1: 0.2634 - val_recall: 0.1962 - val_precision: 0.4853\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0599 - binary_accuracy: 0.9809 - f1: 0.5597 - recall: 0.4592 - precision: 0.7995 - val_loss: 0.0795 - val_binary_accuracy: 0.9763 - val_f1: 0.3029 - val_recall: 0.2336 - val_precision: 0.5253\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0592 - binary_accuracy: 0.9814 - f1: 0.5772 - recall: 0.4747 - precision: 0.8177 - val_loss: 0.0852 - val_binary_accuracy: 0.9753 - val_f1: 0.1798 - val_recall: 0.1243 - val_precision: 0.4168\n",
      "Epoch 29/500\n",
      "11s - loss: 0.0583 - binary_accuracy: 0.9816 - f1: 0.5857 - recall: 0.4836 - precision: 0.8185 - val_loss: 0.0812 - val_binary_accuracy: 0.9765 - val_f1: 0.2964 - val_recall: 0.2294 - val_precision: 0.5053\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0575 - binary_accuracy: 0.9819 - f1: 0.5910 - recall: 0.4906 - precision: 0.8243 - val_loss: 0.0824 - val_binary_accuracy: 0.9766 - val_f1: 0.2494 - val_recall: 0.1786 - val_precision: 0.5135\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0566 - binary_accuracy: 0.9820 - f1: 0.5990 - recall: 0.4974 - precision: 0.8309 - val_loss: 0.0797 - val_binary_accuracy: 0.9767 - val_f1: 0.3350 - val_recall: 0.2723 - val_precision: 0.5318\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0564 - binary_accuracy: 0.9823 - f1: 0.6071 - recall: 0.5065 - precision: 0.8342 - val_loss: 0.0827 - val_binary_accuracy: 0.9761 - val_f1: 0.2841 - val_recall: 0.2242 - val_precision: 0.4685\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0557 - binary_accuracy: 0.9824 - f1: 0.6074 - recall: 0.5094 - precision: 0.8214 - val_loss: 0.0801 - val_binary_accuracy: 0.9759 - val_f1: 0.2966 - val_recall: 0.2303 - val_precision: 0.4973\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0549 - binary_accuracy: 0.9827 - f1: 0.6113 - recall: 0.5091 - precision: 0.8331 - val_loss: 0.0817 - val_binary_accuracy: 0.9755 - val_f1: 0.2488 - val_recall: 0.1858 - val_precision: 0.4638\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0545 - binary_accuracy: 0.9829 - f1: 0.6246 - recall: 0.5231 - precision: 0.8353 - val_loss: 0.0848 - val_binary_accuracy: 0.9759 - val_f1: 0.3153 - val_recall: 0.2531 - val_precision: 0.4931\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0536 - binary_accuracy: 0.9831 - f1: 0.6257 - recall: 0.5265 - precision: 0.8402 - val_loss: 0.0805 - val_binary_accuracy: 0.9764 - val_f1: 0.2714 - val_recall: 0.2003 - val_precision: 0.5195\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0532 - binary_accuracy: 0.9832 - f1: 0.6279 - recall: 0.5325 - precision: 0.8361 - val_loss: 0.0820 - val_binary_accuracy: 0.9758 - val_f1: 0.2982 - val_recall: 0.2372 - val_precision: 0.4879\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0525 - binary_accuracy: 0.9836 - f1: 0.6334 - recall: 0.5336 - precision: 0.8451 - val_loss: 0.0822 - val_binary_accuracy: 0.9760 - val_f1: 0.3024 - val_recall: 0.2397 - val_precision: 0.4955\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0517 - binary_accuracy: 0.9836 - f1: 0.6321 - recall: 0.5335 - precision: 0.8418 - val_loss: 0.0844 - val_binary_accuracy: 0.9762 - val_f1: 0.2967 - val_recall: 0.2318 - val_precision: 0.5093\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0507 - binary_accuracy: 0.9838 - f1: 0.6444 - recall: 0.5481 - precision: 0.8397 - val_loss: 0.0881 - val_binary_accuracy: 0.9754 - val_f1: 0.2641 - val_recall: 0.2002 - val_precision: 0.4747\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9839 - f1: 0.6499 - recall: 0.5507 - precision: 0.8532 - val_loss: 0.0837 - val_binary_accuracy: 0.9759 - val_f1: 0.3414 - val_recall: 0.2810 - val_precision: 0.5147\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0501 - binary_accuracy: 0.9842 - f1: 0.6524 - recall: 0.5521 - precision: 0.8616 - val_loss: 0.0833 - val_binary_accuracy: 0.9760 - val_f1: 0.3112 - val_recall: 0.2523 - val_precision: 0.4797\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0496 - binary_accuracy: 0.9845 - f1: 0.6583 - recall: 0.5576 - precision: 0.8589 - val_loss: 0.0849 - val_binary_accuracy: 0.9757 - val_f1: 0.3004 - val_recall: 0.2395 - val_precision: 0.4851\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0489 - binary_accuracy: 0.9845 - f1: 0.6633 - recall: 0.5698 - precision: 0.8605 - val_loss: 0.0866 - val_binary_accuracy: 0.9766 - val_f1: 0.2714 - val_recall: 0.2002 - val_precision: 0.5113\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0480 - binary_accuracy: 0.9849 - f1: 0.6710 - recall: 0.5720 - precision: 0.8676 - val_loss: 0.0893 - val_binary_accuracy: 0.9746 - val_f1: 0.3080 - val_recall: 0.2518 - val_precision: 0.4706\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0472 - binary_accuracy: 0.9850 - f1: 0.6710 - recall: 0.5770 - precision: 0.8641 - val_loss: 0.0876 - val_binary_accuracy: 0.9757 - val_f1: 0.3265 - val_recall: 0.2621 - val_precision: 0.5130\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0467 - binary_accuracy: 0.9853 - f1: 0.6798 - recall: 0.5836 - precision: 0.8764 - val_loss: 0.0853 - val_binary_accuracy: 0.9760 - val_f1: 0.2927 - val_recall: 0.2299 - val_precision: 0.4778\n",
      "Epoch 48/500\n",
      "11s - loss: 0.0460 - binary_accuracy: 0.9855 - f1: 0.6904 - recall: 0.5946 - precision: 0.8812 - val_loss: 0.0890 - val_binary_accuracy: 0.9763 - val_f1: 0.3032 - val_recall: 0.2367 - val_precision: 0.5106\n",
      "Epoch 49/500\n",
      "11s - loss: 0.0451 - binary_accuracy: 0.9855 - f1: 0.6806 - recall: 0.5861 - precision: 0.8695 - val_loss: 0.0876 - val_binary_accuracy: 0.9757 - val_f1: 0.3134 - val_recall: 0.2490 - val_precision: 0.5027\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0449 - binary_accuracy: 0.9856 - f1: 0.6921 - recall: 0.5990 - precision: 0.8686 - val_loss: 0.0925 - val_binary_accuracy: 0.9743 - val_f1: 0.3092 - val_recall: 0.2556 - val_precision: 0.4603\n",
      "Epoch 51/500\n",
      "11s - loss: 0.0440 - binary_accuracy: 0.9861 - f1: 0.7059 - recall: 0.6109 - precision: 0.8925 - val_loss: 0.0891 - val_binary_accuracy: 0.9751 - val_f1: 0.3184 - val_recall: 0.2645 - val_precision: 0.4711\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0430 - binary_accuracy: 0.9863 - f1: 0.7076 - recall: 0.6168 - precision: 0.8801 - val_loss: 0.0905 - val_binary_accuracy: 0.9765 - val_f1: 0.3184 - val_recall: 0.2545 - val_precision: 0.5043\n",
      "Epoch 53/500\n",
      "11s - loss: 0.0427 - binary_accuracy: 0.9865 - f1: 0.7072 - recall: 0.6168 - precision: 0.8784 - val_loss: 0.0978 - val_binary_accuracy: 0.9750 - val_f1: 0.3022 - val_recall: 0.2426 - val_precision: 0.4787\n",
      "Epoch 54/500\n",
      "11s - loss: 0.0422 - binary_accuracy: 0.9866 - f1: 0.7178 - recall: 0.6275 - precision: 0.8882 - val_loss: 0.0947 - val_binary_accuracy: 0.9753 - val_f1: 0.2738 - val_recall: 0.2156 - val_precision: 0.4553\n",
      "Epoch 55/500\n",
      "11s - loss: 0.0416 - binary_accuracy: 0.9867 - f1: 0.7156 - recall: 0.6245 - precision: 0.8912 - val_loss: 0.0937 - val_binary_accuracy: 0.9757 - val_f1: 0.3384 - val_recall: 0.2797 - val_precision: 0.5008\n",
      "37440/37620 [============================>.] - ETA: 0stn = 147123, fp = 345, fn = 1610, tp = 2887\n",
      "y_pred: 0 = 148733 | 1 = 3232\n",
      "y_true: 0 = 147468 | 1 = 4497\n",
      "acc=0.9871|precision=0.8933|recall=0.6420|f1=0.7471|auc=0.9821|aupr=0.8288|pos_acc=0.6420|neg_acc=0.9892\n",
      "tn = 36433, fp = 254, fn = 661, tp = 272\n",
      "y_pred: 0 = 37094 | 1 = 526\n",
      "y_true: 0 = 36687 | 1 = 933\n",
      "acc=0.9757|precision=0.5171|recall=0.2915|f1=0.3729|auc=0.8804|aupr=0.3272|pos_acc=0.2915|neg_acc=0.9822\n",
      "----------------------- Fold =  3\n",
      "Train on 151965 samples, validate on 37620 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0820 - binary_accuracy: 0.9732 - f1: 0.2467 - recall: 0.1792 - precision: 0.5279 - val_loss: 0.0895 - val_binary_accuracy: 0.9695 - val_f1: 0.2575 - val_recall: 0.1760 - val_precision: 0.5945\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0769 - binary_accuracy: 0.9756 - f1: 0.3091 - recall: 0.2285 - precision: 0.5959 - val_loss: 0.0861 - val_binary_accuracy: 0.9704 - val_f1: 0.3571 - val_recall: 0.2750 - val_precision: 0.5947\n",
      "Epoch 3/500\n",
      "11s - loss: 0.0765 - binary_accuracy: 0.9758 - f1: 0.3174 - recall: 0.2346 - precision: 0.6131 - val_loss: 0.0874 - val_binary_accuracy: 0.9697 - val_f1: 0.2880 - val_recall: 0.2033 - val_precision: 0.5894\n",
      "Epoch 4/500\n",
      "11s - loss: 0.0760 - binary_accuracy: 0.9761 - f1: 0.3282 - recall: 0.2407 - precision: 0.6342 - val_loss: 0.0882 - val_binary_accuracy: 0.9701 - val_f1: 0.3725 - val_recall: 0.2944 - val_precision: 0.5876\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0755 - binary_accuracy: 0.9762 - f1: 0.3351 - recall: 0.2483 - precision: 0.6304 - val_loss: 0.0876 - val_binary_accuracy: 0.9683 - val_f1: 0.1419 - val_recall: 0.0886 - val_precision: 0.4725\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0754 - binary_accuracy: 0.9764 - f1: 0.3379 - recall: 0.2507 - precision: 0.6479 - val_loss: 0.0855 - val_binary_accuracy: 0.9704 - val_f1: 0.3573 - val_recall: 0.2715 - val_precision: 0.6011\n",
      "Epoch 7/500\n",
      "11s - loss: 0.0742 - binary_accuracy: 0.9767 - f1: 0.3519 - recall: 0.2642 - precision: 0.6434 - val_loss: 0.0910 - val_binary_accuracy: 0.9691 - val_f1: 0.1835 - val_recall: 0.1155 - val_precision: 0.5627\n",
      "Epoch 8/500\n",
      "10s - loss: 0.0744 - binary_accuracy: 0.9767 - f1: 0.3535 - recall: 0.2651 - precision: 0.6521 - val_loss: 0.0862 - val_binary_accuracy: 0.9700 - val_f1: 0.3366 - val_recall: 0.2528 - val_precision: 0.5911\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0734 - binary_accuracy: 0.9771 - f1: 0.3703 - recall: 0.2765 - precision: 0.6768 - val_loss: 0.0875 - val_binary_accuracy: 0.9693 - val_f1: 0.3532 - val_recall: 0.2780 - val_precision: 0.5717\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0728 - binary_accuracy: 0.9772 - f1: 0.3765 - recall: 0.2844 - precision: 0.6674 - val_loss: 0.0894 - val_binary_accuracy: 0.9700 - val_f1: 0.4122 - val_recall: 0.3417 - val_precision: 0.5980\n",
      "Epoch 11/500\n",
      "11s - loss: 0.0721 - binary_accuracy: 0.9772 - f1: 0.3822 - recall: 0.2920 - precision: 0.6646 - val_loss: 0.0901 - val_binary_accuracy: 0.9703 - val_f1: 0.3388 - val_recall: 0.2474 - val_precision: 0.6308\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0711 - binary_accuracy: 0.9777 - f1: 0.3982 - recall: 0.3059 - precision: 0.6855 - val_loss: 0.0926 - val_binary_accuracy: 0.9692 - val_f1: 0.3716 - val_recall: 0.3009 - val_precision: 0.5635\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0707 - binary_accuracy: 0.9778 - f1: 0.4002 - recall: 0.3049 - precision: 0.6889 - val_loss: 0.0921 - val_binary_accuracy: 0.9694 - val_f1: 0.3167 - val_recall: 0.2377 - val_precision: 0.5799\n",
      "Epoch 14/500\n",
      "10s - loss: 0.0697 - binary_accuracy: 0.9783 - f1: 0.4214 - recall: 0.3227 - precision: 0.7226 - val_loss: 0.0900 - val_binary_accuracy: 0.9694 - val_f1: 0.2695 - val_recall: 0.1899 - val_precision: 0.5790\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0692 - binary_accuracy: 0.9784 - f1: 0.4254 - recall: 0.3283 - precision: 0.7162 - val_loss: 0.0922 - val_binary_accuracy: 0.9692 - val_f1: 0.2924 - val_recall: 0.2105 - val_precision: 0.5826\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0685 - binary_accuracy: 0.9786 - f1: 0.4356 - recall: 0.3346 - precision: 0.7302 - val_loss: 0.0913 - val_binary_accuracy: 0.9702 - val_f1: 0.3437 - val_recall: 0.2571 - val_precision: 0.6008\n",
      "Epoch 17/500\n",
      "10s - loss: 0.0677 - binary_accuracy: 0.9790 - f1: 0.4489 - recall: 0.3481 - precision: 0.7392 - val_loss: 0.0933 - val_binary_accuracy: 0.9692 - val_f1: 0.3546 - val_recall: 0.2773 - val_precision: 0.5643\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0670 - binary_accuracy: 0.9790 - f1: 0.4463 - recall: 0.3495 - precision: 0.7168 - val_loss: 0.0964 - val_binary_accuracy: 0.9674 - val_f1: 0.3107 - val_recall: 0.2413 - val_precision: 0.5081\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0658 - binary_accuracy: 0.9795 - f1: 0.4593 - recall: 0.3576 - precision: 0.7388 - val_loss: 0.0956 - val_binary_accuracy: 0.9696 - val_f1: 0.3537 - val_recall: 0.2728 - val_precision: 0.5878\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0652 - binary_accuracy: 0.9798 - f1: 0.4743 - recall: 0.3709 - precision: 0.7492 - val_loss: 0.0984 - val_binary_accuracy: 0.9682 - val_f1: 0.3090 - val_recall: 0.2342 - val_precision: 0.5317\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0647 - binary_accuracy: 0.9799 - f1: 0.4799 - recall: 0.3779 - precision: 0.7675 - val_loss: 0.0954 - val_binary_accuracy: 0.9679 - val_f1: 0.3755 - val_recall: 0.3110 - val_precision: 0.5337\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0635 - binary_accuracy: 0.9804 - f1: 0.4972 - recall: 0.3947 - precision: 0.7672 - val_loss: 0.0984 - val_binary_accuracy: 0.9690 - val_f1: 0.3645 - val_recall: 0.2863 - val_precision: 0.5643\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0630 - binary_accuracy: 0.9806 - f1: 0.5053 - recall: 0.4043 - precision: 0.7663 - val_loss: 0.1008 - val_binary_accuracy: 0.9685 - val_f1: 0.3178 - val_recall: 0.2406 - val_precision: 0.5386\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0623 - binary_accuracy: 0.9808 - f1: 0.5110 - recall: 0.4087 - precision: 0.7768 - val_loss: 0.0959 - val_binary_accuracy: 0.9682 - val_f1: 0.3739 - val_recall: 0.3060 - val_precision: 0.5374\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0614 - binary_accuracy: 0.9809 - f1: 0.5190 - recall: 0.4119 - precision: 0.7896 - val_loss: 0.0969 - val_binary_accuracy: 0.9692 - val_f1: 0.2953 - val_recall: 0.2144 - val_precision: 0.5739\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0608 - binary_accuracy: 0.9812 - f1: 0.5195 - recall: 0.4207 - precision: 0.7774 - val_loss: 0.0991 - val_binary_accuracy: 0.9688 - val_f1: 0.3611 - val_recall: 0.2846 - val_precision: 0.5692\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0601 - binary_accuracy: 0.9814 - f1: 0.5211 - recall: 0.4172 - precision: 0.7825 - val_loss: 0.0999 - val_binary_accuracy: 0.9686 - val_f1: 0.3648 - val_recall: 0.2900 - val_precision: 0.5622\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0591 - binary_accuracy: 0.9819 - f1: 0.5439 - recall: 0.4356 - precision: 0.8115 - val_loss: 0.1028 - val_binary_accuracy: 0.9689 - val_f1: 0.2944 - val_recall: 0.2166 - val_precision: 0.5613\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0586 - binary_accuracy: 0.9820 - f1: 0.5461 - recall: 0.4425 - precision: 0.8117 - val_loss: 0.1013 - val_binary_accuracy: 0.9682 - val_f1: 0.3673 - val_recall: 0.3020 - val_precision: 0.5322\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0578 - binary_accuracy: 0.9822 - f1: 0.5498 - recall: 0.4443 - precision: 0.8140 - val_loss: 0.1044 - val_binary_accuracy: 0.9670 - val_f1: 0.3281 - val_recall: 0.2638 - val_precision: 0.5054\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0575 - binary_accuracy: 0.9823 - f1: 0.5571 - recall: 0.4523 - precision: 0.8136 - val_loss: 0.1059 - val_binary_accuracy: 0.9686 - val_f1: 0.2980 - val_recall: 0.2186 - val_precision: 0.5715\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0565 - binary_accuracy: 0.9827 - f1: 0.5612 - recall: 0.4580 - precision: 0.8063 - val_loss: 0.1073 - val_binary_accuracy: 0.9687 - val_f1: 0.3158 - val_recall: 0.2366 - val_precision: 0.5688\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0560 - binary_accuracy: 0.9827 - f1: 0.5736 - recall: 0.4667 - precision: 0.8270 - val_loss: 0.1054 - val_binary_accuracy: 0.9678 - val_f1: 0.3183 - val_recall: 0.2504 - val_precision: 0.5163\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0552 - binary_accuracy: 0.9827 - f1: 0.5666 - recall: 0.4628 - precision: 0.8110 - val_loss: 0.1087 - val_binary_accuracy: 0.9671 - val_f1: 0.3235 - val_recall: 0.2575 - val_precision: 0.5111\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0547 - binary_accuracy: 0.9829 - f1: 0.5784 - recall: 0.4720 - precision: 0.8234 - val_loss: 0.1099 - val_binary_accuracy: 0.9678 - val_f1: 0.3464 - val_recall: 0.2764 - val_precision: 0.5356\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0546 - binary_accuracy: 0.9831 - f1: 0.5840 - recall: 0.4796 - precision: 0.8303 - val_loss: 0.1131 - val_binary_accuracy: 0.9668 - val_f1: 0.3872 - val_recall: 0.3436 - val_precision: 0.4951\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0538 - binary_accuracy: 0.9834 - f1: 0.5962 - recall: 0.4930 - precision: 0.8344 - val_loss: 0.1116 - val_binary_accuracy: 0.9670 - val_f1: 0.3183 - val_recall: 0.2557 - val_precision: 0.4917\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0529 - binary_accuracy: 0.9836 - f1: 0.5935 - recall: 0.4902 - precision: 0.8310 - val_loss: 0.1123 - val_binary_accuracy: 0.9669 - val_f1: 0.3382 - val_recall: 0.2752 - val_precision: 0.5046\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0525 - binary_accuracy: 0.9835 - f1: 0.5875 - recall: 0.4853 - precision: 0.8254 - val_loss: 0.1172 - val_binary_accuracy: 0.9649 - val_f1: 0.3635 - val_recall: 0.3256 - val_precision: 0.4617\n",
      "Epoch 40/500\n",
      "10s - loss: 0.0515 - binary_accuracy: 0.9840 - f1: 0.6077 - recall: 0.5014 - precision: 0.8408 - val_loss: 0.1246 - val_binary_accuracy: 0.9659 - val_f1: 0.3049 - val_recall: 0.2470 - val_precision: 0.4556\n",
      "Epoch 41/500\n",
      "11s - loss: 0.0511 - binary_accuracy: 0.9841 - f1: 0.6096 - recall: 0.5053 - precision: 0.8442 - val_loss: 0.1093 - val_binary_accuracy: 0.9667 - val_f1: 0.3819 - val_recall: 0.3363 - val_precision: 0.5054\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0506 - binary_accuracy: 0.9842 - f1: 0.6159 - recall: 0.5156 - precision: 0.8456 - val_loss: 0.1131 - val_binary_accuracy: 0.9675 - val_f1: 0.3829 - val_recall: 0.3253 - val_precision: 0.5213\n",
      "Epoch 43/500\n",
      "11s - loss: 0.0501 - binary_accuracy: 0.9842 - f1: 0.6176 - recall: 0.5165 - precision: 0.8444 - val_loss: 0.1112 - val_binary_accuracy: 0.9674 - val_f1: 0.3600 - val_recall: 0.2957 - val_precision: 0.5218\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0489 - binary_accuracy: 0.9846 - f1: 0.6271 - recall: 0.5234 - precision: 0.8564 - val_loss: 0.1202 - val_binary_accuracy: 0.9666 - val_f1: 0.3252 - val_recall: 0.2643 - val_precision: 0.4805\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0488 - binary_accuracy: 0.9846 - f1: 0.6265 - recall: 0.5295 - precision: 0.8404 - val_loss: 0.1154 - val_binary_accuracy: 0.9673 - val_f1: 0.3395 - val_recall: 0.2759 - val_precision: 0.5123\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0479 - binary_accuracy: 0.9848 - f1: 0.6352 - recall: 0.5351 - precision: 0.8562 - val_loss: 0.1183 - val_binary_accuracy: 0.9686 - val_f1: 0.3519 - val_recall: 0.2759 - val_precision: 0.5505\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0475 - binary_accuracy: 0.9850 - f1: 0.6363 - recall: 0.5400 - precision: 0.8493 - val_loss: 0.1205 - val_binary_accuracy: 0.9687 - val_f1: 0.3290 - val_recall: 0.2528 - val_precision: 0.5556\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0471 - binary_accuracy: 0.9850 - f1: 0.6470 - recall: 0.5448 - precision: 0.8634 - val_loss: 0.1299 - val_binary_accuracy: 0.9648 - val_f1: 0.3478 - val_recall: 0.3107 - val_precision: 0.4493\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0460 - binary_accuracy: 0.9854 - f1: 0.6525 - recall: 0.5551 - precision: 0.8597 - val_loss: 0.1244 - val_binary_accuracy: 0.9659 - val_f1: 0.3420 - val_recall: 0.2887 - val_precision: 0.4757\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0460 - binary_accuracy: 0.9854 - f1: 0.6538 - recall: 0.5570 - precision: 0.8578 - val_loss: 0.1233 - val_binary_accuracy: 0.9658 - val_f1: 0.3564 - val_recall: 0.3091 - val_precision: 0.4779\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0448 - binary_accuracy: 0.9857 - f1: 0.6578 - recall: 0.5596 - precision: 0.8610 - val_loss: 0.1332 - val_binary_accuracy: 0.9672 - val_f1: 0.3402 - val_recall: 0.2769 - val_precision: 0.5080\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0444 - binary_accuracy: 0.9859 - f1: 0.6691 - recall: 0.5728 - precision: 0.8694 - val_loss: 0.1280 - val_binary_accuracy: 0.9671 - val_f1: 0.3431 - val_recall: 0.2811 - val_precision: 0.5152\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0436 - binary_accuracy: 0.9861 - f1: 0.6726 - recall: 0.5775 - precision: 0.8693 - val_loss: 0.1232 - val_binary_accuracy: 0.9674 - val_f1: 0.3789 - val_recall: 0.3301 - val_precision: 0.5099\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0429 - binary_accuracy: 0.9862 - f1: 0.6771 - recall: 0.5815 - precision: 0.8718 - val_loss: 0.1332 - val_binary_accuracy: 0.9652 - val_f1: 0.3383 - val_recall: 0.2962 - val_precision: 0.4536\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0423 - binary_accuracy: 0.9866 - f1: 0.6907 - recall: 0.5935 - precision: 0.8830 - val_loss: 0.1292 - val_binary_accuracy: 0.9670 - val_f1: 0.3728 - val_recall: 0.3211 - val_precision: 0.5142\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0420 - binary_accuracy: 0.9864 - f1: 0.6814 - recall: 0.5849 - precision: 0.8753 - val_loss: 0.1398 - val_binary_accuracy: 0.9671 - val_f1: 0.3209 - val_recall: 0.2569 - val_precision: 0.4924\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0411 - binary_accuracy: 0.9868 - f1: 0.6869 - recall: 0.5935 - precision: 0.8719 - val_loss: 0.1327 - val_binary_accuracy: 0.9676 - val_f1: 0.3794 - val_recall: 0.3223 - val_precision: 0.5205\n",
      "37472/37620 [============================>.] - ETA: 0stn = 147502, fp = 282, fn = 1554, tp = 2627\n",
      "y_pred: 0 = 149056 | 1 = 2909\n",
      "y_true: 0 = 147784 | 1 = 4181\n",
      "acc=0.9879|precision=0.9031|recall=0.6283|f1=0.7410|auc=0.9831|aupr=0.8312|pos_acc=0.6283|neg_acc=0.9896\n",
      "tn = 36006, fp = 365, fn = 855, tp = 394\n",
      "y_pred: 0 = 36861 | 1 = 759\n",
      "y_true: 0 = 36371 | 1 = 1249\n",
      "acc=0.9676|precision=0.5191|recall=0.3155|f1=0.3924|auc=0.8770|aupr=0.3519|pos_acc=0.3155|neg_acc=0.9768\n",
      "----------------------- Fold =  4\n",
      "Train on 150480 samples, validate on 39105 samples\n",
      "Epoch 1/500\n",
      "11s - loss: 0.0799 - binary_accuracy: 0.9745 - f1: 0.2764 - recall: 0.2028 - precision: 0.5398 - val_loss: 0.0861 - val_binary_accuracy: 0.9717 - val_f1: 0.3450 - val_recall: 0.2682 - val_precision: 0.5900\n",
      "Epoch 2/500\n",
      "10s - loss: 0.0770 - binary_accuracy: 0.9754 - f1: 0.3292 - recall: 0.2459 - precision: 0.5993 - val_loss: 0.0882 - val_binary_accuracy: 0.9718 - val_f1: 0.3193 - val_recall: 0.2407 - val_precision: 0.5928\n",
      "Epoch 3/500\n",
      "10s - loss: 0.0761 - binary_accuracy: 0.9755 - f1: 0.3381 - recall: 0.2563 - precision: 0.6277 - val_loss: 0.0868 - val_binary_accuracy: 0.9717 - val_f1: 0.2513 - val_recall: 0.1752 - val_precision: 0.5647\n",
      "Epoch 4/500\n",
      "11s - loss: 0.0753 - binary_accuracy: 0.9759 - f1: 0.3508 - recall: 0.2657 - precision: 0.6283 - val_loss: 0.0903 - val_binary_accuracy: 0.9709 - val_f1: 0.1974 - val_recall: 0.1336 - val_precision: 0.4863\n",
      "Epoch 5/500\n",
      "10s - loss: 0.0744 - binary_accuracy: 0.9763 - f1: 0.3667 - recall: 0.2785 - precision: 0.6593 - val_loss: 0.0880 - val_binary_accuracy: 0.9713 - val_f1: 0.3530 - val_recall: 0.2806 - val_precision: 0.5823\n",
      "Epoch 6/500\n",
      "10s - loss: 0.0737 - binary_accuracy: 0.9767 - f1: 0.3711 - recall: 0.2810 - precision: 0.6626 - val_loss: 0.0862 - val_binary_accuracy: 0.9711 - val_f1: 0.3200 - val_recall: 0.2473 - val_precision: 0.5508\n",
      "Epoch 7/500\n",
      "10s - loss: 0.0726 - binary_accuracy: 0.9771 - f1: 0.4012 - recall: 0.3064 - precision: 0.6862 - val_loss: 0.0860 - val_binary_accuracy: 0.9714 - val_f1: 0.3273 - val_recall: 0.2521 - val_precision: 0.5633\n",
      "Epoch 8/500\n",
      "11s - loss: 0.0721 - binary_accuracy: 0.9774 - f1: 0.4071 - recall: 0.3123 - precision: 0.6972 - val_loss: 0.0869 - val_binary_accuracy: 0.9707 - val_f1: 0.3168 - val_recall: 0.2489 - val_precision: 0.5263\n",
      "Epoch 9/500\n",
      "10s - loss: 0.0714 - binary_accuracy: 0.9775 - f1: 0.4049 - recall: 0.3130 - precision: 0.6866 - val_loss: 0.0871 - val_binary_accuracy: 0.9716 - val_f1: 0.2883 - val_recall: 0.2109 - val_precision: 0.5563\n",
      "Epoch 10/500\n",
      "10s - loss: 0.0707 - binary_accuracy: 0.9777 - f1: 0.4251 - recall: 0.3269 - precision: 0.7134 - val_loss: 0.0882 - val_binary_accuracy: 0.9723 - val_f1: 0.3231 - val_recall: 0.2417 - val_precision: 0.6038\n",
      "Epoch 11/500\n",
      "10s - loss: 0.0701 - binary_accuracy: 0.9780 - f1: 0.4298 - recall: 0.3346 - precision: 0.7108 - val_loss: 0.0884 - val_binary_accuracy: 0.9722 - val_f1: 0.3146 - val_recall: 0.2365 - val_precision: 0.5970\n",
      "Epoch 12/500\n",
      "10s - loss: 0.0689 - binary_accuracy: 0.9782 - f1: 0.4368 - recall: 0.3399 - precision: 0.7073 - val_loss: 0.0878 - val_binary_accuracy: 0.9702 - val_f1: 0.3109 - val_recall: 0.2435 - val_precision: 0.5243\n",
      "Epoch 13/500\n",
      "10s - loss: 0.0686 - binary_accuracy: 0.9783 - f1: 0.4413 - recall: 0.3452 - precision: 0.7105 - val_loss: 0.0889 - val_binary_accuracy: 0.9711 - val_f1: 0.2743 - val_recall: 0.1992 - val_precision: 0.5561\n",
      "Epoch 14/500\n",
      "11s - loss: 0.0673 - binary_accuracy: 0.9787 - f1: 0.4476 - recall: 0.3493 - precision: 0.7137 - val_loss: 0.0899 - val_binary_accuracy: 0.9715 - val_f1: 0.2824 - val_recall: 0.2063 - val_precision: 0.5708\n",
      "Epoch 15/500\n",
      "10s - loss: 0.0670 - binary_accuracy: 0.9789 - f1: 0.4619 - recall: 0.3628 - precision: 0.7364 - val_loss: 0.0896 - val_binary_accuracy: 0.9703 - val_f1: 0.3285 - val_recall: 0.2633 - val_precision: 0.5301\n",
      "Epoch 16/500\n",
      "10s - loss: 0.0660 - binary_accuracy: 0.9793 - f1: 0.4724 - recall: 0.3723 - precision: 0.7396 - val_loss: 0.0880 - val_binary_accuracy: 0.9711 - val_f1: 0.3367 - val_recall: 0.2624 - val_precision: 0.5494\n",
      "Epoch 17/500\n",
      "11s - loss: 0.0652 - binary_accuracy: 0.9794 - f1: 0.4812 - recall: 0.3801 - precision: 0.7553 - val_loss: 0.0904 - val_binary_accuracy: 0.9717 - val_f1: 0.2966 - val_recall: 0.2169 - val_precision: 0.5750\n",
      "Epoch 18/500\n",
      "10s - loss: 0.0642 - binary_accuracy: 0.9797 - f1: 0.4850 - recall: 0.3872 - precision: 0.7481 - val_loss: 0.0916 - val_binary_accuracy: 0.9711 - val_f1: 0.3126 - val_recall: 0.2366 - val_precision: 0.5474\n",
      "Epoch 19/500\n",
      "10s - loss: 0.0636 - binary_accuracy: 0.9798 - f1: 0.4925 - recall: 0.3884 - precision: 0.7657 - val_loss: 0.0941 - val_binary_accuracy: 0.9711 - val_f1: 0.3013 - val_recall: 0.2223 - val_precision: 0.5725\n",
      "Epoch 20/500\n",
      "10s - loss: 0.0628 - binary_accuracy: 0.9803 - f1: 0.5077 - recall: 0.4060 - precision: 0.7688 - val_loss: 0.0947 - val_binary_accuracy: 0.9708 - val_f1: 0.2969 - val_recall: 0.2223 - val_precision: 0.5459\n",
      "Epoch 21/500\n",
      "10s - loss: 0.0626 - binary_accuracy: 0.9804 - f1: 0.5126 - recall: 0.4127 - precision: 0.7709 - val_loss: 0.0943 - val_binary_accuracy: 0.9708 - val_f1: 0.3665 - val_recall: 0.3034 - val_precision: 0.5383\n",
      "Epoch 22/500\n",
      "10s - loss: 0.0613 - binary_accuracy: 0.9806 - f1: 0.5152 - recall: 0.4135 - precision: 0.7689 - val_loss: 0.0931 - val_binary_accuracy: 0.9717 - val_f1: 0.2965 - val_recall: 0.2151 - val_precision: 0.5654\n",
      "Epoch 23/500\n",
      "10s - loss: 0.0609 - binary_accuracy: 0.9809 - f1: 0.5280 - recall: 0.4265 - precision: 0.7793 - val_loss: 0.0937 - val_binary_accuracy: 0.9710 - val_f1: 0.2888 - val_recall: 0.2120 - val_precision: 0.5604\n",
      "Epoch 24/500\n",
      "10s - loss: 0.0600 - binary_accuracy: 0.9811 - f1: 0.5326 - recall: 0.4270 - precision: 0.7894 - val_loss: 0.0948 - val_binary_accuracy: 0.9698 - val_f1: 0.3882 - val_recall: 0.3400 - val_precision: 0.5158\n",
      "Epoch 25/500\n",
      "10s - loss: 0.0594 - binary_accuracy: 0.9813 - f1: 0.5460 - recall: 0.4456 - precision: 0.7904 - val_loss: 0.0969 - val_binary_accuracy: 0.9700 - val_f1: 0.3629 - val_recall: 0.3073 - val_precision: 0.5202\n",
      "Epoch 26/500\n",
      "10s - loss: 0.0589 - binary_accuracy: 0.9816 - f1: 0.5515 - recall: 0.4491 - precision: 0.7988 - val_loss: 0.0943 - val_binary_accuracy: 0.9708 - val_f1: 0.3575 - val_recall: 0.2928 - val_precision: 0.5400\n",
      "Epoch 27/500\n",
      "10s - loss: 0.0575 - binary_accuracy: 0.9820 - f1: 0.5522 - recall: 0.4487 - precision: 0.7972 - val_loss: 0.0915 - val_binary_accuracy: 0.9707 - val_f1: 0.2967 - val_recall: 0.2213 - val_precision: 0.5320\n",
      "Epoch 28/500\n",
      "10s - loss: 0.0576 - binary_accuracy: 0.9818 - f1: 0.5628 - recall: 0.4608 - precision: 0.8080 - val_loss: 0.0933 - val_binary_accuracy: 0.9710 - val_f1: 0.3277 - val_recall: 0.2505 - val_precision: 0.5516\n",
      "Epoch 29/500\n",
      "10s - loss: 0.0568 - binary_accuracy: 0.9822 - f1: 0.5661 - recall: 0.4622 - precision: 0.8070 - val_loss: 0.0996 - val_binary_accuracy: 0.9685 - val_f1: 0.3463 - val_recall: 0.2936 - val_precision: 0.4844\n",
      "Epoch 30/500\n",
      "10s - loss: 0.0565 - binary_accuracy: 0.9822 - f1: 0.5720 - recall: 0.4721 - precision: 0.7991 - val_loss: 0.0993 - val_binary_accuracy: 0.9710 - val_f1: 0.3755 - val_recall: 0.3121 - val_precision: 0.5520\n",
      "Epoch 31/500\n",
      "10s - loss: 0.0552 - binary_accuracy: 0.9827 - f1: 0.5810 - recall: 0.4783 - precision: 0.8187 - val_loss: 0.1040 - val_binary_accuracy: 0.9698 - val_f1: 0.3548 - val_recall: 0.2919 - val_precision: 0.5200\n",
      "Epoch 32/500\n",
      "10s - loss: 0.0547 - binary_accuracy: 0.9830 - f1: 0.5946 - recall: 0.4929 - precision: 0.8232 - val_loss: 0.0994 - val_binary_accuracy: 0.9702 - val_f1: 0.3568 - val_recall: 0.2971 - val_precision: 0.5113\n",
      "Epoch 33/500\n",
      "10s - loss: 0.0540 - binary_accuracy: 0.9831 - f1: 0.5985 - recall: 0.4986 - precision: 0.8196 - val_loss: 0.1001 - val_binary_accuracy: 0.9689 - val_f1: 0.3589 - val_recall: 0.3095 - val_precision: 0.4790\n",
      "Epoch 34/500\n",
      "10s - loss: 0.0531 - binary_accuracy: 0.9832 - f1: 0.6028 - recall: 0.5006 - precision: 0.8346 - val_loss: 0.1004 - val_binary_accuracy: 0.9703 - val_f1: 0.3671 - val_recall: 0.3117 - val_precision: 0.5254\n",
      "Epoch 35/500\n",
      "10s - loss: 0.0527 - binary_accuracy: 0.9833 - f1: 0.5989 - recall: 0.4994 - precision: 0.8210 - val_loss: 0.1034 - val_binary_accuracy: 0.9685 - val_f1: 0.3476 - val_recall: 0.2968 - val_precision: 0.4810\n",
      "Epoch 36/500\n",
      "10s - loss: 0.0520 - binary_accuracy: 0.9835 - f1: 0.6095 - recall: 0.5114 - precision: 0.8275 - val_loss: 0.1050 - val_binary_accuracy: 0.9703 - val_f1: 0.3686 - val_recall: 0.3094 - val_precision: 0.5221\n",
      "Epoch 37/500\n",
      "10s - loss: 0.0513 - binary_accuracy: 0.9839 - f1: 0.6197 - recall: 0.5216 - precision: 0.8330 - val_loss: 0.1022 - val_binary_accuracy: 0.9695 - val_f1: 0.2939 - val_recall: 0.2279 - val_precision: 0.4878\n",
      "Epoch 38/500\n",
      "10s - loss: 0.0507 - binary_accuracy: 0.9842 - f1: 0.6250 - recall: 0.5301 - precision: 0.8283 - val_loss: 0.1052 - val_binary_accuracy: 0.9695 - val_f1: 0.3209 - val_recall: 0.2589 - val_precision: 0.4858\n",
      "Epoch 39/500\n",
      "10s - loss: 0.0497 - binary_accuracy: 0.9842 - f1: 0.6267 - recall: 0.5310 - precision: 0.8392 - val_loss: 0.1069 - val_binary_accuracy: 0.9693 - val_f1: 0.3425 - val_recall: 0.2826 - val_precision: 0.4988\n",
      "Epoch 40/500\n",
      "11s - loss: 0.0489 - binary_accuracy: 0.9845 - f1: 0.6412 - recall: 0.5481 - precision: 0.8435 - val_loss: 0.1084 - val_binary_accuracy: 0.9690 - val_f1: 0.3394 - val_recall: 0.2779 - val_precision: 0.5003\n",
      "Epoch 41/500\n",
      "10s - loss: 0.0484 - binary_accuracy: 0.9847 - f1: 0.6483 - recall: 0.5524 - precision: 0.8450 - val_loss: 0.1137 - val_binary_accuracy: 0.9694 - val_f1: 0.3644 - val_recall: 0.3090 - val_precision: 0.5103\n",
      "Epoch 42/500\n",
      "10s - loss: 0.0477 - binary_accuracy: 0.9850 - f1: 0.6458 - recall: 0.5489 - precision: 0.8493 - val_loss: 0.1133 - val_binary_accuracy: 0.9682 - val_f1: 0.3136 - val_recall: 0.2611 - val_precision: 0.4677\n",
      "Epoch 43/500\n",
      "10s - loss: 0.0474 - binary_accuracy: 0.9851 - f1: 0.6585 - recall: 0.5649 - precision: 0.8511 - val_loss: 0.1079 - val_binary_accuracy: 0.9696 - val_f1: 0.3294 - val_recall: 0.2647 - val_precision: 0.5083\n",
      "Epoch 44/500\n",
      "10s - loss: 0.0467 - binary_accuracy: 0.9853 - f1: 0.6682 - recall: 0.5754 - precision: 0.8549 - val_loss: 0.1177 - val_binary_accuracy: 0.9680 - val_f1: 0.3639 - val_recall: 0.3245 - val_precision: 0.4753\n",
      "Epoch 45/500\n",
      "10s - loss: 0.0459 - binary_accuracy: 0.9851 - f1: 0.6591 - recall: 0.5659 - precision: 0.8516 - val_loss: 0.1114 - val_binary_accuracy: 0.9672 - val_f1: 0.3605 - val_recall: 0.3231 - val_precision: 0.4598\n",
      "Epoch 46/500\n",
      "10s - loss: 0.0451 - binary_accuracy: 0.9857 - f1: 0.6723 - recall: 0.5779 - precision: 0.8601 - val_loss: 0.1191 - val_binary_accuracy: 0.9685 - val_f1: 0.3162 - val_recall: 0.2622 - val_precision: 0.4585\n",
      "Epoch 47/500\n",
      "10s - loss: 0.0448 - binary_accuracy: 0.9858 - f1: 0.6732 - recall: 0.5810 - precision: 0.8622 - val_loss: 0.1149 - val_binary_accuracy: 0.9679 - val_f1: 0.3325 - val_recall: 0.2860 - val_precision: 0.4561\n",
      "Epoch 48/500\n",
      "10s - loss: 0.0438 - binary_accuracy: 0.9862 - f1: 0.6862 - recall: 0.5962 - precision: 0.8624 - val_loss: 0.1227 - val_binary_accuracy: 0.9694 - val_f1: 0.2838 - val_recall: 0.2164 - val_precision: 0.4843\n",
      "Epoch 49/500\n",
      "10s - loss: 0.0435 - binary_accuracy: 0.9862 - f1: 0.6905 - recall: 0.5979 - precision: 0.8763 - val_loss: 0.1129 - val_binary_accuracy: 0.9661 - val_f1: 0.3404 - val_recall: 0.3050 - val_precision: 0.4290\n",
      "Epoch 50/500\n",
      "10s - loss: 0.0425 - binary_accuracy: 0.9865 - f1: 0.6939 - recall: 0.6044 - precision: 0.8663 - val_loss: 0.1185 - val_binary_accuracy: 0.9681 - val_f1: 0.3388 - val_recall: 0.2909 - val_precision: 0.4683\n",
      "Epoch 51/500\n",
      "10s - loss: 0.0422 - binary_accuracy: 0.9868 - f1: 0.7004 - recall: 0.6153 - precision: 0.8706 - val_loss: 0.1338 - val_binary_accuracy: 0.9682 - val_f1: 0.3621 - val_recall: 0.3160 - val_precision: 0.4837\n",
      "Epoch 52/500\n",
      "10s - loss: 0.0416 - binary_accuracy: 0.9868 - f1: 0.6972 - recall: 0.6092 - precision: 0.8726 - val_loss: 0.1271 - val_binary_accuracy: 0.9694 - val_f1: 0.3602 - val_recall: 0.3069 - val_precision: 0.4957\n",
      "Epoch 53/500\n",
      "10s - loss: 0.0409 - binary_accuracy: 0.9870 - f1: 0.7110 - recall: 0.6248 - precision: 0.8813 - val_loss: 0.1333 - val_binary_accuracy: 0.9684 - val_f1: 0.3106 - val_recall: 0.2530 - val_precision: 0.4681\n",
      "Epoch 54/500\n",
      "10s - loss: 0.0400 - binary_accuracy: 0.9875 - f1: 0.7197 - recall: 0.6318 - precision: 0.8853 - val_loss: 0.1295 - val_binary_accuracy: 0.9662 - val_f1: 0.3237 - val_recall: 0.2825 - val_precision: 0.4332\n",
      "Epoch 55/500\n",
      "10s - loss: 0.0396 - binary_accuracy: 0.9873 - f1: 0.7081 - recall: 0.6251 - precision: 0.8695 - val_loss: 0.1328 - val_binary_accuracy: 0.9678 - val_f1: 0.3529 - val_recall: 0.3128 - val_precision: 0.4527\n",
      "Epoch 56/500\n",
      "10s - loss: 0.0388 - binary_accuracy: 0.9873 - f1: 0.7189 - recall: 0.6378 - precision: 0.8727 - val_loss: 0.1303 - val_binary_accuracy: 0.9673 - val_f1: 0.3513 - val_recall: 0.3156 - val_precision: 0.4478\n",
      "Epoch 57/500\n",
      "10s - loss: 0.0377 - binary_accuracy: 0.9877 - f1: 0.7238 - recall: 0.6423 - precision: 0.8783 - val_loss: 0.1334 - val_binary_accuracy: 0.9668 - val_f1: 0.3720 - val_recall: 0.3463 - val_precision: 0.4542\n",
      "Epoch 58/500\n",
      "10s - loss: 0.0377 - binary_accuracy: 0.9879 - f1: 0.7317 - recall: 0.6567 - precision: 0.8755 - val_loss: 0.1372 - val_binary_accuracy: 0.9674 - val_f1: 0.3322 - val_recall: 0.2854 - val_precision: 0.4467\n",
      "38944/39105 [============================>.] - ETA: 0stn = 145831, fp = 434, fn = 1474, tp = 2741\n",
      "y_pred: 0 = 147305 | 1 = 3175\n",
      "y_true: 0 = 146265 | 1 = 4215\n",
      "acc=0.9873|precision=0.8633|recall=0.6503|f1=0.7418|auc=0.9829|aupr=0.8245|pos_acc=0.6503|neg_acc=0.9900\n",
      "tn = 37482, fp = 408, fn = 866, tp = 349\n",
      "y_pred: 0 = 38348 | 1 = 757\n",
      "y_true: 0 = 37890 | 1 = 1215\n",
      "acc=0.9674|precision=0.4610|recall=0.2872|f1=0.3540|auc=0.8565|aupr=0.2894|pos_acc=0.2872|neg_acc=0.9774\n"
     ]
    }
   ],
   "source": [
    "directory = 'data'\n",
    "for isbalance in [True, False]:\n",
    "    \n",
    "    ID, IM, dtp, mirna_ids, disease_ids, mirna_test_num, disease_test_num, samples = obtain_data(directory, \n",
    "                                                                                                 isbalance)\n",
    "    for task in ['Tp', 'Tm', 'Td']:\n",
    "        \n",
    "        print('========== isbalance = {} | task = {}'.format(isbalance, task))\n",
    "        \n",
    "        if task == 'Tp':\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tp_train_test_idx(samples)\n",
    "            \n",
    "        elif task == 'Tm':\n",
    "            item = 'miRNA'\n",
    "            ids = mirna_ids\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tm_Td_train_test_idx(item, ids, dtp)\n",
    "\n",
    "        elif task == 'Td':\n",
    "            item = 'disease'\n",
    "            ids = disease_ids\n",
    "            train_index_all, test_index_all, train_id_all, test_id_all = generate_task_Tm_Td_train_test_idx(item, ids, dtp)\n",
    "\n",
    "        y_train_pred, y_test_pred, y_train_prob, y_test_prob, performances_train, performances_test = run_dnn(train_index_all, test_index_all, samples)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
